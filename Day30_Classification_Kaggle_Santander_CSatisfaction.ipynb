{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJ2LJedsASgcITQ5LnukSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greensky0107/self_study/blob/main/Day30_Classification_Kaggle_Santander_CSatisfaction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step1. Library 불러오기\n",
        "\n",
        "# Pandas 불러오기\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Numpy 불러오기\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib 불러오기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seaborn 불러오기\n",
        "import seaborn as sns\n",
        "\n",
        "# 데이터 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 모델 불러오기\n",
        "# 의사결정나무\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# 랜덤포레스트\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 평가\n",
        "# accuracy (정확도)\n",
        "from sklearn.metrics import accuracy_score\n",
        "# precision (정밀도)\n",
        "from sklearn.metrics import precision_score\n",
        "# recall (재현율)\n",
        "from sklearn.metrics import recall_score\n",
        "# f1\n",
        "from sklearn.metrics import f1_score\n",
        "# roc auc\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "oeOYMpI-MXQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step2 Dataset 가져와서 확인및 전처리  (colab/content/kaggle_santander_customer_satisfaction/train.csv로 저장. 경로복사함)\n",
        "\n",
        "cust_df = pd.read_csv(\"/content/kaggle_santander_customer_satisfaction/train.csv\")\n",
        "print('dataset shape:', cust_df.shape)\n",
        "cust_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5tSP8OdoTnu_",
        "outputId": "b6c4daf1-86b6-41dd-906e-034fd157f94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset shape: (76020, 371)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
              "0   1     2     23                 0.0                      0.0   \n",
              "1   3     2     34                 0.0                      0.0   \n",
              "2   4     2     23                 0.0                      0.0   \n",
              "\n",
              "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
              "0                      0.0                      0.0                      0.0   \n",
              "1                      0.0                      0.0                      0.0   \n",
              "2                      0.0                      0.0                      0.0   \n",
              "\n",
              "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
              "0                      0.0                      0.0  ...   \n",
              "1                      0.0                      0.0  ...   \n",
              "2                      0.0                      0.0  ...   \n",
              "\n",
              "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
              "0                      0.0                      0.0                     0.0   \n",
              "1                      0.0                      0.0                     0.0   \n",
              "2                      0.0                      0.0                     0.0   \n",
              "\n",
              "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
              "0                     0.0                      0.0                      0.0   \n",
              "1                     0.0                      0.0                      0.0   \n",
              "2                     0.0                      0.0                      0.0   \n",
              "\n",
              "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
              "0                     0.0                     0.0  39205.17       0  \n",
              "1                     0.0                     0.0  49278.03       0  \n",
              "2                     0.0                     0.0  67333.77       0  \n",
              "\n",
              "[3 rows x 371 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac2f389a-88cc-4187-ba61-257f263b79e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39205.17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49278.03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67333.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 371 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac2f389a-88cc-4187-ba61-257f263b79e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac2f389a-88cc-4187-ba61-257f263b79e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac2f389a-88cc-4187-ba61-257f263b79e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6c4541ab-c0c9-443d-a9a3-cc2f10e2cba7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c4541ab-c0c9-443d-a9a3-cc2f10e2cba7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6c4541ab-c0c9-443d-a9a3-cc2f10e2cba7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cust_df"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 Dataset 가져와서 확인및 전처리 (111 실수,  260 정수, null 없음)\n",
        "\n",
        "cust_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIF8Ac2_UapO",
        "outputId": "6147ee68-756e-441f-d465-b312c8e15a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 76020 entries, 0 to 76019\n",
            "Columns: 371 entries, ID to TARGET\n",
            "dtypes: float64(111), int64(260)\n",
            "memory usage: 215.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 Dataset 가져와서 확인및 전처리 (Target의 값 분포 알아보기.  unsatisfied(=1) 비율은 4%)\n",
        "\n",
        "print(cust_df['TARGET'].value_counts())\n",
        "unsatisfied_cnt = cust_df[cust_df['TARGET'] == 1].TARGET.count()\n",
        "total_cnt = cust_df.TARGET.count()\n",
        "print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgeruNQ7VHxk",
        "outputId": "4b2cfd7f-4640-4f1d-8d8e-f49864261e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET\n",
            "0    73012\n",
            "1     3008\n",
            "Name: count, dtype: int64\n",
            "unsatisfied 비율은 0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 Dataset 가져와서 확인및 전처리 (Feature(column)의 값 분포 확인 :  var3의 min이 이상.)\n",
        "\n",
        "cust_df.describe( )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "fCzZ-DyHVlyD",
        "outputId": "d6eba483-9372-44e2-e4ef-faaefa68b567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
              "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
              "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
              "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
              "min         1.000000 -999999.000000      5.000000            0.000000   \n",
              "25%     38104.750000       2.000000     23.000000            0.000000   \n",
              "50%     76043.000000       2.000000     28.000000            0.000000   \n",
              "75%    113748.750000       2.000000     40.000000            0.000000   \n",
              "max    151838.000000     238.000000    105.000000       210000.000000   \n",
              "\n",
              "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                 72.363067               119.529632   \n",
              "std                 339.315831               546.266294   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max               12888.030000             21024.810000   \n",
              "\n",
              "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                  3.559130                 6.472698   \n",
              "std                  93.155749               153.737066   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max                8237.820000             11073.570000   \n",
              "\n",
              "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
              "count             76020.000000             76020.000000  ...   \n",
              "mean                  0.412946                 0.567352  ...   \n",
              "std                  30.604864                36.513513  ...   \n",
              "min                   0.000000                 0.000000  ...   \n",
              "25%                   0.000000                 0.000000  ...   \n",
              "50%                   0.000000                 0.000000  ...   \n",
              "75%                   0.000000                 0.000000  ...   \n",
              "max                6600.000000              6600.000000  ...   \n",
              "\n",
              "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                  7.935824                 1.365146   \n",
              "std                 455.887218               113.959637   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max               50003.880000             20385.720000   \n",
              "\n",
              "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
              "count            76020.000000            76020.000000   \n",
              "mean                12.215580                8.784074   \n",
              "std                783.207399              538.439211   \n",
              "min                  0.000000                0.000000   \n",
              "25%                  0.000000                0.000000   \n",
              "50%                  0.000000                0.000000   \n",
              "75%                  0.000000                0.000000   \n",
              "max             138831.630000            91778.730000   \n",
              "\n",
              "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                 31.505324                 1.858575   \n",
              "std                2013.125393               147.786584   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max              438329.220000             24650.010000   \n",
              "\n",
              "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
              "count            76020.000000            76020.000000  7.602000e+04   \n",
              "mean                76.026165               56.614351  1.172358e+05   \n",
              "std               4040.337842             2852.579397  1.826646e+05   \n",
              "min                  0.000000                0.000000  5.163750e+03   \n",
              "25%                  0.000000                0.000000  6.787061e+04   \n",
              "50%                  0.000000                0.000000  1.064092e+05   \n",
              "75%                  0.000000                0.000000  1.187563e+05   \n",
              "max             681462.900000           397884.300000  2.203474e+07   \n",
              "\n",
              "             TARGET  \n",
              "count  76020.000000  \n",
              "mean       0.039569  \n",
              "std        0.194945  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        0.000000  \n",
              "max        1.000000  \n",
              "\n",
              "[8 rows x 371 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3169907-c0ca-4249-8bb2-9f1f002d63fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>7.602000e+04</td>\n",
              "      <td>76020.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>75964.050723</td>\n",
              "      <td>-1523.199277</td>\n",
              "      <td>33.212865</td>\n",
              "      <td>86.208265</td>\n",
              "      <td>72.363067</td>\n",
              "      <td>119.529632</td>\n",
              "      <td>3.559130</td>\n",
              "      <td>6.472698</td>\n",
              "      <td>0.412946</td>\n",
              "      <td>0.567352</td>\n",
              "      <td>...</td>\n",
              "      <td>7.935824</td>\n",
              "      <td>1.365146</td>\n",
              "      <td>12.215580</td>\n",
              "      <td>8.784074</td>\n",
              "      <td>31.505324</td>\n",
              "      <td>1.858575</td>\n",
              "      <td>76.026165</td>\n",
              "      <td>56.614351</td>\n",
              "      <td>1.172358e+05</td>\n",
              "      <td>0.039569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>43781.947379</td>\n",
              "      <td>39033.462364</td>\n",
              "      <td>12.956486</td>\n",
              "      <td>1614.757313</td>\n",
              "      <td>339.315831</td>\n",
              "      <td>546.266294</td>\n",
              "      <td>93.155749</td>\n",
              "      <td>153.737066</td>\n",
              "      <td>30.604864</td>\n",
              "      <td>36.513513</td>\n",
              "      <td>...</td>\n",
              "      <td>455.887218</td>\n",
              "      <td>113.959637</td>\n",
              "      <td>783.207399</td>\n",
              "      <td>538.439211</td>\n",
              "      <td>2013.125393</td>\n",
              "      <td>147.786584</td>\n",
              "      <td>4040.337842</td>\n",
              "      <td>2852.579397</td>\n",
              "      <td>1.826646e+05</td>\n",
              "      <td>0.194945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-999999.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.163750e+03</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>38104.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.787061e+04</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>76043.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.064092e+05</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>113748.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.187563e+05</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>151838.000000</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>210000.000000</td>\n",
              "      <td>12888.030000</td>\n",
              "      <td>21024.810000</td>\n",
              "      <td>8237.820000</td>\n",
              "      <td>11073.570000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>50003.880000</td>\n",
              "      <td>20385.720000</td>\n",
              "      <td>138831.630000</td>\n",
              "      <td>91778.730000</td>\n",
              "      <td>438329.220000</td>\n",
              "      <td>24650.010000</td>\n",
              "      <td>681462.900000</td>\n",
              "      <td>397884.300000</td>\n",
              "      <td>2.203474e+07</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 371 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3169907-c0ca-4249-8bb2-9f1f002d63fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3169907-c0ca-4249-8bb2-9f1f002d63fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3169907-c0ca-4249-8bb2-9f1f002d63fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b9751ab1-c051-41a9-a831-16f5c4dedc6d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9751ab1-c051-41a9-a831-16f5c4dedc6d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b9751ab1-c051-41a9-a831-16f5c4dedc6d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 Dataset 가져와서 확인및 전처리 (var3의 min 을 count해봐서 가장 많은 값이 무엇인지 확인)\n",
        "\n",
        "cust_df['var3'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "TJmwkV0GWT_i",
        "outputId": "0fd06002-51dc-45b4-8e30-ca4b9ee322f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "var3\n",
              " 2         74165\n",
              " 8           138\n",
              "-999999      116\n",
              " 9           110\n",
              " 3           108\n",
              "           ...  \n",
              " 63            1\n",
              " 194           1\n",
              " 40            1\n",
              " 57            1\n",
              " 87            1\n",
              "Name: count, Length: 208, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>var3</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>74165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-999999</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 Dataset 가져와서 확인및 전처리 (var3의 min 을 count해봐서 가장 많은 값이 무엇인지 확인)\n",
        "\n",
        "# var3 피처 값 대체 및 ID 피처 드롭\n",
        "cust_df['var3'].replace(-999999, 2, inplace=True)\n",
        "cust_df.drop('ID', axis=1, inplace=True)\n",
        "\n",
        "# 피처 세트와 레이블 세트분리. 레이블 컬럼은 DataFrame의 맨 마지막에 위치해 컬럼 위치 -1로 분리\n",
        "# 이거 왜할까?\n",
        "X_features = cust_df.iloc[:, :-1]\n",
        "y_labels = cust_df.iloc[:, -1]\n",
        "print('피처 데이터 shape:{0}'.format(X_features.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2QUZmo-WpPG",
        "outputId": "328e60f1-769b-4509-f34d-add2f6d3cccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "피처 데이터 shape:(76020, 369)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3 Dataset을 train vs. test로 분리\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels,\n",
        "                                                    test_size=0.2, random_state=0)\n",
        "train_cnt = y_train.count()\n",
        "test_cnt = y_test.count()\n",
        "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))\n",
        "\n",
        "print(' 학습 세트 레이블 값 분포 비율')\n",
        "print(y_train.value_counts()/train_cnt)\n",
        "print('\\n 테스트 세트 레이블 값 분포 비율')\n",
        "print(y_test.value_counts()/test_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGK2vgNbbVRn",
        "outputId": "82ddf7e3-6d82-4e9f-e603-a0af23cb34d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 세트 Shape:(60816, 369), 테스트 세트 Shape:(15204, 369)\n",
            " 학습 세트 레이블 값 분포 비율\n",
            "TARGET\n",
            "0    0.960964\n",
            "1    0.039036\n",
            "Name: count, dtype: float64\n",
            "\n",
            " 테스트 세트 레이블 값 분포 비율\n",
            "TARGET\n",
            "0    0.9583\n",
            "1    0.0417\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3 Dataset을 train vs. test로 분리\n",
        "\n",
        "# X_train, y_train을 다시 학습과 검증 데이터 세트로 분리.\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train,\n",
        "                                                    test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "aJWQ0C9Jc1Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[XGBoost Model - Evaluation with ROC&AUC]"
      ],
      "metadata": {
        "id": "rkR4q2BphrNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step4 Model을 XGBoost 정해서 학습하고 ROC AUC로 평가하기\n",
        "\n",
        "# n_estimators는 500으로, learning_rate 0.05, random state는 예제 수행 시마다 동일 예측 결과를 위해 설정.\n",
        "# early_stopping_rounds is moved to the XGBClassifier constructor.\n",
        "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=0, early_stopping_rounds=100)\n",
        "# eval_metric is specified within eval_set\n",
        "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
        "\n",
        "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
        "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))\n",
        "\n",
        "# train:test=80:20, n_nestimators=500, learning_rate=0.05, random_state=0 => ROC AUC 0.8446"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNNS-kpufwDP",
        "outputId": "2f01b882-c323-4d8c-d2c8-fbd496ab8b10"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.21359\tvalidation_1-logloss:0.21326\n",
            "[1]\tvalidation_0-logloss:0.20852\tvalidation_1-logloss:0.20840\n",
            "[2]\tvalidation_0-logloss:0.20378\tvalidation_1-logloss:0.20385\n",
            "[3]\tvalidation_0-logloss:0.19928\tvalidation_1-logloss:0.19957\n",
            "[4]\tvalidation_0-logloss:0.19507\tvalidation_1-logloss:0.19556\n",
            "[5]\tvalidation_0-logloss:0.19110\tvalidation_1-logloss:0.19182\n",
            "[6]\tvalidation_0-logloss:0.18737\tvalidation_1-logloss:0.18827\n",
            "[7]\tvalidation_0-logloss:0.18388\tvalidation_1-logloss:0.18495\n",
            "[8]\tvalidation_0-logloss:0.18059\tvalidation_1-logloss:0.18178\n",
            "[9]\tvalidation_0-logloss:0.17747\tvalidation_1-logloss:0.17885\n",
            "[10]\tvalidation_0-logloss:0.17455\tvalidation_1-logloss:0.17607\n",
            "[11]\tvalidation_0-logloss:0.17179\tvalidation_1-logloss:0.17345\n",
            "[12]\tvalidation_0-logloss:0.16916\tvalidation_1-logloss:0.17101\n",
            "[13]\tvalidation_0-logloss:0.16670\tvalidation_1-logloss:0.16869\n",
            "[14]\tvalidation_0-logloss:0.16437\tvalidation_1-logloss:0.16652\n",
            "[15]\tvalidation_0-logloss:0.16215\tvalidation_1-logloss:0.16449\n",
            "[16]\tvalidation_0-logloss:0.16007\tvalidation_1-logloss:0.16259\n",
            "[17]\tvalidation_0-logloss:0.15809\tvalidation_1-logloss:0.16081\n",
            "[18]\tvalidation_0-logloss:0.15625\tvalidation_1-logloss:0.15914\n",
            "[19]\tvalidation_0-logloss:0.15449\tvalidation_1-logloss:0.15755\n",
            "[20]\tvalidation_0-logloss:0.15281\tvalidation_1-logloss:0.15608\n",
            "[21]\tvalidation_0-logloss:0.15127\tvalidation_1-logloss:0.15466\n",
            "[22]\tvalidation_0-logloss:0.14981\tvalidation_1-logloss:0.15336\n",
            "[23]\tvalidation_0-logloss:0.14842\tvalidation_1-logloss:0.15209\n",
            "[24]\tvalidation_0-logloss:0.14711\tvalidation_1-logloss:0.15093\n",
            "[25]\tvalidation_0-logloss:0.14582\tvalidation_1-logloss:0.14981\n",
            "[26]\tvalidation_0-logloss:0.14462\tvalidation_1-logloss:0.14875\n",
            "[27]\tvalidation_0-logloss:0.14348\tvalidation_1-logloss:0.14779\n",
            "[28]\tvalidation_0-logloss:0.14239\tvalidation_1-logloss:0.14685\n",
            "[29]\tvalidation_0-logloss:0.14138\tvalidation_1-logloss:0.14598\n",
            "[30]\tvalidation_0-logloss:0.14040\tvalidation_1-logloss:0.14518\n",
            "[31]\tvalidation_0-logloss:0.13949\tvalidation_1-logloss:0.14442\n",
            "[32]\tvalidation_0-logloss:0.13860\tvalidation_1-logloss:0.14371\n",
            "[33]\tvalidation_0-logloss:0.13776\tvalidation_1-logloss:0.14306\n",
            "[34]\tvalidation_0-logloss:0.13697\tvalidation_1-logloss:0.14240\n",
            "[35]\tvalidation_0-logloss:0.13622\tvalidation_1-logloss:0.14181\n",
            "[36]\tvalidation_0-logloss:0.13551\tvalidation_1-logloss:0.14128\n",
            "[37]\tvalidation_0-logloss:0.13482\tvalidation_1-logloss:0.14073\n",
            "[38]\tvalidation_0-logloss:0.13417\tvalidation_1-logloss:0.14022\n",
            "[39]\tvalidation_0-logloss:0.13356\tvalidation_1-logloss:0.13975\n",
            "[40]\tvalidation_0-logloss:0.13292\tvalidation_1-logloss:0.13931\n",
            "[41]\tvalidation_0-logloss:0.13234\tvalidation_1-logloss:0.13890\n",
            "[42]\tvalidation_0-logloss:0.13179\tvalidation_1-logloss:0.13852\n",
            "[43]\tvalidation_0-logloss:0.13127\tvalidation_1-logloss:0.13818\n",
            "[44]\tvalidation_0-logloss:0.13077\tvalidation_1-logloss:0.13783\n",
            "[45]\tvalidation_0-logloss:0.13030\tvalidation_1-logloss:0.13754\n",
            "[46]\tvalidation_0-logloss:0.12985\tvalidation_1-logloss:0.13723\n",
            "[47]\tvalidation_0-logloss:0.12944\tvalidation_1-logloss:0.13695\n",
            "[48]\tvalidation_0-logloss:0.12903\tvalidation_1-logloss:0.13669\n",
            "[49]\tvalidation_0-logloss:0.12865\tvalidation_1-logloss:0.13643\n",
            "[50]\tvalidation_0-logloss:0.12830\tvalidation_1-logloss:0.13619\n",
            "[51]\tvalidation_0-logloss:0.12795\tvalidation_1-logloss:0.13599\n",
            "[52]\tvalidation_0-logloss:0.12761\tvalidation_1-logloss:0.13582\n",
            "[53]\tvalidation_0-logloss:0.12724\tvalidation_1-logloss:0.13565\n",
            "[54]\tvalidation_0-logloss:0.12694\tvalidation_1-logloss:0.13546\n",
            "[55]\tvalidation_0-logloss:0.12662\tvalidation_1-logloss:0.13530\n",
            "[56]\tvalidation_0-logloss:0.12625\tvalidation_1-logloss:0.13518\n",
            "[57]\tvalidation_0-logloss:0.12598\tvalidation_1-logloss:0.13503\n",
            "[58]\tvalidation_0-logloss:0.12569\tvalidation_1-logloss:0.13491\n",
            "[59]\tvalidation_0-logloss:0.12542\tvalidation_1-logloss:0.13482\n",
            "[60]\tvalidation_0-logloss:0.12516\tvalidation_1-logloss:0.13470\n",
            "[61]\tvalidation_0-logloss:0.12490\tvalidation_1-logloss:0.13457\n",
            "[62]\tvalidation_0-logloss:0.12465\tvalidation_1-logloss:0.13447\n",
            "[63]\tvalidation_0-logloss:0.12444\tvalidation_1-logloss:0.13435\n",
            "[64]\tvalidation_0-logloss:0.12425\tvalidation_1-logloss:0.13426\n",
            "[65]\tvalidation_0-logloss:0.12406\tvalidation_1-logloss:0.13416\n",
            "[66]\tvalidation_0-logloss:0.12387\tvalidation_1-logloss:0.13407\n",
            "[67]\tvalidation_0-logloss:0.12369\tvalidation_1-logloss:0.13399\n",
            "[68]\tvalidation_0-logloss:0.12350\tvalidation_1-logloss:0.13393\n",
            "[69]\tvalidation_0-logloss:0.12331\tvalidation_1-logloss:0.13386\n",
            "[70]\tvalidation_0-logloss:0.12318\tvalidation_1-logloss:0.13380\n",
            "[71]\tvalidation_0-logloss:0.12303\tvalidation_1-logloss:0.13373\n",
            "[72]\tvalidation_0-logloss:0.12290\tvalidation_1-logloss:0.13368\n",
            "[73]\tvalidation_0-logloss:0.12275\tvalidation_1-logloss:0.13365\n",
            "[74]\tvalidation_0-logloss:0.12260\tvalidation_1-logloss:0.13361\n",
            "[75]\tvalidation_0-logloss:0.12249\tvalidation_1-logloss:0.13357\n",
            "[76]\tvalidation_0-logloss:0.12233\tvalidation_1-logloss:0.13351\n",
            "[77]\tvalidation_0-logloss:0.12218\tvalidation_1-logloss:0.13350\n",
            "[78]\tvalidation_0-logloss:0.12209\tvalidation_1-logloss:0.13348\n",
            "[79]\tvalidation_0-logloss:0.12197\tvalidation_1-logloss:0.13344\n",
            "[80]\tvalidation_0-logloss:0.12189\tvalidation_1-logloss:0.13341\n",
            "[81]\tvalidation_0-logloss:0.12177\tvalidation_1-logloss:0.13339\n",
            "[82]\tvalidation_0-logloss:0.12167\tvalidation_1-logloss:0.13336\n",
            "[83]\tvalidation_0-logloss:0.12157\tvalidation_1-logloss:0.13335\n",
            "[84]\tvalidation_0-logloss:0.12147\tvalidation_1-logloss:0.13333\n",
            "[85]\tvalidation_0-logloss:0.12141\tvalidation_1-logloss:0.13331\n",
            "[86]\tvalidation_0-logloss:0.12130\tvalidation_1-logloss:0.13332\n",
            "[87]\tvalidation_0-logloss:0.12115\tvalidation_1-logloss:0.13327\n",
            "[88]\tvalidation_0-logloss:0.12108\tvalidation_1-logloss:0.13325\n",
            "[89]\tvalidation_0-logloss:0.12096\tvalidation_1-logloss:0.13324\n",
            "[90]\tvalidation_0-logloss:0.12084\tvalidation_1-logloss:0.13324\n",
            "[91]\tvalidation_0-logloss:0.12077\tvalidation_1-logloss:0.13323\n",
            "[92]\tvalidation_0-logloss:0.12058\tvalidation_1-logloss:0.13324\n",
            "[93]\tvalidation_0-logloss:0.12052\tvalidation_1-logloss:0.13325\n",
            "[94]\tvalidation_0-logloss:0.12034\tvalidation_1-logloss:0.13325\n",
            "[95]\tvalidation_0-logloss:0.12016\tvalidation_1-logloss:0.13327\n",
            "[96]\tvalidation_0-logloss:0.11995\tvalidation_1-logloss:0.13325\n",
            "[97]\tvalidation_0-logloss:0.11990\tvalidation_1-logloss:0.13325\n",
            "[98]\tvalidation_0-logloss:0.11972\tvalidation_1-logloss:0.13327\n",
            "[99]\tvalidation_0-logloss:0.11967\tvalidation_1-logloss:0.13327\n",
            "[100]\tvalidation_0-logloss:0.11950\tvalidation_1-logloss:0.13329\n",
            "[101]\tvalidation_0-logloss:0.11943\tvalidation_1-logloss:0.13327\n",
            "[102]\tvalidation_0-logloss:0.11927\tvalidation_1-logloss:0.13326\n",
            "[103]\tvalidation_0-logloss:0.11914\tvalidation_1-logloss:0.13327\n",
            "[104]\tvalidation_0-logloss:0.11912\tvalidation_1-logloss:0.13326\n",
            "[105]\tvalidation_0-logloss:0.11896\tvalidation_1-logloss:0.13328\n",
            "[106]\tvalidation_0-logloss:0.11893\tvalidation_1-logloss:0.13328\n",
            "[107]\tvalidation_0-logloss:0.11889\tvalidation_1-logloss:0.13328\n",
            "[108]\tvalidation_0-logloss:0.11877\tvalidation_1-logloss:0.13328\n",
            "[109]\tvalidation_0-logloss:0.11873\tvalidation_1-logloss:0.13327\n",
            "[110]\tvalidation_0-logloss:0.11871\tvalidation_1-logloss:0.13327\n",
            "[111]\tvalidation_0-logloss:0.11855\tvalidation_1-logloss:0.13331\n",
            "[112]\tvalidation_0-logloss:0.11853\tvalidation_1-logloss:0.13330\n",
            "[113]\tvalidation_0-logloss:0.11850\tvalidation_1-logloss:0.13330\n",
            "[114]\tvalidation_0-logloss:0.11840\tvalidation_1-logloss:0.13329\n",
            "[115]\tvalidation_0-logloss:0.11836\tvalidation_1-logloss:0.13328\n",
            "[116]\tvalidation_0-logloss:0.11834\tvalidation_1-logloss:0.13327\n",
            "[117]\tvalidation_0-logloss:0.11830\tvalidation_1-logloss:0.13328\n",
            "[118]\tvalidation_0-logloss:0.11826\tvalidation_1-logloss:0.13327\n",
            "[119]\tvalidation_0-logloss:0.11824\tvalidation_1-logloss:0.13326\n",
            "[120]\tvalidation_0-logloss:0.11808\tvalidation_1-logloss:0.13332\n",
            "[121]\tvalidation_0-logloss:0.11805\tvalidation_1-logloss:0.13330\n",
            "[122]\tvalidation_0-logloss:0.11798\tvalidation_1-logloss:0.13330\n",
            "[123]\tvalidation_0-logloss:0.11788\tvalidation_1-logloss:0.13328\n",
            "[124]\tvalidation_0-logloss:0.11775\tvalidation_1-logloss:0.13326\n",
            "[125]\tvalidation_0-logloss:0.11774\tvalidation_1-logloss:0.13326\n",
            "[126]\tvalidation_0-logloss:0.11771\tvalidation_1-logloss:0.13326\n",
            "[127]\tvalidation_0-logloss:0.11766\tvalidation_1-logloss:0.13327\n",
            "[128]\tvalidation_0-logloss:0.11761\tvalidation_1-logloss:0.13325\n",
            "[129]\tvalidation_0-logloss:0.11753\tvalidation_1-logloss:0.13325\n",
            "[130]\tvalidation_0-logloss:0.11749\tvalidation_1-logloss:0.13324\n",
            "[131]\tvalidation_0-logloss:0.11746\tvalidation_1-logloss:0.13324\n",
            "[132]\tvalidation_0-logloss:0.11743\tvalidation_1-logloss:0.13325\n",
            "[133]\tvalidation_0-logloss:0.11737\tvalidation_1-logloss:0.13324\n",
            "[134]\tvalidation_0-logloss:0.11729\tvalidation_1-logloss:0.13324\n",
            "[135]\tvalidation_0-logloss:0.11725\tvalidation_1-logloss:0.13324\n",
            "[136]\tvalidation_0-logloss:0.11718\tvalidation_1-logloss:0.13322\n",
            "[137]\tvalidation_0-logloss:0.11716\tvalidation_1-logloss:0.13322\n",
            "[138]\tvalidation_0-logloss:0.11711\tvalidation_1-logloss:0.13322\n",
            "[139]\tvalidation_0-logloss:0.11709\tvalidation_1-logloss:0.13322\n",
            "[140]\tvalidation_0-logloss:0.11704\tvalidation_1-logloss:0.13321\n",
            "[141]\tvalidation_0-logloss:0.11702\tvalidation_1-logloss:0.13321\n",
            "[142]\tvalidation_0-logloss:0.11698\tvalidation_1-logloss:0.13319\n",
            "[143]\tvalidation_0-logloss:0.11695\tvalidation_1-logloss:0.13319\n",
            "[144]\tvalidation_0-logloss:0.11692\tvalidation_1-logloss:0.13318\n",
            "[145]\tvalidation_0-logloss:0.11690\tvalidation_1-logloss:0.13319\n",
            "[146]\tvalidation_0-logloss:0.11685\tvalidation_1-logloss:0.13320\n",
            "[147]\tvalidation_0-logloss:0.11680\tvalidation_1-logloss:0.13318\n",
            "[148]\tvalidation_0-logloss:0.11674\tvalidation_1-logloss:0.13317\n",
            "[149]\tvalidation_0-logloss:0.11666\tvalidation_1-logloss:0.13317\n",
            "[150]\tvalidation_0-logloss:0.11664\tvalidation_1-logloss:0.13317\n",
            "[151]\tvalidation_0-logloss:0.11659\tvalidation_1-logloss:0.13318\n",
            "[152]\tvalidation_0-logloss:0.11656\tvalidation_1-logloss:0.13317\n",
            "[153]\tvalidation_0-logloss:0.11649\tvalidation_1-logloss:0.13316\n",
            "[154]\tvalidation_0-logloss:0.11637\tvalidation_1-logloss:0.13316\n",
            "[155]\tvalidation_0-logloss:0.11629\tvalidation_1-logloss:0.13317\n",
            "[156]\tvalidation_0-logloss:0.11626\tvalidation_1-logloss:0.13318\n",
            "[157]\tvalidation_0-logloss:0.11623\tvalidation_1-logloss:0.13317\n",
            "[158]\tvalidation_0-logloss:0.11614\tvalidation_1-logloss:0.13319\n",
            "[159]\tvalidation_0-logloss:0.11610\tvalidation_1-logloss:0.13319\n",
            "[160]\tvalidation_0-logloss:0.11604\tvalidation_1-logloss:0.13319\n",
            "[161]\tvalidation_0-logloss:0.11597\tvalidation_1-logloss:0.13318\n",
            "[162]\tvalidation_0-logloss:0.11596\tvalidation_1-logloss:0.13318\n",
            "[163]\tvalidation_0-logloss:0.11594\tvalidation_1-logloss:0.13318\n",
            "[164]\tvalidation_0-logloss:0.11591\tvalidation_1-logloss:0.13319\n",
            "[165]\tvalidation_0-logloss:0.11585\tvalidation_1-logloss:0.13319\n",
            "[166]\tvalidation_0-logloss:0.11582\tvalidation_1-logloss:0.13318\n",
            "[167]\tvalidation_0-logloss:0.11575\tvalidation_1-logloss:0.13319\n",
            "[168]\tvalidation_0-logloss:0.11573\tvalidation_1-logloss:0.13319\n",
            "[169]\tvalidation_0-logloss:0.11570\tvalidation_1-logloss:0.13319\n",
            "[170]\tvalidation_0-logloss:0.11567\tvalidation_1-logloss:0.13320\n",
            "[171]\tvalidation_0-logloss:0.11565\tvalidation_1-logloss:0.13320\n",
            "[172]\tvalidation_0-logloss:0.11562\tvalidation_1-logloss:0.13319\n",
            "[173]\tvalidation_0-logloss:0.11551\tvalidation_1-logloss:0.13318\n",
            "[174]\tvalidation_0-logloss:0.11549\tvalidation_1-logloss:0.13318\n",
            "[175]\tvalidation_0-logloss:0.11545\tvalidation_1-logloss:0.13318\n",
            "[176]\tvalidation_0-logloss:0.11532\tvalidation_1-logloss:0.13320\n",
            "[177]\tvalidation_0-logloss:0.11529\tvalidation_1-logloss:0.13321\n",
            "[178]\tvalidation_0-logloss:0.11514\tvalidation_1-logloss:0.13322\n",
            "[179]\tvalidation_0-logloss:0.11513\tvalidation_1-logloss:0.13322\n",
            "[180]\tvalidation_0-logloss:0.11510\tvalidation_1-logloss:0.13321\n",
            "[181]\tvalidation_0-logloss:0.11501\tvalidation_1-logloss:0.13323\n",
            "[182]\tvalidation_0-logloss:0.11495\tvalidation_1-logloss:0.13323\n",
            "[183]\tvalidation_0-logloss:0.11492\tvalidation_1-logloss:0.13323\n",
            "[184]\tvalidation_0-logloss:0.11487\tvalidation_1-logloss:0.13324\n",
            "[185]\tvalidation_0-logloss:0.11485\tvalidation_1-logloss:0.13324\n",
            "[186]\tvalidation_0-logloss:0.11477\tvalidation_1-logloss:0.13326\n",
            "[187]\tvalidation_0-logloss:0.11475\tvalidation_1-logloss:0.13326\n",
            "[188]\tvalidation_0-logloss:0.11469\tvalidation_1-logloss:0.13328\n",
            "[189]\tvalidation_0-logloss:0.11468\tvalidation_1-logloss:0.13327\n",
            "[190]\tvalidation_0-logloss:0.11465\tvalidation_1-logloss:0.13327\n",
            "[191]\tvalidation_0-logloss:0.11462\tvalidation_1-logloss:0.13327\n",
            "[192]\tvalidation_0-logloss:0.11453\tvalidation_1-logloss:0.13326\n",
            "[193]\tvalidation_0-logloss:0.11447\tvalidation_1-logloss:0.13328\n",
            "[194]\tvalidation_0-logloss:0.11444\tvalidation_1-logloss:0.13328\n",
            "[195]\tvalidation_0-logloss:0.11442\tvalidation_1-logloss:0.13328\n",
            "[196]\tvalidation_0-logloss:0.11438\tvalidation_1-logloss:0.13330\n",
            "[197]\tvalidation_0-logloss:0.11431\tvalidation_1-logloss:0.13329\n",
            "[198]\tvalidation_0-logloss:0.11424\tvalidation_1-logloss:0.13331\n",
            "[199]\tvalidation_0-logloss:0.11422\tvalidation_1-logloss:0.13332\n",
            "[200]\tvalidation_0-logloss:0.11419\tvalidation_1-logloss:0.13332\n",
            "[201]\tvalidation_0-logloss:0.11417\tvalidation_1-logloss:0.13331\n",
            "[202]\tvalidation_0-logloss:0.11412\tvalidation_1-logloss:0.13332\n",
            "[203]\tvalidation_0-logloss:0.11403\tvalidation_1-logloss:0.13333\n",
            "[204]\tvalidation_0-logloss:0.11398\tvalidation_1-logloss:0.13332\n",
            "[205]\tvalidation_0-logloss:0.11385\tvalidation_1-logloss:0.13333\n",
            "[206]\tvalidation_0-logloss:0.11383\tvalidation_1-logloss:0.13334\n",
            "[207]\tvalidation_0-logloss:0.11377\tvalidation_1-logloss:0.13332\n",
            "[208]\tvalidation_0-logloss:0.11375\tvalidation_1-logloss:0.13332\n",
            "[209]\tvalidation_0-logloss:0.11368\tvalidation_1-logloss:0.13334\n",
            "[210]\tvalidation_0-logloss:0.11366\tvalidation_1-logloss:0.13334\n",
            "[211]\tvalidation_0-logloss:0.11364\tvalidation_1-logloss:0.13333\n",
            "[212]\tvalidation_0-logloss:0.11362\tvalidation_1-logloss:0.13332\n",
            "[213]\tvalidation_0-logloss:0.11360\tvalidation_1-logloss:0.13332\n",
            "[214]\tvalidation_0-logloss:0.11357\tvalidation_1-logloss:0.13331\n",
            "[215]\tvalidation_0-logloss:0.11344\tvalidation_1-logloss:0.13332\n",
            "[216]\tvalidation_0-logloss:0.11339\tvalidation_1-logloss:0.13334\n",
            "[217]\tvalidation_0-logloss:0.11338\tvalidation_1-logloss:0.13333\n",
            "[218]\tvalidation_0-logloss:0.11336\tvalidation_1-logloss:0.13333\n",
            "[219]\tvalidation_0-logloss:0.11334\tvalidation_1-logloss:0.13332\n",
            "[220]\tvalidation_0-logloss:0.11325\tvalidation_1-logloss:0.13332\n",
            "[221]\tvalidation_0-logloss:0.11321\tvalidation_1-logloss:0.13332\n",
            "[222]\tvalidation_0-logloss:0.11320\tvalidation_1-logloss:0.13331\n",
            "[223]\tvalidation_0-logloss:0.11316\tvalidation_1-logloss:0.13331\n",
            "[224]\tvalidation_0-logloss:0.11307\tvalidation_1-logloss:0.13331\n",
            "[225]\tvalidation_0-logloss:0.11301\tvalidation_1-logloss:0.13330\n",
            "[226]\tvalidation_0-logloss:0.11295\tvalidation_1-logloss:0.13329\n",
            "[227]\tvalidation_0-logloss:0.11293\tvalidation_1-logloss:0.13329\n",
            "[228]\tvalidation_0-logloss:0.11291\tvalidation_1-logloss:0.13328\n",
            "[229]\tvalidation_0-logloss:0.11289\tvalidation_1-logloss:0.13327\n",
            "[230]\tvalidation_0-logloss:0.11286\tvalidation_1-logloss:0.13326\n",
            "[231]\tvalidation_0-logloss:0.11284\tvalidation_1-logloss:0.13329\n",
            "[232]\tvalidation_0-logloss:0.11283\tvalidation_1-logloss:0.13329\n",
            "[233]\tvalidation_0-logloss:0.11282\tvalidation_1-logloss:0.13329\n",
            "[234]\tvalidation_0-logloss:0.11280\tvalidation_1-logloss:0.13329\n",
            "[235]\tvalidation_0-logloss:0.11276\tvalidation_1-logloss:0.13331\n",
            "[236]\tvalidation_0-logloss:0.11273\tvalidation_1-logloss:0.13329\n",
            "[237]\tvalidation_0-logloss:0.11261\tvalidation_1-logloss:0.13327\n",
            "[238]\tvalidation_0-logloss:0.11255\tvalidation_1-logloss:0.13327\n",
            "[239]\tvalidation_0-logloss:0.11252\tvalidation_1-logloss:0.13326\n",
            "[240]\tvalidation_0-logloss:0.11240\tvalidation_1-logloss:0.13325\n",
            "[241]\tvalidation_0-logloss:0.11224\tvalidation_1-logloss:0.13329\n",
            "[242]\tvalidation_0-logloss:0.11219\tvalidation_1-logloss:0.13329\n",
            "[243]\tvalidation_0-logloss:0.11216\tvalidation_1-logloss:0.13330\n",
            "[244]\tvalidation_0-logloss:0.11215\tvalidation_1-logloss:0.13329\n",
            "[245]\tvalidation_0-logloss:0.11209\tvalidation_1-logloss:0.13332\n",
            "[246]\tvalidation_0-logloss:0.11203\tvalidation_1-logloss:0.13332\n",
            "[247]\tvalidation_0-logloss:0.11199\tvalidation_1-logloss:0.13331\n",
            "[248]\tvalidation_0-logloss:0.11196\tvalidation_1-logloss:0.13331\n",
            "[249]\tvalidation_0-logloss:0.11190\tvalidation_1-logloss:0.13331\n",
            "[250]\tvalidation_0-logloss:0.11188\tvalidation_1-logloss:0.13332\n",
            "[251]\tvalidation_0-logloss:0.11187\tvalidation_1-logloss:0.13331\n",
            "[252]\tvalidation_0-logloss:0.11185\tvalidation_1-logloss:0.13331\n",
            "[253]\tvalidation_0-logloss:0.11183\tvalidation_1-logloss:0.13331\n",
            "ROC AUC: 0.8446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step5 XGBoost의  Hyperparameter Tuning을 위해 최적값 찾기\n",
        "\n",
        "from hyperopt import hp\n",
        "\n",
        "# max_depth는 5에서 15까지 1간격으로, min_child_weight는 1에서 6까지 1간격으로\n",
        "# colsample_bytree는 0.5에서 0.95사이, learning_rate는 0.01에서 0.2사이 정규 분포된 값으로 검색.\n",
        "\n",
        "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 15, 1),\n",
        "                    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
        "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n",
        "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 목적 함수 설정.\n",
        "# 추후 fmin()에서 입력된 search_space값으로 XGBClassifier 교차 검증 학습 후 -1* roc_auc 평균 값을 반환.\n",
        "def objective_func(search_space):\n",
        "    # eval_metric and early_stopping_rounds are moved to the XGBClassifier constructor\n",
        "    xgb_clf = XGBClassifier(n_estimators=100,\n",
        "                            max_depth=int(search_space['max_depth']),\n",
        "                            min_child_weight=int(search_space['min_child_weight']),\n",
        "                            colsample_bytree=search_space['colsample_bytree'],\n",
        "                            learning_rate=search_space['learning_rate'],\n",
        "                            eval_metric='auc',  # Specify eval_metric here\n",
        "                            early_stopping_rounds=30 # Specify early_stopping_rounds here\n",
        "                           )\n",
        "    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
        "    roc_auc_list= []\n",
        "\n",
        "    # 3개 k-fold방식 적용\n",
        "    kf = KFold(n_splits=3)\n",
        "    # X_train을 다시 학습과 검증용 데이터로 분리\n",
        "    for tr_index, val_index in kf.split(X_train):\n",
        "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리\n",
        "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
        "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
        "        #  추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.\n",
        "        # Removed early_stopping_rounds from fit()\n",
        "        xgb_clf.fit(X_tr, y_tr,\n",
        "                   eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
        "\n",
        "        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음.\n",
        "        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n",
        "        roc_auc_list.append(score)\n",
        "\n",
        "    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되,\n",
        "    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환.\n",
        "    return -1 * np.mean(roc_auc_list)\n",
        "\n",
        "from hyperopt import fmin, tpe, Trials\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출.\n",
        "best = fmin(fn=objective_func,\n",
        "            space=xgb_search_space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
        "            trials=trials, rstate=np.random.default_rng(seed=30))\n",
        "\n",
        "print('best:', best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkbD7GiDj4qF",
        "outputId": "446fc8f4-e727-478a-8fe6-89835f72e53e"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "[35]\tvalidation_0-auc:0.91306\tvalidation_1-auc:0.83514\n",
            "[36]\tvalidation_0-auc:0.91411\tvalidation_1-auc:0.83473\n",
            "[37]\tvalidation_0-auc:0.91444\tvalidation_1-auc:0.83492\n",
            "[38]\tvalidation_0-auc:0.91468\tvalidation_1-auc:0.83462\n",
            "[39]\tvalidation_0-auc:0.91515\tvalidation_1-auc:0.83401\n",
            "[40]\tvalidation_0-auc:0.91526\tvalidation_1-auc:0.83418\n",
            "[41]\tvalidation_0-auc:0.91540\tvalidation_1-auc:0.83409\n",
            "[42]\tvalidation_0-auc:0.91609\tvalidation_1-auc:0.83382\n",
            "[43]\tvalidation_0-auc:0.91642\tvalidation_1-auc:0.83337\n",
            "[44]\tvalidation_0-auc:0.91755\tvalidation_1-auc:0.83371\n",
            "[0]\tvalidation_0-auc:0.82893\tvalidation_1-auc:0.79630\n",
            "[1]\tvalidation_0-auc:0.84185\tvalidation_1-auc:0.81151\n",
            "[2]\tvalidation_0-auc:0.83892\tvalidation_1-auc:0.81016\n",
            "[3]\tvalidation_0-auc:0.84844\tvalidation_1-auc:0.81883\n",
            "[4]\tvalidation_0-auc:0.85049\tvalidation_1-auc:0.82190\n",
            "[5]\tvalidation_0-auc:0.85235\tvalidation_1-auc:0.82399\n",
            "[6]\tvalidation_0-auc:0.85587\tvalidation_1-auc:0.82399\n",
            "[7]\tvalidation_0-auc:0.85787\tvalidation_1-auc:0.82579\n",
            "[8]\tvalidation_0-auc:0.86054\tvalidation_1-auc:0.82705\n",
            "[9]\tvalidation_0-auc:0.86040\tvalidation_1-auc:0.82705\n",
            "[10]\tvalidation_0-auc:0.86323\tvalidation_1-auc:0.82919\n",
            "[11]\tvalidation_0-auc:0.86510\tvalidation_1-auc:0.83027\n",
            "[12]\tvalidation_0-auc:0.86679\tvalidation_1-auc:0.83074\n",
            "[13]\tvalidation_0-auc:0.86800\tvalidation_1-auc:0.83093\n",
            "[14]\tvalidation_0-auc:0.86846\tvalidation_1-auc:0.83219\n",
            "[15]\tvalidation_0-auc:0.86955\tvalidation_1-auc:0.83237\n",
            "[16]\tvalidation_0-auc:0.87072\tvalidation_1-auc:0.83218\n",
            "[17]\tvalidation_0-auc:0.87214\tvalidation_1-auc:0.83306\n",
            "[18]\tvalidation_0-auc:0.87242\tvalidation_1-auc:0.83314\n",
            "[19]\tvalidation_0-auc:0.87320\tvalidation_1-auc:0.83310\n",
            "[20]\tvalidation_0-auc:0.87451\tvalidation_1-auc:0.83314\n",
            "[21]\tvalidation_0-auc:0.87551\tvalidation_1-auc:0.83339\n",
            "[22]\tvalidation_0-auc:0.87591\tvalidation_1-auc:0.83333\n",
            "[23]\tvalidation_0-auc:0.87642\tvalidation_1-auc:0.83359\n",
            "[24]\tvalidation_0-auc:0.87752\tvalidation_1-auc:0.83408\n",
            "[25]\tvalidation_0-auc:0.87763\tvalidation_1-auc:0.83403\n",
            "[26]\tvalidation_0-auc:0.87802\tvalidation_1-auc:0.83372\n",
            "[27]\tvalidation_0-auc:0.87883\tvalidation_1-auc:0.83308\n",
            "[28]\tvalidation_0-auc:0.87914\tvalidation_1-auc:0.83315\n",
            "[29]\tvalidation_0-auc:0.87962\tvalidation_1-auc:0.83330\n",
            "[30]\tvalidation_0-auc:0.88076\tvalidation_1-auc:0.83377\n",
            "[31]\tvalidation_0-auc:0.88105\tvalidation_1-auc:0.83370\n",
            "[32]\tvalidation_0-auc:0.88192\tvalidation_1-auc:0.83409\n",
            "[33]\tvalidation_0-auc:0.88228\tvalidation_1-auc:0.83420\n",
            "[34]\tvalidation_0-auc:0.88257\tvalidation_1-auc:0.83417\n",
            "[35]\tvalidation_0-auc:0.88289\tvalidation_1-auc:0.83416\n",
            "[36]\tvalidation_0-auc:0.88327\tvalidation_1-auc:0.83427\n",
            "[37]\tvalidation_0-auc:0.88419\tvalidation_1-auc:0.83376\n",
            "[38]\tvalidation_0-auc:0.88481\tvalidation_1-auc:0.83362\n",
            "[39]\tvalidation_0-auc:0.88570\tvalidation_1-auc:0.83362\n",
            "[40]\tvalidation_0-auc:0.88588\tvalidation_1-auc:0.83342\n",
            "[41]\tvalidation_0-auc:0.88620\tvalidation_1-auc:0.83355\n",
            "[42]\tvalidation_0-auc:0.88630\tvalidation_1-auc:0.83374\n",
            "[43]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.83357\n",
            "[44]\tvalidation_0-auc:0.88719\tvalidation_1-auc:0.83333\n",
            "[45]\tvalidation_0-auc:0.88808\tvalidation_1-auc:0.83272\n",
            "[46]\tvalidation_0-auc:0.88890\tvalidation_1-auc:0.83249\n",
            "[47]\tvalidation_0-auc:0.88912\tvalidation_1-auc:0.83204\n",
            "[48]\tvalidation_0-auc:0.88958\tvalidation_1-auc:0.83204\n",
            "[49]\tvalidation_0-auc:0.88989\tvalidation_1-auc:0.83237\n",
            "[50]\tvalidation_0-auc:0.89014\tvalidation_1-auc:0.83196\n",
            "[51]\tvalidation_0-auc:0.89024\tvalidation_1-auc:0.83194\n",
            "[52]\tvalidation_0-auc:0.89081\tvalidation_1-auc:0.83165\n",
            "[53]\tvalidation_0-auc:0.89115\tvalidation_1-auc:0.83181\n",
            "[54]\tvalidation_0-auc:0.89182\tvalidation_1-auc:0.83201\n",
            "[55]\tvalidation_0-auc:0.89226\tvalidation_1-auc:0.83179\n",
            "[56]\tvalidation_0-auc:0.89249\tvalidation_1-auc:0.83145\n",
            "[57]\tvalidation_0-auc:0.89302\tvalidation_1-auc:0.83146\n",
            "[58]\tvalidation_0-auc:0.89364\tvalidation_1-auc:0.83133\n",
            "[59]\tvalidation_0-auc:0.89379\tvalidation_1-auc:0.83084\n",
            "[60]\tvalidation_0-auc:0.89393\tvalidation_1-auc:0.83103\n",
            "[61]\tvalidation_0-auc:0.89420\tvalidation_1-auc:0.83069\n",
            "[62]\tvalidation_0-auc:0.89458\tvalidation_1-auc:0.83051\n",
            "[63]\tvalidation_0-auc:0.89486\tvalidation_1-auc:0.83043\n",
            "[64]\tvalidation_0-auc:0.89508\tvalidation_1-auc:0.83017\n",
            "[65]\tvalidation_0-auc:0.89530\tvalidation_1-auc:0.83002\n",
            "[0]\tvalidation_0-auc:0.83113\tvalidation_1-auc:0.81691\n",
            "[1]\tvalidation_0-auc:0.84067\tvalidation_1-auc:0.82206\n",
            "[2]\tvalidation_0-auc:0.84026\tvalidation_1-auc:0.81787\n",
            "[3]\tvalidation_0-auc:0.84839\tvalidation_1-auc:0.82495\n",
            "[4]\tvalidation_0-auc:0.85285\tvalidation_1-auc:0.82621\n",
            "[5]\tvalidation_0-auc:0.85500\tvalidation_1-auc:0.82897\n",
            "[6]\tvalidation_0-auc:0.85646\tvalidation_1-auc:0.82988\n",
            "[7]\tvalidation_0-auc:0.85851\tvalidation_1-auc:0.82783\n",
            "[8]\tvalidation_0-auc:0.86046\tvalidation_1-auc:0.82957\n",
            "[9]\tvalidation_0-auc:0.85951\tvalidation_1-auc:0.82888\n",
            "[10]\tvalidation_0-auc:0.86153\tvalidation_1-auc:0.83005\n",
            "[11]\tvalidation_0-auc:0.86373\tvalidation_1-auc:0.83127\n",
            "[12]\tvalidation_0-auc:0.86642\tvalidation_1-auc:0.83181\n",
            "[13]\tvalidation_0-auc:0.86789\tvalidation_1-auc:0.83274\n",
            "[14]\tvalidation_0-auc:0.86931\tvalidation_1-auc:0.83457\n",
            "[15]\tvalidation_0-auc:0.87078\tvalidation_1-auc:0.83461\n",
            "[16]\tvalidation_0-auc:0.87198\tvalidation_1-auc:0.83502\n",
            "[17]\tvalidation_0-auc:0.87334\tvalidation_1-auc:0.83604\n",
            "[18]\tvalidation_0-auc:0.87417\tvalidation_1-auc:0.83612\n",
            "[19]\tvalidation_0-auc:0.87475\tvalidation_1-auc:0.83620\n",
            "[20]\tvalidation_0-auc:0.87634\tvalidation_1-auc:0.83547\n",
            "[21]\tvalidation_0-auc:0.87704\tvalidation_1-auc:0.83603\n",
            "[22]\tvalidation_0-auc:0.87780\tvalidation_1-auc:0.83625\n",
            "[23]\tvalidation_0-auc:0.87820\tvalidation_1-auc:0.83626\n",
            "[24]\tvalidation_0-auc:0.87860\tvalidation_1-auc:0.83610\n",
            "[25]\tvalidation_0-auc:0.87864\tvalidation_1-auc:0.83656\n",
            "[26]\tvalidation_0-auc:0.87919\tvalidation_1-auc:0.83633\n",
            "[27]\tvalidation_0-auc:0.88011\tvalidation_1-auc:0.83706\n",
            "[28]\tvalidation_0-auc:0.88062\tvalidation_1-auc:0.83721\n",
            "[29]\tvalidation_0-auc:0.88097\tvalidation_1-auc:0.83742\n",
            "[30]\tvalidation_0-auc:0.88157\tvalidation_1-auc:0.83764\n",
            "[31]\tvalidation_0-auc:0.88175\tvalidation_1-auc:0.83748\n",
            "[32]\tvalidation_0-auc:0.88233\tvalidation_1-auc:0.83753\n",
            "[33]\tvalidation_0-auc:0.88299\tvalidation_1-auc:0.83733\n",
            "[34]\tvalidation_0-auc:0.88359\tvalidation_1-auc:0.83721\n",
            "[35]\tvalidation_0-auc:0.88384\tvalidation_1-auc:0.83726\n",
            "[36]\tvalidation_0-auc:0.88422\tvalidation_1-auc:0.83719\n",
            "[37]\tvalidation_0-auc:0.88517\tvalidation_1-auc:0.83748\n",
            "[38]\tvalidation_0-auc:0.88555\tvalidation_1-auc:0.83744\n",
            "[39]\tvalidation_0-auc:0.88586\tvalidation_1-auc:0.83720\n",
            "[40]\tvalidation_0-auc:0.88621\tvalidation_1-auc:0.83722\n",
            "[41]\tvalidation_0-auc:0.88647\tvalidation_1-auc:0.83708\n",
            "[42]\tvalidation_0-auc:0.88698\tvalidation_1-auc:0.83695\n",
            "[43]\tvalidation_0-auc:0.88747\tvalidation_1-auc:0.83669\n",
            "[44]\tvalidation_0-auc:0.88768\tvalidation_1-auc:0.83660\n",
            "[45]\tvalidation_0-auc:0.88787\tvalidation_1-auc:0.83662\n",
            "[46]\tvalidation_0-auc:0.88822\tvalidation_1-auc:0.83643\n",
            "[47]\tvalidation_0-auc:0.88847\tvalidation_1-auc:0.83623\n",
            "[48]\tvalidation_0-auc:0.88901\tvalidation_1-auc:0.83616\n",
            "[49]\tvalidation_0-auc:0.88916\tvalidation_1-auc:0.83622\n",
            "[50]\tvalidation_0-auc:0.88951\tvalidation_1-auc:0.83613\n",
            "[51]\tvalidation_0-auc:0.89018\tvalidation_1-auc:0.83545\n",
            "[52]\tvalidation_0-auc:0.89025\tvalidation_1-auc:0.83546\n",
            "[53]\tvalidation_0-auc:0.89042\tvalidation_1-auc:0.83565\n",
            "[54]\tvalidation_0-auc:0.89047\tvalidation_1-auc:0.83564\n",
            "[55]\tvalidation_0-auc:0.89135\tvalidation_1-auc:0.83532\n",
            "[56]\tvalidation_0-auc:0.89179\tvalidation_1-auc:0.83555\n",
            "[57]\tvalidation_0-auc:0.89187\tvalidation_1-auc:0.83537\n",
            "[58]\tvalidation_0-auc:0.89260\tvalidation_1-auc:0.83561\n",
            "[59]\tvalidation_0-auc:0.89267\tvalidation_1-auc:0.83549\n",
            "[0]\tvalidation_0-auc:0.83447\tvalidation_1-auc:0.81239\n",
            "[1]\tvalidation_0-auc:0.84256\tvalidation_1-auc:0.82266\n",
            "[2]\tvalidation_0-auc:0.84574\tvalidation_1-auc:0.82040\n",
            "[3]\tvalidation_0-auc:0.84989\tvalidation_1-auc:0.82378\n",
            "[4]\tvalidation_0-auc:0.85166\tvalidation_1-auc:0.82515\n",
            "[5]\tvalidation_0-auc:0.85373\tvalidation_1-auc:0.82558\n",
            "[6]\tvalidation_0-auc:0.85576\tvalidation_1-auc:0.82627\n",
            "[7]\tvalidation_0-auc:0.85715\tvalidation_1-auc:0.82629\n",
            "[8]\tvalidation_0-auc:0.85931\tvalidation_1-auc:0.82909\n",
            "[9]\tvalidation_0-auc:0.86025\tvalidation_1-auc:0.82818\n",
            "[10]\tvalidation_0-auc:0.86252\tvalidation_1-auc:0.83006\n",
            "[11]\tvalidation_0-auc:0.86523\tvalidation_1-auc:0.83210\n",
            "[12]\tvalidation_0-auc:0.86697\tvalidation_1-auc:0.83323\n",
            "[13]\tvalidation_0-auc:0.86805\tvalidation_1-auc:0.83481\n",
            "[14]\tvalidation_0-auc:0.86960\tvalidation_1-auc:0.83519\n",
            "[15]\tvalidation_0-auc:0.87161\tvalidation_1-auc:0.83475\n",
            "[16]\tvalidation_0-auc:0.87250\tvalidation_1-auc:0.83523\n",
            "[17]\tvalidation_0-auc:0.87327\tvalidation_1-auc:0.83525\n",
            "[18]\tvalidation_0-auc:0.87419\tvalidation_1-auc:0.83612\n",
            "[19]\tvalidation_0-auc:0.87471\tvalidation_1-auc:0.83621\n",
            "[20]\tvalidation_0-auc:0.87571\tvalidation_1-auc:0.83602\n",
            "[21]\tvalidation_0-auc:0.87650\tvalidation_1-auc:0.83647\n",
            "[22]\tvalidation_0-auc:0.87720\tvalidation_1-auc:0.83686\n",
            "[23]\tvalidation_0-auc:0.87739\tvalidation_1-auc:0.83714\n",
            "[24]\tvalidation_0-auc:0.87788\tvalidation_1-auc:0.83646\n",
            "[25]\tvalidation_0-auc:0.87822\tvalidation_1-auc:0.83697\n",
            "[26]\tvalidation_0-auc:0.87874\tvalidation_1-auc:0.83675\n",
            "[27]\tvalidation_0-auc:0.87957\tvalidation_1-auc:0.83684\n",
            "[28]\tvalidation_0-auc:0.88043\tvalidation_1-auc:0.83712\n",
            "[29]\tvalidation_0-auc:0.88095\tvalidation_1-auc:0.83676\n",
            "[30]\tvalidation_0-auc:0.88170\tvalidation_1-auc:0.83678\n",
            "[31]\tvalidation_0-auc:0.88202\tvalidation_1-auc:0.83702\n",
            "[32]\tvalidation_0-auc:0.88238\tvalidation_1-auc:0.83721\n",
            "[33]\tvalidation_0-auc:0.88272\tvalidation_1-auc:0.83702\n",
            "[34]\tvalidation_0-auc:0.88326\tvalidation_1-auc:0.83701\n",
            "[35]\tvalidation_0-auc:0.88415\tvalidation_1-auc:0.83746\n",
            "[36]\tvalidation_0-auc:0.88457\tvalidation_1-auc:0.83755\n",
            "[37]\tvalidation_0-auc:0.88535\tvalidation_1-auc:0.83760\n",
            "[38]\tvalidation_0-auc:0.88620\tvalidation_1-auc:0.83761\n",
            "[39]\tvalidation_0-auc:0.88643\tvalidation_1-auc:0.83755\n",
            "[40]\tvalidation_0-auc:0.88672\tvalidation_1-auc:0.83739\n",
            "[41]\tvalidation_0-auc:0.88710\tvalidation_1-auc:0.83712\n",
            "[42]\tvalidation_0-auc:0.88745\tvalidation_1-auc:0.83698\n",
            "[43]\tvalidation_0-auc:0.88828\tvalidation_1-auc:0.83697\n",
            "[44]\tvalidation_0-auc:0.88856\tvalidation_1-auc:0.83710\n",
            "[45]\tvalidation_0-auc:0.88926\tvalidation_1-auc:0.83729\n",
            "[46]\tvalidation_0-auc:0.88940\tvalidation_1-auc:0.83707\n",
            "[47]\tvalidation_0-auc:0.88988\tvalidation_1-auc:0.83713\n",
            "[48]\tvalidation_0-auc:0.89094\tvalidation_1-auc:0.83679\n",
            "[49]\tvalidation_0-auc:0.89109\tvalidation_1-auc:0.83693\n",
            "[50]\tvalidation_0-auc:0.89133\tvalidation_1-auc:0.83708\n",
            "[51]\tvalidation_0-auc:0.89174\tvalidation_1-auc:0.83663\n",
            "[52]\tvalidation_0-auc:0.89239\tvalidation_1-auc:0.83641\n",
            "[53]\tvalidation_0-auc:0.89260\tvalidation_1-auc:0.83640\n",
            "[54]\tvalidation_0-auc:0.89336\tvalidation_1-auc:0.83615\n",
            "[55]\tvalidation_0-auc:0.89347\tvalidation_1-auc:0.83592\n",
            "[56]\tvalidation_0-auc:0.89357\tvalidation_1-auc:0.83623\n",
            "[57]\tvalidation_0-auc:0.89382\tvalidation_1-auc:0.83605\n",
            "[58]\tvalidation_0-auc:0.89404\tvalidation_1-auc:0.83594\n",
            "[59]\tvalidation_0-auc:0.89445\tvalidation_1-auc:0.83585\n",
            "[60]\tvalidation_0-auc:0.89479\tvalidation_1-auc:0.83579\n",
            "[61]\tvalidation_0-auc:0.89495\tvalidation_1-auc:0.83569\n",
            "[62]\tvalidation_0-auc:0.89605\tvalidation_1-auc:0.83539\n",
            "[63]\tvalidation_0-auc:0.89637\tvalidation_1-auc:0.83492\n",
            "[64]\tvalidation_0-auc:0.89654\tvalidation_1-auc:0.83487\n",
            "[65]\tvalidation_0-auc:0.89690\tvalidation_1-auc:0.83495\n",
            "[66]\tvalidation_0-auc:0.89726\tvalidation_1-auc:0.83476\n",
            "[67]\tvalidation_0-auc:0.89732\tvalidation_1-auc:0.83476\n",
            "[68]\tvalidation_0-auc:0.89754\tvalidation_1-auc:0.83451\n",
            "[0]\tvalidation_0-auc:0.84817\tvalidation_1-auc:0.80655\n",
            "[1]\tvalidation_0-auc:0.85967\tvalidation_1-auc:0.81827\n",
            "[2]\tvalidation_0-auc:0.85990\tvalidation_1-auc:0.81259\n",
            "[3]\tvalidation_0-auc:0.86704\tvalidation_1-auc:0.82021\n",
            "[4]\tvalidation_0-auc:0.87213\tvalidation_1-auc:0.82382\n",
            "[5]\tvalidation_0-auc:0.87314\tvalidation_1-auc:0.82586\n",
            "[6]\tvalidation_0-auc:0.87750\tvalidation_1-auc:0.82726\n",
            "[7]\tvalidation_0-auc:0.87962\tvalidation_1-auc:0.82429\n",
            "[8]\tvalidation_0-auc:0.88134\tvalidation_1-auc:0.82698\n",
            "[9]\tvalidation_0-auc:0.88221\tvalidation_1-auc:0.82659\n",
            "[10]\tvalidation_0-auc:0.88404\tvalidation_1-auc:0.82817\n",
            "[11]\tvalidation_0-auc:0.88646\tvalidation_1-auc:0.82834\n",
            "[12]\tvalidation_0-auc:0.88979\tvalidation_1-auc:0.82763\n",
            "[13]\tvalidation_0-auc:0.89182\tvalidation_1-auc:0.82830\n",
            "[14]\tvalidation_0-auc:0.89294\tvalidation_1-auc:0.82923\n",
            "[15]\tvalidation_0-auc:0.89483\tvalidation_1-auc:0.82945\n",
            "[16]\tvalidation_0-auc:0.89667\tvalidation_1-auc:0.82893\n",
            "[17]\tvalidation_0-auc:0.89782\tvalidation_1-auc:0.83075\n",
            "[18]\tvalidation_0-auc:0.89844\tvalidation_1-auc:0.83083\n",
            "[19]\tvalidation_0-auc:0.89934\tvalidation_1-auc:0.83141\n",
            "[20]\tvalidation_0-auc:0.90006\tvalidation_1-auc:0.83202\n",
            "[21]\tvalidation_0-auc:0.90093\tvalidation_1-auc:0.83235\n",
            "[22]\tvalidation_0-auc:0.90189\tvalidation_1-auc:0.83266\n",
            "[23]\tvalidation_0-auc:0.90240\tvalidation_1-auc:0.83286\n",
            "[24]\tvalidation_0-auc:0.90299\tvalidation_1-auc:0.83278\n",
            "[25]\tvalidation_0-auc:0.90374\tvalidation_1-auc:0.83308\n",
            "[26]\tvalidation_0-auc:0.90429\tvalidation_1-auc:0.83310\n",
            "[27]\tvalidation_0-auc:0.90453\tvalidation_1-auc:0.83280\n",
            "[28]\tvalidation_0-auc:0.90554\tvalidation_1-auc:0.83318\n",
            "[29]\tvalidation_0-auc:0.90565\tvalidation_1-auc:0.83332\n",
            "[30]\tvalidation_0-auc:0.90621\tvalidation_1-auc:0.83349\n",
            "[31]\tvalidation_0-auc:0.90680\tvalidation_1-auc:0.83311\n",
            "[32]\tvalidation_0-auc:0.90781\tvalidation_1-auc:0.83255\n",
            "[33]\tvalidation_0-auc:0.90800\tvalidation_1-auc:0.83233\n",
            "[34]\tvalidation_0-auc:0.90828\tvalidation_1-auc:0.83206\n",
            "[35]\tvalidation_0-auc:0.90906\tvalidation_1-auc:0.83189\n",
            "[36]\tvalidation_0-auc:0.90938\tvalidation_1-auc:0.83171\n",
            "[37]\tvalidation_0-auc:0.90962\tvalidation_1-auc:0.83170\n",
            "[38]\tvalidation_0-auc:0.90996\tvalidation_1-auc:0.83156\n",
            "[39]\tvalidation_0-auc:0.91023\tvalidation_1-auc:0.83157\n",
            "[40]\tvalidation_0-auc:0.91056\tvalidation_1-auc:0.83103\n",
            "[41]\tvalidation_0-auc:0.91067\tvalidation_1-auc:0.83071\n",
            "[42]\tvalidation_0-auc:0.91091\tvalidation_1-auc:0.83048\n",
            "[43]\tvalidation_0-auc:0.91169\tvalidation_1-auc:0.83054\n",
            "[44]\tvalidation_0-auc:0.91215\tvalidation_1-auc:0.83060\n",
            "[45]\tvalidation_0-auc:0.91234\tvalidation_1-auc:0.83055\n",
            "[46]\tvalidation_0-auc:0.91271\tvalidation_1-auc:0.83028\n",
            "[47]\tvalidation_0-auc:0.91307\tvalidation_1-auc:0.82991\n",
            "[48]\tvalidation_0-auc:0.91436\tvalidation_1-auc:0.82928\n",
            "[49]\tvalidation_0-auc:0.91441\tvalidation_1-auc:0.82912\n",
            "[50]\tvalidation_0-auc:0.91526\tvalidation_1-auc:0.82927\n",
            "[51]\tvalidation_0-auc:0.91547\tvalidation_1-auc:0.82912\n",
            "[52]\tvalidation_0-auc:0.91558\tvalidation_1-auc:0.82880\n",
            "[53]\tvalidation_0-auc:0.91570\tvalidation_1-auc:0.82875\n",
            "[54]\tvalidation_0-auc:0.91639\tvalidation_1-auc:0.82894\n",
            "[55]\tvalidation_0-auc:0.91660\tvalidation_1-auc:0.82847\n",
            "[56]\tvalidation_0-auc:0.91687\tvalidation_1-auc:0.82818\n",
            "[57]\tvalidation_0-auc:0.91721\tvalidation_1-auc:0.82798\n",
            "[58]\tvalidation_0-auc:0.91794\tvalidation_1-auc:0.82778\n",
            "[59]\tvalidation_0-auc:0.91807\tvalidation_1-auc:0.82757\n",
            "[60]\tvalidation_0-auc:0.91819\tvalidation_1-auc:0.82731\n",
            "[0]\tvalidation_0-auc:0.84951\tvalidation_1-auc:0.81628\n",
            "[1]\tvalidation_0-auc:0.85901\tvalidation_1-auc:0.82557\n",
            "[2]\tvalidation_0-auc:0.86213\tvalidation_1-auc:0.82136\n",
            "[3]\tvalidation_0-auc:0.86977\tvalidation_1-auc:0.82601\n",
            "[4]\tvalidation_0-auc:0.87442\tvalidation_1-auc:0.82721\n",
            "[5]\tvalidation_0-auc:0.87661\tvalidation_1-auc:0.82907\n",
            "[6]\tvalidation_0-auc:0.88059\tvalidation_1-auc:0.83180\n",
            "[7]\tvalidation_0-auc:0.88316\tvalidation_1-auc:0.82982\n",
            "[8]\tvalidation_0-auc:0.88514\tvalidation_1-auc:0.83114\n",
            "[9]\tvalidation_0-auc:0.88480\tvalidation_1-auc:0.82989\n",
            "[10]\tvalidation_0-auc:0.88775\tvalidation_1-auc:0.83247\n",
            "[11]\tvalidation_0-auc:0.89021\tvalidation_1-auc:0.83250\n",
            "[12]\tvalidation_0-auc:0.89343\tvalidation_1-auc:0.83299\n",
            "[13]\tvalidation_0-auc:0.89471\tvalidation_1-auc:0.83298\n",
            "[14]\tvalidation_0-auc:0.89613\tvalidation_1-auc:0.83330\n",
            "[15]\tvalidation_0-auc:0.89688\tvalidation_1-auc:0.83299\n",
            "[16]\tvalidation_0-auc:0.89861\tvalidation_1-auc:0.83342\n",
            "[17]\tvalidation_0-auc:0.89971\tvalidation_1-auc:0.83362\n",
            "[18]\tvalidation_0-auc:0.90101\tvalidation_1-auc:0.83409\n",
            "[19]\tvalidation_0-auc:0.90253\tvalidation_1-auc:0.83365\n",
            "[20]\tvalidation_0-auc:0.90373\tvalidation_1-auc:0.83321\n",
            "[21]\tvalidation_0-auc:0.90475\tvalidation_1-auc:0.83251\n",
            "[22]\tvalidation_0-auc:0.90554\tvalidation_1-auc:0.83319\n",
            "[23]\tvalidation_0-auc:0.90602\tvalidation_1-auc:0.83347\n",
            "[24]\tvalidation_0-auc:0.90659\tvalidation_1-auc:0.83355\n",
            "[25]\tvalidation_0-auc:0.90683\tvalidation_1-auc:0.83385\n",
            "[26]\tvalidation_0-auc:0.90745\tvalidation_1-auc:0.83459\n",
            "[27]\tvalidation_0-auc:0.90763\tvalidation_1-auc:0.83497\n",
            "[28]\tvalidation_0-auc:0.90876\tvalidation_1-auc:0.83481\n",
            "[29]\tvalidation_0-auc:0.90888\tvalidation_1-auc:0.83480\n",
            "[30]\tvalidation_0-auc:0.90978\tvalidation_1-auc:0.83494\n",
            "[31]\tvalidation_0-auc:0.91054\tvalidation_1-auc:0.83501\n",
            "[32]\tvalidation_0-auc:0.91095\tvalidation_1-auc:0.83517\n",
            "[33]\tvalidation_0-auc:0.91126\tvalidation_1-auc:0.83511\n",
            "[34]\tvalidation_0-auc:0.91192\tvalidation_1-auc:0.83532\n",
            "[35]\tvalidation_0-auc:0.91227\tvalidation_1-auc:0.83484\n",
            "[36]\tvalidation_0-auc:0.91244\tvalidation_1-auc:0.83474\n",
            "[37]\tvalidation_0-auc:0.91302\tvalidation_1-auc:0.83444\n",
            "[38]\tvalidation_0-auc:0.91349\tvalidation_1-auc:0.83505\n",
            "[39]\tvalidation_0-auc:0.91401\tvalidation_1-auc:0.83487\n",
            "[40]\tvalidation_0-auc:0.91433\tvalidation_1-auc:0.83490\n",
            "[41]\tvalidation_0-auc:0.91494\tvalidation_1-auc:0.83438\n",
            "[42]\tvalidation_0-auc:0.91525\tvalidation_1-auc:0.83418\n",
            "[43]\tvalidation_0-auc:0.91582\tvalidation_1-auc:0.83441\n",
            "[44]\tvalidation_0-auc:0.91598\tvalidation_1-auc:0.83433\n",
            "[45]\tvalidation_0-auc:0.91607\tvalidation_1-auc:0.83430\n",
            "[46]\tvalidation_0-auc:0.91620\tvalidation_1-auc:0.83404\n",
            "[47]\tvalidation_0-auc:0.91664\tvalidation_1-auc:0.83423\n",
            "[48]\tvalidation_0-auc:0.91690\tvalidation_1-auc:0.83407\n",
            "[49]\tvalidation_0-auc:0.91772\tvalidation_1-auc:0.83393\n",
            "[50]\tvalidation_0-auc:0.91825\tvalidation_1-auc:0.83382\n",
            "[51]\tvalidation_0-auc:0.91845\tvalidation_1-auc:0.83377\n",
            "[52]\tvalidation_0-auc:0.91865\tvalidation_1-auc:0.83374\n",
            "[53]\tvalidation_0-auc:0.91881\tvalidation_1-auc:0.83355\n",
            "[54]\tvalidation_0-auc:0.91889\tvalidation_1-auc:0.83328\n",
            "[55]\tvalidation_0-auc:0.91935\tvalidation_1-auc:0.83307\n",
            "[56]\tvalidation_0-auc:0.91944\tvalidation_1-auc:0.83301\n",
            "[57]\tvalidation_0-auc:0.92030\tvalidation_1-auc:0.83241\n",
            "[58]\tvalidation_0-auc:0.92114\tvalidation_1-auc:0.83209\n",
            "[59]\tvalidation_0-auc:0.92144\tvalidation_1-auc:0.83202\n",
            "[60]\tvalidation_0-auc:0.92212\tvalidation_1-auc:0.83187\n",
            "[61]\tvalidation_0-auc:0.92229\tvalidation_1-auc:0.83188\n",
            "[62]\tvalidation_0-auc:0.92250\tvalidation_1-auc:0.83177\n",
            "[63]\tvalidation_0-auc:0.92268\tvalidation_1-auc:0.83168\n",
            "[64]\tvalidation_0-auc:0.92295\tvalidation_1-auc:0.83150\n",
            "[0]\tvalidation_0-auc:0.85100\tvalidation_1-auc:0.81198\n",
            "[1]\tvalidation_0-auc:0.85774\tvalidation_1-auc:0.82408\n",
            "[2]\tvalidation_0-auc:0.86184\tvalidation_1-auc:0.81869\n",
            "[3]\tvalidation_0-auc:0.86637\tvalidation_1-auc:0.82351\n",
            "[4]\tvalidation_0-auc:0.86966\tvalidation_1-auc:0.82411\n",
            "[5]\tvalidation_0-auc:0.87264\tvalidation_1-auc:0.82694\n",
            "[6]\tvalidation_0-auc:0.87648\tvalidation_1-auc:0.82884\n",
            "[7]\tvalidation_0-auc:0.87982\tvalidation_1-auc:0.82691\n",
            "[8]\tvalidation_0-auc:0.88266\tvalidation_1-auc:0.82804\n",
            "[9]\tvalidation_0-auc:0.88315\tvalidation_1-auc:0.82699\n",
            "[10]\tvalidation_0-auc:0.88570\tvalidation_1-auc:0.82888\n",
            "[11]\tvalidation_0-auc:0.88748\tvalidation_1-auc:0.82987\n",
            "[12]\tvalidation_0-auc:0.89016\tvalidation_1-auc:0.83093\n",
            "[13]\tvalidation_0-auc:0.89148\tvalidation_1-auc:0.83188\n",
            "[14]\tvalidation_0-auc:0.89334\tvalidation_1-auc:0.83264\n",
            "[15]\tvalidation_0-auc:0.89508\tvalidation_1-auc:0.83124\n",
            "[16]\tvalidation_0-auc:0.89662\tvalidation_1-auc:0.83064\n",
            "[17]\tvalidation_0-auc:0.89790\tvalidation_1-auc:0.83189\n",
            "[18]\tvalidation_0-auc:0.89889\tvalidation_1-auc:0.83274\n",
            "[19]\tvalidation_0-auc:0.89997\tvalidation_1-auc:0.83280\n",
            "[20]\tvalidation_0-auc:0.90134\tvalidation_1-auc:0.83207\n",
            "[21]\tvalidation_0-auc:0.90199\tvalidation_1-auc:0.83163\n",
            "[22]\tvalidation_0-auc:0.90323\tvalidation_1-auc:0.83165\n",
            "[23]\tvalidation_0-auc:0.90392\tvalidation_1-auc:0.83178\n",
            "[24]\tvalidation_0-auc:0.90449\tvalidation_1-auc:0.83181\n",
            "[25]\tvalidation_0-auc:0.90549\tvalidation_1-auc:0.83200\n",
            "[26]\tvalidation_0-auc:0.90612\tvalidation_1-auc:0.83200\n",
            "[27]\tvalidation_0-auc:0.90689\tvalidation_1-auc:0.83210\n",
            "[28]\tvalidation_0-auc:0.90764\tvalidation_1-auc:0.83159\n",
            "[29]\tvalidation_0-auc:0.90820\tvalidation_1-auc:0.83216\n",
            "[30]\tvalidation_0-auc:0.90881\tvalidation_1-auc:0.83230\n",
            "[31]\tvalidation_0-auc:0.90961\tvalidation_1-auc:0.83215\n",
            "[32]\tvalidation_0-auc:0.91008\tvalidation_1-auc:0.83270\n",
            "[33]\tvalidation_0-auc:0.91056\tvalidation_1-auc:0.83230\n",
            "[34]\tvalidation_0-auc:0.91142\tvalidation_1-auc:0.83218\n",
            "[35]\tvalidation_0-auc:0.91201\tvalidation_1-auc:0.83260\n",
            "[36]\tvalidation_0-auc:0.91260\tvalidation_1-auc:0.83258\n",
            "[37]\tvalidation_0-auc:0.91283\tvalidation_1-auc:0.83250\n",
            "[38]\tvalidation_0-auc:0.91362\tvalidation_1-auc:0.83232\n",
            "[39]\tvalidation_0-auc:0.91387\tvalidation_1-auc:0.83226\n",
            "[40]\tvalidation_0-auc:0.91428\tvalidation_1-auc:0.83221\n",
            "[41]\tvalidation_0-auc:0.91470\tvalidation_1-auc:0.83193\n",
            "[42]\tvalidation_0-auc:0.91514\tvalidation_1-auc:0.83160\n",
            "[43]\tvalidation_0-auc:0.91546\tvalidation_1-auc:0.83149\n",
            "[44]\tvalidation_0-auc:0.91561\tvalidation_1-auc:0.83131\n",
            "[45]\tvalidation_0-auc:0.91605\tvalidation_1-auc:0.83134\n",
            "[46]\tvalidation_0-auc:0.91637\tvalidation_1-auc:0.83131\n",
            "[47]\tvalidation_0-auc:0.91741\tvalidation_1-auc:0.83084\n",
            "[48]\tvalidation_0-auc:0.91800\tvalidation_1-auc:0.83075\n",
            "[0]\tvalidation_0-auc:0.82893\tvalidation_1-auc:0.79630\n",
            "[1]\tvalidation_0-auc:0.84240\tvalidation_1-auc:0.81208\n",
            "[2]\tvalidation_0-auc:0.83924\tvalidation_1-auc:0.81000\n",
            "[3]\tvalidation_0-auc:0.84806\tvalidation_1-auc:0.81881\n",
            "[4]\tvalidation_0-auc:0.84980\tvalidation_1-auc:0.82061\n",
            "[5]\tvalidation_0-auc:0.85183\tvalidation_1-auc:0.82251\n",
            "[6]\tvalidation_0-auc:0.85489\tvalidation_1-auc:0.82518\n",
            "[7]\tvalidation_0-auc:0.85602\tvalidation_1-auc:0.82659\n",
            "[8]\tvalidation_0-auc:0.85787\tvalidation_1-auc:0.82809\n",
            "[9]\tvalidation_0-auc:0.85701\tvalidation_1-auc:0.82786\n",
            "[10]\tvalidation_0-auc:0.85922\tvalidation_1-auc:0.83002\n",
            "[11]\tvalidation_0-auc:0.86017\tvalidation_1-auc:0.83089\n",
            "[12]\tvalidation_0-auc:0.86220\tvalidation_1-auc:0.83171\n",
            "[13]\tvalidation_0-auc:0.86369\tvalidation_1-auc:0.83217\n",
            "[14]\tvalidation_0-auc:0.86461\tvalidation_1-auc:0.83209\n",
            "[15]\tvalidation_0-auc:0.86529\tvalidation_1-auc:0.83308\n",
            "[16]\tvalidation_0-auc:0.86645\tvalidation_1-auc:0.83230\n",
            "[17]\tvalidation_0-auc:0.86702\tvalidation_1-auc:0.83227\n",
            "[18]\tvalidation_0-auc:0.86752\tvalidation_1-auc:0.83243\n",
            "[19]\tvalidation_0-auc:0.86825\tvalidation_1-auc:0.83238\n",
            "[20]\tvalidation_0-auc:0.86848\tvalidation_1-auc:0.83263\n",
            "[21]\tvalidation_0-auc:0.86912\tvalidation_1-auc:0.83211\n",
            "[22]\tvalidation_0-auc:0.86976\tvalidation_1-auc:0.83253\n",
            "[23]\tvalidation_0-auc:0.87070\tvalidation_1-auc:0.83305\n",
            "[24]\tvalidation_0-auc:0.87143\tvalidation_1-auc:0.83356\n",
            "[25]\tvalidation_0-auc:0.87147\tvalidation_1-auc:0.83342\n",
            "[26]\tvalidation_0-auc:0.87222\tvalidation_1-auc:0.83337\n",
            "[27]\tvalidation_0-auc:0.87284\tvalidation_1-auc:0.83372\n",
            "[28]\tvalidation_0-auc:0.87349\tvalidation_1-auc:0.83348\n",
            "[29]\tvalidation_0-auc:0.87441\tvalidation_1-auc:0.83336\n",
            "[30]\tvalidation_0-auc:0.87508\tvalidation_1-auc:0.83357\n",
            "[31]\tvalidation_0-auc:0.87565\tvalidation_1-auc:0.83371\n",
            "[32]\tvalidation_0-auc:0.87631\tvalidation_1-auc:0.83394\n",
            "[33]\tvalidation_0-auc:0.87704\tvalidation_1-auc:0.83379\n",
            "[34]\tvalidation_0-auc:0.87753\tvalidation_1-auc:0.83388\n",
            "[35]\tvalidation_0-auc:0.87792\tvalidation_1-auc:0.83402\n",
            "[36]\tvalidation_0-auc:0.87820\tvalidation_1-auc:0.83438\n",
            "[37]\tvalidation_0-auc:0.87889\tvalidation_1-auc:0.83432\n",
            "[38]\tvalidation_0-auc:0.87922\tvalidation_1-auc:0.83436\n",
            "[39]\tvalidation_0-auc:0.87969\tvalidation_1-auc:0.83464\n",
            "[40]\tvalidation_0-auc:0.88004\tvalidation_1-auc:0.83502\n",
            "[41]\tvalidation_0-auc:0.88003\tvalidation_1-auc:0.83495\n",
            "[42]\tvalidation_0-auc:0.88048\tvalidation_1-auc:0.83505\n",
            "[43]\tvalidation_0-auc:0.88065\tvalidation_1-auc:0.83550\n",
            "[44]\tvalidation_0-auc:0.88093\tvalidation_1-auc:0.83530\n",
            "[45]\tvalidation_0-auc:0.88120\tvalidation_1-auc:0.83559\n",
            "[46]\tvalidation_0-auc:0.88149\tvalidation_1-auc:0.83541\n",
            "[47]\tvalidation_0-auc:0.88167\tvalidation_1-auc:0.83555\n",
            "[48]\tvalidation_0-auc:0.88217\tvalidation_1-auc:0.83554\n",
            "[49]\tvalidation_0-auc:0.88242\tvalidation_1-auc:0.83554\n",
            "[50]\tvalidation_0-auc:0.88262\tvalidation_1-auc:0.83566\n",
            "[51]\tvalidation_0-auc:0.88267\tvalidation_1-auc:0.83555\n",
            "[52]\tvalidation_0-auc:0.88273\tvalidation_1-auc:0.83549\n",
            "[53]\tvalidation_0-auc:0.88312\tvalidation_1-auc:0.83569\n",
            "[54]\tvalidation_0-auc:0.88357\tvalidation_1-auc:0.83559\n",
            "[55]\tvalidation_0-auc:0.88393\tvalidation_1-auc:0.83542\n",
            "[56]\tvalidation_0-auc:0.88464\tvalidation_1-auc:0.83531\n",
            "[57]\tvalidation_0-auc:0.88490\tvalidation_1-auc:0.83528\n",
            "[58]\tvalidation_0-auc:0.88508\tvalidation_1-auc:0.83517\n",
            "[59]\tvalidation_0-auc:0.88514\tvalidation_1-auc:0.83517\n",
            "[60]\tvalidation_0-auc:0.88524\tvalidation_1-auc:0.83495\n",
            "[61]\tvalidation_0-auc:0.88537\tvalidation_1-auc:0.83494\n",
            "[62]\tvalidation_0-auc:0.88567\tvalidation_1-auc:0.83521\n",
            "[63]\tvalidation_0-auc:0.88589\tvalidation_1-auc:0.83540\n",
            "[64]\tvalidation_0-auc:0.88604\tvalidation_1-auc:0.83506\n",
            "[65]\tvalidation_0-auc:0.88619\tvalidation_1-auc:0.83490\n",
            "[66]\tvalidation_0-auc:0.88627\tvalidation_1-auc:0.83476\n",
            "[67]\tvalidation_0-auc:0.88665\tvalidation_1-auc:0.83452\n",
            "[68]\tvalidation_0-auc:0.88688\tvalidation_1-auc:0.83430\n",
            "[69]\tvalidation_0-auc:0.88696\tvalidation_1-auc:0.83417\n",
            "[70]\tvalidation_0-auc:0.88736\tvalidation_1-auc:0.83384\n",
            "[71]\tvalidation_0-auc:0.88746\tvalidation_1-auc:0.83372\n",
            "[72]\tvalidation_0-auc:0.88793\tvalidation_1-auc:0.83350\n",
            "[73]\tvalidation_0-auc:0.88806\tvalidation_1-auc:0.83335\n",
            "[74]\tvalidation_0-auc:0.88849\tvalidation_1-auc:0.83331\n",
            "[75]\tvalidation_0-auc:0.88850\tvalidation_1-auc:0.83329\n",
            "[76]\tvalidation_0-auc:0.88913\tvalidation_1-auc:0.83340\n",
            "[77]\tvalidation_0-auc:0.88965\tvalidation_1-auc:0.83303\n",
            "[78]\tvalidation_0-auc:0.88979\tvalidation_1-auc:0.83295\n",
            "[79]\tvalidation_0-auc:0.88997\tvalidation_1-auc:0.83284\n",
            "[80]\tvalidation_0-auc:0.89005\tvalidation_1-auc:0.83271\n",
            "[81]\tvalidation_0-auc:0.89024\tvalidation_1-auc:0.83250\n",
            "[82]\tvalidation_0-auc:0.89049\tvalidation_1-auc:0.83238\n",
            "[0]\tvalidation_0-auc:0.83113\tvalidation_1-auc:0.81691\n",
            "[1]\tvalidation_0-auc:0.84052\tvalidation_1-auc:0.82192\n",
            "[2]\tvalidation_0-auc:0.83922\tvalidation_1-auc:0.81675\n",
            "[3]\tvalidation_0-auc:0.84688\tvalidation_1-auc:0.82266\n",
            "[4]\tvalidation_0-auc:0.85101\tvalidation_1-auc:0.82783\n",
            "[5]\tvalidation_0-auc:0.85380\tvalidation_1-auc:0.82974\n",
            "[6]\tvalidation_0-auc:0.85623\tvalidation_1-auc:0.82991\n",
            "[7]\tvalidation_0-auc:0.85714\tvalidation_1-auc:0.82862\n",
            "[8]\tvalidation_0-auc:0.85856\tvalidation_1-auc:0.83058\n",
            "[9]\tvalidation_0-auc:0.85684\tvalidation_1-auc:0.82913\n",
            "[10]\tvalidation_0-auc:0.85920\tvalidation_1-auc:0.83070\n",
            "[11]\tvalidation_0-auc:0.86083\tvalidation_1-auc:0.83122\n",
            "[12]\tvalidation_0-auc:0.86272\tvalidation_1-auc:0.83185\n",
            "[13]\tvalidation_0-auc:0.86375\tvalidation_1-auc:0.83245\n",
            "[14]\tvalidation_0-auc:0.86416\tvalidation_1-auc:0.83290\n",
            "[15]\tvalidation_0-auc:0.86442\tvalidation_1-auc:0.83213\n",
            "[16]\tvalidation_0-auc:0.86620\tvalidation_1-auc:0.83324\n",
            "[17]\tvalidation_0-auc:0.86701\tvalidation_1-auc:0.83349\n",
            "[18]\tvalidation_0-auc:0.86794\tvalidation_1-auc:0.83397\n",
            "[19]\tvalidation_0-auc:0.86911\tvalidation_1-auc:0.83509\n",
            "[20]\tvalidation_0-auc:0.87009\tvalidation_1-auc:0.83501\n",
            "[21]\tvalidation_0-auc:0.87070\tvalidation_1-auc:0.83487\n",
            "[22]\tvalidation_0-auc:0.87117\tvalidation_1-auc:0.83540\n",
            "[23]\tvalidation_0-auc:0.87196\tvalidation_1-auc:0.83550\n",
            "[24]\tvalidation_0-auc:0.87249\tvalidation_1-auc:0.83546\n",
            "[25]\tvalidation_0-auc:0.87286\tvalidation_1-auc:0.83577\n",
            "[26]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.83594\n",
            "[27]\tvalidation_0-auc:0.87431\tvalidation_1-auc:0.83599\n",
            "[28]\tvalidation_0-auc:0.87482\tvalidation_1-auc:0.83580\n",
            "[29]\tvalidation_0-auc:0.87516\tvalidation_1-auc:0.83567\n",
            "[30]\tvalidation_0-auc:0.87565\tvalidation_1-auc:0.83625\n",
            "[31]\tvalidation_0-auc:0.87645\tvalidation_1-auc:0.83658\n",
            "[32]\tvalidation_0-auc:0.87697\tvalidation_1-auc:0.83675\n",
            "[33]\tvalidation_0-auc:0.87724\tvalidation_1-auc:0.83676\n",
            "[34]\tvalidation_0-auc:0.87771\tvalidation_1-auc:0.83674\n",
            "[35]\tvalidation_0-auc:0.87822\tvalidation_1-auc:0.83679\n",
            "[36]\tvalidation_0-auc:0.87837\tvalidation_1-auc:0.83700\n",
            "[37]\tvalidation_0-auc:0.87888\tvalidation_1-auc:0.83703\n",
            "[38]\tvalidation_0-auc:0.87929\tvalidation_1-auc:0.83730\n",
            "[39]\tvalidation_0-auc:0.87961\tvalidation_1-auc:0.83746\n",
            "[40]\tvalidation_0-auc:0.88038\tvalidation_1-auc:0.83742\n",
            "[41]\tvalidation_0-auc:0.88067\tvalidation_1-auc:0.83740\n",
            "[42]\tvalidation_0-auc:0.88154\tvalidation_1-auc:0.83758\n",
            "[43]\tvalidation_0-auc:0.88183\tvalidation_1-auc:0.83743\n",
            "[44]\tvalidation_0-auc:0.88242\tvalidation_1-auc:0.83768\n",
            "[45]\tvalidation_0-auc:0.88257\tvalidation_1-auc:0.83771\n",
            "[46]\tvalidation_0-auc:0.88302\tvalidation_1-auc:0.83772\n",
            "[47]\tvalidation_0-auc:0.88334\tvalidation_1-auc:0.83759\n",
            "[48]\tvalidation_0-auc:0.88354\tvalidation_1-auc:0.83752\n",
            "[49]\tvalidation_0-auc:0.88378\tvalidation_1-auc:0.83745\n",
            "[50]\tvalidation_0-auc:0.88407\tvalidation_1-auc:0.83737\n",
            "[51]\tvalidation_0-auc:0.88405\tvalidation_1-auc:0.83718\n",
            "[52]\tvalidation_0-auc:0.88474\tvalidation_1-auc:0.83709\n",
            "[53]\tvalidation_0-auc:0.88483\tvalidation_1-auc:0.83718\n",
            "[54]\tvalidation_0-auc:0.88511\tvalidation_1-auc:0.83703\n",
            "[55]\tvalidation_0-auc:0.88556\tvalidation_1-auc:0.83703\n",
            "[56]\tvalidation_0-auc:0.88577\tvalidation_1-auc:0.83703\n",
            "[57]\tvalidation_0-auc:0.88629\tvalidation_1-auc:0.83737\n",
            "[58]\tvalidation_0-auc:0.88660\tvalidation_1-auc:0.83736\n",
            "[59]\tvalidation_0-auc:0.88670\tvalidation_1-auc:0.83741\n",
            "[60]\tvalidation_0-auc:0.88674\tvalidation_1-auc:0.83734\n",
            "[61]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.83771\n",
            "[62]\tvalidation_0-auc:0.88716\tvalidation_1-auc:0.83781\n",
            "[63]\tvalidation_0-auc:0.88773\tvalidation_1-auc:0.83759\n",
            "[64]\tvalidation_0-auc:0.88809\tvalidation_1-auc:0.83766\n",
            "[65]\tvalidation_0-auc:0.88822\tvalidation_1-auc:0.83764\n",
            "[66]\tvalidation_0-auc:0.88852\tvalidation_1-auc:0.83746\n",
            "[67]\tvalidation_0-auc:0.88868\tvalidation_1-auc:0.83721\n",
            "[68]\tvalidation_0-auc:0.88888\tvalidation_1-auc:0.83724\n",
            "[69]\tvalidation_0-auc:0.88917\tvalidation_1-auc:0.83728\n",
            "[70]\tvalidation_0-auc:0.88931\tvalidation_1-auc:0.83713\n",
            "[71]\tvalidation_0-auc:0.88937\tvalidation_1-auc:0.83710\n",
            "[72]\tvalidation_0-auc:0.88953\tvalidation_1-auc:0.83710\n",
            "[73]\tvalidation_0-auc:0.88969\tvalidation_1-auc:0.83711\n",
            "[74]\tvalidation_0-auc:0.88986\tvalidation_1-auc:0.83694\n",
            "[75]\tvalidation_0-auc:0.89043\tvalidation_1-auc:0.83686\n",
            "[76]\tvalidation_0-auc:0.89076\tvalidation_1-auc:0.83689\n",
            "[77]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83685\n",
            "[78]\tvalidation_0-auc:0.89138\tvalidation_1-auc:0.83694\n",
            "[79]\tvalidation_0-auc:0.89151\tvalidation_1-auc:0.83704\n",
            "[80]\tvalidation_0-auc:0.89174\tvalidation_1-auc:0.83690\n",
            "[81]\tvalidation_0-auc:0.89190\tvalidation_1-auc:0.83689\n",
            "[82]\tvalidation_0-auc:0.89193\tvalidation_1-auc:0.83681\n",
            "[83]\tvalidation_0-auc:0.89199\tvalidation_1-auc:0.83680\n",
            "[84]\tvalidation_0-auc:0.89199\tvalidation_1-auc:0.83673\n",
            "[85]\tvalidation_0-auc:0.89230\tvalidation_1-auc:0.83674\n",
            "[86]\tvalidation_0-auc:0.89244\tvalidation_1-auc:0.83663\n",
            "[87]\tvalidation_0-auc:0.89250\tvalidation_1-auc:0.83662\n",
            "[88]\tvalidation_0-auc:0.89285\tvalidation_1-auc:0.83636\n",
            "[89]\tvalidation_0-auc:0.89311\tvalidation_1-auc:0.83633\n",
            "[90]\tvalidation_0-auc:0.89355\tvalidation_1-auc:0.83638\n",
            "[91]\tvalidation_0-auc:0.89366\tvalidation_1-auc:0.83629\n",
            "[0]\tvalidation_0-auc:0.83447\tvalidation_1-auc:0.81239\n",
            "[1]\tvalidation_0-auc:0.84221\tvalidation_1-auc:0.82211\n",
            "[2]\tvalidation_0-auc:0.84539\tvalidation_1-auc:0.81970\n",
            "[3]\tvalidation_0-auc:0.84854\tvalidation_1-auc:0.82351\n",
            "[4]\tvalidation_0-auc:0.85069\tvalidation_1-auc:0.82645\n",
            "[5]\tvalidation_0-auc:0.85177\tvalidation_1-auc:0.82804\n",
            "[6]\tvalidation_0-auc:0.85318\tvalidation_1-auc:0.82826\n",
            "[7]\tvalidation_0-auc:0.85462\tvalidation_1-auc:0.82710\n",
            "[8]\tvalidation_0-auc:0.85552\tvalidation_1-auc:0.82710\n",
            "[9]\tvalidation_0-auc:0.85603\tvalidation_1-auc:0.82664\n",
            "[10]\tvalidation_0-auc:0.85827\tvalidation_1-auc:0.82970\n",
            "[11]\tvalidation_0-auc:0.86069\tvalidation_1-auc:0.83133\n",
            "[12]\tvalidation_0-auc:0.86234\tvalidation_1-auc:0.83175\n",
            "[13]\tvalidation_0-auc:0.86277\tvalidation_1-auc:0.83222\n",
            "[14]\tvalidation_0-auc:0.86349\tvalidation_1-auc:0.83266\n",
            "[15]\tvalidation_0-auc:0.86437\tvalidation_1-auc:0.83269\n",
            "[16]\tvalidation_0-auc:0.86547\tvalidation_1-auc:0.83346\n",
            "[17]\tvalidation_0-auc:0.86675\tvalidation_1-auc:0.83449\n",
            "[18]\tvalidation_0-auc:0.86784\tvalidation_1-auc:0.83478\n",
            "[19]\tvalidation_0-auc:0.86895\tvalidation_1-auc:0.83582\n",
            "[20]\tvalidation_0-auc:0.86962\tvalidation_1-auc:0.83528\n",
            "[21]\tvalidation_0-auc:0.86982\tvalidation_1-auc:0.83464\n",
            "[22]\tvalidation_0-auc:0.87083\tvalidation_1-auc:0.83486\n",
            "[23]\tvalidation_0-auc:0.87120\tvalidation_1-auc:0.83535\n",
            "[24]\tvalidation_0-auc:0.87177\tvalidation_1-auc:0.83533\n",
            "[25]\tvalidation_0-auc:0.87241\tvalidation_1-auc:0.83604\n",
            "[26]\tvalidation_0-auc:0.87336\tvalidation_1-auc:0.83641\n",
            "[27]\tvalidation_0-auc:0.87406\tvalidation_1-auc:0.83695\n",
            "[28]\tvalidation_0-auc:0.87451\tvalidation_1-auc:0.83677\n",
            "[29]\tvalidation_0-auc:0.87474\tvalidation_1-auc:0.83690\n",
            "[30]\tvalidation_0-auc:0.87538\tvalidation_1-auc:0.83721\n",
            "[31]\tvalidation_0-auc:0.87578\tvalidation_1-auc:0.83657\n",
            "[32]\tvalidation_0-auc:0.87648\tvalidation_1-auc:0.83666\n",
            "[33]\tvalidation_0-auc:0.87674\tvalidation_1-auc:0.83640\n",
            "[34]\tvalidation_0-auc:0.87726\tvalidation_1-auc:0.83633\n",
            "[35]\tvalidation_0-auc:0.87764\tvalidation_1-auc:0.83666\n",
            "[36]\tvalidation_0-auc:0.87787\tvalidation_1-auc:0.83656\n",
            "[37]\tvalidation_0-auc:0.87848\tvalidation_1-auc:0.83638\n",
            "[38]\tvalidation_0-auc:0.87860\tvalidation_1-auc:0.83652\n",
            "[39]\tvalidation_0-auc:0.87895\tvalidation_1-auc:0.83689\n",
            "[40]\tvalidation_0-auc:0.87924\tvalidation_1-auc:0.83665\n",
            "[41]\tvalidation_0-auc:0.87950\tvalidation_1-auc:0.83644\n",
            "[42]\tvalidation_0-auc:0.88017\tvalidation_1-auc:0.83627\n",
            "[43]\tvalidation_0-auc:0.88045\tvalidation_1-auc:0.83662\n",
            "[44]\tvalidation_0-auc:0.88110\tvalidation_1-auc:0.83672\n",
            "[45]\tvalidation_0-auc:0.88144\tvalidation_1-auc:0.83710\n",
            "[46]\tvalidation_0-auc:0.88228\tvalidation_1-auc:0.83710\n",
            "[47]\tvalidation_0-auc:0.88269\tvalidation_1-auc:0.83712\n",
            "[48]\tvalidation_0-auc:0.88311\tvalidation_1-auc:0.83730\n",
            "[49]\tvalidation_0-auc:0.88354\tvalidation_1-auc:0.83742\n",
            "[50]\tvalidation_0-auc:0.88367\tvalidation_1-auc:0.83755\n",
            "[51]\tvalidation_0-auc:0.88394\tvalidation_1-auc:0.83727\n",
            "[52]\tvalidation_0-auc:0.88441\tvalidation_1-auc:0.83713\n",
            "[53]\tvalidation_0-auc:0.88456\tvalidation_1-auc:0.83709\n",
            "[54]\tvalidation_0-auc:0.88502\tvalidation_1-auc:0.83713\n",
            "[55]\tvalidation_0-auc:0.88556\tvalidation_1-auc:0.83707\n",
            "[56]\tvalidation_0-auc:0.88604\tvalidation_1-auc:0.83706\n",
            "[57]\tvalidation_0-auc:0.88635\tvalidation_1-auc:0.83728\n",
            "[58]\tvalidation_0-auc:0.88695\tvalidation_1-auc:0.83750\n",
            "[59]\tvalidation_0-auc:0.88708\tvalidation_1-auc:0.83785\n",
            "[60]\tvalidation_0-auc:0.88728\tvalidation_1-auc:0.83764\n",
            "[61]\tvalidation_0-auc:0.88747\tvalidation_1-auc:0.83778\n",
            "[62]\tvalidation_0-auc:0.88795\tvalidation_1-auc:0.83790\n",
            "[63]\tvalidation_0-auc:0.88814\tvalidation_1-auc:0.83805\n",
            "[64]\tvalidation_0-auc:0.88860\tvalidation_1-auc:0.83794\n",
            "[65]\tvalidation_0-auc:0.88874\tvalidation_1-auc:0.83787\n",
            "[66]\tvalidation_0-auc:0.88890\tvalidation_1-auc:0.83790\n",
            "[67]\tvalidation_0-auc:0.88931\tvalidation_1-auc:0.83797\n",
            "[68]\tvalidation_0-auc:0.88962\tvalidation_1-auc:0.83801\n",
            "[69]\tvalidation_0-auc:0.88986\tvalidation_1-auc:0.83800\n",
            "[70]\tvalidation_0-auc:0.89023\tvalidation_1-auc:0.83810\n",
            "[71]\tvalidation_0-auc:0.89077\tvalidation_1-auc:0.83803\n",
            "[72]\tvalidation_0-auc:0.89093\tvalidation_1-auc:0.83802\n",
            "[73]\tvalidation_0-auc:0.89100\tvalidation_1-auc:0.83807\n",
            "[74]\tvalidation_0-auc:0.89135\tvalidation_1-auc:0.83813\n",
            "[75]\tvalidation_0-auc:0.89160\tvalidation_1-auc:0.83786\n",
            "[76]\tvalidation_0-auc:0.89218\tvalidation_1-auc:0.83808\n",
            "[77]\tvalidation_0-auc:0.89239\tvalidation_1-auc:0.83808\n",
            "[78]\tvalidation_0-auc:0.89290\tvalidation_1-auc:0.83807\n",
            "[79]\tvalidation_0-auc:0.89355\tvalidation_1-auc:0.83798\n",
            "[80]\tvalidation_0-auc:0.89371\tvalidation_1-auc:0.83800\n",
            "[81]\tvalidation_0-auc:0.89381\tvalidation_1-auc:0.83795\n",
            "[82]\tvalidation_0-auc:0.89401\tvalidation_1-auc:0.83790\n",
            "[83]\tvalidation_0-auc:0.89411\tvalidation_1-auc:0.83771\n",
            "[84]\tvalidation_0-auc:0.89427\tvalidation_1-auc:0.83779\n",
            "[85]\tvalidation_0-auc:0.89457\tvalidation_1-auc:0.83747\n",
            "[86]\tvalidation_0-auc:0.89465\tvalidation_1-auc:0.83745\n",
            "[87]\tvalidation_0-auc:0.89478\tvalidation_1-auc:0.83737\n",
            "[88]\tvalidation_0-auc:0.89485\tvalidation_1-auc:0.83739\n",
            "[89]\tvalidation_0-auc:0.89526\tvalidation_1-auc:0.83716\n",
            "[90]\tvalidation_0-auc:0.89542\tvalidation_1-auc:0.83723\n",
            "[91]\tvalidation_0-auc:0.89578\tvalidation_1-auc:0.83715\n",
            "[92]\tvalidation_0-auc:0.89636\tvalidation_1-auc:0.83710\n",
            "[93]\tvalidation_0-auc:0.89660\tvalidation_1-auc:0.83701\n",
            "[94]\tvalidation_0-auc:0.89688\tvalidation_1-auc:0.83710\n",
            "[95]\tvalidation_0-auc:0.89705\tvalidation_1-auc:0.83717\n",
            "[96]\tvalidation_0-auc:0.89708\tvalidation_1-auc:0.83713\n",
            "[97]\tvalidation_0-auc:0.89716\tvalidation_1-auc:0.83695\n",
            "[98]\tvalidation_0-auc:0.89732\tvalidation_1-auc:0.83700\n",
            "[99]\tvalidation_0-auc:0.89738\tvalidation_1-auc:0.83701\n",
            "[0]\tvalidation_0-auc:0.81792\tvalidation_1-auc:0.79031\n",
            "[1]\tvalidation_0-auc:0.83347\tvalidation_1-auc:0.80916\n",
            "[2]\tvalidation_0-auc:0.83399\tvalidation_1-auc:0.80400\n",
            "[3]\tvalidation_0-auc:0.84378\tvalidation_1-auc:0.81498\n",
            "[4]\tvalidation_0-auc:0.84631\tvalidation_1-auc:0.81801\n",
            "[5]\tvalidation_0-auc:0.84846\tvalidation_1-auc:0.81987\n",
            "[6]\tvalidation_0-auc:0.84975\tvalidation_1-auc:0.82140\n",
            "[7]\tvalidation_0-auc:0.85091\tvalidation_1-auc:0.82147\n",
            "[8]\tvalidation_0-auc:0.85238\tvalidation_1-auc:0.82446\n",
            "[9]\tvalidation_0-auc:0.85451\tvalidation_1-auc:0.82633\n",
            "[10]\tvalidation_0-auc:0.85550\tvalidation_1-auc:0.82774\n",
            "[11]\tvalidation_0-auc:0.85631\tvalidation_1-auc:0.82811\n",
            "[12]\tvalidation_0-auc:0.85735\tvalidation_1-auc:0.82744\n",
            "[13]\tvalidation_0-auc:0.85853\tvalidation_1-auc:0.82747\n",
            "[14]\tvalidation_0-auc:0.85987\tvalidation_1-auc:0.82822\n",
            "[15]\tvalidation_0-auc:0.86082\tvalidation_1-auc:0.82848\n",
            "[16]\tvalidation_0-auc:0.86157\tvalidation_1-auc:0.82871\n",
            "[17]\tvalidation_0-auc:0.86333\tvalidation_1-auc:0.82957\n",
            "[18]\tvalidation_0-auc:0.86431\tvalidation_1-auc:0.83031\n",
            "[19]\tvalidation_0-auc:0.86526\tvalidation_1-auc:0.83025\n",
            "[20]\tvalidation_0-auc:0.86675\tvalidation_1-auc:0.83156\n",
            "[21]\tvalidation_0-auc:0.86776\tvalidation_1-auc:0.83156\n",
            "[22]\tvalidation_0-auc:0.86881\tvalidation_1-auc:0.83221\n",
            "[23]\tvalidation_0-auc:0.86987\tvalidation_1-auc:0.83214\n",
            "[24]\tvalidation_0-auc:0.87017\tvalidation_1-auc:0.83231\n",
            "[25]\tvalidation_0-auc:0.87046\tvalidation_1-auc:0.83223\n",
            "[26]\tvalidation_0-auc:0.87109\tvalidation_1-auc:0.83193\n",
            "[27]\tvalidation_0-auc:0.87194\tvalidation_1-auc:0.83227\n",
            "[28]\tvalidation_0-auc:0.87270\tvalidation_1-auc:0.83334\n",
            "[29]\tvalidation_0-auc:0.87312\tvalidation_1-auc:0.83344\n",
            "[30]\tvalidation_0-auc:0.87371\tvalidation_1-auc:0.83356\n",
            "[31]\tvalidation_0-auc:0.87412\tvalidation_1-auc:0.83356\n",
            "[32]\tvalidation_0-auc:0.87454\tvalidation_1-auc:0.83373\n",
            "[33]\tvalidation_0-auc:0.87473\tvalidation_1-auc:0.83375\n",
            "[34]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.83372\n",
            "[35]\tvalidation_0-auc:0.87528\tvalidation_1-auc:0.83318\n",
            "[36]\tvalidation_0-auc:0.87593\tvalidation_1-auc:0.83319\n",
            "[37]\tvalidation_0-auc:0.87636\tvalidation_1-auc:0.83325\n",
            "[38]\tvalidation_0-auc:0.87645\tvalidation_1-auc:0.83324\n",
            "[39]\tvalidation_0-auc:0.87674\tvalidation_1-auc:0.83329\n",
            "[40]\tvalidation_0-auc:0.87701\tvalidation_1-auc:0.83329\n",
            "[41]\tvalidation_0-auc:0.87728\tvalidation_1-auc:0.83332\n",
            "[42]\tvalidation_0-auc:0.87750\tvalidation_1-auc:0.83328\n",
            "[43]\tvalidation_0-auc:0.87808\tvalidation_1-auc:0.83349\n",
            "[44]\tvalidation_0-auc:0.87836\tvalidation_1-auc:0.83341\n",
            "[45]\tvalidation_0-auc:0.87911\tvalidation_1-auc:0.83346\n",
            "[46]\tvalidation_0-auc:0.87944\tvalidation_1-auc:0.83321\n",
            "[47]\tvalidation_0-auc:0.88013\tvalidation_1-auc:0.83301\n",
            "[48]\tvalidation_0-auc:0.88077\tvalidation_1-auc:0.83320\n",
            "[49]\tvalidation_0-auc:0.88100\tvalidation_1-auc:0.83300\n",
            "[50]\tvalidation_0-auc:0.88130\tvalidation_1-auc:0.83279\n",
            "[51]\tvalidation_0-auc:0.88153\tvalidation_1-auc:0.83274\n",
            "[52]\tvalidation_0-auc:0.88209\tvalidation_1-auc:0.83242\n",
            "[53]\tvalidation_0-auc:0.88241\tvalidation_1-auc:0.83237\n",
            "[54]\tvalidation_0-auc:0.88258\tvalidation_1-auc:0.83255\n",
            "[55]\tvalidation_0-auc:0.88270\tvalidation_1-auc:0.83244\n",
            "[56]\tvalidation_0-auc:0.88319\tvalidation_1-auc:0.83195\n",
            "[57]\tvalidation_0-auc:0.88346\tvalidation_1-auc:0.83191\n",
            "[58]\tvalidation_0-auc:0.88432\tvalidation_1-auc:0.83204\n",
            "[59]\tvalidation_0-auc:0.88506\tvalidation_1-auc:0.83198\n",
            "[60]\tvalidation_0-auc:0.88514\tvalidation_1-auc:0.83184\n",
            "[61]\tvalidation_0-auc:0.88549\tvalidation_1-auc:0.83198\n",
            "[62]\tvalidation_0-auc:0.88578\tvalidation_1-auc:0.83188\n",
            "[0]\tvalidation_0-auc:0.82234\tvalidation_1-auc:0.81043\n",
            "[1]\tvalidation_0-auc:0.82970\tvalidation_1-auc:0.81536\n",
            "[2]\tvalidation_0-auc:0.83212\tvalidation_1-auc:0.81286\n",
            "[3]\tvalidation_0-auc:0.84113\tvalidation_1-auc:0.82165\n",
            "[4]\tvalidation_0-auc:0.84673\tvalidation_1-auc:0.82792\n",
            "[5]\tvalidation_0-auc:0.84887\tvalidation_1-auc:0.82970\n",
            "[6]\tvalidation_0-auc:0.85096\tvalidation_1-auc:0.83211\n",
            "[7]\tvalidation_0-auc:0.85205\tvalidation_1-auc:0.83007\n",
            "[8]\tvalidation_0-auc:0.85385\tvalidation_1-auc:0.83053\n",
            "[9]\tvalidation_0-auc:0.85552\tvalidation_1-auc:0.83167\n",
            "[10]\tvalidation_0-auc:0.85612\tvalidation_1-auc:0.83181\n",
            "[11]\tvalidation_0-auc:0.85680\tvalidation_1-auc:0.83260\n",
            "[12]\tvalidation_0-auc:0.85827\tvalidation_1-auc:0.83380\n",
            "[13]\tvalidation_0-auc:0.85919\tvalidation_1-auc:0.83432\n",
            "[14]\tvalidation_0-auc:0.86103\tvalidation_1-auc:0.83523\n",
            "[15]\tvalidation_0-auc:0.86170\tvalidation_1-auc:0.83544\n",
            "[16]\tvalidation_0-auc:0.86235\tvalidation_1-auc:0.83630\n",
            "[17]\tvalidation_0-auc:0.86351\tvalidation_1-auc:0.83634\n",
            "[18]\tvalidation_0-auc:0.86410\tvalidation_1-auc:0.83659\n",
            "[19]\tvalidation_0-auc:0.86496\tvalidation_1-auc:0.83675\n",
            "[20]\tvalidation_0-auc:0.86637\tvalidation_1-auc:0.83644\n",
            "[21]\tvalidation_0-auc:0.86779\tvalidation_1-auc:0.83643\n",
            "[22]\tvalidation_0-auc:0.86837\tvalidation_1-auc:0.83657\n",
            "[23]\tvalidation_0-auc:0.86884\tvalidation_1-auc:0.83653\n",
            "[24]\tvalidation_0-auc:0.86919\tvalidation_1-auc:0.83681\n",
            "[25]\tvalidation_0-auc:0.86966\tvalidation_1-auc:0.83671\n",
            "[26]\tvalidation_0-auc:0.87069\tvalidation_1-auc:0.83652\n",
            "[27]\tvalidation_0-auc:0.87119\tvalidation_1-auc:0.83679\n",
            "[28]\tvalidation_0-auc:0.87240\tvalidation_1-auc:0.83695\n",
            "[29]\tvalidation_0-auc:0.87271\tvalidation_1-auc:0.83704\n",
            "[30]\tvalidation_0-auc:0.87353\tvalidation_1-auc:0.83696\n",
            "[31]\tvalidation_0-auc:0.87387\tvalidation_1-auc:0.83700\n",
            "[32]\tvalidation_0-auc:0.87480\tvalidation_1-auc:0.83710\n",
            "[33]\tvalidation_0-auc:0.87518\tvalidation_1-auc:0.83744\n",
            "[34]\tvalidation_0-auc:0.87628\tvalidation_1-auc:0.83737\n",
            "[35]\tvalidation_0-auc:0.87647\tvalidation_1-auc:0.83748\n",
            "[36]\tvalidation_0-auc:0.87728\tvalidation_1-auc:0.83765\n",
            "[37]\tvalidation_0-auc:0.87744\tvalidation_1-auc:0.83763\n",
            "[38]\tvalidation_0-auc:0.87800\tvalidation_1-auc:0.83787\n",
            "[39]\tvalidation_0-auc:0.87813\tvalidation_1-auc:0.83800\n",
            "[40]\tvalidation_0-auc:0.87845\tvalidation_1-auc:0.83801\n",
            "[41]\tvalidation_0-auc:0.87857\tvalidation_1-auc:0.83792\n",
            "[42]\tvalidation_0-auc:0.87900\tvalidation_1-auc:0.83769\n",
            "[43]\tvalidation_0-auc:0.87929\tvalidation_1-auc:0.83752\n",
            "[44]\tvalidation_0-auc:0.87948\tvalidation_1-auc:0.83745\n",
            "[45]\tvalidation_0-auc:0.87978\tvalidation_1-auc:0.83736\n",
            "[46]\tvalidation_0-auc:0.88031\tvalidation_1-auc:0.83732\n",
            "[47]\tvalidation_0-auc:0.88070\tvalidation_1-auc:0.83714\n",
            "[48]\tvalidation_0-auc:0.88082\tvalidation_1-auc:0.83706\n",
            "[49]\tvalidation_0-auc:0.88131\tvalidation_1-auc:0.83707\n",
            "[50]\tvalidation_0-auc:0.88145\tvalidation_1-auc:0.83705\n",
            "[51]\tvalidation_0-auc:0.88162\tvalidation_1-auc:0.83703\n",
            "[52]\tvalidation_0-auc:0.88168\tvalidation_1-auc:0.83700\n",
            "[53]\tvalidation_0-auc:0.88223\tvalidation_1-auc:0.83700\n",
            "[54]\tvalidation_0-auc:0.88274\tvalidation_1-auc:0.83702\n",
            "[55]\tvalidation_0-auc:0.88317\tvalidation_1-auc:0.83662\n",
            "[56]\tvalidation_0-auc:0.88330\tvalidation_1-auc:0.83659\n",
            "[57]\tvalidation_0-auc:0.88355\tvalidation_1-auc:0.83658\n",
            "[58]\tvalidation_0-auc:0.88377\tvalidation_1-auc:0.83668\n",
            "[59]\tvalidation_0-auc:0.88426\tvalidation_1-auc:0.83658\n",
            "[60]\tvalidation_0-auc:0.88451\tvalidation_1-auc:0.83656\n",
            "[61]\tvalidation_0-auc:0.88466\tvalidation_1-auc:0.83662\n",
            "[62]\tvalidation_0-auc:0.88488\tvalidation_1-auc:0.83657\n",
            "[63]\tvalidation_0-auc:0.88563\tvalidation_1-auc:0.83654\n",
            "[64]\tvalidation_0-auc:0.88573\tvalidation_1-auc:0.83647\n",
            "[65]\tvalidation_0-auc:0.88626\tvalidation_1-auc:0.83661\n",
            "[66]\tvalidation_0-auc:0.88651\tvalidation_1-auc:0.83659\n",
            "[67]\tvalidation_0-auc:0.88668\tvalidation_1-auc:0.83653\n",
            "[68]\tvalidation_0-auc:0.88751\tvalidation_1-auc:0.83659\n",
            "[69]\tvalidation_0-auc:0.88761\tvalidation_1-auc:0.83640\n",
            "[0]\tvalidation_0-auc:0.82408\tvalidation_1-auc:0.81091\n",
            "[1]\tvalidation_0-auc:0.83511\tvalidation_1-auc:0.81947\n",
            "[2]\tvalidation_0-auc:0.84101\tvalidation_1-auc:0.81915\n",
            "[3]\tvalidation_0-auc:0.84400\tvalidation_1-auc:0.82176\n",
            "[4]\tvalidation_0-auc:0.84633\tvalidation_1-auc:0.82395\n",
            "[5]\tvalidation_0-auc:0.84932\tvalidation_1-auc:0.82949\n",
            "[6]\tvalidation_0-auc:0.85184\tvalidation_1-auc:0.83048\n",
            "[7]\tvalidation_0-auc:0.85264\tvalidation_1-auc:0.83023\n",
            "[8]\tvalidation_0-auc:0.85395\tvalidation_1-auc:0.83118\n",
            "[9]\tvalidation_0-auc:0.85451\tvalidation_1-auc:0.83250\n",
            "[10]\tvalidation_0-auc:0.85572\tvalidation_1-auc:0.83306\n",
            "[11]\tvalidation_0-auc:0.85706\tvalidation_1-auc:0.83406\n",
            "[12]\tvalidation_0-auc:0.85871\tvalidation_1-auc:0.83453\n",
            "[13]\tvalidation_0-auc:0.85896\tvalidation_1-auc:0.83424\n",
            "[14]\tvalidation_0-auc:0.86016\tvalidation_1-auc:0.83534\n",
            "[15]\tvalidation_0-auc:0.86104\tvalidation_1-auc:0.83525\n",
            "[16]\tvalidation_0-auc:0.86183\tvalidation_1-auc:0.83571\n",
            "[17]\tvalidation_0-auc:0.86283\tvalidation_1-auc:0.83617\n",
            "[18]\tvalidation_0-auc:0.86418\tvalidation_1-auc:0.83738\n",
            "[19]\tvalidation_0-auc:0.86502\tvalidation_1-auc:0.83701\n",
            "[20]\tvalidation_0-auc:0.86653\tvalidation_1-auc:0.83654\n",
            "[21]\tvalidation_0-auc:0.86822\tvalidation_1-auc:0.83669\n",
            "[22]\tvalidation_0-auc:0.86923\tvalidation_1-auc:0.83698\n",
            "[23]\tvalidation_0-auc:0.86980\tvalidation_1-auc:0.83731\n",
            "[24]\tvalidation_0-auc:0.87036\tvalidation_1-auc:0.83734\n",
            "[25]\tvalidation_0-auc:0.87108\tvalidation_1-auc:0.83848\n",
            "[26]\tvalidation_0-auc:0.87153\tvalidation_1-auc:0.83826\n",
            "[27]\tvalidation_0-auc:0.87207\tvalidation_1-auc:0.83808\n",
            "[28]\tvalidation_0-auc:0.87300\tvalidation_1-auc:0.83810\n",
            "[29]\tvalidation_0-auc:0.87329\tvalidation_1-auc:0.83784\n",
            "[30]\tvalidation_0-auc:0.87405\tvalidation_1-auc:0.83746\n",
            "[31]\tvalidation_0-auc:0.87500\tvalidation_1-auc:0.83756\n",
            "[32]\tvalidation_0-auc:0.87602\tvalidation_1-auc:0.83784\n",
            "[33]\tvalidation_0-auc:0.87641\tvalidation_1-auc:0.83780\n",
            "[34]\tvalidation_0-auc:0.87718\tvalidation_1-auc:0.83745\n",
            "[35]\tvalidation_0-auc:0.87753\tvalidation_1-auc:0.83763\n",
            "[36]\tvalidation_0-auc:0.87839\tvalidation_1-auc:0.83770\n",
            "[37]\tvalidation_0-auc:0.87862\tvalidation_1-auc:0.83803\n",
            "[38]\tvalidation_0-auc:0.87899\tvalidation_1-auc:0.83793\n",
            "[39]\tvalidation_0-auc:0.87958\tvalidation_1-auc:0.83826\n",
            "[40]\tvalidation_0-auc:0.87969\tvalidation_1-auc:0.83821\n",
            "[41]\tvalidation_0-auc:0.87996\tvalidation_1-auc:0.83821\n",
            "[42]\tvalidation_0-auc:0.88038\tvalidation_1-auc:0.83808\n",
            "[43]\tvalidation_0-auc:0.88078\tvalidation_1-auc:0.83775\n",
            "[44]\tvalidation_0-auc:0.88132\tvalidation_1-auc:0.83800\n",
            "[45]\tvalidation_0-auc:0.88166\tvalidation_1-auc:0.83820\n",
            "[46]\tvalidation_0-auc:0.88183\tvalidation_1-auc:0.83820\n",
            "[47]\tvalidation_0-auc:0.88194\tvalidation_1-auc:0.83841\n",
            "[48]\tvalidation_0-auc:0.88211\tvalidation_1-auc:0.83837\n",
            "[49]\tvalidation_0-auc:0.88220\tvalidation_1-auc:0.83836\n",
            "[50]\tvalidation_0-auc:0.88272\tvalidation_1-auc:0.83847\n",
            "[51]\tvalidation_0-auc:0.88300\tvalidation_1-auc:0.83801\n",
            "[52]\tvalidation_0-auc:0.88350\tvalidation_1-auc:0.83802\n",
            "[53]\tvalidation_0-auc:0.88388\tvalidation_1-auc:0.83782\n",
            "[54]\tvalidation_0-auc:0.88473\tvalidation_1-auc:0.83799\n",
            "[55]\tvalidation_0-auc:0.88535\tvalidation_1-auc:0.83785\n",
            "[0]\tvalidation_0-auc:0.84700\tvalidation_1-auc:0.80636\n",
            "[1]\tvalidation_0-auc:0.85254\tvalidation_1-auc:0.80291\n",
            "[2]\tvalidation_0-auc:0.84979\tvalidation_1-auc:0.79765\n",
            "[3]\tvalidation_0-auc:0.84820\tvalidation_1-auc:0.79333\n",
            "[4]\tvalidation_0-auc:0.86285\tvalidation_1-auc:0.81123\n",
            "[5]\tvalidation_0-auc:0.87009\tvalidation_1-auc:0.81867\n",
            "[6]\tvalidation_0-auc:0.87658\tvalidation_1-auc:0.82430\n",
            "[7]\tvalidation_0-auc:0.87754\tvalidation_1-auc:0.82194\n",
            "[8]\tvalidation_0-auc:0.88290\tvalidation_1-auc:0.82618\n",
            "[9]\tvalidation_0-auc:0.88423\tvalidation_1-auc:0.82453\n",
            "[10]\tvalidation_0-auc:0.88469\tvalidation_1-auc:0.82207\n",
            "[11]\tvalidation_0-auc:0.88954\tvalidation_1-auc:0.82607\n",
            "[12]\tvalidation_0-auc:0.89411\tvalidation_1-auc:0.82689\n",
            "[13]\tvalidation_0-auc:0.89619\tvalidation_1-auc:0.82893\n",
            "[14]\tvalidation_0-auc:0.89836\tvalidation_1-auc:0.83081\n",
            "[15]\tvalidation_0-auc:0.90023\tvalidation_1-auc:0.83070\n",
            "[16]\tvalidation_0-auc:0.90312\tvalidation_1-auc:0.83098\n",
            "[17]\tvalidation_0-auc:0.90528\tvalidation_1-auc:0.82969\n",
            "[18]\tvalidation_0-auc:0.90605\tvalidation_1-auc:0.83012\n",
            "[19]\tvalidation_0-auc:0.90669\tvalidation_1-auc:0.83030\n",
            "[20]\tvalidation_0-auc:0.90816\tvalidation_1-auc:0.82950\n",
            "[21]\tvalidation_0-auc:0.90888\tvalidation_1-auc:0.82906\n",
            "[22]\tvalidation_0-auc:0.90955\tvalidation_1-auc:0.82913\n",
            "[23]\tvalidation_0-auc:0.90986\tvalidation_1-auc:0.82920\n",
            "[24]\tvalidation_0-auc:0.91001\tvalidation_1-auc:0.82868\n",
            "[25]\tvalidation_0-auc:0.91003\tvalidation_1-auc:0.82797\n",
            "[26]\tvalidation_0-auc:0.91035\tvalidation_1-auc:0.82833\n",
            "[27]\tvalidation_0-auc:0.91093\tvalidation_1-auc:0.82823\n",
            "[28]\tvalidation_0-auc:0.91194\tvalidation_1-auc:0.82863\n",
            "[29]\tvalidation_0-auc:0.91217\tvalidation_1-auc:0.82853\n",
            "[30]\tvalidation_0-auc:0.91291\tvalidation_1-auc:0.82852\n",
            "[31]\tvalidation_0-auc:0.91342\tvalidation_1-auc:0.82818\n",
            "[32]\tvalidation_0-auc:0.91371\tvalidation_1-auc:0.82804\n",
            "[33]\tvalidation_0-auc:0.91419\tvalidation_1-auc:0.82777\n",
            "[34]\tvalidation_0-auc:0.91440\tvalidation_1-auc:0.82748\n",
            "[35]\tvalidation_0-auc:0.91533\tvalidation_1-auc:0.82733\n",
            "[36]\tvalidation_0-auc:0.91562\tvalidation_1-auc:0.82683\n",
            "[37]\tvalidation_0-auc:0.91631\tvalidation_1-auc:0.82623\n",
            "[38]\tvalidation_0-auc:0.91780\tvalidation_1-auc:0.82612\n",
            "[39]\tvalidation_0-auc:0.91810\tvalidation_1-auc:0.82570\n",
            "[40]\tvalidation_0-auc:0.91814\tvalidation_1-auc:0.82551\n",
            "[41]\tvalidation_0-auc:0.91838\tvalidation_1-auc:0.82547\n",
            "[42]\tvalidation_0-auc:0.91898\tvalidation_1-auc:0.82548\n",
            "[43]\tvalidation_0-auc:0.91950\tvalidation_1-auc:0.82529\n",
            "[44]\tvalidation_0-auc:0.91960\tvalidation_1-auc:0.82510\n",
            "[45]\tvalidation_0-auc:0.91979\tvalidation_1-auc:0.82498\n",
            "[46]\tvalidation_0-auc:0.92025\tvalidation_1-auc:0.82474\n",
            "[0]\tvalidation_0-auc:0.85038\tvalidation_1-auc:0.81624\n",
            "[1]\tvalidation_0-auc:0.85485\tvalidation_1-auc:0.80876\n",
            "[2]\tvalidation_0-auc:0.85141\tvalidation_1-auc:0.79988\n",
            "[3]\tvalidation_0-auc:0.84889\tvalidation_1-auc:0.79303\n",
            "[4]\tvalidation_0-auc:0.86580\tvalidation_1-auc:0.80978\n",
            "[5]\tvalidation_0-auc:0.87208\tvalidation_1-auc:0.81799\n",
            "[6]\tvalidation_0-auc:0.87857\tvalidation_1-auc:0.82213\n",
            "[7]\tvalidation_0-auc:0.88103\tvalidation_1-auc:0.81868\n",
            "[8]\tvalidation_0-auc:0.88558\tvalidation_1-auc:0.82395\n",
            "[9]\tvalidation_0-auc:0.88631\tvalidation_1-auc:0.82137\n",
            "[10]\tvalidation_0-auc:0.88856\tvalidation_1-auc:0.82019\n",
            "[11]\tvalidation_0-auc:0.89230\tvalidation_1-auc:0.82507\n",
            "[12]\tvalidation_0-auc:0.89703\tvalidation_1-auc:0.82685\n",
            "[13]\tvalidation_0-auc:0.89925\tvalidation_1-auc:0.82912\n",
            "[14]\tvalidation_0-auc:0.90131\tvalidation_1-auc:0.83117\n",
            "[15]\tvalidation_0-auc:0.90286\tvalidation_1-auc:0.83073\n",
            "[16]\tvalidation_0-auc:0.90457\tvalidation_1-auc:0.83198\n",
            "[17]\tvalidation_0-auc:0.90581\tvalidation_1-auc:0.83284\n",
            "[18]\tvalidation_0-auc:0.90756\tvalidation_1-auc:0.83325\n",
            "[19]\tvalidation_0-auc:0.90852\tvalidation_1-auc:0.83425\n",
            "[20]\tvalidation_0-auc:0.90913\tvalidation_1-auc:0.83397\n",
            "[21]\tvalidation_0-auc:0.90981\tvalidation_1-auc:0.83387\n",
            "[22]\tvalidation_0-auc:0.91020\tvalidation_1-auc:0.83414\n",
            "[23]\tvalidation_0-auc:0.91151\tvalidation_1-auc:0.83344\n",
            "[24]\tvalidation_0-auc:0.91172\tvalidation_1-auc:0.83359\n",
            "[25]\tvalidation_0-auc:0.91202\tvalidation_1-auc:0.83353\n",
            "[26]\tvalidation_0-auc:0.91263\tvalidation_1-auc:0.83364\n",
            "[27]\tvalidation_0-auc:0.91323\tvalidation_1-auc:0.83319\n",
            "[28]\tvalidation_0-auc:0.91402\tvalidation_1-auc:0.83281\n",
            "[29]\tvalidation_0-auc:0.91469\tvalidation_1-auc:0.83300\n",
            "[30]\tvalidation_0-auc:0.91518\tvalidation_1-auc:0.83261\n",
            "[31]\tvalidation_0-auc:0.91532\tvalidation_1-auc:0.83254\n",
            "[32]\tvalidation_0-auc:0.91594\tvalidation_1-auc:0.83229\n",
            "[33]\tvalidation_0-auc:0.91606\tvalidation_1-auc:0.83223\n",
            "[34]\tvalidation_0-auc:0.91646\tvalidation_1-auc:0.83205\n",
            "[35]\tvalidation_0-auc:0.91669\tvalidation_1-auc:0.83180\n",
            "[36]\tvalidation_0-auc:0.91693\tvalidation_1-auc:0.83167\n",
            "[37]\tvalidation_0-auc:0.91770\tvalidation_1-auc:0.83155\n",
            "[38]\tvalidation_0-auc:0.91832\tvalidation_1-auc:0.83141\n",
            "[39]\tvalidation_0-auc:0.91916\tvalidation_1-auc:0.83139\n",
            "[40]\tvalidation_0-auc:0.91932\tvalidation_1-auc:0.83131\n",
            "[41]\tvalidation_0-auc:0.91960\tvalidation_1-auc:0.83121\n",
            "[42]\tvalidation_0-auc:0.91984\tvalidation_1-auc:0.83138\n",
            "[43]\tvalidation_0-auc:0.92020\tvalidation_1-auc:0.83129\n",
            "[44]\tvalidation_0-auc:0.92040\tvalidation_1-auc:0.83099\n",
            "[45]\tvalidation_0-auc:0.92068\tvalidation_1-auc:0.83074\n",
            "[46]\tvalidation_0-auc:0.92107\tvalidation_1-auc:0.83049\n",
            "[47]\tvalidation_0-auc:0.92187\tvalidation_1-auc:0.83045\n",
            "[48]\tvalidation_0-auc:0.92297\tvalidation_1-auc:0.83001\n",
            "[49]\tvalidation_0-auc:0.92316\tvalidation_1-auc:0.83001\n",
            "[0]\tvalidation_0-auc:0.85156\tvalidation_1-auc:0.80901\n",
            "[1]\tvalidation_0-auc:0.85730\tvalidation_1-auc:0.80774\n",
            "[2]\tvalidation_0-auc:0.85308\tvalidation_1-auc:0.80093\n",
            "[3]\tvalidation_0-auc:0.84872\tvalidation_1-auc:0.79422\n",
            "[4]\tvalidation_0-auc:0.86404\tvalidation_1-auc:0.81197\n",
            "[5]\tvalidation_0-auc:0.87115\tvalidation_1-auc:0.82210\n",
            "[6]\tvalidation_0-auc:0.87881\tvalidation_1-auc:0.82467\n",
            "[7]\tvalidation_0-auc:0.87958\tvalidation_1-auc:0.82232\n",
            "[8]\tvalidation_0-auc:0.88488\tvalidation_1-auc:0.82763\n",
            "[9]\tvalidation_0-auc:0.88454\tvalidation_1-auc:0.82513\n",
            "[10]\tvalidation_0-auc:0.88676\tvalidation_1-auc:0.82279\n",
            "[11]\tvalidation_0-auc:0.89128\tvalidation_1-auc:0.82632\n",
            "[12]\tvalidation_0-auc:0.89459\tvalidation_1-auc:0.82964\n",
            "[13]\tvalidation_0-auc:0.89636\tvalidation_1-auc:0.83179\n",
            "[14]\tvalidation_0-auc:0.89906\tvalidation_1-auc:0.83272\n",
            "[15]\tvalidation_0-auc:0.90103\tvalidation_1-auc:0.83149\n",
            "[16]\tvalidation_0-auc:0.90173\tvalidation_1-auc:0.83185\n",
            "[17]\tvalidation_0-auc:0.90365\tvalidation_1-auc:0.83335\n",
            "[18]\tvalidation_0-auc:0.90436\tvalidation_1-auc:0.83361\n",
            "[19]\tvalidation_0-auc:0.90539\tvalidation_1-auc:0.83451\n",
            "[20]\tvalidation_0-auc:0.90680\tvalidation_1-auc:0.83428\n",
            "[21]\tvalidation_0-auc:0.90748\tvalidation_1-auc:0.83362\n",
            "[22]\tvalidation_0-auc:0.90873\tvalidation_1-auc:0.83408\n",
            "[23]\tvalidation_0-auc:0.90949\tvalidation_1-auc:0.83465\n",
            "[24]\tvalidation_0-auc:0.91006\tvalidation_1-auc:0.83472\n",
            "[25]\tvalidation_0-auc:0.91061\tvalidation_1-auc:0.83461\n",
            "[26]\tvalidation_0-auc:0.91157\tvalidation_1-auc:0.83434\n",
            "[27]\tvalidation_0-auc:0.91214\tvalidation_1-auc:0.83449\n",
            "[28]\tvalidation_0-auc:0.91306\tvalidation_1-auc:0.83432\n",
            "[29]\tvalidation_0-auc:0.91374\tvalidation_1-auc:0.83409\n",
            "[30]\tvalidation_0-auc:0.91435\tvalidation_1-auc:0.83362\n",
            "[31]\tvalidation_0-auc:0.91472\tvalidation_1-auc:0.83327\n",
            "[32]\tvalidation_0-auc:0.91503\tvalidation_1-auc:0.83385\n",
            "[33]\tvalidation_0-auc:0.91532\tvalidation_1-auc:0.83347\n",
            "[34]\tvalidation_0-auc:0.91604\tvalidation_1-auc:0.83305\n",
            "[35]\tvalidation_0-auc:0.91750\tvalidation_1-auc:0.83309\n",
            "[36]\tvalidation_0-auc:0.91769\tvalidation_1-auc:0.83300\n",
            "[37]\tvalidation_0-auc:0.91801\tvalidation_1-auc:0.83271\n",
            "[38]\tvalidation_0-auc:0.91901\tvalidation_1-auc:0.83297\n",
            "[39]\tvalidation_0-auc:0.91933\tvalidation_1-auc:0.83293\n",
            "[40]\tvalidation_0-auc:0.91971\tvalidation_1-auc:0.83226\n",
            "[41]\tvalidation_0-auc:0.91991\tvalidation_1-auc:0.83198\n",
            "[42]\tvalidation_0-auc:0.92067\tvalidation_1-auc:0.83197\n",
            "[43]\tvalidation_0-auc:0.92223\tvalidation_1-auc:0.83133\n",
            "[44]\tvalidation_0-auc:0.92294\tvalidation_1-auc:0.83088\n",
            "[45]\tvalidation_0-auc:0.92344\tvalidation_1-auc:0.83139\n",
            "[46]\tvalidation_0-auc:0.92379\tvalidation_1-auc:0.83087\n",
            "[47]\tvalidation_0-auc:0.92398\tvalidation_1-auc:0.83090\n",
            "[48]\tvalidation_0-auc:0.92508\tvalidation_1-auc:0.83118\n",
            "[49]\tvalidation_0-auc:0.92522\tvalidation_1-auc:0.83106\n",
            "[50]\tvalidation_0-auc:0.92534\tvalidation_1-auc:0.83101\n",
            "[51]\tvalidation_0-auc:0.92575\tvalidation_1-auc:0.83062\n",
            "[52]\tvalidation_0-auc:0.92593\tvalidation_1-auc:0.82991\n",
            "[53]\tvalidation_0-auc:0.92602\tvalidation_1-auc:0.82973\n",
            "[0]\tvalidation_0-auc:0.82893\tvalidation_1-auc:0.79630\n",
            "[1]\tvalidation_0-auc:0.84186\tvalidation_1-auc:0.81151\n",
            "[2]\tvalidation_0-auc:0.83878\tvalidation_1-auc:0.81018\n",
            "[3]\tvalidation_0-auc:0.84856\tvalidation_1-auc:0.81873\n",
            "[4]\tvalidation_0-auc:0.85082\tvalidation_1-auc:0.82229\n",
            "[5]\tvalidation_0-auc:0.85234\tvalidation_1-auc:0.82412\n",
            "[6]\tvalidation_0-auc:0.85613\tvalidation_1-auc:0.82493\n",
            "[7]\tvalidation_0-auc:0.85812\tvalidation_1-auc:0.82642\n",
            "[8]\tvalidation_0-auc:0.86104\tvalidation_1-auc:0.82779\n",
            "[9]\tvalidation_0-auc:0.86144\tvalidation_1-auc:0.82740\n",
            "[10]\tvalidation_0-auc:0.86383\tvalidation_1-auc:0.82891\n",
            "[11]\tvalidation_0-auc:0.86639\tvalidation_1-auc:0.82975\n",
            "[12]\tvalidation_0-auc:0.86789\tvalidation_1-auc:0.82988\n",
            "[13]\tvalidation_0-auc:0.86882\tvalidation_1-auc:0.83061\n",
            "[14]\tvalidation_0-auc:0.86990\tvalidation_1-auc:0.83184\n",
            "[15]\tvalidation_0-auc:0.87085\tvalidation_1-auc:0.83229\n",
            "[16]\tvalidation_0-auc:0.87194\tvalidation_1-auc:0.83244\n",
            "[17]\tvalidation_0-auc:0.87275\tvalidation_1-auc:0.83217\n",
            "[18]\tvalidation_0-auc:0.87345\tvalidation_1-auc:0.83271\n",
            "[19]\tvalidation_0-auc:0.87434\tvalidation_1-auc:0.83248\n",
            "[20]\tvalidation_0-auc:0.87545\tvalidation_1-auc:0.83261\n",
            "[21]\tvalidation_0-auc:0.87616\tvalidation_1-auc:0.83288\n",
            "[22]\tvalidation_0-auc:0.87649\tvalidation_1-auc:0.83318\n",
            "[23]\tvalidation_0-auc:0.87671\tvalidation_1-auc:0.83305\n",
            "[24]\tvalidation_0-auc:0.87697\tvalidation_1-auc:0.83308\n",
            "[25]\tvalidation_0-auc:0.87742\tvalidation_1-auc:0.83311\n",
            "[26]\tvalidation_0-auc:0.87792\tvalidation_1-auc:0.83251\n",
            "[27]\tvalidation_0-auc:0.87842\tvalidation_1-auc:0.83247\n",
            "[28]\tvalidation_0-auc:0.87970\tvalidation_1-auc:0.83304\n",
            "[29]\tvalidation_0-auc:0.88022\tvalidation_1-auc:0.83317\n",
            "[30]\tvalidation_0-auc:0.88100\tvalidation_1-auc:0.83338\n",
            "[31]\tvalidation_0-auc:0.88231\tvalidation_1-auc:0.83334\n",
            "[32]\tvalidation_0-auc:0.88239\tvalidation_1-auc:0.83306\n",
            "[33]\tvalidation_0-auc:0.88308\tvalidation_1-auc:0.83304\n",
            "[34]\tvalidation_0-auc:0.88325\tvalidation_1-auc:0.83293\n",
            "[35]\tvalidation_0-auc:0.88443\tvalidation_1-auc:0.83263\n",
            "[36]\tvalidation_0-auc:0.88456\tvalidation_1-auc:0.83271\n",
            "[37]\tvalidation_0-auc:0.88560\tvalidation_1-auc:0.83296\n",
            "[38]\tvalidation_0-auc:0.88662\tvalidation_1-auc:0.83250\n",
            "[39]\tvalidation_0-auc:0.88716\tvalidation_1-auc:0.83244\n",
            "[40]\tvalidation_0-auc:0.88754\tvalidation_1-auc:0.83222\n",
            "[41]\tvalidation_0-auc:0.88785\tvalidation_1-auc:0.83186\n",
            "[42]\tvalidation_0-auc:0.88799\tvalidation_1-auc:0.83169\n",
            "[43]\tvalidation_0-auc:0.88813\tvalidation_1-auc:0.83187\n",
            "[44]\tvalidation_0-auc:0.88878\tvalidation_1-auc:0.83172\n",
            "[45]\tvalidation_0-auc:0.88940\tvalidation_1-auc:0.83206\n",
            "[46]\tvalidation_0-auc:0.88983\tvalidation_1-auc:0.83194\n",
            "[47]\tvalidation_0-auc:0.88999\tvalidation_1-auc:0.83183\n",
            "[48]\tvalidation_0-auc:0.89023\tvalidation_1-auc:0.83180\n",
            "[49]\tvalidation_0-auc:0.89093\tvalidation_1-auc:0.83153\n",
            "[50]\tvalidation_0-auc:0.89153\tvalidation_1-auc:0.83105\n",
            "[51]\tvalidation_0-auc:0.89185\tvalidation_1-auc:0.83083\n",
            "[52]\tvalidation_0-auc:0.89223\tvalidation_1-auc:0.83038\n",
            "[53]\tvalidation_0-auc:0.89307\tvalidation_1-auc:0.82996\n",
            "[54]\tvalidation_0-auc:0.89326\tvalidation_1-auc:0.82974\n",
            "[55]\tvalidation_0-auc:0.89340\tvalidation_1-auc:0.82953\n",
            "[56]\tvalidation_0-auc:0.89415\tvalidation_1-auc:0.82890\n",
            "[57]\tvalidation_0-auc:0.89437\tvalidation_1-auc:0.82859\n",
            "[58]\tvalidation_0-auc:0.89468\tvalidation_1-auc:0.82834\n",
            "[59]\tvalidation_0-auc:0.89547\tvalidation_1-auc:0.82812\n",
            "[60]\tvalidation_0-auc:0.89593\tvalidation_1-auc:0.82793\n",
            "[0]\tvalidation_0-auc:0.83113\tvalidation_1-auc:0.81691\n",
            "[1]\tvalidation_0-auc:0.84061\tvalidation_1-auc:0.82215\n",
            "[2]\tvalidation_0-auc:0.84047\tvalidation_1-auc:0.81790\n",
            "[3]\tvalidation_0-auc:0.84876\tvalidation_1-auc:0.82481\n",
            "[4]\tvalidation_0-auc:0.85334\tvalidation_1-auc:0.82624\n",
            "[5]\tvalidation_0-auc:0.85571\tvalidation_1-auc:0.82890\n",
            "[6]\tvalidation_0-auc:0.85763\tvalidation_1-auc:0.82871\n",
            "[7]\tvalidation_0-auc:0.85971\tvalidation_1-auc:0.82770\n",
            "[8]\tvalidation_0-auc:0.86223\tvalidation_1-auc:0.82938\n",
            "[9]\tvalidation_0-auc:0.86130\tvalidation_1-auc:0.82801\n",
            "[10]\tvalidation_0-auc:0.86387\tvalidation_1-auc:0.83073\n",
            "[11]\tvalidation_0-auc:0.86561\tvalidation_1-auc:0.83224\n",
            "[12]\tvalidation_0-auc:0.86803\tvalidation_1-auc:0.83321\n",
            "[13]\tvalidation_0-auc:0.86942\tvalidation_1-auc:0.83425\n",
            "[14]\tvalidation_0-auc:0.87012\tvalidation_1-auc:0.83539\n",
            "[15]\tvalidation_0-auc:0.87185\tvalidation_1-auc:0.83502\n",
            "[16]\tvalidation_0-auc:0.87322\tvalidation_1-auc:0.83634\n",
            "[17]\tvalidation_0-auc:0.87415\tvalidation_1-auc:0.83650\n",
            "[18]\tvalidation_0-auc:0.87478\tvalidation_1-auc:0.83651\n",
            "[19]\tvalidation_0-auc:0.87580\tvalidation_1-auc:0.83702\n",
            "[20]\tvalidation_0-auc:0.87713\tvalidation_1-auc:0.83685\n",
            "[21]\tvalidation_0-auc:0.87757\tvalidation_1-auc:0.83686\n",
            "[22]\tvalidation_0-auc:0.87820\tvalidation_1-auc:0.83742\n",
            "[23]\tvalidation_0-auc:0.87849\tvalidation_1-auc:0.83737\n",
            "[24]\tvalidation_0-auc:0.87969\tvalidation_1-auc:0.83717\n",
            "[25]\tvalidation_0-auc:0.87993\tvalidation_1-auc:0.83717\n",
            "[26]\tvalidation_0-auc:0.88060\tvalidation_1-auc:0.83745\n",
            "[27]\tvalidation_0-auc:0.88125\tvalidation_1-auc:0.83811\n",
            "[28]\tvalidation_0-auc:0.88232\tvalidation_1-auc:0.83806\n",
            "[29]\tvalidation_0-auc:0.88241\tvalidation_1-auc:0.83793\n",
            "[30]\tvalidation_0-auc:0.88274\tvalidation_1-auc:0.83751\n",
            "[31]\tvalidation_0-auc:0.88358\tvalidation_1-auc:0.83753\n",
            "[32]\tvalidation_0-auc:0.88376\tvalidation_1-auc:0.83774\n",
            "[33]\tvalidation_0-auc:0.88428\tvalidation_1-auc:0.83776\n",
            "[34]\tvalidation_0-auc:0.88483\tvalidation_1-auc:0.83764\n",
            "[35]\tvalidation_0-auc:0.88552\tvalidation_1-auc:0.83800\n",
            "[36]\tvalidation_0-auc:0.88570\tvalidation_1-auc:0.83781\n",
            "[37]\tvalidation_0-auc:0.88639\tvalidation_1-auc:0.83769\n",
            "[38]\tvalidation_0-auc:0.88768\tvalidation_1-auc:0.83740\n",
            "[39]\tvalidation_0-auc:0.88780\tvalidation_1-auc:0.83740\n",
            "[40]\tvalidation_0-auc:0.88804\tvalidation_1-auc:0.83757\n",
            "[41]\tvalidation_0-auc:0.88821\tvalidation_1-auc:0.83755\n",
            "[42]\tvalidation_0-auc:0.88864\tvalidation_1-auc:0.83756\n",
            "[43]\tvalidation_0-auc:0.88874\tvalidation_1-auc:0.83757\n",
            "[44]\tvalidation_0-auc:0.88959\tvalidation_1-auc:0.83770\n",
            "[45]\tvalidation_0-auc:0.88987\tvalidation_1-auc:0.83788\n",
            "[46]\tvalidation_0-auc:0.88999\tvalidation_1-auc:0.83784\n",
            "[47]\tvalidation_0-auc:0.89065\tvalidation_1-auc:0.83749\n",
            "[48]\tvalidation_0-auc:0.89113\tvalidation_1-auc:0.83725\n",
            "[49]\tvalidation_0-auc:0.89124\tvalidation_1-auc:0.83722\n",
            "[50]\tvalidation_0-auc:0.89150\tvalidation_1-auc:0.83736\n",
            "[51]\tvalidation_0-auc:0.89162\tvalidation_1-auc:0.83723\n",
            "[52]\tvalidation_0-auc:0.89208\tvalidation_1-auc:0.83718\n",
            "[53]\tvalidation_0-auc:0.89216\tvalidation_1-auc:0.83712\n",
            "[54]\tvalidation_0-auc:0.89238\tvalidation_1-auc:0.83719\n",
            "[55]\tvalidation_0-auc:0.89252\tvalidation_1-auc:0.83709\n",
            "[56]\tvalidation_0-auc:0.89282\tvalidation_1-auc:0.83720\n",
            "[0]\tvalidation_0-auc:0.83447\tvalidation_1-auc:0.81239\n",
            "[1]\tvalidation_0-auc:0.84254\tvalidation_1-auc:0.82269\n",
            "[2]\tvalidation_0-auc:0.84579\tvalidation_1-auc:0.82046\n",
            "[3]\tvalidation_0-auc:0.85012\tvalidation_1-auc:0.82384\n",
            "[4]\tvalidation_0-auc:0.85203\tvalidation_1-auc:0.82519\n",
            "[5]\tvalidation_0-auc:0.85415\tvalidation_1-auc:0.82577\n",
            "[6]\tvalidation_0-auc:0.85705\tvalidation_1-auc:0.82874\n",
            "[7]\tvalidation_0-auc:0.85921\tvalidation_1-auc:0.82749\n",
            "[8]\tvalidation_0-auc:0.86087\tvalidation_1-auc:0.83007\n",
            "[9]\tvalidation_0-auc:0.86221\tvalidation_1-auc:0.82924\n",
            "[10]\tvalidation_0-auc:0.86389\tvalidation_1-auc:0.83091\n",
            "[11]\tvalidation_0-auc:0.86619\tvalidation_1-auc:0.83238\n",
            "[12]\tvalidation_0-auc:0.86767\tvalidation_1-auc:0.83370\n",
            "[13]\tvalidation_0-auc:0.86894\tvalidation_1-auc:0.83529\n",
            "[14]\tvalidation_0-auc:0.86994\tvalidation_1-auc:0.83621\n",
            "[15]\tvalidation_0-auc:0.87177\tvalidation_1-auc:0.83506\n",
            "[16]\tvalidation_0-auc:0.87245\tvalidation_1-auc:0.83560\n",
            "[17]\tvalidation_0-auc:0.87317\tvalidation_1-auc:0.83547\n",
            "[18]\tvalidation_0-auc:0.87376\tvalidation_1-auc:0.83587\n",
            "[19]\tvalidation_0-auc:0.87459\tvalidation_1-auc:0.83621\n",
            "[20]\tvalidation_0-auc:0.87542\tvalidation_1-auc:0.83559\n",
            "[21]\tvalidation_0-auc:0.87594\tvalidation_1-auc:0.83517\n",
            "[22]\tvalidation_0-auc:0.87678\tvalidation_1-auc:0.83600\n",
            "[23]\tvalidation_0-auc:0.87726\tvalidation_1-auc:0.83598\n",
            "[24]\tvalidation_0-auc:0.87865\tvalidation_1-auc:0.83630\n",
            "[25]\tvalidation_0-auc:0.87885\tvalidation_1-auc:0.83634\n",
            "[26]\tvalidation_0-auc:0.87956\tvalidation_1-auc:0.83628\n",
            "[27]\tvalidation_0-auc:0.88047\tvalidation_1-auc:0.83707\n",
            "[28]\tvalidation_0-auc:0.88135\tvalidation_1-auc:0.83723\n",
            "[29]\tvalidation_0-auc:0.88237\tvalidation_1-auc:0.83679\n",
            "[30]\tvalidation_0-auc:0.88293\tvalidation_1-auc:0.83672\n",
            "[31]\tvalidation_0-auc:0.88350\tvalidation_1-auc:0.83683\n",
            "[32]\tvalidation_0-auc:0.88412\tvalidation_1-auc:0.83676\n",
            "[33]\tvalidation_0-auc:0.88440\tvalidation_1-auc:0.83653\n",
            "[34]\tvalidation_0-auc:0.88487\tvalidation_1-auc:0.83645\n",
            "[35]\tvalidation_0-auc:0.88530\tvalidation_1-auc:0.83679\n",
            "[36]\tvalidation_0-auc:0.88654\tvalidation_1-auc:0.83659\n",
            "[37]\tvalidation_0-auc:0.88729\tvalidation_1-auc:0.83632\n",
            "[38]\tvalidation_0-auc:0.88756\tvalidation_1-auc:0.83627\n",
            "[39]\tvalidation_0-auc:0.88799\tvalidation_1-auc:0.83612\n",
            "[40]\tvalidation_0-auc:0.88828\tvalidation_1-auc:0.83624\n",
            "[41]\tvalidation_0-auc:0.88863\tvalidation_1-auc:0.83595\n",
            "[42]\tvalidation_0-auc:0.88917\tvalidation_1-auc:0.83593\n",
            "[43]\tvalidation_0-auc:0.88951\tvalidation_1-auc:0.83602\n",
            "[44]\tvalidation_0-auc:0.88966\tvalidation_1-auc:0.83599\n",
            "[45]\tvalidation_0-auc:0.89002\tvalidation_1-auc:0.83596\n",
            "[46]\tvalidation_0-auc:0.89072\tvalidation_1-auc:0.83601\n",
            "[47]\tvalidation_0-auc:0.89092\tvalidation_1-auc:0.83591\n",
            "[48]\tvalidation_0-auc:0.89213\tvalidation_1-auc:0.83567\n",
            "[49]\tvalidation_0-auc:0.89243\tvalidation_1-auc:0.83595\n",
            "[50]\tvalidation_0-auc:0.89281\tvalidation_1-auc:0.83567\n",
            "[51]\tvalidation_0-auc:0.89427\tvalidation_1-auc:0.83567\n",
            "[52]\tvalidation_0-auc:0.89475\tvalidation_1-auc:0.83541\n",
            "[53]\tvalidation_0-auc:0.89494\tvalidation_1-auc:0.83537\n",
            "[54]\tvalidation_0-auc:0.89517\tvalidation_1-auc:0.83537\n",
            "[55]\tvalidation_0-auc:0.89533\tvalidation_1-auc:0.83522\n",
            "[56]\tvalidation_0-auc:0.89575\tvalidation_1-auc:0.83511\n",
            "[57]\tvalidation_0-auc:0.89612\tvalidation_1-auc:0.83509\n",
            "[58]\tvalidation_0-auc:0.89656\tvalidation_1-auc:0.83498\n",
            "[0]\tvalidation_0-auc:0.84781\tvalidation_1-auc:0.80613\n",
            "[1]\tvalidation_0-auc:0.85915\tvalidation_1-auc:0.81864\n",
            "[2]\tvalidation_0-auc:0.85802\tvalidation_1-auc:0.81433\n",
            "[3]\tvalidation_0-auc:0.86209\tvalidation_1-auc:0.82077\n",
            "[4]\tvalidation_0-auc:0.86589\tvalidation_1-auc:0.82360\n",
            "[5]\tvalidation_0-auc:0.86735\tvalidation_1-auc:0.82410\n",
            "[6]\tvalidation_0-auc:0.86983\tvalidation_1-auc:0.82846\n",
            "[7]\tvalidation_0-auc:0.87201\tvalidation_1-auc:0.82768\n",
            "[8]\tvalidation_0-auc:0.87407\tvalidation_1-auc:0.82853\n",
            "[9]\tvalidation_0-auc:0.87230\tvalidation_1-auc:0.82800\n",
            "[10]\tvalidation_0-auc:0.87393\tvalidation_1-auc:0.82933\n",
            "[11]\tvalidation_0-auc:0.87505\tvalidation_1-auc:0.83054\n",
            "[12]\tvalidation_0-auc:0.87591\tvalidation_1-auc:0.83040\n",
            "[13]\tvalidation_0-auc:0.87736\tvalidation_1-auc:0.83057\n",
            "[14]\tvalidation_0-auc:0.87804\tvalidation_1-auc:0.83080\n",
            "[15]\tvalidation_0-auc:0.87886\tvalidation_1-auc:0.83070\n",
            "[16]\tvalidation_0-auc:0.87981\tvalidation_1-auc:0.83071\n",
            "[17]\tvalidation_0-auc:0.88085\tvalidation_1-auc:0.83099\n",
            "[18]\tvalidation_0-auc:0.88095\tvalidation_1-auc:0.83130\n",
            "[19]\tvalidation_0-auc:0.88163\tvalidation_1-auc:0.83184\n",
            "[20]\tvalidation_0-auc:0.88225\tvalidation_1-auc:0.83180\n",
            "[21]\tvalidation_0-auc:0.88281\tvalidation_1-auc:0.83148\n",
            "[22]\tvalidation_0-auc:0.88337\tvalidation_1-auc:0.83230\n",
            "[23]\tvalidation_0-auc:0.88381\tvalidation_1-auc:0.83239\n",
            "[24]\tvalidation_0-auc:0.88418\tvalidation_1-auc:0.83240\n",
            "[25]\tvalidation_0-auc:0.88415\tvalidation_1-auc:0.83270\n",
            "[26]\tvalidation_0-auc:0.88471\tvalidation_1-auc:0.83282\n",
            "[27]\tvalidation_0-auc:0.88535\tvalidation_1-auc:0.83318\n",
            "[28]\tvalidation_0-auc:0.88565\tvalidation_1-auc:0.83327\n",
            "[29]\tvalidation_0-auc:0.88572\tvalidation_1-auc:0.83255\n",
            "[30]\tvalidation_0-auc:0.88657\tvalidation_1-auc:0.83260\n",
            "[31]\tvalidation_0-auc:0.88724\tvalidation_1-auc:0.83213\n",
            "[32]\tvalidation_0-auc:0.88821\tvalidation_1-auc:0.83212\n",
            "[33]\tvalidation_0-auc:0.88839\tvalidation_1-auc:0.83153\n",
            "[34]\tvalidation_0-auc:0.88854\tvalidation_1-auc:0.83125\n",
            "[35]\tvalidation_0-auc:0.88951\tvalidation_1-auc:0.83194\n",
            "[36]\tvalidation_0-auc:0.89048\tvalidation_1-auc:0.83197\n",
            "[37]\tvalidation_0-auc:0.89091\tvalidation_1-auc:0.83165\n",
            "[38]\tvalidation_0-auc:0.89191\tvalidation_1-auc:0.83214\n",
            "[39]\tvalidation_0-auc:0.89273\tvalidation_1-auc:0.83199\n",
            "[40]\tvalidation_0-auc:0.89311\tvalidation_1-auc:0.83167\n",
            "[41]\tvalidation_0-auc:0.89337\tvalidation_1-auc:0.83134\n",
            "[42]\tvalidation_0-auc:0.89363\tvalidation_1-auc:0.83111\n",
            "[43]\tvalidation_0-auc:0.89436\tvalidation_1-auc:0.83145\n",
            "[44]\tvalidation_0-auc:0.89496\tvalidation_1-auc:0.83083\n",
            "[45]\tvalidation_0-auc:0.89534\tvalidation_1-auc:0.83127\n",
            "[46]\tvalidation_0-auc:0.89597\tvalidation_1-auc:0.83091\n",
            "[47]\tvalidation_0-auc:0.89616\tvalidation_1-auc:0.83073\n",
            "[48]\tvalidation_0-auc:0.89687\tvalidation_1-auc:0.83100\n",
            "[49]\tvalidation_0-auc:0.89770\tvalidation_1-auc:0.83159\n",
            "[50]\tvalidation_0-auc:0.89828\tvalidation_1-auc:0.83215\n",
            "[51]\tvalidation_0-auc:0.89871\tvalidation_1-auc:0.83253\n",
            "[52]\tvalidation_0-auc:0.89930\tvalidation_1-auc:0.83228\n",
            "[53]\tvalidation_0-auc:0.89975\tvalidation_1-auc:0.83258\n",
            "[54]\tvalidation_0-auc:0.90009\tvalidation_1-auc:0.83208\n",
            "[55]\tvalidation_0-auc:0.90047\tvalidation_1-auc:0.83200\n",
            "[56]\tvalidation_0-auc:0.90102\tvalidation_1-auc:0.83221\n",
            "[57]\tvalidation_0-auc:0.90172\tvalidation_1-auc:0.83234\n",
            "[58]\tvalidation_0-auc:0.90219\tvalidation_1-auc:0.83255\n",
            "[0]\tvalidation_0-auc:0.85064\tvalidation_1-auc:0.81634\n",
            "[1]\tvalidation_0-auc:0.85753\tvalidation_1-auc:0.82407\n",
            "[2]\tvalidation_0-auc:0.86014\tvalidation_1-auc:0.81826\n",
            "[3]\tvalidation_0-auc:0.86704\tvalidation_1-auc:0.82378\n",
            "[4]\tvalidation_0-auc:0.86967\tvalidation_1-auc:0.82548\n",
            "[5]\tvalidation_0-auc:0.87150\tvalidation_1-auc:0.82884\n",
            "[6]\tvalidation_0-auc:0.87325\tvalidation_1-auc:0.83055\n",
            "[7]\tvalidation_0-auc:0.87367\tvalidation_1-auc:0.82858\n",
            "[8]\tvalidation_0-auc:0.87550\tvalidation_1-auc:0.83096\n",
            "[9]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.82824\n",
            "[10]\tvalidation_0-auc:0.87511\tvalidation_1-auc:0.83000\n",
            "[11]\tvalidation_0-auc:0.87648\tvalidation_1-auc:0.83115\n",
            "[12]\tvalidation_0-auc:0.87870\tvalidation_1-auc:0.83195\n",
            "[13]\tvalidation_0-auc:0.87963\tvalidation_1-auc:0.83256\n",
            "[14]\tvalidation_0-auc:0.88018\tvalidation_1-auc:0.83315\n",
            "[15]\tvalidation_0-auc:0.88004\tvalidation_1-auc:0.83247\n",
            "[16]\tvalidation_0-auc:0.88119\tvalidation_1-auc:0.83293\n",
            "[17]\tvalidation_0-auc:0.88212\tvalidation_1-auc:0.83327\n",
            "[18]\tvalidation_0-auc:0.88293\tvalidation_1-auc:0.83376\n",
            "[19]\tvalidation_0-auc:0.88372\tvalidation_1-auc:0.83423\n",
            "[20]\tvalidation_0-auc:0.88424\tvalidation_1-auc:0.83336\n",
            "[21]\tvalidation_0-auc:0.88431\tvalidation_1-auc:0.83304\n",
            "[22]\tvalidation_0-auc:0.88497\tvalidation_1-auc:0.83321\n",
            "[23]\tvalidation_0-auc:0.88610\tvalidation_1-auc:0.83391\n",
            "[24]\tvalidation_0-auc:0.88652\tvalidation_1-auc:0.83428\n",
            "[25]\tvalidation_0-auc:0.88673\tvalidation_1-auc:0.83450\n",
            "[26]\tvalidation_0-auc:0.88768\tvalidation_1-auc:0.83466\n",
            "[27]\tvalidation_0-auc:0.88822\tvalidation_1-auc:0.83474\n",
            "[28]\tvalidation_0-auc:0.88833\tvalidation_1-auc:0.83479\n",
            "[29]\tvalidation_0-auc:0.88843\tvalidation_1-auc:0.83419\n",
            "[30]\tvalidation_0-auc:0.88907\tvalidation_1-auc:0.83469\n",
            "[31]\tvalidation_0-auc:0.88960\tvalidation_1-auc:0.83362\n",
            "[32]\tvalidation_0-auc:0.89048\tvalidation_1-auc:0.83419\n",
            "[33]\tvalidation_0-auc:0.89064\tvalidation_1-auc:0.83366\n",
            "[34]\tvalidation_0-auc:0.89067\tvalidation_1-auc:0.83308\n",
            "[35]\tvalidation_0-auc:0.89150\tvalidation_1-auc:0.83367\n",
            "[36]\tvalidation_0-auc:0.89231\tvalidation_1-auc:0.83395\n",
            "[37]\tvalidation_0-auc:0.89227\tvalidation_1-auc:0.83314\n",
            "[38]\tvalidation_0-auc:0.89325\tvalidation_1-auc:0.83375\n",
            "[39]\tvalidation_0-auc:0.89411\tvalidation_1-auc:0.83399\n",
            "[40]\tvalidation_0-auc:0.89421\tvalidation_1-auc:0.83363\n",
            "[41]\tvalidation_0-auc:0.89464\tvalidation_1-auc:0.83358\n",
            "[42]\tvalidation_0-auc:0.89495\tvalidation_1-auc:0.83355\n",
            "[43]\tvalidation_0-auc:0.89590\tvalidation_1-auc:0.83427\n",
            "[44]\tvalidation_0-auc:0.89631\tvalidation_1-auc:0.83429\n",
            "[45]\tvalidation_0-auc:0.89706\tvalidation_1-auc:0.83465\n",
            "[46]\tvalidation_0-auc:0.89766\tvalidation_1-auc:0.83432\n",
            "[47]\tvalidation_0-auc:0.89781\tvalidation_1-auc:0.83372\n",
            "[48]\tvalidation_0-auc:0.89909\tvalidation_1-auc:0.83417\n",
            "[49]\tvalidation_0-auc:0.89994\tvalidation_1-auc:0.83480\n",
            "[50]\tvalidation_0-auc:0.90032\tvalidation_1-auc:0.83526\n",
            "[51]\tvalidation_0-auc:0.90087\tvalidation_1-auc:0.83542\n",
            "[52]\tvalidation_0-auc:0.90133\tvalidation_1-auc:0.83533\n",
            "[53]\tvalidation_0-auc:0.90173\tvalidation_1-auc:0.83563\n",
            "[54]\tvalidation_0-auc:0.90198\tvalidation_1-auc:0.83502\n",
            "[55]\tvalidation_0-auc:0.90223\tvalidation_1-auc:0.83471\n",
            "[56]\tvalidation_0-auc:0.90281\tvalidation_1-auc:0.83500\n",
            "[57]\tvalidation_0-auc:0.90356\tvalidation_1-auc:0.83511\n",
            "[58]\tvalidation_0-auc:0.90398\tvalidation_1-auc:0.83508\n",
            "[59]\tvalidation_0-auc:0.90441\tvalidation_1-auc:0.83556\n",
            "[60]\tvalidation_0-auc:0.90455\tvalidation_1-auc:0.83532\n",
            "[61]\tvalidation_0-auc:0.90499\tvalidation_1-auc:0.83566\n",
            "[62]\tvalidation_0-auc:0.90546\tvalidation_1-auc:0.83575\n",
            "[63]\tvalidation_0-auc:0.90585\tvalidation_1-auc:0.83621\n",
            "[64]\tvalidation_0-auc:0.90648\tvalidation_1-auc:0.83631\n",
            "[65]\tvalidation_0-auc:0.90669\tvalidation_1-auc:0.83625\n",
            "[66]\tvalidation_0-auc:0.90695\tvalidation_1-auc:0.83664\n",
            "[67]\tvalidation_0-auc:0.90747\tvalidation_1-auc:0.83683\n",
            "[68]\tvalidation_0-auc:0.90787\tvalidation_1-auc:0.83673\n",
            "[69]\tvalidation_0-auc:0.90804\tvalidation_1-auc:0.83658\n",
            "[70]\tvalidation_0-auc:0.90818\tvalidation_1-auc:0.83687\n",
            "[71]\tvalidation_0-auc:0.90831\tvalidation_1-auc:0.83694\n",
            "[72]\tvalidation_0-auc:0.90850\tvalidation_1-auc:0.83698\n",
            "[73]\tvalidation_0-auc:0.90890\tvalidation_1-auc:0.83690\n",
            "[74]\tvalidation_0-auc:0.90904\tvalidation_1-auc:0.83702\n",
            "[75]\tvalidation_0-auc:0.90919\tvalidation_1-auc:0.83699\n",
            "[76]\tvalidation_0-auc:0.90931\tvalidation_1-auc:0.83724\n",
            "[77]\tvalidation_0-auc:0.90957\tvalidation_1-auc:0.83723\n",
            "[78]\tvalidation_0-auc:0.90969\tvalidation_1-auc:0.83737\n",
            "[79]\tvalidation_0-auc:0.91012\tvalidation_1-auc:0.83726\n",
            "[80]\tvalidation_0-auc:0.91041\tvalidation_1-auc:0.83740\n",
            "[81]\tvalidation_0-auc:0.91076\tvalidation_1-auc:0.83735\n",
            "[82]\tvalidation_0-auc:0.91101\tvalidation_1-auc:0.83728\n",
            "[83]\tvalidation_0-auc:0.91150\tvalidation_1-auc:0.83723\n",
            "[84]\tvalidation_0-auc:0.91150\tvalidation_1-auc:0.83722\n",
            "[85]\tvalidation_0-auc:0.91188\tvalidation_1-auc:0.83724\n",
            "[86]\tvalidation_0-auc:0.91213\tvalidation_1-auc:0.83710\n",
            "[87]\tvalidation_0-auc:0.91221\tvalidation_1-auc:0.83710\n",
            "[88]\tvalidation_0-auc:0.91234\tvalidation_1-auc:0.83711\n",
            "[89]\tvalidation_0-auc:0.91260\tvalidation_1-auc:0.83711\n",
            "[90]\tvalidation_0-auc:0.91275\tvalidation_1-auc:0.83718\n",
            "[91]\tvalidation_0-auc:0.91280\tvalidation_1-auc:0.83734\n",
            "[92]\tvalidation_0-auc:0.91321\tvalidation_1-auc:0.83720\n",
            "[93]\tvalidation_0-auc:0.91332\tvalidation_1-auc:0.83712\n",
            "[94]\tvalidation_0-auc:0.91349\tvalidation_1-auc:0.83719\n",
            "[95]\tvalidation_0-auc:0.91371\tvalidation_1-auc:0.83711\n",
            "[96]\tvalidation_0-auc:0.91392\tvalidation_1-auc:0.83701\n",
            "[97]\tvalidation_0-auc:0.91422\tvalidation_1-auc:0.83682\n",
            "[98]\tvalidation_0-auc:0.91439\tvalidation_1-auc:0.83686\n",
            "[99]\tvalidation_0-auc:0.91454\tvalidation_1-auc:0.83683\n",
            "[0]\tvalidation_0-auc:0.85049\tvalidation_1-auc:0.81156\n",
            "[1]\tvalidation_0-auc:0.85680\tvalidation_1-auc:0.82255\n",
            "[2]\tvalidation_0-auc:0.85904\tvalidation_1-auc:0.81430\n",
            "[3]\tvalidation_0-auc:0.86313\tvalidation_1-auc:0.82184\n",
            "[4]\tvalidation_0-auc:0.86456\tvalidation_1-auc:0.82366\n",
            "[5]\tvalidation_0-auc:0.86661\tvalidation_1-auc:0.82697\n",
            "[6]\tvalidation_0-auc:0.86861\tvalidation_1-auc:0.82726\n",
            "[7]\tvalidation_0-auc:0.87109\tvalidation_1-auc:0.82602\n",
            "[8]\tvalidation_0-auc:0.87254\tvalidation_1-auc:0.82667\n",
            "[9]\tvalidation_0-auc:0.87284\tvalidation_1-auc:0.82591\n",
            "[10]\tvalidation_0-auc:0.87407\tvalidation_1-auc:0.82748\n",
            "[11]\tvalidation_0-auc:0.87516\tvalidation_1-auc:0.82778\n",
            "[12]\tvalidation_0-auc:0.87690\tvalidation_1-auc:0.82780\n",
            "[13]\tvalidation_0-auc:0.87724\tvalidation_1-auc:0.82778\n",
            "[14]\tvalidation_0-auc:0.87791\tvalidation_1-auc:0.82841\n",
            "[15]\tvalidation_0-auc:0.87910\tvalidation_1-auc:0.82841\n",
            "[16]\tvalidation_0-auc:0.88001\tvalidation_1-auc:0.82844\n",
            "[17]\tvalidation_0-auc:0.88061\tvalidation_1-auc:0.82865\n",
            "[18]\tvalidation_0-auc:0.88129\tvalidation_1-auc:0.82906\n",
            "[19]\tvalidation_0-auc:0.88172\tvalidation_1-auc:0.82883\n",
            "[20]\tvalidation_0-auc:0.88230\tvalidation_1-auc:0.82856\n",
            "[21]\tvalidation_0-auc:0.88340\tvalidation_1-auc:0.82782\n",
            "[22]\tvalidation_0-auc:0.88468\tvalidation_1-auc:0.82892\n",
            "[23]\tvalidation_0-auc:0.88548\tvalidation_1-auc:0.82962\n",
            "[24]\tvalidation_0-auc:0.88591\tvalidation_1-auc:0.82983\n",
            "[25]\tvalidation_0-auc:0.88615\tvalidation_1-auc:0.83024\n",
            "[26]\tvalidation_0-auc:0.88665\tvalidation_1-auc:0.83015\n",
            "[27]\tvalidation_0-auc:0.88730\tvalidation_1-auc:0.83025\n",
            "[28]\tvalidation_0-auc:0.88791\tvalidation_1-auc:0.83027\n",
            "[29]\tvalidation_0-auc:0.88814\tvalidation_1-auc:0.82972\n",
            "[30]\tvalidation_0-auc:0.88891\tvalidation_1-auc:0.82993\n",
            "[31]\tvalidation_0-auc:0.88950\tvalidation_1-auc:0.82933\n",
            "[32]\tvalidation_0-auc:0.89031\tvalidation_1-auc:0.82958\n",
            "[33]\tvalidation_0-auc:0.89055\tvalidation_1-auc:0.82915\n",
            "[34]\tvalidation_0-auc:0.89095\tvalidation_1-auc:0.82912\n",
            "[35]\tvalidation_0-auc:0.89146\tvalidation_1-auc:0.82956\n",
            "[36]\tvalidation_0-auc:0.89235\tvalidation_1-auc:0.82986\n",
            "[37]\tvalidation_0-auc:0.89284\tvalidation_1-auc:0.82927\n",
            "[38]\tvalidation_0-auc:0.89393\tvalidation_1-auc:0.83001\n",
            "[39]\tvalidation_0-auc:0.89477\tvalidation_1-auc:0.83048\n",
            "[40]\tvalidation_0-auc:0.89519\tvalidation_1-auc:0.83014\n",
            "[41]\tvalidation_0-auc:0.89599\tvalidation_1-auc:0.83041\n",
            "[42]\tvalidation_0-auc:0.89656\tvalidation_1-auc:0.83010\n",
            "[43]\tvalidation_0-auc:0.89734\tvalidation_1-auc:0.83068\n",
            "[44]\tvalidation_0-auc:0.89769\tvalidation_1-auc:0.82998\n",
            "[45]\tvalidation_0-auc:0.89803\tvalidation_1-auc:0.83058\n",
            "[46]\tvalidation_0-auc:0.89860\tvalidation_1-auc:0.83046\n",
            "[47]\tvalidation_0-auc:0.89895\tvalidation_1-auc:0.83013\n",
            "[48]\tvalidation_0-auc:0.89983\tvalidation_1-auc:0.83090\n",
            "[49]\tvalidation_0-auc:0.90031\tvalidation_1-auc:0.83085\n",
            "[50]\tvalidation_0-auc:0.90058\tvalidation_1-auc:0.83100\n",
            "[51]\tvalidation_0-auc:0.90117\tvalidation_1-auc:0.83129\n",
            "[52]\tvalidation_0-auc:0.90140\tvalidation_1-auc:0.83110\n",
            "[53]\tvalidation_0-auc:0.90165\tvalidation_1-auc:0.83153\n",
            "[54]\tvalidation_0-auc:0.90194\tvalidation_1-auc:0.83107\n",
            "[55]\tvalidation_0-auc:0.90227\tvalidation_1-auc:0.83120\n",
            "[56]\tvalidation_0-auc:0.90271\tvalidation_1-auc:0.83158\n",
            "[57]\tvalidation_0-auc:0.90311\tvalidation_1-auc:0.83168\n",
            "[58]\tvalidation_0-auc:0.90390\tvalidation_1-auc:0.83212\n",
            "[59]\tvalidation_0-auc:0.90430\tvalidation_1-auc:0.83264\n",
            "[60]\tvalidation_0-auc:0.90443\tvalidation_1-auc:0.83241\n",
            "[61]\tvalidation_0-auc:0.90483\tvalidation_1-auc:0.83274\n",
            "[62]\tvalidation_0-auc:0.90507\tvalidation_1-auc:0.83308\n",
            "[63]\tvalidation_0-auc:0.90535\tvalidation_1-auc:0.83302\n",
            "[64]\tvalidation_0-auc:0.90584\tvalidation_1-auc:0.83317\n",
            "[65]\tvalidation_0-auc:0.90625\tvalidation_1-auc:0.83310\n",
            "[66]\tvalidation_0-auc:0.90649\tvalidation_1-auc:0.83358\n",
            "[67]\tvalidation_0-auc:0.90660\tvalidation_1-auc:0.83393\n",
            "[68]\tvalidation_0-auc:0.90680\tvalidation_1-auc:0.83390\n",
            "[69]\tvalidation_0-auc:0.90722\tvalidation_1-auc:0.83358\n",
            "[70]\tvalidation_0-auc:0.90737\tvalidation_1-auc:0.83373\n",
            "[71]\tvalidation_0-auc:0.90780\tvalidation_1-auc:0.83372\n",
            "[72]\tvalidation_0-auc:0.90807\tvalidation_1-auc:0.83378\n",
            "[73]\tvalidation_0-auc:0.90819\tvalidation_1-auc:0.83361\n",
            "[74]\tvalidation_0-auc:0.90835\tvalidation_1-auc:0.83369\n",
            "[75]\tvalidation_0-auc:0.90844\tvalidation_1-auc:0.83380\n",
            "[76]\tvalidation_0-auc:0.90858\tvalidation_1-auc:0.83395\n",
            "[77]\tvalidation_0-auc:0.90890\tvalidation_1-auc:0.83401\n",
            "[78]\tvalidation_0-auc:0.90936\tvalidation_1-auc:0.83407\n",
            "[79]\tvalidation_0-auc:0.90954\tvalidation_1-auc:0.83386\n",
            "[80]\tvalidation_0-auc:0.90970\tvalidation_1-auc:0.83408\n",
            "[81]\tvalidation_0-auc:0.90989\tvalidation_1-auc:0.83403\n",
            "[82]\tvalidation_0-auc:0.91012\tvalidation_1-auc:0.83392\n",
            "[83]\tvalidation_0-auc:0.91050\tvalidation_1-auc:0.83379\n",
            "[84]\tvalidation_0-auc:0.91069\tvalidation_1-auc:0.83363\n",
            "[85]\tvalidation_0-auc:0.91080\tvalidation_1-auc:0.83349\n",
            "[86]\tvalidation_0-auc:0.91109\tvalidation_1-auc:0.83347\n",
            "[87]\tvalidation_0-auc:0.91119\tvalidation_1-auc:0.83366\n",
            "[88]\tvalidation_0-auc:0.91134\tvalidation_1-auc:0.83380\n",
            "[89]\tvalidation_0-auc:0.91145\tvalidation_1-auc:0.83379\n",
            "[90]\tvalidation_0-auc:0.91161\tvalidation_1-auc:0.83370\n",
            "[91]\tvalidation_0-auc:0.91180\tvalidation_1-auc:0.83379\n",
            "[92]\tvalidation_0-auc:0.91213\tvalidation_1-auc:0.83388\n",
            "[93]\tvalidation_0-auc:0.91235\tvalidation_1-auc:0.83394\n",
            "[94]\tvalidation_0-auc:0.91249\tvalidation_1-auc:0.83408\n",
            "[95]\tvalidation_0-auc:0.91281\tvalidation_1-auc:0.83419\n",
            "[96]\tvalidation_0-auc:0.91291\tvalidation_1-auc:0.83416\n",
            "[97]\tvalidation_0-auc:0.91321\tvalidation_1-auc:0.83408\n",
            "[98]\tvalidation_0-auc:0.91333\tvalidation_1-auc:0.83414\n",
            "[99]\tvalidation_0-auc:0.91341\tvalidation_1-auc:0.83400\n",
            "[0]\tvalidation_0-auc:0.81792\tvalidation_1-auc:0.79031\n",
            "[1]\tvalidation_0-auc:0.83289\tvalidation_1-auc:0.80869\n",
            "[2]\tvalidation_0-auc:0.83182\tvalidation_1-auc:0.80478\n",
            "[3]\tvalidation_0-auc:0.83500\tvalidation_1-auc:0.81136\n",
            "[4]\tvalidation_0-auc:0.83744\tvalidation_1-auc:0.81426\n",
            "[5]\tvalidation_0-auc:0.84010\tvalidation_1-auc:0.81631\n",
            "[6]\tvalidation_0-auc:0.84051\tvalidation_1-auc:0.81560\n",
            "[7]\tvalidation_0-auc:0.83831\tvalidation_1-auc:0.81597\n",
            "[8]\tvalidation_0-auc:0.84028\tvalidation_1-auc:0.81979\n",
            "[9]\tvalidation_0-auc:0.84108\tvalidation_1-auc:0.81963\n",
            "[10]\tvalidation_0-auc:0.84073\tvalidation_1-auc:0.81952\n",
            "[11]\tvalidation_0-auc:0.84136\tvalidation_1-auc:0.82062\n",
            "[12]\tvalidation_0-auc:0.84183\tvalidation_1-auc:0.82027\n",
            "[13]\tvalidation_0-auc:0.84173\tvalidation_1-auc:0.82107\n",
            "[14]\tvalidation_0-auc:0.84236\tvalidation_1-auc:0.82137\n",
            "[15]\tvalidation_0-auc:0.84309\tvalidation_1-auc:0.82209\n",
            "[16]\tvalidation_0-auc:0.84336\tvalidation_1-auc:0.82195\n",
            "[17]\tvalidation_0-auc:0.84358\tvalidation_1-auc:0.82171\n",
            "[18]\tvalidation_0-auc:0.84402\tvalidation_1-auc:0.82146\n",
            "[19]\tvalidation_0-auc:0.84413\tvalidation_1-auc:0.82174\n",
            "[20]\tvalidation_0-auc:0.84447\tvalidation_1-auc:0.82273\n",
            "[21]\tvalidation_0-auc:0.84437\tvalidation_1-auc:0.82321\n",
            "[22]\tvalidation_0-auc:0.84480\tvalidation_1-auc:0.82373\n",
            "[23]\tvalidation_0-auc:0.84492\tvalidation_1-auc:0.82346\n",
            "[24]\tvalidation_0-auc:0.84487\tvalidation_1-auc:0.82321\n",
            "[25]\tvalidation_0-auc:0.84493\tvalidation_1-auc:0.82330\n",
            "[26]\tvalidation_0-auc:0.84547\tvalidation_1-auc:0.82348\n",
            "[27]\tvalidation_0-auc:0.84590\tvalidation_1-auc:0.82410\n",
            "[28]\tvalidation_0-auc:0.84604\tvalidation_1-auc:0.82463\n",
            "[29]\tvalidation_0-auc:0.84602\tvalidation_1-auc:0.82439\n",
            "[30]\tvalidation_0-auc:0.84622\tvalidation_1-auc:0.82491\n",
            "[31]\tvalidation_0-auc:0.84619\tvalidation_1-auc:0.82506\n",
            "[32]\tvalidation_0-auc:0.84622\tvalidation_1-auc:0.82504\n",
            "[33]\tvalidation_0-auc:0.84601\tvalidation_1-auc:0.82465\n",
            "[34]\tvalidation_0-auc:0.84624\tvalidation_1-auc:0.82478\n",
            "[35]\tvalidation_0-auc:0.84641\tvalidation_1-auc:0.82480\n",
            "[36]\tvalidation_0-auc:0.84678\tvalidation_1-auc:0.82492\n",
            "[37]\tvalidation_0-auc:0.84687\tvalidation_1-auc:0.82513\n",
            "[38]\tvalidation_0-auc:0.84716\tvalidation_1-auc:0.82527\n",
            "[39]\tvalidation_0-auc:0.84735\tvalidation_1-auc:0.82531\n",
            "[40]\tvalidation_0-auc:0.84742\tvalidation_1-auc:0.82543\n",
            "[41]\tvalidation_0-auc:0.84769\tvalidation_1-auc:0.82564\n",
            "[42]\tvalidation_0-auc:0.84800\tvalidation_1-auc:0.82654\n",
            "[43]\tvalidation_0-auc:0.84812\tvalidation_1-auc:0.82640\n",
            "[44]\tvalidation_0-auc:0.84807\tvalidation_1-auc:0.82665\n",
            "[45]\tvalidation_0-auc:0.84839\tvalidation_1-auc:0.82663\n",
            "[46]\tvalidation_0-auc:0.84884\tvalidation_1-auc:0.82728\n",
            "[47]\tvalidation_0-auc:0.84895\tvalidation_1-auc:0.82704\n",
            "[48]\tvalidation_0-auc:0.84902\tvalidation_1-auc:0.82654\n",
            "[49]\tvalidation_0-auc:0.84914\tvalidation_1-auc:0.82665\n",
            "[50]\tvalidation_0-auc:0.84916\tvalidation_1-auc:0.82672\n",
            "[51]\tvalidation_0-auc:0.84928\tvalidation_1-auc:0.82697\n",
            "[52]\tvalidation_0-auc:0.84931\tvalidation_1-auc:0.82740\n",
            "[53]\tvalidation_0-auc:0.84953\tvalidation_1-auc:0.82756\n",
            "[54]\tvalidation_0-auc:0.84949\tvalidation_1-auc:0.82729\n",
            "[55]\tvalidation_0-auc:0.84953\tvalidation_1-auc:0.82735\n",
            "[56]\tvalidation_0-auc:0.84978\tvalidation_1-auc:0.82733\n",
            "[57]\tvalidation_0-auc:0.84987\tvalidation_1-auc:0.82732\n",
            "[58]\tvalidation_0-auc:0.85010\tvalidation_1-auc:0.82712\n",
            "[59]\tvalidation_0-auc:0.85017\tvalidation_1-auc:0.82748\n",
            "[60]\tvalidation_0-auc:0.85017\tvalidation_1-auc:0.82750\n",
            "[61]\tvalidation_0-auc:0.85020\tvalidation_1-auc:0.82755\n",
            "[62]\tvalidation_0-auc:0.85037\tvalidation_1-auc:0.82758\n",
            "[63]\tvalidation_0-auc:0.85052\tvalidation_1-auc:0.82752\n",
            "[64]\tvalidation_0-auc:0.85069\tvalidation_1-auc:0.82752\n",
            "[65]\tvalidation_0-auc:0.85059\tvalidation_1-auc:0.82769\n",
            "[66]\tvalidation_0-auc:0.85082\tvalidation_1-auc:0.82759\n",
            "[67]\tvalidation_0-auc:0.85107\tvalidation_1-auc:0.82772\n",
            "[68]\tvalidation_0-auc:0.85103\tvalidation_1-auc:0.82767\n",
            "[69]\tvalidation_0-auc:0.85125\tvalidation_1-auc:0.82779\n",
            "[70]\tvalidation_0-auc:0.85126\tvalidation_1-auc:0.82780\n",
            "[71]\tvalidation_0-auc:0.85153\tvalidation_1-auc:0.82788\n",
            "[72]\tvalidation_0-auc:0.85198\tvalidation_1-auc:0.82800\n",
            "[73]\tvalidation_0-auc:0.85228\tvalidation_1-auc:0.82825\n",
            "[74]\tvalidation_0-auc:0.85255\tvalidation_1-auc:0.82835\n",
            "[75]\tvalidation_0-auc:0.85272\tvalidation_1-auc:0.82832\n",
            "[76]\tvalidation_0-auc:0.85284\tvalidation_1-auc:0.82824\n",
            "[77]\tvalidation_0-auc:0.85308\tvalidation_1-auc:0.82835\n",
            "[78]\tvalidation_0-auc:0.85331\tvalidation_1-auc:0.82833\n",
            "[79]\tvalidation_0-auc:0.85319\tvalidation_1-auc:0.82828\n",
            "[80]\tvalidation_0-auc:0.85350\tvalidation_1-auc:0.82846\n",
            "[81]\tvalidation_0-auc:0.85327\tvalidation_1-auc:0.82849\n",
            "[82]\tvalidation_0-auc:0.85345\tvalidation_1-auc:0.82884\n",
            "[83]\tvalidation_0-auc:0.85331\tvalidation_1-auc:0.82868\n",
            "[84]\tvalidation_0-auc:0.85335\tvalidation_1-auc:0.82871\n",
            "[85]\tvalidation_0-auc:0.85343\tvalidation_1-auc:0.82876\n",
            "[86]\tvalidation_0-auc:0.85371\tvalidation_1-auc:0.82921\n",
            "[87]\tvalidation_0-auc:0.85395\tvalidation_1-auc:0.82923\n",
            "[88]\tvalidation_0-auc:0.85427\tvalidation_1-auc:0.82923\n",
            "[89]\tvalidation_0-auc:0.85435\tvalidation_1-auc:0.82914\n",
            "[90]\tvalidation_0-auc:0.85438\tvalidation_1-auc:0.82950\n",
            "[91]\tvalidation_0-auc:0.85452\tvalidation_1-auc:0.82945\n",
            "[92]\tvalidation_0-auc:0.85463\tvalidation_1-auc:0.82973\n",
            "[93]\tvalidation_0-auc:0.85480\tvalidation_1-auc:0.82966\n",
            "[94]\tvalidation_0-auc:0.85494\tvalidation_1-auc:0.82958\n",
            "[95]\tvalidation_0-auc:0.85491\tvalidation_1-auc:0.82951\n",
            "[96]\tvalidation_0-auc:0.85482\tvalidation_1-auc:0.82927\n",
            "[97]\tvalidation_0-auc:0.85489\tvalidation_1-auc:0.82927\n",
            "[98]\tvalidation_0-auc:0.85512\tvalidation_1-auc:0.82950\n",
            "[99]\tvalidation_0-auc:0.85536\tvalidation_1-auc:0.82976\n",
            "[0]\tvalidation_0-auc:0.82234\tvalidation_1-auc:0.81043\n",
            "[1]\tvalidation_0-auc:0.82868\tvalidation_1-auc:0.81449\n",
            "[2]\tvalidation_0-auc:0.83051\tvalidation_1-auc:0.81175\n",
            "[3]\tvalidation_0-auc:0.83733\tvalidation_1-auc:0.81953\n",
            "[4]\tvalidation_0-auc:0.83887\tvalidation_1-auc:0.82328\n",
            "[5]\tvalidation_0-auc:0.84012\tvalidation_1-auc:0.82448\n",
            "[6]\tvalidation_0-auc:0.84005\tvalidation_1-auc:0.82505\n",
            "[7]\tvalidation_0-auc:0.84075\tvalidation_1-auc:0.82275\n",
            "[8]\tvalidation_0-auc:0.84241\tvalidation_1-auc:0.82439\n",
            "[9]\tvalidation_0-auc:0.84222\tvalidation_1-auc:0.82504\n",
            "[10]\tvalidation_0-auc:0.84298\tvalidation_1-auc:0.82578\n",
            "[11]\tvalidation_0-auc:0.84285\tvalidation_1-auc:0.82571\n",
            "[12]\tvalidation_0-auc:0.84304\tvalidation_1-auc:0.82632\n",
            "[13]\tvalidation_0-auc:0.84357\tvalidation_1-auc:0.82706\n",
            "[14]\tvalidation_0-auc:0.84373\tvalidation_1-auc:0.82691\n",
            "[15]\tvalidation_0-auc:0.84523\tvalidation_1-auc:0.82727\n",
            "[16]\tvalidation_0-auc:0.84523\tvalidation_1-auc:0.82740\n",
            "[17]\tvalidation_0-auc:0.84540\tvalidation_1-auc:0.82867\n",
            "[18]\tvalidation_0-auc:0.84529\tvalidation_1-auc:0.82862\n",
            "[19]\tvalidation_0-auc:0.84543\tvalidation_1-auc:0.82906\n",
            "[20]\tvalidation_0-auc:0.84549\tvalidation_1-auc:0.82913\n",
            "[21]\tvalidation_0-auc:0.84505\tvalidation_1-auc:0.82820\n",
            "[22]\tvalidation_0-auc:0.84560\tvalidation_1-auc:0.82866\n",
            "[23]\tvalidation_0-auc:0.84598\tvalidation_1-auc:0.82915\n",
            "[24]\tvalidation_0-auc:0.84601\tvalidation_1-auc:0.82935\n",
            "[25]\tvalidation_0-auc:0.84577\tvalidation_1-auc:0.82918\n",
            "[26]\tvalidation_0-auc:0.84625\tvalidation_1-auc:0.82927\n",
            "[27]\tvalidation_0-auc:0.84689\tvalidation_1-auc:0.82902\n",
            "[28]\tvalidation_0-auc:0.84697\tvalidation_1-auc:0.82912\n",
            "[29]\tvalidation_0-auc:0.84706\tvalidation_1-auc:0.82935\n",
            "[30]\tvalidation_0-auc:0.84725\tvalidation_1-auc:0.82932\n",
            "[31]\tvalidation_0-auc:0.84747\tvalidation_1-auc:0.82940\n",
            "[32]\tvalidation_0-auc:0.84773\tvalidation_1-auc:0.82963\n",
            "[33]\tvalidation_0-auc:0.84776\tvalidation_1-auc:0.82943\n",
            "[34]\tvalidation_0-auc:0.84767\tvalidation_1-auc:0.82905\n",
            "[35]\tvalidation_0-auc:0.84811\tvalidation_1-auc:0.82948\n",
            "[36]\tvalidation_0-auc:0.84824\tvalidation_1-auc:0.82953\n",
            "[37]\tvalidation_0-auc:0.84858\tvalidation_1-auc:0.82969\n",
            "[38]\tvalidation_0-auc:0.84909\tvalidation_1-auc:0.82985\n",
            "[39]\tvalidation_0-auc:0.84936\tvalidation_1-auc:0.82998\n",
            "[40]\tvalidation_0-auc:0.84918\tvalidation_1-auc:0.82990\n",
            "[41]\tvalidation_0-auc:0.84938\tvalidation_1-auc:0.82982\n",
            "[42]\tvalidation_0-auc:0.84944\tvalidation_1-auc:0.82933\n",
            "[43]\tvalidation_0-auc:0.84957\tvalidation_1-auc:0.82962\n",
            "[44]\tvalidation_0-auc:0.84920\tvalidation_1-auc:0.82920\n",
            "[45]\tvalidation_0-auc:0.84945\tvalidation_1-auc:0.82925\n",
            "[46]\tvalidation_0-auc:0.84975\tvalidation_1-auc:0.82926\n",
            "[47]\tvalidation_0-auc:0.85013\tvalidation_1-auc:0.82972\n",
            "[48]\tvalidation_0-auc:0.85034\tvalidation_1-auc:0.82987\n",
            "[49]\tvalidation_0-auc:0.85057\tvalidation_1-auc:0.82996\n",
            "[50]\tvalidation_0-auc:0.85066\tvalidation_1-auc:0.83001\n",
            "[51]\tvalidation_0-auc:0.85078\tvalidation_1-auc:0.83025\n",
            "[52]\tvalidation_0-auc:0.85049\tvalidation_1-auc:0.83006\n",
            "[53]\tvalidation_0-auc:0.85072\tvalidation_1-auc:0.83021\n",
            "[54]\tvalidation_0-auc:0.85042\tvalidation_1-auc:0.82965\n",
            "[55]\tvalidation_0-auc:0.84999\tvalidation_1-auc:0.82920\n",
            "[56]\tvalidation_0-auc:0.85031\tvalidation_1-auc:0.82930\n",
            "[57]\tvalidation_0-auc:0.85079\tvalidation_1-auc:0.82971\n",
            "[58]\tvalidation_0-auc:0.85085\tvalidation_1-auc:0.82973\n",
            "[59]\tvalidation_0-auc:0.85122\tvalidation_1-auc:0.83022\n",
            "[60]\tvalidation_0-auc:0.85103\tvalidation_1-auc:0.82982\n",
            "[61]\tvalidation_0-auc:0.85128\tvalidation_1-auc:0.83017\n",
            "[62]\tvalidation_0-auc:0.85140\tvalidation_1-auc:0.83018\n",
            "[63]\tvalidation_0-auc:0.85151\tvalidation_1-auc:0.83029\n",
            "[64]\tvalidation_0-auc:0.85187\tvalidation_1-auc:0.83060\n",
            "[65]\tvalidation_0-auc:0.85170\tvalidation_1-auc:0.83035\n",
            "[66]\tvalidation_0-auc:0.85188\tvalidation_1-auc:0.83049\n",
            "[67]\tvalidation_0-auc:0.85211\tvalidation_1-auc:0.83064\n",
            "[68]\tvalidation_0-auc:0.85191\tvalidation_1-auc:0.83020\n",
            "[69]\tvalidation_0-auc:0.85169\tvalidation_1-auc:0.83028\n",
            "[70]\tvalidation_0-auc:0.85191\tvalidation_1-auc:0.83048\n",
            "[71]\tvalidation_0-auc:0.85203\tvalidation_1-auc:0.83070\n",
            "[72]\tvalidation_0-auc:0.85223\tvalidation_1-auc:0.83080\n",
            "[73]\tvalidation_0-auc:0.85246\tvalidation_1-auc:0.83111\n",
            "[74]\tvalidation_0-auc:0.85260\tvalidation_1-auc:0.83119\n",
            "[75]\tvalidation_0-auc:0.85291\tvalidation_1-auc:0.83122\n",
            "[76]\tvalidation_0-auc:0.85311\tvalidation_1-auc:0.83123\n",
            "[77]\tvalidation_0-auc:0.85327\tvalidation_1-auc:0.83137\n",
            "[78]\tvalidation_0-auc:0.85344\tvalidation_1-auc:0.83134\n",
            "[79]\tvalidation_0-auc:0.85348\tvalidation_1-auc:0.83135\n",
            "[80]\tvalidation_0-auc:0.85360\tvalidation_1-auc:0.83137\n",
            "[81]\tvalidation_0-auc:0.85368\tvalidation_1-auc:0.83136\n",
            "[82]\tvalidation_0-auc:0.85382\tvalidation_1-auc:0.83132\n",
            "[83]\tvalidation_0-auc:0.85376\tvalidation_1-auc:0.83118\n",
            "[84]\tvalidation_0-auc:0.85362\tvalidation_1-auc:0.83106\n",
            "[85]\tvalidation_0-auc:0.85376\tvalidation_1-auc:0.83109\n",
            "[86]\tvalidation_0-auc:0.85391\tvalidation_1-auc:0.83122\n",
            "[87]\tvalidation_0-auc:0.85404\tvalidation_1-auc:0.83124\n",
            "[88]\tvalidation_0-auc:0.85426\tvalidation_1-auc:0.83129\n",
            "[89]\tvalidation_0-auc:0.85453\tvalidation_1-auc:0.83121\n",
            "[90]\tvalidation_0-auc:0.85439\tvalidation_1-auc:0.83128\n",
            "[91]\tvalidation_0-auc:0.85459\tvalidation_1-auc:0.83132\n",
            "[92]\tvalidation_0-auc:0.85452\tvalidation_1-auc:0.83113\n",
            "[93]\tvalidation_0-auc:0.85463\tvalidation_1-auc:0.83110\n",
            "[94]\tvalidation_0-auc:0.85479\tvalidation_1-auc:0.83113\n",
            "[95]\tvalidation_0-auc:0.85472\tvalidation_1-auc:0.83113\n",
            "[96]\tvalidation_0-auc:0.85477\tvalidation_1-auc:0.83122\n",
            "[97]\tvalidation_0-auc:0.85483\tvalidation_1-auc:0.83128\n",
            "[98]\tvalidation_0-auc:0.85510\tvalidation_1-auc:0.83141\n",
            "[99]\tvalidation_0-auc:0.85527\tvalidation_1-auc:0.83164\n",
            "[0]\tvalidation_0-auc:0.82408\tvalidation_1-auc:0.81091\n",
            "[1]\tvalidation_0-auc:0.83431\tvalidation_1-auc:0.82017\n",
            "[2]\tvalidation_0-auc:0.83836\tvalidation_1-auc:0.81906\n",
            "[3]\tvalidation_0-auc:0.84029\tvalidation_1-auc:0.82232\n",
            "[4]\tvalidation_0-auc:0.84088\tvalidation_1-auc:0.82389\n",
            "[5]\tvalidation_0-auc:0.84167\tvalidation_1-auc:0.82563\n",
            "[6]\tvalidation_0-auc:0.84202\tvalidation_1-auc:0.82544\n",
            "[7]\tvalidation_0-auc:0.84212\tvalidation_1-auc:0.82361\n",
            "[8]\tvalidation_0-auc:0.84280\tvalidation_1-auc:0.82435\n",
            "[9]\tvalidation_0-auc:0.84270\tvalidation_1-auc:0.82448\n",
            "[10]\tvalidation_0-auc:0.84308\tvalidation_1-auc:0.82538\n",
            "[11]\tvalidation_0-auc:0.84320\tvalidation_1-auc:0.82571\n",
            "[12]\tvalidation_0-auc:0.84311\tvalidation_1-auc:0.82585\n",
            "[13]\tvalidation_0-auc:0.84315\tvalidation_1-auc:0.82636\n",
            "[14]\tvalidation_0-auc:0.84275\tvalidation_1-auc:0.82631\n",
            "[15]\tvalidation_0-auc:0.84465\tvalidation_1-auc:0.82732\n",
            "[16]\tvalidation_0-auc:0.84453\tvalidation_1-auc:0.82727\n",
            "[17]\tvalidation_0-auc:0.84433\tvalidation_1-auc:0.82685\n",
            "[18]\tvalidation_0-auc:0.84417\tvalidation_1-auc:0.82686\n",
            "[19]\tvalidation_0-auc:0.84466\tvalidation_1-auc:0.82707\n",
            "[20]\tvalidation_0-auc:0.84455\tvalidation_1-auc:0.82707\n",
            "[21]\tvalidation_0-auc:0.84544\tvalidation_1-auc:0.82623\n",
            "[22]\tvalidation_0-auc:0.84563\tvalidation_1-auc:0.82654\n",
            "[23]\tvalidation_0-auc:0.84578\tvalidation_1-auc:0.82664\n",
            "[24]\tvalidation_0-auc:0.84606\tvalidation_1-auc:0.82732\n",
            "[25]\tvalidation_0-auc:0.84601\tvalidation_1-auc:0.82761\n",
            "[26]\tvalidation_0-auc:0.84613\tvalidation_1-auc:0.82764\n",
            "[27]\tvalidation_0-auc:0.84624\tvalidation_1-auc:0.82763\n",
            "[28]\tvalidation_0-auc:0.84611\tvalidation_1-auc:0.82721\n",
            "[29]\tvalidation_0-auc:0.84647\tvalidation_1-auc:0.82761\n",
            "[30]\tvalidation_0-auc:0.84654\tvalidation_1-auc:0.82780\n",
            "[31]\tvalidation_0-auc:0.84667\tvalidation_1-auc:0.82797\n",
            "[32]\tvalidation_0-auc:0.84668\tvalidation_1-auc:0.82797\n",
            "[33]\tvalidation_0-auc:0.84635\tvalidation_1-auc:0.82715\n",
            "[34]\tvalidation_0-auc:0.84639\tvalidation_1-auc:0.82679\n",
            "[35]\tvalidation_0-auc:0.84691\tvalidation_1-auc:0.82759\n",
            "[36]\tvalidation_0-auc:0.84696\tvalidation_1-auc:0.82752\n",
            "[37]\tvalidation_0-auc:0.84709\tvalidation_1-auc:0.82754\n",
            "[38]\tvalidation_0-auc:0.84730\tvalidation_1-auc:0.82766\n",
            "[39]\tvalidation_0-auc:0.84757\tvalidation_1-auc:0.82766\n",
            "[40]\tvalidation_0-auc:0.84737\tvalidation_1-auc:0.82708\n",
            "[41]\tvalidation_0-auc:0.84792\tvalidation_1-auc:0.82745\n",
            "[42]\tvalidation_0-auc:0.84787\tvalidation_1-auc:0.82733\n",
            "[43]\tvalidation_0-auc:0.84799\tvalidation_1-auc:0.82761\n",
            "[44]\tvalidation_0-auc:0.84807\tvalidation_1-auc:0.82744\n",
            "[45]\tvalidation_0-auc:0.84818\tvalidation_1-auc:0.82748\n",
            "[46]\tvalidation_0-auc:0.84845\tvalidation_1-auc:0.82771\n",
            "[47]\tvalidation_0-auc:0.84851\tvalidation_1-auc:0.82782\n",
            "[48]\tvalidation_0-auc:0.84854\tvalidation_1-auc:0.82787\n",
            "[49]\tvalidation_0-auc:0.84864\tvalidation_1-auc:0.82788\n",
            "[50]\tvalidation_0-auc:0.84915\tvalidation_1-auc:0.82845\n",
            "[51]\tvalidation_0-auc:0.84973\tvalidation_1-auc:0.82922\n",
            "[52]\tvalidation_0-auc:0.84960\tvalidation_1-auc:0.82888\n",
            "[53]\tvalidation_0-auc:0.84977\tvalidation_1-auc:0.82917\n",
            "[54]\tvalidation_0-auc:0.84979\tvalidation_1-auc:0.82887\n",
            "[55]\tvalidation_0-auc:0.84976\tvalidation_1-auc:0.82883\n",
            "[56]\tvalidation_0-auc:0.85001\tvalidation_1-auc:0.82891\n",
            "[57]\tvalidation_0-auc:0.85009\tvalidation_1-auc:0.82911\n",
            "[58]\tvalidation_0-auc:0.85031\tvalidation_1-auc:0.82956\n",
            "[59]\tvalidation_0-auc:0.85045\tvalidation_1-auc:0.82977\n",
            "[60]\tvalidation_0-auc:0.85051\tvalidation_1-auc:0.82946\n",
            "[61]\tvalidation_0-auc:0.85072\tvalidation_1-auc:0.82975\n",
            "[62]\tvalidation_0-auc:0.85094\tvalidation_1-auc:0.82994\n",
            "[63]\tvalidation_0-auc:0.85115\tvalidation_1-auc:0.83006\n",
            "[64]\tvalidation_0-auc:0.85160\tvalidation_1-auc:0.83087\n",
            "[65]\tvalidation_0-auc:0.85168\tvalidation_1-auc:0.83081\n",
            "[66]\tvalidation_0-auc:0.85181\tvalidation_1-auc:0.83082\n",
            "[67]\tvalidation_0-auc:0.85204\tvalidation_1-auc:0.83082\n",
            "[68]\tvalidation_0-auc:0.85209\tvalidation_1-auc:0.83069\n",
            "[69]\tvalidation_0-auc:0.85198\tvalidation_1-auc:0.83030\n",
            "[70]\tvalidation_0-auc:0.85242\tvalidation_1-auc:0.83047\n",
            "[71]\tvalidation_0-auc:0.85255\tvalidation_1-auc:0.83053\n",
            "[72]\tvalidation_0-auc:0.85284\tvalidation_1-auc:0.83097\n",
            "[73]\tvalidation_0-auc:0.85302\tvalidation_1-auc:0.83106\n",
            "[74]\tvalidation_0-auc:0.85315\tvalidation_1-auc:0.83127\n",
            "[75]\tvalidation_0-auc:0.85327\tvalidation_1-auc:0.83128\n",
            "[76]\tvalidation_0-auc:0.85331\tvalidation_1-auc:0.83143\n",
            "[77]\tvalidation_0-auc:0.85341\tvalidation_1-auc:0.83157\n",
            "[78]\tvalidation_0-auc:0.85361\tvalidation_1-auc:0.83189\n",
            "[79]\tvalidation_0-auc:0.85382\tvalidation_1-auc:0.83190\n",
            "[80]\tvalidation_0-auc:0.85395\tvalidation_1-auc:0.83193\n",
            "[81]\tvalidation_0-auc:0.85396\tvalidation_1-auc:0.83189\n",
            "[82]\tvalidation_0-auc:0.85400\tvalidation_1-auc:0.83195\n",
            "[83]\tvalidation_0-auc:0.85403\tvalidation_1-auc:0.83194\n",
            "[84]\tvalidation_0-auc:0.85413\tvalidation_1-auc:0.83194\n",
            "[85]\tvalidation_0-auc:0.85443\tvalidation_1-auc:0.83212\n",
            "[86]\tvalidation_0-auc:0.85461\tvalidation_1-auc:0.83227\n",
            "[87]\tvalidation_0-auc:0.85460\tvalidation_1-auc:0.83238\n",
            "[88]\tvalidation_0-auc:0.85474\tvalidation_1-auc:0.83241\n",
            "[89]\tvalidation_0-auc:0.85486\tvalidation_1-auc:0.83257\n",
            "[90]\tvalidation_0-auc:0.85497\tvalidation_1-auc:0.83251\n",
            "[91]\tvalidation_0-auc:0.85516\tvalidation_1-auc:0.83259\n",
            "[92]\tvalidation_0-auc:0.85522\tvalidation_1-auc:0.83246\n",
            "[93]\tvalidation_0-auc:0.85541\tvalidation_1-auc:0.83265\n",
            "[94]\tvalidation_0-auc:0.85552\tvalidation_1-auc:0.83283\n",
            "[95]\tvalidation_0-auc:0.85552\tvalidation_1-auc:0.83278\n",
            "[96]\tvalidation_0-auc:0.85557\tvalidation_1-auc:0.83270\n",
            "[97]\tvalidation_0-auc:0.85559\tvalidation_1-auc:0.83246\n",
            "[98]\tvalidation_0-auc:0.85570\tvalidation_1-auc:0.83272\n",
            "[99]\tvalidation_0-auc:0.85579\tvalidation_1-auc:0.83295\n",
            "[0]\tvalidation_0-auc:0.84123\tvalidation_1-auc:0.80123\n",
            "[1]\tvalidation_0-auc:0.85123\tvalidation_1-auc:0.81103\n",
            "[2]\tvalidation_0-auc:0.85510\tvalidation_1-auc:0.81069\n",
            "[3]\tvalidation_0-auc:0.85884\tvalidation_1-auc:0.81468\n",
            "[4]\tvalidation_0-auc:0.86049\tvalidation_1-auc:0.81414\n",
            "[5]\tvalidation_0-auc:0.86287\tvalidation_1-auc:0.81839\n",
            "[6]\tvalidation_0-auc:0.86601\tvalidation_1-auc:0.82005\n",
            "[7]\tvalidation_0-auc:0.86626\tvalidation_1-auc:0.82015\n",
            "[8]\tvalidation_0-auc:0.86907\tvalidation_1-auc:0.82196\n",
            "[9]\tvalidation_0-auc:0.87025\tvalidation_1-auc:0.82389\n",
            "[10]\tvalidation_0-auc:0.87130\tvalidation_1-auc:0.82502\n",
            "[11]\tvalidation_0-auc:0.87273\tvalidation_1-auc:0.82631\n",
            "[12]\tvalidation_0-auc:0.87408\tvalidation_1-auc:0.82692\n",
            "[13]\tvalidation_0-auc:0.87586\tvalidation_1-auc:0.82801\n",
            "[14]\tvalidation_0-auc:0.87709\tvalidation_1-auc:0.82811\n",
            "[15]\tvalidation_0-auc:0.87909\tvalidation_1-auc:0.82815\n",
            "[16]\tvalidation_0-auc:0.88127\tvalidation_1-auc:0.82736\n",
            "[17]\tvalidation_0-auc:0.88214\tvalidation_1-auc:0.82804\n",
            "[18]\tvalidation_0-auc:0.88283\tvalidation_1-auc:0.82869\n",
            "[19]\tvalidation_0-auc:0.88396\tvalidation_1-auc:0.82929\n",
            "[20]\tvalidation_0-auc:0.88526\tvalidation_1-auc:0.83043\n",
            "[21]\tvalidation_0-auc:0.88706\tvalidation_1-auc:0.83056\n",
            "[22]\tvalidation_0-auc:0.88855\tvalidation_1-auc:0.83121\n",
            "[23]\tvalidation_0-auc:0.88950\tvalidation_1-auc:0.83141\n",
            "[24]\tvalidation_0-auc:0.89089\tvalidation_1-auc:0.83163\n",
            "[25]\tvalidation_0-auc:0.89151\tvalidation_1-auc:0.83188\n",
            "[26]\tvalidation_0-auc:0.89321\tvalidation_1-auc:0.83184\n",
            "[27]\tvalidation_0-auc:0.89419\tvalidation_1-auc:0.83217\n",
            "[28]\tvalidation_0-auc:0.89577\tvalidation_1-auc:0.83183\n",
            "[29]\tvalidation_0-auc:0.89704\tvalidation_1-auc:0.83201\n",
            "[30]\tvalidation_0-auc:0.89813\tvalidation_1-auc:0.83154\n",
            "[31]\tvalidation_0-auc:0.89901\tvalidation_1-auc:0.83143\n",
            "[32]\tvalidation_0-auc:0.89956\tvalidation_1-auc:0.83127\n",
            "[33]\tvalidation_0-auc:0.90052\tvalidation_1-auc:0.83157\n",
            "[34]\tvalidation_0-auc:0.90111\tvalidation_1-auc:0.83127\n",
            "[35]\tvalidation_0-auc:0.90150\tvalidation_1-auc:0.83122\n",
            "[36]\tvalidation_0-auc:0.90246\tvalidation_1-auc:0.83149\n",
            "[37]\tvalidation_0-auc:0.90327\tvalidation_1-auc:0.83157\n",
            "[38]\tvalidation_0-auc:0.90386\tvalidation_1-auc:0.83170\n",
            "[39]\tvalidation_0-auc:0.90420\tvalidation_1-auc:0.83187\n",
            "[40]\tvalidation_0-auc:0.90513\tvalidation_1-auc:0.83166\n",
            "[41]\tvalidation_0-auc:0.90571\tvalidation_1-auc:0.83162\n",
            "[42]\tvalidation_0-auc:0.90612\tvalidation_1-auc:0.83151\n",
            "[43]\tvalidation_0-auc:0.90650\tvalidation_1-auc:0.83125\n",
            "[44]\tvalidation_0-auc:0.90708\tvalidation_1-auc:0.83115\n",
            "[45]\tvalidation_0-auc:0.90752\tvalidation_1-auc:0.83109\n",
            "[46]\tvalidation_0-auc:0.90783\tvalidation_1-auc:0.83121\n",
            "[47]\tvalidation_0-auc:0.90817\tvalidation_1-auc:0.83158\n",
            "[48]\tvalidation_0-auc:0.90847\tvalidation_1-auc:0.83152\n",
            "[49]\tvalidation_0-auc:0.90867\tvalidation_1-auc:0.83162\n",
            "[50]\tvalidation_0-auc:0.90927\tvalidation_1-auc:0.83135\n",
            "[51]\tvalidation_0-auc:0.90946\tvalidation_1-auc:0.83128\n",
            "[52]\tvalidation_0-auc:0.90956\tvalidation_1-auc:0.83128\n",
            "[53]\tvalidation_0-auc:0.90992\tvalidation_1-auc:0.83129\n",
            "[54]\tvalidation_0-auc:0.91024\tvalidation_1-auc:0.83119\n",
            "[55]\tvalidation_0-auc:0.91041\tvalidation_1-auc:0.83106\n",
            "[56]\tvalidation_0-auc:0.91054\tvalidation_1-auc:0.83108\n",
            "[0]\tvalidation_0-auc:0.84376\tvalidation_1-auc:0.81811\n",
            "[1]\tvalidation_0-auc:0.85090\tvalidation_1-auc:0.82049\n",
            "[2]\tvalidation_0-auc:0.85244\tvalidation_1-auc:0.81729\n",
            "[3]\tvalidation_0-auc:0.86041\tvalidation_1-auc:0.82289\n",
            "[4]\tvalidation_0-auc:0.86369\tvalidation_1-auc:0.82533\n",
            "[5]\tvalidation_0-auc:0.86690\tvalidation_1-auc:0.82843\n",
            "[6]\tvalidation_0-auc:0.86999\tvalidation_1-auc:0.83060\n",
            "[7]\tvalidation_0-auc:0.87134\tvalidation_1-auc:0.82842\n",
            "[8]\tvalidation_0-auc:0.87303\tvalidation_1-auc:0.83019\n",
            "[9]\tvalidation_0-auc:0.87449\tvalidation_1-auc:0.83178\n",
            "[10]\tvalidation_0-auc:0.87584\tvalidation_1-auc:0.83238\n",
            "[11]\tvalidation_0-auc:0.87668\tvalidation_1-auc:0.83318\n",
            "[12]\tvalidation_0-auc:0.87840\tvalidation_1-auc:0.83385\n",
            "[13]\tvalidation_0-auc:0.87903\tvalidation_1-auc:0.83307\n",
            "[14]\tvalidation_0-auc:0.88012\tvalidation_1-auc:0.83333\n",
            "[15]\tvalidation_0-auc:0.88119\tvalidation_1-auc:0.83293\n",
            "[16]\tvalidation_0-auc:0.88210\tvalidation_1-auc:0.83366\n",
            "[17]\tvalidation_0-auc:0.88308\tvalidation_1-auc:0.83402\n",
            "[18]\tvalidation_0-auc:0.88441\tvalidation_1-auc:0.83422\n",
            "[19]\tvalidation_0-auc:0.88564\tvalidation_1-auc:0.83460\n",
            "[20]\tvalidation_0-auc:0.88713\tvalidation_1-auc:0.83402\n",
            "[21]\tvalidation_0-auc:0.88814\tvalidation_1-auc:0.83421\n",
            "[22]\tvalidation_0-auc:0.88955\tvalidation_1-auc:0.83498\n",
            "[23]\tvalidation_0-auc:0.89097\tvalidation_1-auc:0.83507\n",
            "[24]\tvalidation_0-auc:0.89245\tvalidation_1-auc:0.83533\n",
            "[25]\tvalidation_0-auc:0.89328\tvalidation_1-auc:0.83546\n",
            "[26]\tvalidation_0-auc:0.89412\tvalidation_1-auc:0.83487\n",
            "[27]\tvalidation_0-auc:0.89567\tvalidation_1-auc:0.83555\n",
            "[28]\tvalidation_0-auc:0.89669\tvalidation_1-auc:0.83536\n",
            "[29]\tvalidation_0-auc:0.89783\tvalidation_1-auc:0.83560\n",
            "[30]\tvalidation_0-auc:0.89853\tvalidation_1-auc:0.83591\n",
            "[31]\tvalidation_0-auc:0.89975\tvalidation_1-auc:0.83598\n",
            "[32]\tvalidation_0-auc:0.90014\tvalidation_1-auc:0.83577\n",
            "[33]\tvalidation_0-auc:0.90111\tvalidation_1-auc:0.83622\n",
            "[34]\tvalidation_0-auc:0.90213\tvalidation_1-auc:0.83615\n",
            "[35]\tvalidation_0-auc:0.90270\tvalidation_1-auc:0.83638\n",
            "[36]\tvalidation_0-auc:0.90354\tvalidation_1-auc:0.83669\n",
            "[37]\tvalidation_0-auc:0.90415\tvalidation_1-auc:0.83668\n",
            "[38]\tvalidation_0-auc:0.90480\tvalidation_1-auc:0.83702\n",
            "[39]\tvalidation_0-auc:0.90555\tvalidation_1-auc:0.83687\n",
            "[40]\tvalidation_0-auc:0.90649\tvalidation_1-auc:0.83639\n",
            "[41]\tvalidation_0-auc:0.90671\tvalidation_1-auc:0.83622\n",
            "[42]\tvalidation_0-auc:0.90707\tvalidation_1-auc:0.83602\n",
            "[43]\tvalidation_0-auc:0.90731\tvalidation_1-auc:0.83601\n",
            "[44]\tvalidation_0-auc:0.90790\tvalidation_1-auc:0.83616\n",
            "[45]\tvalidation_0-auc:0.90812\tvalidation_1-auc:0.83615\n",
            "[46]\tvalidation_0-auc:0.90859\tvalidation_1-auc:0.83603\n",
            "[47]\tvalidation_0-auc:0.90912\tvalidation_1-auc:0.83616\n",
            "[48]\tvalidation_0-auc:0.90954\tvalidation_1-auc:0.83597\n",
            "[49]\tvalidation_0-auc:0.91002\tvalidation_1-auc:0.83603\n",
            "[50]\tvalidation_0-auc:0.91048\tvalidation_1-auc:0.83622\n",
            "[51]\tvalidation_0-auc:0.91121\tvalidation_1-auc:0.83618\n",
            "[52]\tvalidation_0-auc:0.91144\tvalidation_1-auc:0.83612\n",
            "[53]\tvalidation_0-auc:0.91167\tvalidation_1-auc:0.83599\n",
            "[54]\tvalidation_0-auc:0.91228\tvalidation_1-auc:0.83578\n",
            "[55]\tvalidation_0-auc:0.91282\tvalidation_1-auc:0.83579\n",
            "[56]\tvalidation_0-auc:0.91322\tvalidation_1-auc:0.83570\n",
            "[57]\tvalidation_0-auc:0.91355\tvalidation_1-auc:0.83574\n",
            "[58]\tvalidation_0-auc:0.91407\tvalidation_1-auc:0.83538\n",
            "[59]\tvalidation_0-auc:0.91423\tvalidation_1-auc:0.83550\n",
            "[60]\tvalidation_0-auc:0.91448\tvalidation_1-auc:0.83563\n",
            "[61]\tvalidation_0-auc:0.91467\tvalidation_1-auc:0.83573\n",
            "[62]\tvalidation_0-auc:0.91522\tvalidation_1-auc:0.83567\n",
            "[63]\tvalidation_0-auc:0.91549\tvalidation_1-auc:0.83563\n",
            "[64]\tvalidation_0-auc:0.91598\tvalidation_1-auc:0.83561\n",
            "[65]\tvalidation_0-auc:0.91627\tvalidation_1-auc:0.83567\n",
            "[66]\tvalidation_0-auc:0.91637\tvalidation_1-auc:0.83558\n",
            "[67]\tvalidation_0-auc:0.91663\tvalidation_1-auc:0.83560\n",
            "[68]\tvalidation_0-auc:0.91680\tvalidation_1-auc:0.83545\n",
            "[0]\tvalidation_0-auc:0.84404\tvalidation_1-auc:0.80947\n",
            "[1]\tvalidation_0-auc:0.85284\tvalidation_1-auc:0.81966\n",
            "[2]\tvalidation_0-auc:0.85432\tvalidation_1-auc:0.81753\n",
            "[3]\tvalidation_0-auc:0.85863\tvalidation_1-auc:0.82082\n",
            "[4]\tvalidation_0-auc:0.86091\tvalidation_1-auc:0.82213\n",
            "[5]\tvalidation_0-auc:0.86315\tvalidation_1-auc:0.82501\n",
            "[6]\tvalidation_0-auc:0.86514\tvalidation_1-auc:0.82586\n",
            "[7]\tvalidation_0-auc:0.86734\tvalidation_1-auc:0.82689\n",
            "[8]\tvalidation_0-auc:0.86907\tvalidation_1-auc:0.82891\n",
            "[9]\tvalidation_0-auc:0.87108\tvalidation_1-auc:0.82959\n",
            "[10]\tvalidation_0-auc:0.87317\tvalidation_1-auc:0.83068\n",
            "[11]\tvalidation_0-auc:0.87414\tvalidation_1-auc:0.83174\n",
            "[12]\tvalidation_0-auc:0.87569\tvalidation_1-auc:0.83293\n",
            "[13]\tvalidation_0-auc:0.87651\tvalidation_1-auc:0.83317\n",
            "[14]\tvalidation_0-auc:0.87777\tvalidation_1-auc:0.83342\n",
            "[15]\tvalidation_0-auc:0.87857\tvalidation_1-auc:0.83337\n",
            "[16]\tvalidation_0-auc:0.88041\tvalidation_1-auc:0.83322\n",
            "[17]\tvalidation_0-auc:0.88293\tvalidation_1-auc:0.83297\n",
            "[18]\tvalidation_0-auc:0.88484\tvalidation_1-auc:0.83324\n",
            "[19]\tvalidation_0-auc:0.88685\tvalidation_1-auc:0.83475\n",
            "[20]\tvalidation_0-auc:0.88857\tvalidation_1-auc:0.83360\n",
            "[21]\tvalidation_0-auc:0.88921\tvalidation_1-auc:0.83325\n",
            "[22]\tvalidation_0-auc:0.89155\tvalidation_1-auc:0.83403\n",
            "[23]\tvalidation_0-auc:0.89272\tvalidation_1-auc:0.83450\n",
            "[24]\tvalidation_0-auc:0.89363\tvalidation_1-auc:0.83517\n",
            "[25]\tvalidation_0-auc:0.89438\tvalidation_1-auc:0.83537\n",
            "[26]\tvalidation_0-auc:0.89604\tvalidation_1-auc:0.83577\n",
            "[27]\tvalidation_0-auc:0.89730\tvalidation_1-auc:0.83618\n",
            "[28]\tvalidation_0-auc:0.89900\tvalidation_1-auc:0.83628\n",
            "[29]\tvalidation_0-auc:0.90034\tvalidation_1-auc:0.83618\n",
            "[30]\tvalidation_0-auc:0.90141\tvalidation_1-auc:0.83656\n",
            "[31]\tvalidation_0-auc:0.90222\tvalidation_1-auc:0.83663\n",
            "[32]\tvalidation_0-auc:0.90281\tvalidation_1-auc:0.83615\n",
            "[33]\tvalidation_0-auc:0.90368\tvalidation_1-auc:0.83557\n",
            "[34]\tvalidation_0-auc:0.90458\tvalidation_1-auc:0.83479\n",
            "[35]\tvalidation_0-auc:0.90509\tvalidation_1-auc:0.83533\n",
            "[36]\tvalidation_0-auc:0.90623\tvalidation_1-auc:0.83520\n",
            "[37]\tvalidation_0-auc:0.90674\tvalidation_1-auc:0.83544\n",
            "[38]\tvalidation_0-auc:0.90725\tvalidation_1-auc:0.83513\n",
            "[39]\tvalidation_0-auc:0.90758\tvalidation_1-auc:0.83519\n",
            "[40]\tvalidation_0-auc:0.90813\tvalidation_1-auc:0.83497\n",
            "[41]\tvalidation_0-auc:0.90841\tvalidation_1-auc:0.83498\n",
            "[42]\tvalidation_0-auc:0.90904\tvalidation_1-auc:0.83514\n",
            "[43]\tvalidation_0-auc:0.90957\tvalidation_1-auc:0.83518\n",
            "[44]\tvalidation_0-auc:0.90989\tvalidation_1-auc:0.83506\n",
            "[45]\tvalidation_0-auc:0.91057\tvalidation_1-auc:0.83515\n",
            "[46]\tvalidation_0-auc:0.91090\tvalidation_1-auc:0.83522\n",
            "[47]\tvalidation_0-auc:0.91124\tvalidation_1-auc:0.83554\n",
            "[48]\tvalidation_0-auc:0.91147\tvalidation_1-auc:0.83568\n",
            "[49]\tvalidation_0-auc:0.91173\tvalidation_1-auc:0.83579\n",
            "[50]\tvalidation_0-auc:0.91224\tvalidation_1-auc:0.83574\n",
            "[51]\tvalidation_0-auc:0.91271\tvalidation_1-auc:0.83582\n",
            "[52]\tvalidation_0-auc:0.91285\tvalidation_1-auc:0.83582\n",
            "[53]\tvalidation_0-auc:0.91371\tvalidation_1-auc:0.83581\n",
            "[54]\tvalidation_0-auc:0.91419\tvalidation_1-auc:0.83573\n",
            "[55]\tvalidation_0-auc:0.91472\tvalidation_1-auc:0.83574\n",
            "[56]\tvalidation_0-auc:0.91495\tvalidation_1-auc:0.83574\n",
            "[57]\tvalidation_0-auc:0.91521\tvalidation_1-auc:0.83604\n",
            "[58]\tvalidation_0-auc:0.91544\tvalidation_1-auc:0.83614\n",
            "[59]\tvalidation_0-auc:0.91574\tvalidation_1-auc:0.83615\n",
            "[60]\tvalidation_0-auc:0.91619\tvalidation_1-auc:0.83604\n",
            "[61]\tvalidation_0-auc:0.91689\tvalidation_1-auc:0.83608\n",
            "[0]\tvalidation_0-auc:0.84414\tvalidation_1-auc:0.80657\n",
            "[1]\tvalidation_0-auc:0.85377\tvalidation_1-auc:0.81641\n",
            "[2]\tvalidation_0-auc:0.85443\tvalidation_1-auc:0.81028\n",
            "[3]\tvalidation_0-auc:0.86194\tvalidation_1-auc:0.81891\n",
            "[4]\tvalidation_0-auc:0.86688\tvalidation_1-auc:0.82103\n",
            "[5]\tvalidation_0-auc:0.86898\tvalidation_1-auc:0.82366\n",
            "[6]\tvalidation_0-auc:0.87063\tvalidation_1-auc:0.82520\n",
            "[7]\tvalidation_0-auc:0.87169\tvalidation_1-auc:0.82526\n",
            "[8]\tvalidation_0-auc:0.87328\tvalidation_1-auc:0.82724\n",
            "[9]\tvalidation_0-auc:0.87298\tvalidation_1-auc:0.82624\n",
            "[10]\tvalidation_0-auc:0.87497\tvalidation_1-auc:0.82881\n",
            "[11]\tvalidation_0-auc:0.87665\tvalidation_1-auc:0.82883\n",
            "[12]\tvalidation_0-auc:0.87925\tvalidation_1-auc:0.82870\n",
            "[13]\tvalidation_0-auc:0.88094\tvalidation_1-auc:0.82948\n",
            "[14]\tvalidation_0-auc:0.88244\tvalidation_1-auc:0.82918\n",
            "[15]\tvalidation_0-auc:0.88275\tvalidation_1-auc:0.82966\n",
            "[16]\tvalidation_0-auc:0.88407\tvalidation_1-auc:0.82935\n",
            "[17]\tvalidation_0-auc:0.88552\tvalidation_1-auc:0.83012\n",
            "[18]\tvalidation_0-auc:0.88670\tvalidation_1-auc:0.83071\n",
            "[19]\tvalidation_0-auc:0.88788\tvalidation_1-auc:0.83064\n",
            "[20]\tvalidation_0-auc:0.88867\tvalidation_1-auc:0.83044\n",
            "[21]\tvalidation_0-auc:0.88914\tvalidation_1-auc:0.83069\n",
            "[22]\tvalidation_0-auc:0.89001\tvalidation_1-auc:0.83101\n",
            "[23]\tvalidation_0-auc:0.89109\tvalidation_1-auc:0.83189\n",
            "[24]\tvalidation_0-auc:0.89204\tvalidation_1-auc:0.83278\n",
            "[25]\tvalidation_0-auc:0.89282\tvalidation_1-auc:0.83279\n",
            "[26]\tvalidation_0-auc:0.89372\tvalidation_1-auc:0.83268\n",
            "[27]\tvalidation_0-auc:0.89444\tvalidation_1-auc:0.83242\n",
            "[28]\tvalidation_0-auc:0.89563\tvalidation_1-auc:0.83202\n",
            "[29]\tvalidation_0-auc:0.89622\tvalidation_1-auc:0.83215\n",
            "[30]\tvalidation_0-auc:0.89693\tvalidation_1-auc:0.83218\n",
            "[31]\tvalidation_0-auc:0.89786\tvalidation_1-auc:0.83176\n",
            "[32]\tvalidation_0-auc:0.89816\tvalidation_1-auc:0.83186\n",
            "[33]\tvalidation_0-auc:0.89851\tvalidation_1-auc:0.83201\n",
            "[34]\tvalidation_0-auc:0.89977\tvalidation_1-auc:0.83255\n",
            "[35]\tvalidation_0-auc:0.89988\tvalidation_1-auc:0.83267\n",
            "[36]\tvalidation_0-auc:0.90020\tvalidation_1-auc:0.83257\n",
            "[37]\tvalidation_0-auc:0.90064\tvalidation_1-auc:0.83272\n",
            "[38]\tvalidation_0-auc:0.90118\tvalidation_1-auc:0.83271\n",
            "[39]\tvalidation_0-auc:0.90177\tvalidation_1-auc:0.83240\n",
            "[40]\tvalidation_0-auc:0.90188\tvalidation_1-auc:0.83242\n",
            "[41]\tvalidation_0-auc:0.90223\tvalidation_1-auc:0.83237\n",
            "[42]\tvalidation_0-auc:0.90282\tvalidation_1-auc:0.83223\n",
            "[43]\tvalidation_0-auc:0.90294\tvalidation_1-auc:0.83227\n",
            "[44]\tvalidation_0-auc:0.90331\tvalidation_1-auc:0.83211\n",
            "[45]\tvalidation_0-auc:0.90345\tvalidation_1-auc:0.83217\n",
            "[46]\tvalidation_0-auc:0.90356\tvalidation_1-auc:0.83190\n",
            "[47]\tvalidation_0-auc:0.90445\tvalidation_1-auc:0.83174\n",
            "[48]\tvalidation_0-auc:0.90457\tvalidation_1-auc:0.83157\n",
            "[49]\tvalidation_0-auc:0.90499\tvalidation_1-auc:0.83142\n",
            "[50]\tvalidation_0-auc:0.90524\tvalidation_1-auc:0.83096\n",
            "[51]\tvalidation_0-auc:0.90539\tvalidation_1-auc:0.83092\n",
            "[52]\tvalidation_0-auc:0.90570\tvalidation_1-auc:0.83060\n",
            "[53]\tvalidation_0-auc:0.90594\tvalidation_1-auc:0.83060\n",
            "[54]\tvalidation_0-auc:0.90613\tvalidation_1-auc:0.83047\n",
            "[0]\tvalidation_0-auc:0.84430\tvalidation_1-auc:0.81493\n",
            "[1]\tvalidation_0-auc:0.85281\tvalidation_1-auc:0.82322\n",
            "[2]\tvalidation_0-auc:0.85416\tvalidation_1-auc:0.81890\n",
            "[3]\tvalidation_0-auc:0.86351\tvalidation_1-auc:0.82380\n",
            "[4]\tvalidation_0-auc:0.86706\tvalidation_1-auc:0.82715\n",
            "[5]\tvalidation_0-auc:0.86971\tvalidation_1-auc:0.83008\n",
            "[6]\tvalidation_0-auc:0.87280\tvalidation_1-auc:0.83203\n",
            "[7]\tvalidation_0-auc:0.87432\tvalidation_1-auc:0.82881\n",
            "[8]\tvalidation_0-auc:0.87622\tvalidation_1-auc:0.83025\n",
            "[9]\tvalidation_0-auc:0.87456\tvalidation_1-auc:0.82754\n",
            "[10]\tvalidation_0-auc:0.87660\tvalidation_1-auc:0.83004\n",
            "[11]\tvalidation_0-auc:0.87848\tvalidation_1-auc:0.83066\n",
            "[12]\tvalidation_0-auc:0.88125\tvalidation_1-auc:0.83201\n",
            "[13]\tvalidation_0-auc:0.88281\tvalidation_1-auc:0.83423\n",
            "[14]\tvalidation_0-auc:0.88372\tvalidation_1-auc:0.83494\n",
            "[15]\tvalidation_0-auc:0.88428\tvalidation_1-auc:0.83539\n",
            "[16]\tvalidation_0-auc:0.88621\tvalidation_1-auc:0.83503\n",
            "[17]\tvalidation_0-auc:0.88719\tvalidation_1-auc:0.83551\n",
            "[18]\tvalidation_0-auc:0.88846\tvalidation_1-auc:0.83570\n",
            "[19]\tvalidation_0-auc:0.88942\tvalidation_1-auc:0.83609\n",
            "[20]\tvalidation_0-auc:0.89061\tvalidation_1-auc:0.83512\n",
            "[21]\tvalidation_0-auc:0.89144\tvalidation_1-auc:0.83460\n",
            "[22]\tvalidation_0-auc:0.89265\tvalidation_1-auc:0.83512\n",
            "[23]\tvalidation_0-auc:0.89343\tvalidation_1-auc:0.83534\n",
            "[24]\tvalidation_0-auc:0.89385\tvalidation_1-auc:0.83581\n",
            "[25]\tvalidation_0-auc:0.89467\tvalidation_1-auc:0.83603\n",
            "[26]\tvalidation_0-auc:0.89519\tvalidation_1-auc:0.83641\n",
            "[27]\tvalidation_0-auc:0.89603\tvalidation_1-auc:0.83679\n",
            "[28]\tvalidation_0-auc:0.89715\tvalidation_1-auc:0.83642\n",
            "[29]\tvalidation_0-auc:0.89776\tvalidation_1-auc:0.83640\n",
            "[30]\tvalidation_0-auc:0.89824\tvalidation_1-auc:0.83630\n",
            "[31]\tvalidation_0-auc:0.89907\tvalidation_1-auc:0.83680\n",
            "[32]\tvalidation_0-auc:0.89971\tvalidation_1-auc:0.83653\n",
            "[33]\tvalidation_0-auc:0.90015\tvalidation_1-auc:0.83642\n",
            "[34]\tvalidation_0-auc:0.90121\tvalidation_1-auc:0.83616\n",
            "[35]\tvalidation_0-auc:0.90162\tvalidation_1-auc:0.83616\n",
            "[36]\tvalidation_0-auc:0.90201\tvalidation_1-auc:0.83673\n",
            "[37]\tvalidation_0-auc:0.90223\tvalidation_1-auc:0.83674\n",
            "[38]\tvalidation_0-auc:0.90243\tvalidation_1-auc:0.83664\n",
            "[39]\tvalidation_0-auc:0.90266\tvalidation_1-auc:0.83662\n",
            "[40]\tvalidation_0-auc:0.90284\tvalidation_1-auc:0.83684\n",
            "[41]\tvalidation_0-auc:0.90324\tvalidation_1-auc:0.83670\n",
            "[42]\tvalidation_0-auc:0.90450\tvalidation_1-auc:0.83660\n",
            "[43]\tvalidation_0-auc:0.90469\tvalidation_1-auc:0.83643\n",
            "[44]\tvalidation_0-auc:0.90512\tvalidation_1-auc:0.83630\n",
            "[45]\tvalidation_0-auc:0.90522\tvalidation_1-auc:0.83620\n",
            "[46]\tvalidation_0-auc:0.90590\tvalidation_1-auc:0.83616\n",
            "[47]\tvalidation_0-auc:0.90599\tvalidation_1-auc:0.83615\n",
            "[48]\tvalidation_0-auc:0.90660\tvalidation_1-auc:0.83592\n",
            "[49]\tvalidation_0-auc:0.90683\tvalidation_1-auc:0.83590\n",
            "[50]\tvalidation_0-auc:0.90695\tvalidation_1-auc:0.83593\n",
            "[51]\tvalidation_0-auc:0.90720\tvalidation_1-auc:0.83584\n",
            "[52]\tvalidation_0-auc:0.90748\tvalidation_1-auc:0.83591\n",
            "[53]\tvalidation_0-auc:0.90769\tvalidation_1-auc:0.83596\n",
            "[54]\tvalidation_0-auc:0.90790\tvalidation_1-auc:0.83611\n",
            "[55]\tvalidation_0-auc:0.90808\tvalidation_1-auc:0.83612\n",
            "[56]\tvalidation_0-auc:0.90880\tvalidation_1-auc:0.83585\n",
            "[57]\tvalidation_0-auc:0.90907\tvalidation_1-auc:0.83621\n",
            "[58]\tvalidation_0-auc:0.90933\tvalidation_1-auc:0.83618\n",
            "[59]\tvalidation_0-auc:0.90961\tvalidation_1-auc:0.83618\n",
            "[60]\tvalidation_0-auc:0.90980\tvalidation_1-auc:0.83625\n",
            "[61]\tvalidation_0-auc:0.91031\tvalidation_1-auc:0.83608\n",
            "[62]\tvalidation_0-auc:0.91091\tvalidation_1-auc:0.83618\n",
            "[63]\tvalidation_0-auc:0.91106\tvalidation_1-auc:0.83623\n",
            "[64]\tvalidation_0-auc:0.91132\tvalidation_1-auc:0.83618\n",
            "[65]\tvalidation_0-auc:0.91180\tvalidation_1-auc:0.83606\n",
            "[66]\tvalidation_0-auc:0.91186\tvalidation_1-auc:0.83606\n",
            "[67]\tvalidation_0-auc:0.91194\tvalidation_1-auc:0.83591\n",
            "[68]\tvalidation_0-auc:0.91219\tvalidation_1-auc:0.83553\n",
            "[69]\tvalidation_0-auc:0.91230\tvalidation_1-auc:0.83552\n",
            "[0]\tvalidation_0-auc:0.84585\tvalidation_1-auc:0.81505\n",
            "[1]\tvalidation_0-auc:0.85301\tvalidation_1-auc:0.82442\n",
            "[2]\tvalidation_0-auc:0.85368\tvalidation_1-auc:0.81905\n",
            "[3]\tvalidation_0-auc:0.85857\tvalidation_1-auc:0.82235\n",
            "[4]\tvalidation_0-auc:0.86078\tvalidation_1-auc:0.82343\n",
            "[5]\tvalidation_0-auc:0.86494\tvalidation_1-auc:0.82638\n",
            "[6]\tvalidation_0-auc:0.86763\tvalidation_1-auc:0.82673\n",
            "[7]\tvalidation_0-auc:0.87054\tvalidation_1-auc:0.82547\n",
            "[8]\tvalidation_0-auc:0.87152\tvalidation_1-auc:0.82625\n",
            "[9]\tvalidation_0-auc:0.87200\tvalidation_1-auc:0.82535\n",
            "[10]\tvalidation_0-auc:0.87445\tvalidation_1-auc:0.82788\n",
            "[11]\tvalidation_0-auc:0.87703\tvalidation_1-auc:0.82948\n",
            "[12]\tvalidation_0-auc:0.87878\tvalidation_1-auc:0.83056\n",
            "[13]\tvalidation_0-auc:0.88037\tvalidation_1-auc:0.83187\n",
            "[14]\tvalidation_0-auc:0.88203\tvalidation_1-auc:0.83292\n",
            "[15]\tvalidation_0-auc:0.88328\tvalidation_1-auc:0.83280\n",
            "[16]\tvalidation_0-auc:0.88473\tvalidation_1-auc:0.83319\n",
            "[17]\tvalidation_0-auc:0.88651\tvalidation_1-auc:0.83429\n",
            "[18]\tvalidation_0-auc:0.88750\tvalidation_1-auc:0.83451\n",
            "[19]\tvalidation_0-auc:0.88896\tvalidation_1-auc:0.83477\n",
            "[20]\tvalidation_0-auc:0.88994\tvalidation_1-auc:0.83445\n",
            "[21]\tvalidation_0-auc:0.89092\tvalidation_1-auc:0.83440\n",
            "[22]\tvalidation_0-auc:0.89217\tvalidation_1-auc:0.83472\n",
            "[23]\tvalidation_0-auc:0.89292\tvalidation_1-auc:0.83513\n",
            "[24]\tvalidation_0-auc:0.89340\tvalidation_1-auc:0.83517\n",
            "[25]\tvalidation_0-auc:0.89389\tvalidation_1-auc:0.83537\n",
            "[26]\tvalidation_0-auc:0.89489\tvalidation_1-auc:0.83551\n",
            "[27]\tvalidation_0-auc:0.89553\tvalidation_1-auc:0.83584\n",
            "[28]\tvalidation_0-auc:0.89637\tvalidation_1-auc:0.83585\n",
            "[29]\tvalidation_0-auc:0.89686\tvalidation_1-auc:0.83561\n",
            "[30]\tvalidation_0-auc:0.89709\tvalidation_1-auc:0.83571\n",
            "[31]\tvalidation_0-auc:0.89789\tvalidation_1-auc:0.83532\n",
            "[32]\tvalidation_0-auc:0.89846\tvalidation_1-auc:0.83563\n",
            "[33]\tvalidation_0-auc:0.89889\tvalidation_1-auc:0.83570\n",
            "[34]\tvalidation_0-auc:0.89958\tvalidation_1-auc:0.83545\n",
            "[35]\tvalidation_0-auc:0.89988\tvalidation_1-auc:0.83513\n",
            "[36]\tvalidation_0-auc:0.90042\tvalidation_1-auc:0.83559\n",
            "[37]\tvalidation_0-auc:0.90062\tvalidation_1-auc:0.83574\n",
            "[38]\tvalidation_0-auc:0.90108\tvalidation_1-auc:0.83600\n",
            "[39]\tvalidation_0-auc:0.90183\tvalidation_1-auc:0.83633\n",
            "[40]\tvalidation_0-auc:0.90203\tvalidation_1-auc:0.83626\n",
            "[41]\tvalidation_0-auc:0.90218\tvalidation_1-auc:0.83601\n",
            "[42]\tvalidation_0-auc:0.90273\tvalidation_1-auc:0.83607\n",
            "[43]\tvalidation_0-auc:0.90319\tvalidation_1-auc:0.83623\n",
            "[44]\tvalidation_0-auc:0.90349\tvalidation_1-auc:0.83626\n",
            "[45]\tvalidation_0-auc:0.90438\tvalidation_1-auc:0.83645\n",
            "[46]\tvalidation_0-auc:0.90473\tvalidation_1-auc:0.83615\n",
            "[47]\tvalidation_0-auc:0.90557\tvalidation_1-auc:0.83645\n",
            "[48]\tvalidation_0-auc:0.90572\tvalidation_1-auc:0.83676\n",
            "[49]\tvalidation_0-auc:0.90624\tvalidation_1-auc:0.83647\n",
            "[50]\tvalidation_0-auc:0.90641\tvalidation_1-auc:0.83651\n",
            "[51]\tvalidation_0-auc:0.90706\tvalidation_1-auc:0.83672\n",
            "[52]\tvalidation_0-auc:0.90715\tvalidation_1-auc:0.83664\n",
            "[53]\tvalidation_0-auc:0.90769\tvalidation_1-auc:0.83685\n",
            "[54]\tvalidation_0-auc:0.90795\tvalidation_1-auc:0.83649\n",
            "[55]\tvalidation_0-auc:0.90822\tvalidation_1-auc:0.83629\n",
            "[56]\tvalidation_0-auc:0.90860\tvalidation_1-auc:0.83641\n",
            "[57]\tvalidation_0-auc:0.90921\tvalidation_1-auc:0.83647\n",
            "[58]\tvalidation_0-auc:0.90980\tvalidation_1-auc:0.83633\n",
            "[59]\tvalidation_0-auc:0.91014\tvalidation_1-auc:0.83628\n",
            "[60]\tvalidation_0-auc:0.91025\tvalidation_1-auc:0.83606\n",
            "[61]\tvalidation_0-auc:0.91043\tvalidation_1-auc:0.83600\n",
            "[62]\tvalidation_0-auc:0.91058\tvalidation_1-auc:0.83596\n",
            "[63]\tvalidation_0-auc:0.91137\tvalidation_1-auc:0.83593\n",
            "[64]\tvalidation_0-auc:0.91189\tvalidation_1-auc:0.83591\n",
            "[65]\tvalidation_0-auc:0.91212\tvalidation_1-auc:0.83568\n",
            "[66]\tvalidation_0-auc:0.91226\tvalidation_1-auc:0.83556\n",
            "[67]\tvalidation_0-auc:0.91238\tvalidation_1-auc:0.83565\n",
            "[68]\tvalidation_0-auc:0.91262\tvalidation_1-auc:0.83575\n",
            "[69]\tvalidation_0-auc:0.91304\tvalidation_1-auc:0.83591\n",
            "[70]\tvalidation_0-auc:0.91366\tvalidation_1-auc:0.83560\n",
            "[71]\tvalidation_0-auc:0.91455\tvalidation_1-auc:0.83528\n",
            "[72]\tvalidation_0-auc:0.91481\tvalidation_1-auc:0.83517\n",
            "[73]\tvalidation_0-auc:0.91522\tvalidation_1-auc:0.83527\n",
            "[74]\tvalidation_0-auc:0.91533\tvalidation_1-auc:0.83526\n",
            "[75]\tvalidation_0-auc:0.91541\tvalidation_1-auc:0.83520\n",
            "[76]\tvalidation_0-auc:0.91558\tvalidation_1-auc:0.83516\n",
            "[77]\tvalidation_0-auc:0.91583\tvalidation_1-auc:0.83496\n",
            "[78]\tvalidation_0-auc:0.91593\tvalidation_1-auc:0.83494\n",
            "[79]\tvalidation_0-auc:0.91609\tvalidation_1-auc:0.83486\n",
            "[80]\tvalidation_0-auc:0.91627\tvalidation_1-auc:0.83478\n",
            "[81]\tvalidation_0-auc:0.91664\tvalidation_1-auc:0.83465\n",
            "[82]\tvalidation_0-auc:0.91679\tvalidation_1-auc:0.83471\n",
            "[83]\tvalidation_0-auc:0.91698\tvalidation_1-auc:0.83454\n",
            "[0]\tvalidation_0-auc:0.83151\tvalidation_1-auc:0.79801\n",
            "[1]\tvalidation_0-auc:0.84135\tvalidation_1-auc:0.81159\n",
            "[2]\tvalidation_0-auc:0.84082\tvalidation_1-auc:0.81108\n",
            "[3]\tvalidation_0-auc:0.84930\tvalidation_1-auc:0.81917\n",
            "[4]\tvalidation_0-auc:0.85257\tvalidation_1-auc:0.82302\n",
            "[5]\tvalidation_0-auc:0.85427\tvalidation_1-auc:0.82548\n",
            "[6]\tvalidation_0-auc:0.85851\tvalidation_1-auc:0.82572\n",
            "[7]\tvalidation_0-auc:0.86112\tvalidation_1-auc:0.82735\n",
            "[8]\tvalidation_0-auc:0.86406\tvalidation_1-auc:0.82901\n",
            "[9]\tvalidation_0-auc:0.86398\tvalidation_1-auc:0.82896\n",
            "[10]\tvalidation_0-auc:0.86653\tvalidation_1-auc:0.82965\n",
            "[11]\tvalidation_0-auc:0.86775\tvalidation_1-auc:0.83012\n",
            "[12]\tvalidation_0-auc:0.86950\tvalidation_1-auc:0.82992\n",
            "[13]\tvalidation_0-auc:0.87126\tvalidation_1-auc:0.83022\n",
            "[14]\tvalidation_0-auc:0.87261\tvalidation_1-auc:0.83090\n",
            "[15]\tvalidation_0-auc:0.87427\tvalidation_1-auc:0.83103\n",
            "[16]\tvalidation_0-auc:0.87565\tvalidation_1-auc:0.82976\n",
            "[17]\tvalidation_0-auc:0.87725\tvalidation_1-auc:0.82963\n",
            "[18]\tvalidation_0-auc:0.87772\tvalidation_1-auc:0.82965\n",
            "[19]\tvalidation_0-auc:0.87955\tvalidation_1-auc:0.82921\n",
            "[20]\tvalidation_0-auc:0.88117\tvalidation_1-auc:0.82849\n",
            "[21]\tvalidation_0-auc:0.88187\tvalidation_1-auc:0.82918\n",
            "[22]\tvalidation_0-auc:0.88289\tvalidation_1-auc:0.82950\n",
            "[23]\tvalidation_0-auc:0.88353\tvalidation_1-auc:0.82987\n",
            "[24]\tvalidation_0-auc:0.88414\tvalidation_1-auc:0.82998\n",
            "[25]\tvalidation_0-auc:0.88444\tvalidation_1-auc:0.83019\n",
            "[26]\tvalidation_0-auc:0.88505\tvalidation_1-auc:0.83043\n",
            "[27]\tvalidation_0-auc:0.88593\tvalidation_1-auc:0.83050\n",
            "[28]\tvalidation_0-auc:0.88635\tvalidation_1-auc:0.83046\n",
            "[29]\tvalidation_0-auc:0.88700\tvalidation_1-auc:0.83081\n",
            "[30]\tvalidation_0-auc:0.88789\tvalidation_1-auc:0.83051\n",
            "[31]\tvalidation_0-auc:0.88832\tvalidation_1-auc:0.83028\n",
            "[32]\tvalidation_0-auc:0.88869\tvalidation_1-auc:0.82964\n",
            "[33]\tvalidation_0-auc:0.88884\tvalidation_1-auc:0.82964\n",
            "[34]\tvalidation_0-auc:0.88974\tvalidation_1-auc:0.82986\n",
            "[35]\tvalidation_0-auc:0.88991\tvalidation_1-auc:0.83029\n",
            "[36]\tvalidation_0-auc:0.88998\tvalidation_1-auc:0.83040\n",
            "[37]\tvalidation_0-auc:0.89115\tvalidation_1-auc:0.83034\n",
            "[38]\tvalidation_0-auc:0.89187\tvalidation_1-auc:0.83064\n",
            "[39]\tvalidation_0-auc:0.89205\tvalidation_1-auc:0.83053\n",
            "[40]\tvalidation_0-auc:0.89235\tvalidation_1-auc:0.83047\n",
            "[41]\tvalidation_0-auc:0.89251\tvalidation_1-auc:0.83043\n",
            "[42]\tvalidation_0-auc:0.89270\tvalidation_1-auc:0.83020\n",
            "[43]\tvalidation_0-auc:0.89296\tvalidation_1-auc:0.83005\n",
            "[44]\tvalidation_0-auc:0.89348\tvalidation_1-auc:0.83013\n",
            "[0]\tvalidation_0-auc:0.83347\tvalidation_1-auc:0.81638\n",
            "[1]\tvalidation_0-auc:0.84191\tvalidation_1-auc:0.82045\n",
            "[2]\tvalidation_0-auc:0.84248\tvalidation_1-auc:0.81493\n",
            "[3]\tvalidation_0-auc:0.85206\tvalidation_1-auc:0.82353\n",
            "[4]\tvalidation_0-auc:0.85582\tvalidation_1-auc:0.82599\n",
            "[5]\tvalidation_0-auc:0.85892\tvalidation_1-auc:0.82947\n",
            "[6]\tvalidation_0-auc:0.86048\tvalidation_1-auc:0.83043\n",
            "[7]\tvalidation_0-auc:0.86199\tvalidation_1-auc:0.82887\n",
            "[8]\tvalidation_0-auc:0.86458\tvalidation_1-auc:0.83039\n",
            "[9]\tvalidation_0-auc:0.86419\tvalidation_1-auc:0.82950\n",
            "[10]\tvalidation_0-auc:0.86768\tvalidation_1-auc:0.83057\n",
            "[11]\tvalidation_0-auc:0.86930\tvalidation_1-auc:0.83132\n",
            "[12]\tvalidation_0-auc:0.87194\tvalidation_1-auc:0.83340\n",
            "[13]\tvalidation_0-auc:0.87318\tvalidation_1-auc:0.83384\n",
            "[14]\tvalidation_0-auc:0.87468\tvalidation_1-auc:0.83431\n",
            "[15]\tvalidation_0-auc:0.87634\tvalidation_1-auc:0.83469\n",
            "[16]\tvalidation_0-auc:0.87730\tvalidation_1-auc:0.83437\n",
            "[17]\tvalidation_0-auc:0.87872\tvalidation_1-auc:0.83524\n",
            "[18]\tvalidation_0-auc:0.87957\tvalidation_1-auc:0.83538\n",
            "[19]\tvalidation_0-auc:0.88042\tvalidation_1-auc:0.83574\n",
            "[20]\tvalidation_0-auc:0.88201\tvalidation_1-auc:0.83576\n",
            "[21]\tvalidation_0-auc:0.88286\tvalidation_1-auc:0.83548\n",
            "[22]\tvalidation_0-auc:0.88358\tvalidation_1-auc:0.83577\n",
            "[23]\tvalidation_0-auc:0.88420\tvalidation_1-auc:0.83629\n",
            "[24]\tvalidation_0-auc:0.88452\tvalidation_1-auc:0.83612\n",
            "[25]\tvalidation_0-auc:0.88533\tvalidation_1-auc:0.83617\n",
            "[26]\tvalidation_0-auc:0.88579\tvalidation_1-auc:0.83588\n",
            "[27]\tvalidation_0-auc:0.88632\tvalidation_1-auc:0.83536\n",
            "[28]\tvalidation_0-auc:0.88724\tvalidation_1-auc:0.83522\n",
            "[29]\tvalidation_0-auc:0.88785\tvalidation_1-auc:0.83492\n",
            "[30]\tvalidation_0-auc:0.88801\tvalidation_1-auc:0.83488\n",
            "[31]\tvalidation_0-auc:0.88886\tvalidation_1-auc:0.83512\n",
            "[32]\tvalidation_0-auc:0.88925\tvalidation_1-auc:0.83511\n",
            "[33]\tvalidation_0-auc:0.88947\tvalidation_1-auc:0.83508\n",
            "[34]\tvalidation_0-auc:0.88974\tvalidation_1-auc:0.83493\n",
            "[35]\tvalidation_0-auc:0.89008\tvalidation_1-auc:0.83506\n",
            "[36]\tvalidation_0-auc:0.89027\tvalidation_1-auc:0.83503\n",
            "[37]\tvalidation_0-auc:0.89109\tvalidation_1-auc:0.83497\n",
            "[38]\tvalidation_0-auc:0.89172\tvalidation_1-auc:0.83519\n",
            "[39]\tvalidation_0-auc:0.89212\tvalidation_1-auc:0.83493\n",
            "[40]\tvalidation_0-auc:0.89245\tvalidation_1-auc:0.83487\n",
            "[41]\tvalidation_0-auc:0.89264\tvalidation_1-auc:0.83464\n",
            "[42]\tvalidation_0-auc:0.89307\tvalidation_1-auc:0.83497\n",
            "[43]\tvalidation_0-auc:0.89328\tvalidation_1-auc:0.83511\n",
            "[44]\tvalidation_0-auc:0.89364\tvalidation_1-auc:0.83478\n",
            "[45]\tvalidation_0-auc:0.89385\tvalidation_1-auc:0.83474\n",
            "[46]\tvalidation_0-auc:0.89411\tvalidation_1-auc:0.83474\n",
            "[47]\tvalidation_0-auc:0.89441\tvalidation_1-auc:0.83443\n",
            "[48]\tvalidation_0-auc:0.89482\tvalidation_1-auc:0.83452\n",
            "[49]\tvalidation_0-auc:0.89612\tvalidation_1-auc:0.83454\n",
            "[50]\tvalidation_0-auc:0.89632\tvalidation_1-auc:0.83430\n",
            "[51]\tvalidation_0-auc:0.89658\tvalidation_1-auc:0.83424\n",
            "[52]\tvalidation_0-auc:0.89678\tvalidation_1-auc:0.83402\n",
            "[0]\tvalidation_0-auc:0.83554\tvalidation_1-auc:0.81040\n",
            "[1]\tvalidation_0-auc:0.84477\tvalidation_1-auc:0.82328\n",
            "[2]\tvalidation_0-auc:0.84867\tvalidation_1-auc:0.82096\n",
            "[3]\tvalidation_0-auc:0.85207\tvalidation_1-auc:0.82342\n",
            "[4]\tvalidation_0-auc:0.85428\tvalidation_1-auc:0.82582\n",
            "[5]\tvalidation_0-auc:0.85669\tvalidation_1-auc:0.82715\n",
            "[6]\tvalidation_0-auc:0.85931\tvalidation_1-auc:0.82871\n",
            "[7]\tvalidation_0-auc:0.86078\tvalidation_1-auc:0.82854\n",
            "[8]\tvalidation_0-auc:0.86174\tvalidation_1-auc:0.83050\n",
            "[9]\tvalidation_0-auc:0.86313\tvalidation_1-auc:0.82943\n",
            "[10]\tvalidation_0-auc:0.86606\tvalidation_1-auc:0.83192\n",
            "[11]\tvalidation_0-auc:0.86918\tvalidation_1-auc:0.83396\n",
            "[12]\tvalidation_0-auc:0.87133\tvalidation_1-auc:0.83424\n",
            "[13]\tvalidation_0-auc:0.87351\tvalidation_1-auc:0.83541\n",
            "[14]\tvalidation_0-auc:0.87508\tvalidation_1-auc:0.83572\n",
            "[15]\tvalidation_0-auc:0.87634\tvalidation_1-auc:0.83509\n",
            "[16]\tvalidation_0-auc:0.87734\tvalidation_1-auc:0.83475\n",
            "[17]\tvalidation_0-auc:0.87848\tvalidation_1-auc:0.83588\n",
            "[18]\tvalidation_0-auc:0.87936\tvalidation_1-auc:0.83603\n",
            "[19]\tvalidation_0-auc:0.88011\tvalidation_1-auc:0.83649\n",
            "[20]\tvalidation_0-auc:0.88143\tvalidation_1-auc:0.83621\n",
            "[21]\tvalidation_0-auc:0.88319\tvalidation_1-auc:0.83617\n",
            "[22]\tvalidation_0-auc:0.88429\tvalidation_1-auc:0.83670\n",
            "[23]\tvalidation_0-auc:0.88499\tvalidation_1-auc:0.83685\n",
            "[24]\tvalidation_0-auc:0.88588\tvalidation_1-auc:0.83730\n",
            "[25]\tvalidation_0-auc:0.88643\tvalidation_1-auc:0.83752\n",
            "[26]\tvalidation_0-auc:0.88709\tvalidation_1-auc:0.83717\n",
            "[27]\tvalidation_0-auc:0.88794\tvalidation_1-auc:0.83758\n",
            "[28]\tvalidation_0-auc:0.88908\tvalidation_1-auc:0.83749\n",
            "[29]\tvalidation_0-auc:0.89009\tvalidation_1-auc:0.83746\n",
            "[30]\tvalidation_0-auc:0.89089\tvalidation_1-auc:0.83816\n",
            "[31]\tvalidation_0-auc:0.89116\tvalidation_1-auc:0.83812\n",
            "[32]\tvalidation_0-auc:0.89176\tvalidation_1-auc:0.83790\n",
            "[33]\tvalidation_0-auc:0.89251\tvalidation_1-auc:0.83794\n",
            "[34]\tvalidation_0-auc:0.89293\tvalidation_1-auc:0.83780\n",
            "[35]\tvalidation_0-auc:0.89411\tvalidation_1-auc:0.83807\n",
            "[36]\tvalidation_0-auc:0.89447\tvalidation_1-auc:0.83845\n",
            "[37]\tvalidation_0-auc:0.89468\tvalidation_1-auc:0.83837\n",
            "[38]\tvalidation_0-auc:0.89515\tvalidation_1-auc:0.83847\n",
            "[39]\tvalidation_0-auc:0.89604\tvalidation_1-auc:0.83859\n",
            "[40]\tvalidation_0-auc:0.89625\tvalidation_1-auc:0.83823\n",
            "[41]\tvalidation_0-auc:0.89660\tvalidation_1-auc:0.83833\n",
            "[42]\tvalidation_0-auc:0.89670\tvalidation_1-auc:0.83850\n",
            "[43]\tvalidation_0-auc:0.89750\tvalidation_1-auc:0.83825\n",
            "[44]\tvalidation_0-auc:0.89792\tvalidation_1-auc:0.83817\n",
            "[45]\tvalidation_0-auc:0.89818\tvalidation_1-auc:0.83811\n",
            "[46]\tvalidation_0-auc:0.89925\tvalidation_1-auc:0.83787\n",
            "[47]\tvalidation_0-auc:0.89943\tvalidation_1-auc:0.83784\n",
            "[48]\tvalidation_0-auc:0.89963\tvalidation_1-auc:0.83767\n",
            "[49]\tvalidation_0-auc:0.89990\tvalidation_1-auc:0.83758\n",
            "[50]\tvalidation_0-auc:0.90030\tvalidation_1-auc:0.83754\n",
            "[51]\tvalidation_0-auc:0.90054\tvalidation_1-auc:0.83754\n",
            "[52]\tvalidation_0-auc:0.90089\tvalidation_1-auc:0.83754\n",
            "[53]\tvalidation_0-auc:0.90108\tvalidation_1-auc:0.83732\n",
            "[54]\tvalidation_0-auc:0.90134\tvalidation_1-auc:0.83734\n",
            "[55]\tvalidation_0-auc:0.90291\tvalidation_1-auc:0.83791\n",
            "[56]\tvalidation_0-auc:0.90304\tvalidation_1-auc:0.83777\n",
            "[57]\tvalidation_0-auc:0.90315\tvalidation_1-auc:0.83788\n",
            "[58]\tvalidation_0-auc:0.90384\tvalidation_1-auc:0.83769\n",
            "[59]\tvalidation_0-auc:0.90503\tvalidation_1-auc:0.83747\n",
            "[60]\tvalidation_0-auc:0.90522\tvalidation_1-auc:0.83737\n",
            "[61]\tvalidation_0-auc:0.90599\tvalidation_1-auc:0.83747\n",
            "[62]\tvalidation_0-auc:0.90611\tvalidation_1-auc:0.83757\n",
            "[63]\tvalidation_0-auc:0.90652\tvalidation_1-auc:0.83741\n",
            "[64]\tvalidation_0-auc:0.90669\tvalidation_1-auc:0.83720\n",
            "[65]\tvalidation_0-auc:0.90676\tvalidation_1-auc:0.83714\n",
            "[66]\tvalidation_0-auc:0.90710\tvalidation_1-auc:0.83716\n",
            "[67]\tvalidation_0-auc:0.90729\tvalidation_1-auc:0.83702\n",
            "[68]\tvalidation_0-auc:0.90770\tvalidation_1-auc:0.83652\n",
            "[69]\tvalidation_0-auc:0.90793\tvalidation_1-auc:0.83641\n",
            "[0]\tvalidation_0-auc:0.85748\tvalidation_1-auc:0.80175\n",
            "[1]\tvalidation_0-auc:0.86855\tvalidation_1-auc:0.81035\n",
            "[2]\tvalidation_0-auc:0.86875\tvalidation_1-auc:0.81204\n",
            "[3]\tvalidation_0-auc:0.87590\tvalidation_1-auc:0.81544\n",
            "[4]\tvalidation_0-auc:0.87830\tvalidation_1-auc:0.82005\n",
            "[5]\tvalidation_0-auc:0.87942\tvalidation_1-auc:0.82283\n",
            "[6]\tvalidation_0-auc:0.88353\tvalidation_1-auc:0.82588\n",
            "[7]\tvalidation_0-auc:0.88750\tvalidation_1-auc:0.82563\n",
            "[8]\tvalidation_0-auc:0.88936\tvalidation_1-auc:0.82697\n",
            "[9]\tvalidation_0-auc:0.88910\tvalidation_1-auc:0.82603\n",
            "[10]\tvalidation_0-auc:0.89226\tvalidation_1-auc:0.82828\n",
            "[11]\tvalidation_0-auc:0.89399\tvalidation_1-auc:0.82945\n",
            "[12]\tvalidation_0-auc:0.89528\tvalidation_1-auc:0.82947\n",
            "[13]\tvalidation_0-auc:0.89626\tvalidation_1-auc:0.82976\n",
            "[14]\tvalidation_0-auc:0.89701\tvalidation_1-auc:0.82989\n",
            "[15]\tvalidation_0-auc:0.89846\tvalidation_1-auc:0.82992\n",
            "[16]\tvalidation_0-auc:0.90032\tvalidation_1-auc:0.82929\n",
            "[17]\tvalidation_0-auc:0.90163\tvalidation_1-auc:0.83021\n",
            "[18]\tvalidation_0-auc:0.90216\tvalidation_1-auc:0.83052\n",
            "[19]\tvalidation_0-auc:0.90318\tvalidation_1-auc:0.83056\n",
            "[20]\tvalidation_0-auc:0.90419\tvalidation_1-auc:0.83062\n",
            "[21]\tvalidation_0-auc:0.90487\tvalidation_1-auc:0.83023\n",
            "[22]\tvalidation_0-auc:0.90585\tvalidation_1-auc:0.83045\n",
            "[23]\tvalidation_0-auc:0.90684\tvalidation_1-auc:0.82984\n",
            "[24]\tvalidation_0-auc:0.90756\tvalidation_1-auc:0.83028\n",
            "[25]\tvalidation_0-auc:0.90752\tvalidation_1-auc:0.83073\n",
            "[26]\tvalidation_0-auc:0.90885\tvalidation_1-auc:0.83111\n",
            "[27]\tvalidation_0-auc:0.90981\tvalidation_1-auc:0.83116\n",
            "[28]\tvalidation_0-auc:0.91055\tvalidation_1-auc:0.83113\n",
            "[29]\tvalidation_0-auc:0.91090\tvalidation_1-auc:0.83090\n",
            "[30]\tvalidation_0-auc:0.91170\tvalidation_1-auc:0.83117\n",
            "[31]\tvalidation_0-auc:0.91238\tvalidation_1-auc:0.83063\n",
            "[32]\tvalidation_0-auc:0.91363\tvalidation_1-auc:0.83078\n",
            "[33]\tvalidation_0-auc:0.91437\tvalidation_1-auc:0.83043\n",
            "[34]\tvalidation_0-auc:0.91466\tvalidation_1-auc:0.83030\n",
            "[35]\tvalidation_0-auc:0.91524\tvalidation_1-auc:0.83108\n",
            "[36]\tvalidation_0-auc:0.91591\tvalidation_1-auc:0.83150\n",
            "[37]\tvalidation_0-auc:0.91684\tvalidation_1-auc:0.83186\n",
            "[38]\tvalidation_0-auc:0.91779\tvalidation_1-auc:0.83185\n",
            "[39]\tvalidation_0-auc:0.91819\tvalidation_1-auc:0.83167\n",
            "[40]\tvalidation_0-auc:0.91867\tvalidation_1-auc:0.83147\n",
            "[41]\tvalidation_0-auc:0.91925\tvalidation_1-auc:0.83134\n",
            "[42]\tvalidation_0-auc:0.91946\tvalidation_1-auc:0.83100\n",
            "[43]\tvalidation_0-auc:0.91986\tvalidation_1-auc:0.83096\n",
            "[44]\tvalidation_0-auc:0.92043\tvalidation_1-auc:0.83072\n",
            "[45]\tvalidation_0-auc:0.92105\tvalidation_1-auc:0.83074\n",
            "[46]\tvalidation_0-auc:0.92162\tvalidation_1-auc:0.83043\n",
            "[47]\tvalidation_0-auc:0.92226\tvalidation_1-auc:0.83069\n",
            "[48]\tvalidation_0-auc:0.92275\tvalidation_1-auc:0.83107\n",
            "[49]\tvalidation_0-auc:0.92314\tvalidation_1-auc:0.83131\n",
            "[50]\tvalidation_0-auc:0.92320\tvalidation_1-auc:0.83140\n",
            "[51]\tvalidation_0-auc:0.92349\tvalidation_1-auc:0.83139\n",
            "[52]\tvalidation_0-auc:0.92382\tvalidation_1-auc:0.83110\n",
            "[53]\tvalidation_0-auc:0.92395\tvalidation_1-auc:0.83104\n",
            "[54]\tvalidation_0-auc:0.92441\tvalidation_1-auc:0.83097\n",
            "[55]\tvalidation_0-auc:0.92459\tvalidation_1-auc:0.83085\n",
            "[56]\tvalidation_0-auc:0.92473\tvalidation_1-auc:0.83109\n",
            "[57]\tvalidation_0-auc:0.92480\tvalidation_1-auc:0.83125\n",
            "[58]\tvalidation_0-auc:0.92490\tvalidation_1-auc:0.83096\n",
            "[59]\tvalidation_0-auc:0.92503\tvalidation_1-auc:0.83121\n",
            "[60]\tvalidation_0-auc:0.92518\tvalidation_1-auc:0.83090\n",
            "[61]\tvalidation_0-auc:0.92519\tvalidation_1-auc:0.83086\n",
            "[62]\tvalidation_0-auc:0.92597\tvalidation_1-auc:0.83073\n",
            "[63]\tvalidation_0-auc:0.92619\tvalidation_1-auc:0.83063\n",
            "[64]\tvalidation_0-auc:0.92660\tvalidation_1-auc:0.83071\n",
            "[65]\tvalidation_0-auc:0.92674\tvalidation_1-auc:0.83044\n",
            "[66]\tvalidation_0-auc:0.92711\tvalidation_1-auc:0.83044\n",
            "[67]\tvalidation_0-auc:0.92755\tvalidation_1-auc:0.83030\n",
            "[0]\tvalidation_0-auc:0.85813\tvalidation_1-auc:0.81069\n",
            "[1]\tvalidation_0-auc:0.86803\tvalidation_1-auc:0.82221\n",
            "[2]\tvalidation_0-auc:0.87229\tvalidation_1-auc:0.81503\n",
            "[3]\tvalidation_0-auc:0.87846\tvalidation_1-auc:0.82061\n",
            "[4]\tvalidation_0-auc:0.88078\tvalidation_1-auc:0.82524\n",
            "[5]\tvalidation_0-auc:0.88320\tvalidation_1-auc:0.82627\n",
            "[6]\tvalidation_0-auc:0.88705\tvalidation_1-auc:0.82793\n",
            "[7]\tvalidation_0-auc:0.89030\tvalidation_1-auc:0.82763\n",
            "[8]\tvalidation_0-auc:0.89141\tvalidation_1-auc:0.82921\n",
            "[9]\tvalidation_0-auc:0.89062\tvalidation_1-auc:0.82767\n",
            "[10]\tvalidation_0-auc:0.89251\tvalidation_1-auc:0.82967\n",
            "[11]\tvalidation_0-auc:0.89405\tvalidation_1-auc:0.83094\n",
            "[12]\tvalidation_0-auc:0.89549\tvalidation_1-auc:0.83133\n",
            "[13]\tvalidation_0-auc:0.89702\tvalidation_1-auc:0.83202\n",
            "[14]\tvalidation_0-auc:0.89791\tvalidation_1-auc:0.83323\n",
            "[15]\tvalidation_0-auc:0.89933\tvalidation_1-auc:0.83261\n",
            "[16]\tvalidation_0-auc:0.90123\tvalidation_1-auc:0.83345\n",
            "[17]\tvalidation_0-auc:0.90223\tvalidation_1-auc:0.83366\n",
            "[18]\tvalidation_0-auc:0.90297\tvalidation_1-auc:0.83368\n",
            "[19]\tvalidation_0-auc:0.90367\tvalidation_1-auc:0.83310\n",
            "[20]\tvalidation_0-auc:0.90463\tvalidation_1-auc:0.83263\n",
            "[21]\tvalidation_0-auc:0.90549\tvalidation_1-auc:0.83185\n",
            "[22]\tvalidation_0-auc:0.90626\tvalidation_1-auc:0.83233\n",
            "[23]\tvalidation_0-auc:0.90725\tvalidation_1-auc:0.83327\n",
            "[24]\tvalidation_0-auc:0.90748\tvalidation_1-auc:0.83273\n",
            "[25]\tvalidation_0-auc:0.90795\tvalidation_1-auc:0.83377\n",
            "[26]\tvalidation_0-auc:0.90939\tvalidation_1-auc:0.83367\n",
            "[27]\tvalidation_0-auc:0.91073\tvalidation_1-auc:0.83375\n",
            "[28]\tvalidation_0-auc:0.91176\tvalidation_1-auc:0.83358\n",
            "[29]\tvalidation_0-auc:0.91214\tvalidation_1-auc:0.83362\n",
            "[30]\tvalidation_0-auc:0.91317\tvalidation_1-auc:0.83355\n",
            "[31]\tvalidation_0-auc:0.91405\tvalidation_1-auc:0.83262\n",
            "[32]\tvalidation_0-auc:0.91465\tvalidation_1-auc:0.83263\n",
            "[33]\tvalidation_0-auc:0.91531\tvalidation_1-auc:0.83198\n",
            "[34]\tvalidation_0-auc:0.91560\tvalidation_1-auc:0.83178\n",
            "[35]\tvalidation_0-auc:0.91628\tvalidation_1-auc:0.83219\n",
            "[36]\tvalidation_0-auc:0.91694\tvalidation_1-auc:0.83272\n",
            "[37]\tvalidation_0-auc:0.91763\tvalidation_1-auc:0.83252\n",
            "[38]\tvalidation_0-auc:0.91796\tvalidation_1-auc:0.83268\n",
            "[39]\tvalidation_0-auc:0.91839\tvalidation_1-auc:0.83303\n",
            "[40]\tvalidation_0-auc:0.91883\tvalidation_1-auc:0.83342\n",
            "[41]\tvalidation_0-auc:0.91945\tvalidation_1-auc:0.83324\n",
            "[42]\tvalidation_0-auc:0.92027\tvalidation_1-auc:0.83273\n",
            "[43]\tvalidation_0-auc:0.92050\tvalidation_1-auc:0.83274\n",
            "[44]\tvalidation_0-auc:0.92115\tvalidation_1-auc:0.83280\n",
            "[45]\tvalidation_0-auc:0.92135\tvalidation_1-auc:0.83319\n",
            "[46]\tvalidation_0-auc:0.92204\tvalidation_1-auc:0.83308\n",
            "[47]\tvalidation_0-auc:0.92249\tvalidation_1-auc:0.83277\n",
            "[48]\tvalidation_0-auc:0.92340\tvalidation_1-auc:0.83295\n",
            "[49]\tvalidation_0-auc:0.92383\tvalidation_1-auc:0.83325\n",
            "[50]\tvalidation_0-auc:0.92401\tvalidation_1-auc:0.83332\n",
            "[51]\tvalidation_0-auc:0.92456\tvalidation_1-auc:0.83334\n",
            "[52]\tvalidation_0-auc:0.92505\tvalidation_1-auc:0.83294\n",
            "[53]\tvalidation_0-auc:0.92541\tvalidation_1-auc:0.83292\n",
            "[54]\tvalidation_0-auc:0.92572\tvalidation_1-auc:0.83291\n",
            "[0]\tvalidation_0-auc:0.86198\tvalidation_1-auc:0.80932\n",
            "[1]\tvalidation_0-auc:0.87018\tvalidation_1-auc:0.82161\n",
            "[2]\tvalidation_0-auc:0.87279\tvalidation_1-auc:0.81730\n",
            "[3]\tvalidation_0-auc:0.87499\tvalidation_1-auc:0.82146\n",
            "[4]\tvalidation_0-auc:0.87712\tvalidation_1-auc:0.82447\n",
            "[5]\tvalidation_0-auc:0.87961\tvalidation_1-auc:0.82677\n",
            "[6]\tvalidation_0-auc:0.88399\tvalidation_1-auc:0.82626\n",
            "[7]\tvalidation_0-auc:0.88714\tvalidation_1-auc:0.82408\n",
            "[8]\tvalidation_0-auc:0.88911\tvalidation_1-auc:0.82557\n",
            "[9]\tvalidation_0-auc:0.88999\tvalidation_1-auc:0.82408\n",
            "[10]\tvalidation_0-auc:0.89218\tvalidation_1-auc:0.82649\n",
            "[11]\tvalidation_0-auc:0.89372\tvalidation_1-auc:0.82760\n",
            "[12]\tvalidation_0-auc:0.89636\tvalidation_1-auc:0.82774\n",
            "[13]\tvalidation_0-auc:0.89763\tvalidation_1-auc:0.82853\n",
            "[14]\tvalidation_0-auc:0.89887\tvalidation_1-auc:0.82900\n",
            "[15]\tvalidation_0-auc:0.90023\tvalidation_1-auc:0.82712\n",
            "[16]\tvalidation_0-auc:0.90191\tvalidation_1-auc:0.82779\n",
            "[17]\tvalidation_0-auc:0.90326\tvalidation_1-auc:0.82844\n",
            "[18]\tvalidation_0-auc:0.90396\tvalidation_1-auc:0.82855\n",
            "[19]\tvalidation_0-auc:0.90479\tvalidation_1-auc:0.82876\n",
            "[20]\tvalidation_0-auc:0.90635\tvalidation_1-auc:0.82818\n",
            "[21]\tvalidation_0-auc:0.90738\tvalidation_1-auc:0.82723\n",
            "[22]\tvalidation_0-auc:0.90821\tvalidation_1-auc:0.82798\n",
            "[23]\tvalidation_0-auc:0.90914\tvalidation_1-auc:0.82890\n",
            "[24]\tvalidation_0-auc:0.91007\tvalidation_1-auc:0.82900\n",
            "[25]\tvalidation_0-auc:0.91017\tvalidation_1-auc:0.82995\n",
            "[26]\tvalidation_0-auc:0.91080\tvalidation_1-auc:0.83028\n",
            "[27]\tvalidation_0-auc:0.91178\tvalidation_1-auc:0.83086\n",
            "[28]\tvalidation_0-auc:0.91297\tvalidation_1-auc:0.83007\n",
            "[29]\tvalidation_0-auc:0.91373\tvalidation_1-auc:0.82941\n",
            "[30]\tvalidation_0-auc:0.91460\tvalidation_1-auc:0.82974\n",
            "[31]\tvalidation_0-auc:0.91516\tvalidation_1-auc:0.82902\n",
            "[32]\tvalidation_0-auc:0.91577\tvalidation_1-auc:0.82918\n",
            "[33]\tvalidation_0-auc:0.91648\tvalidation_1-auc:0.82882\n",
            "[34]\tvalidation_0-auc:0.91692\tvalidation_1-auc:0.82837\n",
            "[35]\tvalidation_0-auc:0.91728\tvalidation_1-auc:0.82880\n",
            "[36]\tvalidation_0-auc:0.91773\tvalidation_1-auc:0.82905\n",
            "[37]\tvalidation_0-auc:0.91833\tvalidation_1-auc:0.82887\n",
            "[38]\tvalidation_0-auc:0.91891\tvalidation_1-auc:0.82897\n",
            "[39]\tvalidation_0-auc:0.91920\tvalidation_1-auc:0.82972\n",
            "[40]\tvalidation_0-auc:0.91995\tvalidation_1-auc:0.82950\n",
            "[41]\tvalidation_0-auc:0.92039\tvalidation_1-auc:0.82904\n",
            "[42]\tvalidation_0-auc:0.92091\tvalidation_1-auc:0.82853\n",
            "[43]\tvalidation_0-auc:0.92147\tvalidation_1-auc:0.82951\n",
            "[44]\tvalidation_0-auc:0.92226\tvalidation_1-auc:0.82954\n",
            "[45]\tvalidation_0-auc:0.92275\tvalidation_1-auc:0.82973\n",
            "[46]\tvalidation_0-auc:0.92328\tvalidation_1-auc:0.82939\n",
            "[47]\tvalidation_0-auc:0.92365\tvalidation_1-auc:0.82921\n",
            "[48]\tvalidation_0-auc:0.92409\tvalidation_1-auc:0.82952\n",
            "[49]\tvalidation_0-auc:0.92473\tvalidation_1-auc:0.83009\n",
            "[50]\tvalidation_0-auc:0.92478\tvalidation_1-auc:0.83051\n",
            "[51]\tvalidation_0-auc:0.92491\tvalidation_1-auc:0.83010\n",
            "[52]\tvalidation_0-auc:0.92513\tvalidation_1-auc:0.82996\n",
            "[53]\tvalidation_0-auc:0.92530\tvalidation_1-auc:0.82956\n",
            "[54]\tvalidation_0-auc:0.92586\tvalidation_1-auc:0.82955\n",
            "[55]\tvalidation_0-auc:0.92619\tvalidation_1-auc:0.82967\n",
            "[56]\tvalidation_0-auc:0.92645\tvalidation_1-auc:0.82963\n",
            "[57]\tvalidation_0-auc:0.92694\tvalidation_1-auc:0.82996\n",
            "[0]\tvalidation_0-auc:0.81705\tvalidation_1-auc:0.78935\n",
            "[1]\tvalidation_0-auc:0.81896\tvalidation_1-auc:0.79283\n",
            "[2]\tvalidation_0-auc:0.81322\tvalidation_1-auc:0.78517\n",
            "[3]\tvalidation_0-auc:0.80906\tvalidation_1-auc:0.78364\n",
            "[4]\tvalidation_0-auc:0.82571\tvalidation_1-auc:0.79841\n",
            "[5]\tvalidation_0-auc:0.83184\tvalidation_1-auc:0.80409\n",
            "[6]\tvalidation_0-auc:0.83648\tvalidation_1-auc:0.81062\n",
            "[7]\tvalidation_0-auc:0.83523\tvalidation_1-auc:0.81001\n",
            "[8]\tvalidation_0-auc:0.83961\tvalidation_1-auc:0.81458\n",
            "[9]\tvalidation_0-auc:0.83814\tvalidation_1-auc:0.81237\n",
            "[10]\tvalidation_0-auc:0.83718\tvalidation_1-auc:0.81002\n",
            "[11]\tvalidation_0-auc:0.84104\tvalidation_1-auc:0.81378\n",
            "[12]\tvalidation_0-auc:0.84378\tvalidation_1-auc:0.81721\n",
            "[13]\tvalidation_0-auc:0.84618\tvalidation_1-auc:0.82085\n",
            "[14]\tvalidation_0-auc:0.84865\tvalidation_1-auc:0.82345\n",
            "[15]\tvalidation_0-auc:0.84717\tvalidation_1-auc:0.82076\n",
            "[16]\tvalidation_0-auc:0.84993\tvalidation_1-auc:0.82352\n",
            "[17]\tvalidation_0-auc:0.85198\tvalidation_1-auc:0.82478\n",
            "[18]\tvalidation_0-auc:0.85258\tvalidation_1-auc:0.82539\n",
            "[19]\tvalidation_0-auc:0.85371\tvalidation_1-auc:0.82643\n",
            "[20]\tvalidation_0-auc:0.85357\tvalidation_1-auc:0.82598\n",
            "[21]\tvalidation_0-auc:0.85303\tvalidation_1-auc:0.82531\n",
            "[22]\tvalidation_0-auc:0.85390\tvalidation_1-auc:0.82637\n",
            "[23]\tvalidation_0-auc:0.85487\tvalidation_1-auc:0.82728\n",
            "[24]\tvalidation_0-auc:0.85452\tvalidation_1-auc:0.82736\n",
            "[25]\tvalidation_0-auc:0.85524\tvalidation_1-auc:0.82839\n",
            "[26]\tvalidation_0-auc:0.85665\tvalidation_1-auc:0.82915\n",
            "[27]\tvalidation_0-auc:0.85762\tvalidation_1-auc:0.82934\n",
            "[28]\tvalidation_0-auc:0.85813\tvalidation_1-auc:0.82980\n",
            "[29]\tvalidation_0-auc:0.85803\tvalidation_1-auc:0.82942\n",
            "[30]\tvalidation_0-auc:0.85893\tvalidation_1-auc:0.83002\n",
            "[31]\tvalidation_0-auc:0.85911\tvalidation_1-auc:0.82951\n",
            "[32]\tvalidation_0-auc:0.86046\tvalidation_1-auc:0.83074\n",
            "[33]\tvalidation_0-auc:0.86108\tvalidation_1-auc:0.83020\n",
            "[34]\tvalidation_0-auc:0.86109\tvalidation_1-auc:0.82951\n",
            "[35]\tvalidation_0-auc:0.86185\tvalidation_1-auc:0.83036\n",
            "[36]\tvalidation_0-auc:0.86235\tvalidation_1-auc:0.83108\n",
            "[37]\tvalidation_0-auc:0.86255\tvalidation_1-auc:0.83126\n",
            "[38]\tvalidation_0-auc:0.86310\tvalidation_1-auc:0.83176\n",
            "[39]\tvalidation_0-auc:0.86352\tvalidation_1-auc:0.83205\n",
            "[40]\tvalidation_0-auc:0.86383\tvalidation_1-auc:0.83185\n",
            "[41]\tvalidation_0-auc:0.86411\tvalidation_1-auc:0.83162\n",
            "[42]\tvalidation_0-auc:0.86457\tvalidation_1-auc:0.83170\n",
            "[43]\tvalidation_0-auc:0.86507\tvalidation_1-auc:0.83220\n",
            "[44]\tvalidation_0-auc:0.86519\tvalidation_1-auc:0.83214\n",
            "[45]\tvalidation_0-auc:0.86572\tvalidation_1-auc:0.83267\n",
            "[46]\tvalidation_0-auc:0.86628\tvalidation_1-auc:0.83261\n",
            "[47]\tvalidation_0-auc:0.86682\tvalidation_1-auc:0.83279\n",
            "[48]\tvalidation_0-auc:0.86724\tvalidation_1-auc:0.83296\n",
            "[49]\tvalidation_0-auc:0.86807\tvalidation_1-auc:0.83315\n",
            "[50]\tvalidation_0-auc:0.86853\tvalidation_1-auc:0.83319\n",
            "[51]\tvalidation_0-auc:0.86870\tvalidation_1-auc:0.83326\n",
            "[52]\tvalidation_0-auc:0.86887\tvalidation_1-auc:0.83320\n",
            "[53]\tvalidation_0-auc:0.86915\tvalidation_1-auc:0.83329\n",
            "[54]\tvalidation_0-auc:0.86955\tvalidation_1-auc:0.83321\n",
            "[55]\tvalidation_0-auc:0.86998\tvalidation_1-auc:0.83322\n",
            "[56]\tvalidation_0-auc:0.87045\tvalidation_1-auc:0.83345\n",
            "[57]\tvalidation_0-auc:0.87107\tvalidation_1-auc:0.83363\n",
            "[58]\tvalidation_0-auc:0.87119\tvalidation_1-auc:0.83365\n",
            "[59]\tvalidation_0-auc:0.87126\tvalidation_1-auc:0.83377\n",
            "[60]\tvalidation_0-auc:0.87143\tvalidation_1-auc:0.83382\n",
            "[61]\tvalidation_0-auc:0.87163\tvalidation_1-auc:0.83393\n",
            "[62]\tvalidation_0-auc:0.87208\tvalidation_1-auc:0.83415\n",
            "[63]\tvalidation_0-auc:0.87222\tvalidation_1-auc:0.83398\n",
            "[64]\tvalidation_0-auc:0.87247\tvalidation_1-auc:0.83423\n",
            "[65]\tvalidation_0-auc:0.87270\tvalidation_1-auc:0.83419\n",
            "[66]\tvalidation_0-auc:0.87286\tvalidation_1-auc:0.83430\n",
            "[67]\tvalidation_0-auc:0.87310\tvalidation_1-auc:0.83441\n",
            "[68]\tvalidation_0-auc:0.87346\tvalidation_1-auc:0.83435\n",
            "[69]\tvalidation_0-auc:0.87352\tvalidation_1-auc:0.83425\n",
            "[70]\tvalidation_0-auc:0.87371\tvalidation_1-auc:0.83412\n",
            "[71]\tvalidation_0-auc:0.87379\tvalidation_1-auc:0.83402\n",
            "[72]\tvalidation_0-auc:0.87438\tvalidation_1-auc:0.83405\n",
            "[73]\tvalidation_0-auc:0.87449\tvalidation_1-auc:0.83410\n",
            "[74]\tvalidation_0-auc:0.87458\tvalidation_1-auc:0.83419\n",
            "[75]\tvalidation_0-auc:0.87465\tvalidation_1-auc:0.83414\n",
            "[76]\tvalidation_0-auc:0.87462\tvalidation_1-auc:0.83411\n",
            "[77]\tvalidation_0-auc:0.87477\tvalidation_1-auc:0.83386\n",
            "[78]\tvalidation_0-auc:0.87504\tvalidation_1-auc:0.83386\n",
            "[79]\tvalidation_0-auc:0.87514\tvalidation_1-auc:0.83395\n",
            "[80]\tvalidation_0-auc:0.87538\tvalidation_1-auc:0.83405\n",
            "[81]\tvalidation_0-auc:0.87553\tvalidation_1-auc:0.83389\n",
            "[82]\tvalidation_0-auc:0.87573\tvalidation_1-auc:0.83381\n",
            "[83]\tvalidation_0-auc:0.87578\tvalidation_1-auc:0.83382\n",
            "[84]\tvalidation_0-auc:0.87590\tvalidation_1-auc:0.83389\n",
            "[85]\tvalidation_0-auc:0.87632\tvalidation_1-auc:0.83387\n",
            "[86]\tvalidation_0-auc:0.87640\tvalidation_1-auc:0.83384\n",
            "[87]\tvalidation_0-auc:0.87686\tvalidation_1-auc:0.83347\n",
            "[88]\tvalidation_0-auc:0.87723\tvalidation_1-auc:0.83342\n",
            "[89]\tvalidation_0-auc:0.87726\tvalidation_1-auc:0.83344\n",
            "[90]\tvalidation_0-auc:0.87757\tvalidation_1-auc:0.83331\n",
            "[91]\tvalidation_0-auc:0.87769\tvalidation_1-auc:0.83332\n",
            "[92]\tvalidation_0-auc:0.87796\tvalidation_1-auc:0.83331\n",
            "[93]\tvalidation_0-auc:0.87809\tvalidation_1-auc:0.83324\n",
            "[94]\tvalidation_0-auc:0.87820\tvalidation_1-auc:0.83316\n",
            "[95]\tvalidation_0-auc:0.87845\tvalidation_1-auc:0.83318\n",
            "[96]\tvalidation_0-auc:0.87850\tvalidation_1-auc:0.83305\n",
            "[97]\tvalidation_0-auc:0.87875\tvalidation_1-auc:0.83297\n",
            "[0]\tvalidation_0-auc:0.82096\tvalidation_1-auc:0.81190\n",
            "[1]\tvalidation_0-auc:0.81455\tvalidation_1-auc:0.79882\n",
            "[2]\tvalidation_0-auc:0.81217\tvalidation_1-auc:0.79402\n",
            "[3]\tvalidation_0-auc:0.81085\tvalidation_1-auc:0.79131\n",
            "[4]\tvalidation_0-auc:0.82517\tvalidation_1-auc:0.80621\n",
            "[5]\tvalidation_0-auc:0.83244\tvalidation_1-auc:0.81370\n",
            "[6]\tvalidation_0-auc:0.83781\tvalidation_1-auc:0.81828\n",
            "[7]\tvalidation_0-auc:0.83595\tvalidation_1-auc:0.81460\n",
            "[8]\tvalidation_0-auc:0.84047\tvalidation_1-auc:0.81782\n",
            "[9]\tvalidation_0-auc:0.83890\tvalidation_1-auc:0.81605\n",
            "[10]\tvalidation_0-auc:0.83825\tvalidation_1-auc:0.81435\n",
            "[11]\tvalidation_0-auc:0.84233\tvalidation_1-auc:0.82076\n",
            "[12]\tvalidation_0-auc:0.84577\tvalidation_1-auc:0.82351\n",
            "[13]\tvalidation_0-auc:0.84757\tvalidation_1-auc:0.82463\n",
            "[14]\tvalidation_0-auc:0.84914\tvalidation_1-auc:0.82669\n",
            "[15]\tvalidation_0-auc:0.84848\tvalidation_1-auc:0.82504\n",
            "[16]\tvalidation_0-auc:0.84954\tvalidation_1-auc:0.82618\n",
            "[17]\tvalidation_0-auc:0.85115\tvalidation_1-auc:0.82774\n",
            "[18]\tvalidation_0-auc:0.85262\tvalidation_1-auc:0.82998\n",
            "[19]\tvalidation_0-auc:0.85364\tvalidation_1-auc:0.83098\n",
            "[20]\tvalidation_0-auc:0.85341\tvalidation_1-auc:0.82941\n",
            "[21]\tvalidation_0-auc:0.85338\tvalidation_1-auc:0.82815\n",
            "[22]\tvalidation_0-auc:0.85462\tvalidation_1-auc:0.83014\n",
            "[23]\tvalidation_0-auc:0.85549\tvalidation_1-auc:0.83113\n",
            "[24]\tvalidation_0-auc:0.85498\tvalidation_1-auc:0.82973\n",
            "[25]\tvalidation_0-auc:0.85620\tvalidation_1-auc:0.83145\n",
            "[26]\tvalidation_0-auc:0.85725\tvalidation_1-auc:0.83248\n",
            "[27]\tvalidation_0-auc:0.85836\tvalidation_1-auc:0.83324\n",
            "[28]\tvalidation_0-auc:0.85876\tvalidation_1-auc:0.83324\n",
            "[29]\tvalidation_0-auc:0.85851\tvalidation_1-auc:0.83254\n",
            "[30]\tvalidation_0-auc:0.85933\tvalidation_1-auc:0.83276\n",
            "[31]\tvalidation_0-auc:0.85924\tvalidation_1-auc:0.83243\n",
            "[32]\tvalidation_0-auc:0.86039\tvalidation_1-auc:0.83320\n",
            "[33]\tvalidation_0-auc:0.86039\tvalidation_1-auc:0.83291\n",
            "[34]\tvalidation_0-auc:0.86025\tvalidation_1-auc:0.83274\n",
            "[35]\tvalidation_0-auc:0.86113\tvalidation_1-auc:0.83318\n",
            "[36]\tvalidation_0-auc:0.86196\tvalidation_1-auc:0.83368\n",
            "[37]\tvalidation_0-auc:0.86228\tvalidation_1-auc:0.83341\n",
            "[38]\tvalidation_0-auc:0.86327\tvalidation_1-auc:0.83367\n",
            "[39]\tvalidation_0-auc:0.86375\tvalidation_1-auc:0.83362\n",
            "[40]\tvalidation_0-auc:0.86391\tvalidation_1-auc:0.83371\n",
            "[41]\tvalidation_0-auc:0.86398\tvalidation_1-auc:0.83379\n",
            "[42]\tvalidation_0-auc:0.86417\tvalidation_1-auc:0.83358\n",
            "[43]\tvalidation_0-auc:0.86489\tvalidation_1-auc:0.83420\n",
            "[44]\tvalidation_0-auc:0.86517\tvalidation_1-auc:0.83443\n",
            "[45]\tvalidation_0-auc:0.86559\tvalidation_1-auc:0.83490\n",
            "[46]\tvalidation_0-auc:0.86589\tvalidation_1-auc:0.83472\n",
            "[47]\tvalidation_0-auc:0.86624\tvalidation_1-auc:0.83432\n",
            "[48]\tvalidation_0-auc:0.86684\tvalidation_1-auc:0.83481\n",
            "[49]\tvalidation_0-auc:0.86732\tvalidation_1-auc:0.83518\n",
            "[50]\tvalidation_0-auc:0.86765\tvalidation_1-auc:0.83552\n",
            "[51]\tvalidation_0-auc:0.86800\tvalidation_1-auc:0.83567\n",
            "[52]\tvalidation_0-auc:0.86801\tvalidation_1-auc:0.83574\n",
            "[53]\tvalidation_0-auc:0.86798\tvalidation_1-auc:0.83559\n",
            "[54]\tvalidation_0-auc:0.86835\tvalidation_1-auc:0.83585\n",
            "[55]\tvalidation_0-auc:0.86850\tvalidation_1-auc:0.83562\n",
            "[56]\tvalidation_0-auc:0.86904\tvalidation_1-auc:0.83590\n",
            "[57]\tvalidation_0-auc:0.86939\tvalidation_1-auc:0.83608\n",
            "[58]\tvalidation_0-auc:0.86982\tvalidation_1-auc:0.83647\n",
            "[59]\tvalidation_0-auc:0.86988\tvalidation_1-auc:0.83672\n",
            "[60]\tvalidation_0-auc:0.86997\tvalidation_1-auc:0.83676\n",
            "[61]\tvalidation_0-auc:0.87015\tvalidation_1-auc:0.83688\n",
            "[62]\tvalidation_0-auc:0.87036\tvalidation_1-auc:0.83681\n",
            "[63]\tvalidation_0-auc:0.87065\tvalidation_1-auc:0.83705\n",
            "[64]\tvalidation_0-auc:0.87081\tvalidation_1-auc:0.83700\n",
            "[65]\tvalidation_0-auc:0.87121\tvalidation_1-auc:0.83727\n",
            "[66]\tvalidation_0-auc:0.87136\tvalidation_1-auc:0.83714\n",
            "[67]\tvalidation_0-auc:0.87164\tvalidation_1-auc:0.83738\n",
            "[68]\tvalidation_0-auc:0.87211\tvalidation_1-auc:0.83739\n",
            "[69]\tvalidation_0-auc:0.87228\tvalidation_1-auc:0.83725\n",
            "[70]\tvalidation_0-auc:0.87250\tvalidation_1-auc:0.83736\n",
            "[71]\tvalidation_0-auc:0.87261\tvalidation_1-auc:0.83726\n",
            "[72]\tvalidation_0-auc:0.87286\tvalidation_1-auc:0.83738\n",
            "[73]\tvalidation_0-auc:0.87302\tvalidation_1-auc:0.83747\n",
            "[74]\tvalidation_0-auc:0.87317\tvalidation_1-auc:0.83749\n",
            "[75]\tvalidation_0-auc:0.87330\tvalidation_1-auc:0.83762\n",
            "[76]\tvalidation_0-auc:0.87349\tvalidation_1-auc:0.83772\n",
            "[77]\tvalidation_0-auc:0.87356\tvalidation_1-auc:0.83771\n",
            "[78]\tvalidation_0-auc:0.87382\tvalidation_1-auc:0.83776\n",
            "[79]\tvalidation_0-auc:0.87397\tvalidation_1-auc:0.83778\n",
            "[80]\tvalidation_0-auc:0.87427\tvalidation_1-auc:0.83773\n",
            "[81]\tvalidation_0-auc:0.87438\tvalidation_1-auc:0.83770\n",
            "[82]\tvalidation_0-auc:0.87469\tvalidation_1-auc:0.83770\n",
            "[83]\tvalidation_0-auc:0.87501\tvalidation_1-auc:0.83770\n",
            "[84]\tvalidation_0-auc:0.87503\tvalidation_1-auc:0.83775\n",
            "[85]\tvalidation_0-auc:0.87517\tvalidation_1-auc:0.83777\n",
            "[86]\tvalidation_0-auc:0.87538\tvalidation_1-auc:0.83769\n",
            "[87]\tvalidation_0-auc:0.87541\tvalidation_1-auc:0.83769\n",
            "[88]\tvalidation_0-auc:0.87548\tvalidation_1-auc:0.83769\n",
            "[89]\tvalidation_0-auc:0.87549\tvalidation_1-auc:0.83775\n",
            "[90]\tvalidation_0-auc:0.87563\tvalidation_1-auc:0.83765\n",
            "[91]\tvalidation_0-auc:0.87602\tvalidation_1-auc:0.83759\n",
            "[92]\tvalidation_0-auc:0.87638\tvalidation_1-auc:0.83758\n",
            "[93]\tvalidation_0-auc:0.87643\tvalidation_1-auc:0.83744\n",
            "[94]\tvalidation_0-auc:0.87679\tvalidation_1-auc:0.83737\n",
            "[95]\tvalidation_0-auc:0.87691\tvalidation_1-auc:0.83737\n",
            "[96]\tvalidation_0-auc:0.87710\tvalidation_1-auc:0.83728\n",
            "[97]\tvalidation_0-auc:0.87717\tvalidation_1-auc:0.83724\n",
            "[98]\tvalidation_0-auc:0.87723\tvalidation_1-auc:0.83729\n",
            "[99]\tvalidation_0-auc:0.87729\tvalidation_1-auc:0.83730\n",
            "[0]\tvalidation_0-auc:0.82447\tvalidation_1-auc:0.81347\n",
            "[1]\tvalidation_0-auc:0.82584\tvalidation_1-auc:0.80971\n",
            "[2]\tvalidation_0-auc:0.81683\tvalidation_1-auc:0.79756\n",
            "[3]\tvalidation_0-auc:0.81228\tvalidation_1-auc:0.79405\n",
            "[4]\tvalidation_0-auc:0.82753\tvalidation_1-auc:0.81085\n",
            "[5]\tvalidation_0-auc:0.83223\tvalidation_1-auc:0.81402\n",
            "[6]\tvalidation_0-auc:0.83894\tvalidation_1-auc:0.81838\n",
            "[7]\tvalidation_0-auc:0.83588\tvalidation_1-auc:0.81616\n",
            "[8]\tvalidation_0-auc:0.84121\tvalidation_1-auc:0.81905\n",
            "[9]\tvalidation_0-auc:0.83897\tvalidation_1-auc:0.81871\n",
            "[10]\tvalidation_0-auc:0.83798\tvalidation_1-auc:0.81726\n",
            "[11]\tvalidation_0-auc:0.84173\tvalidation_1-auc:0.82068\n",
            "[12]\tvalidation_0-auc:0.84390\tvalidation_1-auc:0.82275\n",
            "[13]\tvalidation_0-auc:0.84592\tvalidation_1-auc:0.82482\n",
            "[14]\tvalidation_0-auc:0.84823\tvalidation_1-auc:0.82701\n",
            "[15]\tvalidation_0-auc:0.84699\tvalidation_1-auc:0.82573\n",
            "[16]\tvalidation_0-auc:0.84827\tvalidation_1-auc:0.82651\n",
            "[17]\tvalidation_0-auc:0.85019\tvalidation_1-auc:0.82889\n",
            "[18]\tvalidation_0-auc:0.85113\tvalidation_1-auc:0.83018\n",
            "[19]\tvalidation_0-auc:0.85167\tvalidation_1-auc:0.83123\n",
            "[20]\tvalidation_0-auc:0.85183\tvalidation_1-auc:0.83012\n",
            "[21]\tvalidation_0-auc:0.85105\tvalidation_1-auc:0.82921\n",
            "[22]\tvalidation_0-auc:0.85338\tvalidation_1-auc:0.83045\n",
            "[23]\tvalidation_0-auc:0.85424\tvalidation_1-auc:0.83147\n",
            "[24]\tvalidation_0-auc:0.85416\tvalidation_1-auc:0.83135\n",
            "[25]\tvalidation_0-auc:0.85479\tvalidation_1-auc:0.83246\n",
            "[26]\tvalidation_0-auc:0.85610\tvalidation_1-auc:0.83295\n",
            "[27]\tvalidation_0-auc:0.85684\tvalidation_1-auc:0.83322\n",
            "[28]\tvalidation_0-auc:0.85717\tvalidation_1-auc:0.83274\n",
            "[29]\tvalidation_0-auc:0.85687\tvalidation_1-auc:0.83244\n",
            "[30]\tvalidation_0-auc:0.85751\tvalidation_1-auc:0.83298\n",
            "[31]\tvalidation_0-auc:0.85753\tvalidation_1-auc:0.83271\n",
            "[32]\tvalidation_0-auc:0.85810\tvalidation_1-auc:0.83323\n",
            "[33]\tvalidation_0-auc:0.85851\tvalidation_1-auc:0.83367\n",
            "[34]\tvalidation_0-auc:0.85886\tvalidation_1-auc:0.83332\n",
            "[35]\tvalidation_0-auc:0.85978\tvalidation_1-auc:0.83337\n",
            "[36]\tvalidation_0-auc:0.86025\tvalidation_1-auc:0.83403\n",
            "[37]\tvalidation_0-auc:0.86067\tvalidation_1-auc:0.83430\n",
            "[38]\tvalidation_0-auc:0.86133\tvalidation_1-auc:0.83482\n",
            "[39]\tvalidation_0-auc:0.86207\tvalidation_1-auc:0.83557\n",
            "[40]\tvalidation_0-auc:0.86248\tvalidation_1-auc:0.83549\n",
            "[41]\tvalidation_0-auc:0.86277\tvalidation_1-auc:0.83552\n",
            "[42]\tvalidation_0-auc:0.86326\tvalidation_1-auc:0.83578\n",
            "[43]\tvalidation_0-auc:0.86395\tvalidation_1-auc:0.83650\n",
            "[44]\tvalidation_0-auc:0.86437\tvalidation_1-auc:0.83634\n",
            "[45]\tvalidation_0-auc:0.86503\tvalidation_1-auc:0.83698\n",
            "[46]\tvalidation_0-auc:0.86557\tvalidation_1-auc:0.83688\n",
            "[47]\tvalidation_0-auc:0.86604\tvalidation_1-auc:0.83662\n",
            "[48]\tvalidation_0-auc:0.86662\tvalidation_1-auc:0.83712\n",
            "[49]\tvalidation_0-auc:0.86710\tvalidation_1-auc:0.83745\n",
            "[50]\tvalidation_0-auc:0.86746\tvalidation_1-auc:0.83787\n",
            "[51]\tvalidation_0-auc:0.86766\tvalidation_1-auc:0.83757\n",
            "[52]\tvalidation_0-auc:0.86784\tvalidation_1-auc:0.83737\n",
            "[53]\tvalidation_0-auc:0.86799\tvalidation_1-auc:0.83714\n",
            "[54]\tvalidation_0-auc:0.86846\tvalidation_1-auc:0.83696\n",
            "[55]\tvalidation_0-auc:0.86874\tvalidation_1-auc:0.83692\n",
            "[56]\tvalidation_0-auc:0.86914\tvalidation_1-auc:0.83724\n",
            "[57]\tvalidation_0-auc:0.86944\tvalidation_1-auc:0.83742\n",
            "[58]\tvalidation_0-auc:0.86971\tvalidation_1-auc:0.83791\n",
            "[59]\tvalidation_0-auc:0.86998\tvalidation_1-auc:0.83799\n",
            "[60]\tvalidation_0-auc:0.87007\tvalidation_1-auc:0.83783\n",
            "[61]\tvalidation_0-auc:0.87019\tvalidation_1-auc:0.83806\n",
            "[62]\tvalidation_0-auc:0.87037\tvalidation_1-auc:0.83859\n",
            "[63]\tvalidation_0-auc:0.87069\tvalidation_1-auc:0.83897\n",
            "[64]\tvalidation_0-auc:0.87104\tvalidation_1-auc:0.83912\n",
            "[65]\tvalidation_0-auc:0.87145\tvalidation_1-auc:0.83887\n",
            "[66]\tvalidation_0-auc:0.87163\tvalidation_1-auc:0.83899\n",
            "[67]\tvalidation_0-auc:0.87178\tvalidation_1-auc:0.83905\n",
            "[68]\tvalidation_0-auc:0.87204\tvalidation_1-auc:0.83892\n",
            "[69]\tvalidation_0-auc:0.87243\tvalidation_1-auc:0.83884\n",
            "[70]\tvalidation_0-auc:0.87286\tvalidation_1-auc:0.83925\n",
            "[71]\tvalidation_0-auc:0.87297\tvalidation_1-auc:0.83920\n",
            "[72]\tvalidation_0-auc:0.87352\tvalidation_1-auc:0.83911\n",
            "[73]\tvalidation_0-auc:0.87373\tvalidation_1-auc:0.83929\n",
            "[74]\tvalidation_0-auc:0.87395\tvalidation_1-auc:0.83944\n",
            "[75]\tvalidation_0-auc:0.87405\tvalidation_1-auc:0.83963\n",
            "[76]\tvalidation_0-auc:0.87419\tvalidation_1-auc:0.83979\n",
            "[77]\tvalidation_0-auc:0.87423\tvalidation_1-auc:0.83996\n",
            "[78]\tvalidation_0-auc:0.87448\tvalidation_1-auc:0.84013\n",
            "[79]\tvalidation_0-auc:0.87485\tvalidation_1-auc:0.84001\n",
            "[80]\tvalidation_0-auc:0.87491\tvalidation_1-auc:0.84022\n",
            "[81]\tvalidation_0-auc:0.87533\tvalidation_1-auc:0.83993\n",
            "[82]\tvalidation_0-auc:0.87557\tvalidation_1-auc:0.83989\n",
            "[83]\tvalidation_0-auc:0.87582\tvalidation_1-auc:0.83983\n",
            "[84]\tvalidation_0-auc:0.87598\tvalidation_1-auc:0.83981\n",
            "[85]\tvalidation_0-auc:0.87619\tvalidation_1-auc:0.83970\n",
            "[86]\tvalidation_0-auc:0.87633\tvalidation_1-auc:0.83972\n",
            "[87]\tvalidation_0-auc:0.87647\tvalidation_1-auc:0.83998\n",
            "[88]\tvalidation_0-auc:0.87664\tvalidation_1-auc:0.84009\n",
            "[89]\tvalidation_0-auc:0.87679\tvalidation_1-auc:0.84008\n",
            "[90]\tvalidation_0-auc:0.87708\tvalidation_1-auc:0.83982\n",
            "[91]\tvalidation_0-auc:0.87737\tvalidation_1-auc:0.84007\n",
            "[92]\tvalidation_0-auc:0.87772\tvalidation_1-auc:0.84008\n",
            "[93]\tvalidation_0-auc:0.87800\tvalidation_1-auc:0.84018\n",
            "[94]\tvalidation_0-auc:0.87803\tvalidation_1-auc:0.84026\n",
            "[95]\tvalidation_0-auc:0.87844\tvalidation_1-auc:0.83997\n",
            "[96]\tvalidation_0-auc:0.87865\tvalidation_1-auc:0.83996\n",
            "[97]\tvalidation_0-auc:0.87887\tvalidation_1-auc:0.83980\n",
            "[98]\tvalidation_0-auc:0.87908\tvalidation_1-auc:0.83979\n",
            "[99]\tvalidation_0-auc:0.87918\tvalidation_1-auc:0.83988\n",
            "[0]\tvalidation_0-auc:0.83972\tvalidation_1-auc:0.80411\n",
            "[1]\tvalidation_0-auc:0.84884\tvalidation_1-auc:0.81363\n",
            "[2]\tvalidation_0-auc:0.84749\tvalidation_1-auc:0.81393\n",
            "[3]\tvalidation_0-auc:0.85012\tvalidation_1-auc:0.81914\n",
            "[4]\tvalidation_0-auc:0.85248\tvalidation_1-auc:0.82159\n",
            "[5]\tvalidation_0-auc:0.85481\tvalidation_1-auc:0.82287\n",
            "[6]\tvalidation_0-auc:0.85586\tvalidation_1-auc:0.82376\n",
            "[7]\tvalidation_0-auc:0.85638\tvalidation_1-auc:0.82396\n",
            "[8]\tvalidation_0-auc:0.85744\tvalidation_1-auc:0.82509\n",
            "[9]\tvalidation_0-auc:0.85602\tvalidation_1-auc:0.82354\n",
            "[10]\tvalidation_0-auc:0.85791\tvalidation_1-auc:0.82475\n",
            "[11]\tvalidation_0-auc:0.85986\tvalidation_1-auc:0.82645\n",
            "[12]\tvalidation_0-auc:0.86049\tvalidation_1-auc:0.82664\n",
            "[13]\tvalidation_0-auc:0.86172\tvalidation_1-auc:0.82704\n",
            "[14]\tvalidation_0-auc:0.86217\tvalidation_1-auc:0.82749\n",
            "[15]\tvalidation_0-auc:0.86291\tvalidation_1-auc:0.82705\n",
            "[16]\tvalidation_0-auc:0.86379\tvalidation_1-auc:0.82753\n",
            "[17]\tvalidation_0-auc:0.86458\tvalidation_1-auc:0.82753\n",
            "[18]\tvalidation_0-auc:0.86467\tvalidation_1-auc:0.82763\n",
            "[19]\tvalidation_0-auc:0.86523\tvalidation_1-auc:0.82780\n",
            "[20]\tvalidation_0-auc:0.86537\tvalidation_1-auc:0.82811\n",
            "[21]\tvalidation_0-auc:0.86561\tvalidation_1-auc:0.82828\n",
            "[22]\tvalidation_0-auc:0.86679\tvalidation_1-auc:0.82866\n",
            "[23]\tvalidation_0-auc:0.86727\tvalidation_1-auc:0.82898\n",
            "[24]\tvalidation_0-auc:0.86772\tvalidation_1-auc:0.82956\n",
            "[25]\tvalidation_0-auc:0.86804\tvalidation_1-auc:0.82989\n",
            "[26]\tvalidation_0-auc:0.86836\tvalidation_1-auc:0.82991\n",
            "[27]\tvalidation_0-auc:0.86873\tvalidation_1-auc:0.83009\n",
            "[28]\tvalidation_0-auc:0.86906\tvalidation_1-auc:0.83012\n",
            "[29]\tvalidation_0-auc:0.86898\tvalidation_1-auc:0.82969\n",
            "[30]\tvalidation_0-auc:0.86940\tvalidation_1-auc:0.82961\n",
            "[31]\tvalidation_0-auc:0.86952\tvalidation_1-auc:0.82937\n",
            "[32]\tvalidation_0-auc:0.86986\tvalidation_1-auc:0.82976\n",
            "[33]\tvalidation_0-auc:0.86972\tvalidation_1-auc:0.82914\n",
            "[34]\tvalidation_0-auc:0.86919\tvalidation_1-auc:0.82884\n",
            "[35]\tvalidation_0-auc:0.87038\tvalidation_1-auc:0.82959\n",
            "[36]\tvalidation_0-auc:0.87136\tvalidation_1-auc:0.82995\n",
            "[37]\tvalidation_0-auc:0.87103\tvalidation_1-auc:0.82956\n",
            "[38]\tvalidation_0-auc:0.87216\tvalidation_1-auc:0.83028\n",
            "[39]\tvalidation_0-auc:0.87267\tvalidation_1-auc:0.83070\n",
            "[40]\tvalidation_0-auc:0.87271\tvalidation_1-auc:0.83046\n",
            "[41]\tvalidation_0-auc:0.87231\tvalidation_1-auc:0.82989\n",
            "[42]\tvalidation_0-auc:0.87214\tvalidation_1-auc:0.82990\n",
            "[43]\tvalidation_0-auc:0.87280\tvalidation_1-auc:0.83018\n",
            "[44]\tvalidation_0-auc:0.87262\tvalidation_1-auc:0.83008\n",
            "[45]\tvalidation_0-auc:0.87336\tvalidation_1-auc:0.83018\n",
            "[46]\tvalidation_0-auc:0.87331\tvalidation_1-auc:0.83013\n",
            "[47]\tvalidation_0-auc:0.87341\tvalidation_1-auc:0.82978\n",
            "[48]\tvalidation_0-auc:0.87407\tvalidation_1-auc:0.83021\n",
            "[49]\tvalidation_0-auc:0.87493\tvalidation_1-auc:0.83034\n",
            "[50]\tvalidation_0-auc:0.87545\tvalidation_1-auc:0.83055\n",
            "[51]\tvalidation_0-auc:0.87603\tvalidation_1-auc:0.83077\n",
            "[52]\tvalidation_0-auc:0.87592\tvalidation_1-auc:0.83045\n",
            "[53]\tvalidation_0-auc:0.87667\tvalidation_1-auc:0.83081\n",
            "[54]\tvalidation_0-auc:0.87652\tvalidation_1-auc:0.83060\n",
            "[55]\tvalidation_0-auc:0.87649\tvalidation_1-auc:0.83040\n",
            "[56]\tvalidation_0-auc:0.87722\tvalidation_1-auc:0.83069\n",
            "[57]\tvalidation_0-auc:0.87815\tvalidation_1-auc:0.83120\n",
            "[58]\tvalidation_0-auc:0.87888\tvalidation_1-auc:0.83152\n",
            "[59]\tvalidation_0-auc:0.87926\tvalidation_1-auc:0.83170\n",
            "[60]\tvalidation_0-auc:0.87914\tvalidation_1-auc:0.83146\n",
            "[61]\tvalidation_0-auc:0.87958\tvalidation_1-auc:0.83149\n",
            "[62]\tvalidation_0-auc:0.88027\tvalidation_1-auc:0.83190\n",
            "[63]\tvalidation_0-auc:0.88093\tvalidation_1-auc:0.83215\n",
            "[64]\tvalidation_0-auc:0.88139\tvalidation_1-auc:0.83236\n",
            "[65]\tvalidation_0-auc:0.88166\tvalidation_1-auc:0.83222\n",
            "[66]\tvalidation_0-auc:0.88212\tvalidation_1-auc:0.83241\n",
            "[67]\tvalidation_0-auc:0.88245\tvalidation_1-auc:0.83238\n",
            "[68]\tvalidation_0-auc:0.88259\tvalidation_1-auc:0.83217\n",
            "[69]\tvalidation_0-auc:0.88285\tvalidation_1-auc:0.83186\n",
            "[70]\tvalidation_0-auc:0.88319\tvalidation_1-auc:0.83222\n",
            "[71]\tvalidation_0-auc:0.88325\tvalidation_1-auc:0.83192\n",
            "[72]\tvalidation_0-auc:0.88368\tvalidation_1-auc:0.83210\n",
            "[73]\tvalidation_0-auc:0.88407\tvalidation_1-auc:0.83243\n",
            "[74]\tvalidation_0-auc:0.88441\tvalidation_1-auc:0.83265\n",
            "[75]\tvalidation_0-auc:0.88471\tvalidation_1-auc:0.83320\n",
            "[76]\tvalidation_0-auc:0.88500\tvalidation_1-auc:0.83344\n",
            "[77]\tvalidation_0-auc:0.88525\tvalidation_1-auc:0.83364\n",
            "[78]\tvalidation_0-auc:0.88560\tvalidation_1-auc:0.83368\n",
            "[79]\tvalidation_0-auc:0.88608\tvalidation_1-auc:0.83342\n",
            "[80]\tvalidation_0-auc:0.88654\tvalidation_1-auc:0.83358\n",
            "[81]\tvalidation_0-auc:0.88673\tvalidation_1-auc:0.83349\n",
            "[82]\tvalidation_0-auc:0.88694\tvalidation_1-auc:0.83341\n",
            "[83]\tvalidation_0-auc:0.88729\tvalidation_1-auc:0.83350\n",
            "[84]\tvalidation_0-auc:0.88748\tvalidation_1-auc:0.83328\n",
            "[85]\tvalidation_0-auc:0.88767\tvalidation_1-auc:0.83314\n",
            "[86]\tvalidation_0-auc:0.88782\tvalidation_1-auc:0.83295\n",
            "[87]\tvalidation_0-auc:0.88807\tvalidation_1-auc:0.83314\n",
            "[88]\tvalidation_0-auc:0.88844\tvalidation_1-auc:0.83345\n",
            "[89]\tvalidation_0-auc:0.88875\tvalidation_1-auc:0.83327\n",
            "[90]\tvalidation_0-auc:0.88880\tvalidation_1-auc:0.83308\n",
            "[91]\tvalidation_0-auc:0.88888\tvalidation_1-auc:0.83338\n",
            "[92]\tvalidation_0-auc:0.88909\tvalidation_1-auc:0.83307\n",
            "[93]\tvalidation_0-auc:0.88936\tvalidation_1-auc:0.83315\n",
            "[94]\tvalidation_0-auc:0.88977\tvalidation_1-auc:0.83345\n",
            "[95]\tvalidation_0-auc:0.89008\tvalidation_1-auc:0.83336\n",
            "[96]\tvalidation_0-auc:0.89007\tvalidation_1-auc:0.83336\n",
            "[97]\tvalidation_0-auc:0.89030\tvalidation_1-auc:0.83334\n",
            "[98]\tvalidation_0-auc:0.89066\tvalidation_1-auc:0.83350\n",
            "[99]\tvalidation_0-auc:0.89086\tvalidation_1-auc:0.83345\n",
            "[0]\tvalidation_0-auc:0.84143\tvalidation_1-auc:0.81891\n",
            "[1]\tvalidation_0-auc:0.84943\tvalidation_1-auc:0.82351\n",
            "[2]\tvalidation_0-auc:0.84921\tvalidation_1-auc:0.81659\n",
            "[3]\tvalidation_0-auc:0.85482\tvalidation_1-auc:0.82185\n",
            "[4]\tvalidation_0-auc:0.85743\tvalidation_1-auc:0.82485\n",
            "[5]\tvalidation_0-auc:0.85951\tvalidation_1-auc:0.82759\n",
            "[6]\tvalidation_0-auc:0.86042\tvalidation_1-auc:0.82906\n",
            "[7]\tvalidation_0-auc:0.85990\tvalidation_1-auc:0.82618\n",
            "[8]\tvalidation_0-auc:0.86086\tvalidation_1-auc:0.82739\n",
            "[9]\tvalidation_0-auc:0.85943\tvalidation_1-auc:0.82523\n",
            "[10]\tvalidation_0-auc:0.86061\tvalidation_1-auc:0.82654\n",
            "[11]\tvalidation_0-auc:0.86138\tvalidation_1-auc:0.82791\n",
            "[12]\tvalidation_0-auc:0.86316\tvalidation_1-auc:0.83009\n",
            "[13]\tvalidation_0-auc:0.86420\tvalidation_1-auc:0.83052\n",
            "[14]\tvalidation_0-auc:0.86488\tvalidation_1-auc:0.83091\n",
            "[15]\tvalidation_0-auc:0.86528\tvalidation_1-auc:0.83014\n",
            "[16]\tvalidation_0-auc:0.86638\tvalidation_1-auc:0.83112\n",
            "[17]\tvalidation_0-auc:0.86716\tvalidation_1-auc:0.83166\n",
            "[18]\tvalidation_0-auc:0.86773\tvalidation_1-auc:0.83225\n",
            "[19]\tvalidation_0-auc:0.86827\tvalidation_1-auc:0.83245\n",
            "[20]\tvalidation_0-auc:0.86812\tvalidation_1-auc:0.83128\n",
            "[21]\tvalidation_0-auc:0.86786\tvalidation_1-auc:0.83047\n",
            "[22]\tvalidation_0-auc:0.86846\tvalidation_1-auc:0.83047\n",
            "[23]\tvalidation_0-auc:0.86917\tvalidation_1-auc:0.83112\n",
            "[24]\tvalidation_0-auc:0.86944\tvalidation_1-auc:0.83147\n",
            "[25]\tvalidation_0-auc:0.86949\tvalidation_1-auc:0.83196\n",
            "[26]\tvalidation_0-auc:0.86983\tvalidation_1-auc:0.83228\n",
            "[27]\tvalidation_0-auc:0.87035\tvalidation_1-auc:0.83287\n",
            "[28]\tvalidation_0-auc:0.87014\tvalidation_1-auc:0.83216\n",
            "[29]\tvalidation_0-auc:0.86981\tvalidation_1-auc:0.83167\n",
            "[30]\tvalidation_0-auc:0.87027\tvalidation_1-auc:0.83156\n",
            "[31]\tvalidation_0-auc:0.87020\tvalidation_1-auc:0.83124\n",
            "[32]\tvalidation_0-auc:0.87079\tvalidation_1-auc:0.83154\n",
            "[33]\tvalidation_0-auc:0.87036\tvalidation_1-auc:0.83076\n",
            "[34]\tvalidation_0-auc:0.87021\tvalidation_1-auc:0.82997\n",
            "[35]\tvalidation_0-auc:0.87096\tvalidation_1-auc:0.83070\n",
            "[36]\tvalidation_0-auc:0.87193\tvalidation_1-auc:0.83103\n",
            "[37]\tvalidation_0-auc:0.87159\tvalidation_1-auc:0.83021\n",
            "[38]\tvalidation_0-auc:0.87231\tvalidation_1-auc:0.83118\n",
            "[39]\tvalidation_0-auc:0.87317\tvalidation_1-auc:0.83152\n",
            "[40]\tvalidation_0-auc:0.87302\tvalidation_1-auc:0.83110\n",
            "[41]\tvalidation_0-auc:0.87273\tvalidation_1-auc:0.83007\n",
            "[42]\tvalidation_0-auc:0.87250\tvalidation_1-auc:0.82953\n",
            "[43]\tvalidation_0-auc:0.87303\tvalidation_1-auc:0.82999\n",
            "[44]\tvalidation_0-auc:0.87295\tvalidation_1-auc:0.82923\n",
            "[45]\tvalidation_0-auc:0.87359\tvalidation_1-auc:0.82950\n",
            "[46]\tvalidation_0-auc:0.87361\tvalidation_1-auc:0.82899\n",
            "[47]\tvalidation_0-auc:0.87347\tvalidation_1-auc:0.82855\n",
            "[48]\tvalidation_0-auc:0.87436\tvalidation_1-auc:0.82885\n",
            "[49]\tvalidation_0-auc:0.87495\tvalidation_1-auc:0.82940\n",
            "[50]\tvalidation_0-auc:0.87534\tvalidation_1-auc:0.82986\n",
            "[51]\tvalidation_0-auc:0.87592\tvalidation_1-auc:0.83033\n",
            "[52]\tvalidation_0-auc:0.87586\tvalidation_1-auc:0.82974\n",
            "[53]\tvalidation_0-auc:0.87638\tvalidation_1-auc:0.83012\n",
            "[54]\tvalidation_0-auc:0.87652\tvalidation_1-auc:0.82980\n",
            "[55]\tvalidation_0-auc:0.87668\tvalidation_1-auc:0.82942\n",
            "[56]\tvalidation_0-auc:0.87743\tvalidation_1-auc:0.82984\n",
            "[0]\tvalidation_0-auc:0.84076\tvalidation_1-auc:0.81300\n",
            "[1]\tvalidation_0-auc:0.84659\tvalidation_1-auc:0.82082\n",
            "[2]\tvalidation_0-auc:0.84938\tvalidation_1-auc:0.81678\n",
            "[3]\tvalidation_0-auc:0.85462\tvalidation_1-auc:0.82213\n",
            "[4]\tvalidation_0-auc:0.85655\tvalidation_1-auc:0.82435\n",
            "[5]\tvalidation_0-auc:0.85733\tvalidation_1-auc:0.82684\n",
            "[6]\tvalidation_0-auc:0.85759\tvalidation_1-auc:0.82795\n",
            "[7]\tvalidation_0-auc:0.85844\tvalidation_1-auc:0.82714\n",
            "[8]\tvalidation_0-auc:0.85951\tvalidation_1-auc:0.82701\n",
            "[9]\tvalidation_0-auc:0.85957\tvalidation_1-auc:0.82580\n",
            "[10]\tvalidation_0-auc:0.86236\tvalidation_1-auc:0.82769\n",
            "[11]\tvalidation_0-auc:0.86348\tvalidation_1-auc:0.82798\n",
            "[12]\tvalidation_0-auc:0.86411\tvalidation_1-auc:0.82835\n",
            "[13]\tvalidation_0-auc:0.86398\tvalidation_1-auc:0.82832\n",
            "[14]\tvalidation_0-auc:0.86447\tvalidation_1-auc:0.82849\n",
            "[15]\tvalidation_0-auc:0.86484\tvalidation_1-auc:0.82889\n",
            "[16]\tvalidation_0-auc:0.86545\tvalidation_1-auc:0.82900\n",
            "[17]\tvalidation_0-auc:0.86593\tvalidation_1-auc:0.82902\n",
            "[18]\tvalidation_0-auc:0.86608\tvalidation_1-auc:0.82950\n",
            "[19]\tvalidation_0-auc:0.86638\tvalidation_1-auc:0.82946\n",
            "[20]\tvalidation_0-auc:0.86684\tvalidation_1-auc:0.82897\n",
            "[21]\tvalidation_0-auc:0.86665\tvalidation_1-auc:0.82857\n",
            "[22]\tvalidation_0-auc:0.86708\tvalidation_1-auc:0.82822\n",
            "[23]\tvalidation_0-auc:0.86767\tvalidation_1-auc:0.82823\n",
            "[24]\tvalidation_0-auc:0.86801\tvalidation_1-auc:0.82846\n",
            "[25]\tvalidation_0-auc:0.86811\tvalidation_1-auc:0.82890\n",
            "[26]\tvalidation_0-auc:0.86828\tvalidation_1-auc:0.82915\n",
            "[27]\tvalidation_0-auc:0.86867\tvalidation_1-auc:0.82942\n",
            "[28]\tvalidation_0-auc:0.86907\tvalidation_1-auc:0.82879\n",
            "[29]\tvalidation_0-auc:0.86898\tvalidation_1-auc:0.82897\n",
            "[30]\tvalidation_0-auc:0.86911\tvalidation_1-auc:0.82900\n",
            "[31]\tvalidation_0-auc:0.86938\tvalidation_1-auc:0.82912\n",
            "[32]\tvalidation_0-auc:0.86997\tvalidation_1-auc:0.82916\n",
            "[33]\tvalidation_0-auc:0.87021\tvalidation_1-auc:0.82866\n",
            "[34]\tvalidation_0-auc:0.87012\tvalidation_1-auc:0.82839\n",
            "[35]\tvalidation_0-auc:0.87043\tvalidation_1-auc:0.82881\n",
            "[36]\tvalidation_0-auc:0.87130\tvalidation_1-auc:0.82973\n",
            "[37]\tvalidation_0-auc:0.87137\tvalidation_1-auc:0.82968\n",
            "[38]\tvalidation_0-auc:0.87195\tvalidation_1-auc:0.83002\n",
            "[39]\tvalidation_0-auc:0.87246\tvalidation_1-auc:0.83045\n",
            "[40]\tvalidation_0-auc:0.87259\tvalidation_1-auc:0.83026\n",
            "[41]\tvalidation_0-auc:0.87247\tvalidation_1-auc:0.82968\n",
            "[42]\tvalidation_0-auc:0.87231\tvalidation_1-auc:0.82929\n",
            "[43]\tvalidation_0-auc:0.87280\tvalidation_1-auc:0.82978\n",
            "[44]\tvalidation_0-auc:0.87270\tvalidation_1-auc:0.82945\n",
            "[45]\tvalidation_0-auc:0.87311\tvalidation_1-auc:0.83019\n",
            "[46]\tvalidation_0-auc:0.87351\tvalidation_1-auc:0.82969\n",
            "[47]\tvalidation_0-auc:0.87364\tvalidation_1-auc:0.82948\n",
            "[48]\tvalidation_0-auc:0.87454\tvalidation_1-auc:0.83036\n",
            "[49]\tvalidation_0-auc:0.87552\tvalidation_1-auc:0.83130\n",
            "[50]\tvalidation_0-auc:0.87655\tvalidation_1-auc:0.83181\n",
            "[51]\tvalidation_0-auc:0.87739\tvalidation_1-auc:0.83240\n",
            "[52]\tvalidation_0-auc:0.87730\tvalidation_1-auc:0.83196\n",
            "[53]\tvalidation_0-auc:0.87779\tvalidation_1-auc:0.83243\n",
            "[54]\tvalidation_0-auc:0.87784\tvalidation_1-auc:0.83224\n",
            "[55]\tvalidation_0-auc:0.87775\tvalidation_1-auc:0.83205\n",
            "[56]\tvalidation_0-auc:0.87845\tvalidation_1-auc:0.83259\n",
            "[57]\tvalidation_0-auc:0.87907\tvalidation_1-auc:0.83277\n",
            "[58]\tvalidation_0-auc:0.87994\tvalidation_1-auc:0.83329\n",
            "[59]\tvalidation_0-auc:0.88042\tvalidation_1-auc:0.83351\n",
            "[60]\tvalidation_0-auc:0.88023\tvalidation_1-auc:0.83288\n",
            "[61]\tvalidation_0-auc:0.88071\tvalidation_1-auc:0.83328\n",
            "[62]\tvalidation_0-auc:0.88139\tvalidation_1-auc:0.83378\n",
            "[63]\tvalidation_0-auc:0.88180\tvalidation_1-auc:0.83405\n",
            "[64]\tvalidation_0-auc:0.88232\tvalidation_1-auc:0.83437\n",
            "[65]\tvalidation_0-auc:0.88239\tvalidation_1-auc:0.83401\n",
            "[66]\tvalidation_0-auc:0.88287\tvalidation_1-auc:0.83427\n",
            "[67]\tvalidation_0-auc:0.88319\tvalidation_1-auc:0.83456\n",
            "[68]\tvalidation_0-auc:0.88339\tvalidation_1-auc:0.83457\n",
            "[69]\tvalidation_0-auc:0.88358\tvalidation_1-auc:0.83449\n",
            "[70]\tvalidation_0-auc:0.88383\tvalidation_1-auc:0.83473\n",
            "[71]\tvalidation_0-auc:0.88393\tvalidation_1-auc:0.83474\n",
            "[72]\tvalidation_0-auc:0.88452\tvalidation_1-auc:0.83499\n",
            "[73]\tvalidation_0-auc:0.88496\tvalidation_1-auc:0.83525\n",
            "[74]\tvalidation_0-auc:0.88534\tvalidation_1-auc:0.83550\n",
            "[75]\tvalidation_0-auc:0.88555\tvalidation_1-auc:0.83559\n",
            "[76]\tvalidation_0-auc:0.88601\tvalidation_1-auc:0.83561\n",
            "[77]\tvalidation_0-auc:0.88631\tvalidation_1-auc:0.83571\n",
            "[78]\tvalidation_0-auc:0.88661\tvalidation_1-auc:0.83569\n",
            "[79]\tvalidation_0-auc:0.88681\tvalidation_1-auc:0.83547\n",
            "[80]\tvalidation_0-auc:0.88712\tvalidation_1-auc:0.83557\n",
            "[81]\tvalidation_0-auc:0.88730\tvalidation_1-auc:0.83525\n",
            "[82]\tvalidation_0-auc:0.88766\tvalidation_1-auc:0.83524\n",
            "[83]\tvalidation_0-auc:0.88793\tvalidation_1-auc:0.83505\n",
            "[84]\tvalidation_0-auc:0.88802\tvalidation_1-auc:0.83496\n",
            "[85]\tvalidation_0-auc:0.88831\tvalidation_1-auc:0.83492\n",
            "[86]\tvalidation_0-auc:0.88842\tvalidation_1-auc:0.83470\n",
            "[87]\tvalidation_0-auc:0.88861\tvalidation_1-auc:0.83496\n",
            "[88]\tvalidation_0-auc:0.88890\tvalidation_1-auc:0.83516\n",
            "[89]\tvalidation_0-auc:0.88920\tvalidation_1-auc:0.83498\n",
            "[90]\tvalidation_0-auc:0.88928\tvalidation_1-auc:0.83489\n",
            "[91]\tvalidation_0-auc:0.88942\tvalidation_1-auc:0.83509\n",
            "[92]\tvalidation_0-auc:0.88978\tvalidation_1-auc:0.83513\n",
            "[93]\tvalidation_0-auc:0.89008\tvalidation_1-auc:0.83530\n",
            "[94]\tvalidation_0-auc:0.89032\tvalidation_1-auc:0.83541\n",
            "[95]\tvalidation_0-auc:0.89057\tvalidation_1-auc:0.83533\n",
            "[96]\tvalidation_0-auc:0.89062\tvalidation_1-auc:0.83534\n",
            "[97]\tvalidation_0-auc:0.89095\tvalidation_1-auc:0.83525\n",
            "[98]\tvalidation_0-auc:0.89135\tvalidation_1-auc:0.83539\n",
            "[99]\tvalidation_0-auc:0.89139\tvalidation_1-auc:0.83526\n",
            "[0]\tvalidation_0-auc:0.85836\tvalidation_1-auc:0.80303\n",
            "[1]\tvalidation_0-auc:0.86926\tvalidation_1-auc:0.81390\n",
            "[2]\tvalidation_0-auc:0.87104\tvalidation_1-auc:0.81435\n",
            "[3]\tvalidation_0-auc:0.88102\tvalidation_1-auc:0.82227\n",
            "[4]\tvalidation_0-auc:0.88269\tvalidation_1-auc:0.82488\n",
            "[5]\tvalidation_0-auc:0.88459\tvalidation_1-auc:0.82565\n",
            "[6]\tvalidation_0-auc:0.88949\tvalidation_1-auc:0.82745\n",
            "[7]\tvalidation_0-auc:0.89304\tvalidation_1-auc:0.82514\n",
            "[8]\tvalidation_0-auc:0.89500\tvalidation_1-auc:0.82800\n",
            "[9]\tvalidation_0-auc:0.89573\tvalidation_1-auc:0.82579\n",
            "[10]\tvalidation_0-auc:0.89793\tvalidation_1-auc:0.82729\n",
            "[11]\tvalidation_0-auc:0.90051\tvalidation_1-auc:0.82846\n",
            "[12]\tvalidation_0-auc:0.90431\tvalidation_1-auc:0.82834\n",
            "[13]\tvalidation_0-auc:0.90654\tvalidation_1-auc:0.82803\n",
            "[14]\tvalidation_0-auc:0.90791\tvalidation_1-auc:0.82781\n",
            "[15]\tvalidation_0-auc:0.91028\tvalidation_1-auc:0.82790\n",
            "[16]\tvalidation_0-auc:0.91226\tvalidation_1-auc:0.82746\n",
            "[17]\tvalidation_0-auc:0.91310\tvalidation_1-auc:0.82761\n",
            "[18]\tvalidation_0-auc:0.91443\tvalidation_1-auc:0.82826\n",
            "[19]\tvalidation_0-auc:0.91599\tvalidation_1-auc:0.82814\n",
            "[20]\tvalidation_0-auc:0.91695\tvalidation_1-auc:0.82802\n",
            "[21]\tvalidation_0-auc:0.91774\tvalidation_1-auc:0.82792\n",
            "[22]\tvalidation_0-auc:0.91880\tvalidation_1-auc:0.82842\n",
            "[23]\tvalidation_0-auc:0.91944\tvalidation_1-auc:0.82838\n",
            "[24]\tvalidation_0-auc:0.92011\tvalidation_1-auc:0.82811\n",
            "[25]\tvalidation_0-auc:0.92034\tvalidation_1-auc:0.82798\n",
            "[26]\tvalidation_0-auc:0.92074\tvalidation_1-auc:0.82741\n",
            "[27]\tvalidation_0-auc:0.92115\tvalidation_1-auc:0.82716\n",
            "[28]\tvalidation_0-auc:0.92255\tvalidation_1-auc:0.82709\n",
            "[29]\tvalidation_0-auc:0.92283\tvalidation_1-auc:0.82655\n",
            "[30]\tvalidation_0-auc:0.92372\tvalidation_1-auc:0.82671\n",
            "[31]\tvalidation_0-auc:0.92407\tvalidation_1-auc:0.82636\n",
            "[32]\tvalidation_0-auc:0.92441\tvalidation_1-auc:0.82655\n",
            "[33]\tvalidation_0-auc:0.92481\tvalidation_1-auc:0.82640\n",
            "[34]\tvalidation_0-auc:0.92493\tvalidation_1-auc:0.82610\n",
            "[35]\tvalidation_0-auc:0.92555\tvalidation_1-auc:0.82519\n",
            "[36]\tvalidation_0-auc:0.92588\tvalidation_1-auc:0.82535\n",
            "[37]\tvalidation_0-auc:0.92665\tvalidation_1-auc:0.82529\n",
            "[38]\tvalidation_0-auc:0.92710\tvalidation_1-auc:0.82519\n",
            "[39]\tvalidation_0-auc:0.92743\tvalidation_1-auc:0.82505\n",
            "[40]\tvalidation_0-auc:0.92787\tvalidation_1-auc:0.82464\n",
            "[0]\tvalidation_0-auc:0.85863\tvalidation_1-auc:0.81297\n",
            "[1]\tvalidation_0-auc:0.86958\tvalidation_1-auc:0.82186\n",
            "[2]\tvalidation_0-auc:0.87190\tvalidation_1-auc:0.81361\n",
            "[3]\tvalidation_0-auc:0.88088\tvalidation_1-auc:0.82090\n",
            "[4]\tvalidation_0-auc:0.88332\tvalidation_1-auc:0.82405\n",
            "[5]\tvalidation_0-auc:0.88747\tvalidation_1-auc:0.82639\n",
            "[6]\tvalidation_0-auc:0.89148\tvalidation_1-auc:0.82932\n",
            "[7]\tvalidation_0-auc:0.89590\tvalidation_1-auc:0.82707\n",
            "[8]\tvalidation_0-auc:0.89812\tvalidation_1-auc:0.82915\n",
            "[9]\tvalidation_0-auc:0.89775\tvalidation_1-auc:0.82700\n",
            "[10]\tvalidation_0-auc:0.90025\tvalidation_1-auc:0.82875\n",
            "[11]\tvalidation_0-auc:0.90266\tvalidation_1-auc:0.82870\n",
            "[12]\tvalidation_0-auc:0.90616\tvalidation_1-auc:0.82920\n",
            "[13]\tvalidation_0-auc:0.90739\tvalidation_1-auc:0.83099\n",
            "[14]\tvalidation_0-auc:0.90875\tvalidation_1-auc:0.83209\n",
            "[15]\tvalidation_0-auc:0.91145\tvalidation_1-auc:0.83275\n",
            "[16]\tvalidation_0-auc:0.91377\tvalidation_1-auc:0.83195\n",
            "[17]\tvalidation_0-auc:0.91562\tvalidation_1-auc:0.83217\n",
            "[18]\tvalidation_0-auc:0.91709\tvalidation_1-auc:0.83218\n",
            "[19]\tvalidation_0-auc:0.91860\tvalidation_1-auc:0.83251\n",
            "[20]\tvalidation_0-auc:0.91992\tvalidation_1-auc:0.83148\n",
            "[21]\tvalidation_0-auc:0.92104\tvalidation_1-auc:0.83183\n",
            "[22]\tvalidation_0-auc:0.92193\tvalidation_1-auc:0.83282\n",
            "[23]\tvalidation_0-auc:0.92257\tvalidation_1-auc:0.83309\n",
            "[24]\tvalidation_0-auc:0.92345\tvalidation_1-auc:0.83390\n",
            "[25]\tvalidation_0-auc:0.92384\tvalidation_1-auc:0.83421\n",
            "[26]\tvalidation_0-auc:0.92467\tvalidation_1-auc:0.83409\n",
            "[27]\tvalidation_0-auc:0.92499\tvalidation_1-auc:0.83394\n",
            "[28]\tvalidation_0-auc:0.92602\tvalidation_1-auc:0.83387\n",
            "[29]\tvalidation_0-auc:0.92624\tvalidation_1-auc:0.83352\n",
            "[30]\tvalidation_0-auc:0.92727\tvalidation_1-auc:0.83373\n",
            "[31]\tvalidation_0-auc:0.92782\tvalidation_1-auc:0.83351\n",
            "[32]\tvalidation_0-auc:0.92819\tvalidation_1-auc:0.83326\n",
            "[33]\tvalidation_0-auc:0.92840\tvalidation_1-auc:0.83357\n",
            "[34]\tvalidation_0-auc:0.92941\tvalidation_1-auc:0.83290\n",
            "[35]\tvalidation_0-auc:0.92959\tvalidation_1-auc:0.83270\n",
            "[36]\tvalidation_0-auc:0.92980\tvalidation_1-auc:0.83248\n",
            "[37]\tvalidation_0-auc:0.93020\tvalidation_1-auc:0.83207\n",
            "[38]\tvalidation_0-auc:0.93068\tvalidation_1-auc:0.83209\n",
            "[39]\tvalidation_0-auc:0.93095\tvalidation_1-auc:0.83246\n",
            "[40]\tvalidation_0-auc:0.93167\tvalidation_1-auc:0.83202\n",
            "[41]\tvalidation_0-auc:0.93190\tvalidation_1-auc:0.83197\n",
            "[42]\tvalidation_0-auc:0.93255\tvalidation_1-auc:0.83137\n",
            "[43]\tvalidation_0-auc:0.93285\tvalidation_1-auc:0.83122\n",
            "[44]\tvalidation_0-auc:0.93320\tvalidation_1-auc:0.83122\n",
            "[45]\tvalidation_0-auc:0.93354\tvalidation_1-auc:0.83127\n",
            "[46]\tvalidation_0-auc:0.93380\tvalidation_1-auc:0.83099\n",
            "[47]\tvalidation_0-auc:0.93402\tvalidation_1-auc:0.83090\n",
            "[48]\tvalidation_0-auc:0.93411\tvalidation_1-auc:0.83058\n",
            "[49]\tvalidation_0-auc:0.93451\tvalidation_1-auc:0.83045\n",
            "[50]\tvalidation_0-auc:0.93519\tvalidation_1-auc:0.83036\n",
            "[51]\tvalidation_0-auc:0.93551\tvalidation_1-auc:0.83010\n",
            "[52]\tvalidation_0-auc:0.93559\tvalidation_1-auc:0.82982\n",
            "[53]\tvalidation_0-auc:0.93586\tvalidation_1-auc:0.82983\n",
            "[54]\tvalidation_0-auc:0.93602\tvalidation_1-auc:0.82948\n",
            "[0]\tvalidation_0-auc:0.86150\tvalidation_1-auc:0.80603\n",
            "[1]\tvalidation_0-auc:0.86904\tvalidation_1-auc:0.81987\n",
            "[2]\tvalidation_0-auc:0.87317\tvalidation_1-auc:0.81754\n",
            "[3]\tvalidation_0-auc:0.87891\tvalidation_1-auc:0.82087\n",
            "[4]\tvalidation_0-auc:0.88066\tvalidation_1-auc:0.82243\n",
            "[5]\tvalidation_0-auc:0.88361\tvalidation_1-auc:0.82400\n",
            "[6]\tvalidation_0-auc:0.88706\tvalidation_1-auc:0.82575\n",
            "[7]\tvalidation_0-auc:0.89159\tvalidation_1-auc:0.82453\n",
            "[8]\tvalidation_0-auc:0.89512\tvalidation_1-auc:0.82645\n",
            "[9]\tvalidation_0-auc:0.89626\tvalidation_1-auc:0.82485\n",
            "[10]\tvalidation_0-auc:0.89874\tvalidation_1-auc:0.82669\n",
            "[11]\tvalidation_0-auc:0.90044\tvalidation_1-auc:0.82687\n",
            "[12]\tvalidation_0-auc:0.90367\tvalidation_1-auc:0.82766\n",
            "[13]\tvalidation_0-auc:0.90614\tvalidation_1-auc:0.82899\n",
            "[14]\tvalidation_0-auc:0.90789\tvalidation_1-auc:0.83081\n",
            "[15]\tvalidation_0-auc:0.90985\tvalidation_1-auc:0.82958\n",
            "[16]\tvalidation_0-auc:0.91173\tvalidation_1-auc:0.82969\n",
            "[17]\tvalidation_0-auc:0.91360\tvalidation_1-auc:0.83069\n",
            "[18]\tvalidation_0-auc:0.91484\tvalidation_1-auc:0.83180\n",
            "[19]\tvalidation_0-auc:0.91605\tvalidation_1-auc:0.83181\n",
            "[20]\tvalidation_0-auc:0.91750\tvalidation_1-auc:0.83116\n",
            "[21]\tvalidation_0-auc:0.91935\tvalidation_1-auc:0.82999\n",
            "[22]\tvalidation_0-auc:0.92023\tvalidation_1-auc:0.83032\n",
            "[23]\tvalidation_0-auc:0.92100\tvalidation_1-auc:0.83019\n",
            "[24]\tvalidation_0-auc:0.92162\tvalidation_1-auc:0.83055\n",
            "[25]\tvalidation_0-auc:0.92195\tvalidation_1-auc:0.83112\n",
            "[26]\tvalidation_0-auc:0.92276\tvalidation_1-auc:0.83096\n",
            "[27]\tvalidation_0-auc:0.92344\tvalidation_1-auc:0.83107\n",
            "[28]\tvalidation_0-auc:0.92435\tvalidation_1-auc:0.83048\n",
            "[29]\tvalidation_0-auc:0.92495\tvalidation_1-auc:0.83004\n",
            "[30]\tvalidation_0-auc:0.92555\tvalidation_1-auc:0.83053\n",
            "[31]\tvalidation_0-auc:0.92593\tvalidation_1-auc:0.83032\n",
            "[32]\tvalidation_0-auc:0.92642\tvalidation_1-auc:0.83071\n",
            "[33]\tvalidation_0-auc:0.92686\tvalidation_1-auc:0.83060\n",
            "[34]\tvalidation_0-auc:0.92723\tvalidation_1-auc:0.83061\n",
            "[35]\tvalidation_0-auc:0.92782\tvalidation_1-auc:0.83115\n",
            "[36]\tvalidation_0-auc:0.92892\tvalidation_1-auc:0.83102\n",
            "[37]\tvalidation_0-auc:0.92934\tvalidation_1-auc:0.83096\n",
            "[38]\tvalidation_0-auc:0.92979\tvalidation_1-auc:0.83101\n",
            "[39]\tvalidation_0-auc:0.93047\tvalidation_1-auc:0.83130\n",
            "[40]\tvalidation_0-auc:0.93076\tvalidation_1-auc:0.83107\n",
            "[41]\tvalidation_0-auc:0.93105\tvalidation_1-auc:0.83082\n",
            "[42]\tvalidation_0-auc:0.93127\tvalidation_1-auc:0.83057\n",
            "[43]\tvalidation_0-auc:0.93172\tvalidation_1-auc:0.83084\n",
            "[44]\tvalidation_0-auc:0.93220\tvalidation_1-auc:0.83072\n",
            "[45]\tvalidation_0-auc:0.93240\tvalidation_1-auc:0.83070\n",
            "[46]\tvalidation_0-auc:0.93255\tvalidation_1-auc:0.83072\n",
            "[47]\tvalidation_0-auc:0.93273\tvalidation_1-auc:0.83049\n",
            "[48]\tvalidation_0-auc:0.93353\tvalidation_1-auc:0.83008\n",
            "[49]\tvalidation_0-auc:0.93428\tvalidation_1-auc:0.83012\n",
            "[0]\tvalidation_0-auc:0.83151\tvalidation_1-auc:0.79801\n",
            "[1]\tvalidation_0-auc:0.84286\tvalidation_1-auc:0.81313\n",
            "[2]\tvalidation_0-auc:0.84202\tvalidation_1-auc:0.80661\n",
            "[3]\tvalidation_0-auc:0.85250\tvalidation_1-auc:0.81544\n",
            "[4]\tvalidation_0-auc:0.85439\tvalidation_1-auc:0.81883\n",
            "[5]\tvalidation_0-auc:0.85634\tvalidation_1-auc:0.82235\n",
            "[6]\tvalidation_0-auc:0.85822\tvalidation_1-auc:0.82320\n",
            "[7]\tvalidation_0-auc:0.85983\tvalidation_1-auc:0.82422\n",
            "[8]\tvalidation_0-auc:0.86259\tvalidation_1-auc:0.82758\n",
            "[9]\tvalidation_0-auc:0.86272\tvalidation_1-auc:0.82774\n",
            "[10]\tvalidation_0-auc:0.86457\tvalidation_1-auc:0.82984\n",
            "[11]\tvalidation_0-auc:0.86616\tvalidation_1-auc:0.83010\n",
            "[12]\tvalidation_0-auc:0.86805\tvalidation_1-auc:0.82974\n",
            "[13]\tvalidation_0-auc:0.86975\tvalidation_1-auc:0.82958\n",
            "[14]\tvalidation_0-auc:0.87094\tvalidation_1-auc:0.82954\n",
            "[15]\tvalidation_0-auc:0.87233\tvalidation_1-auc:0.83129\n",
            "[16]\tvalidation_0-auc:0.87363\tvalidation_1-auc:0.83150\n",
            "[17]\tvalidation_0-auc:0.87488\tvalidation_1-auc:0.83186\n",
            "[18]\tvalidation_0-auc:0.87592\tvalidation_1-auc:0.83208\n",
            "[19]\tvalidation_0-auc:0.87686\tvalidation_1-auc:0.83212\n",
            "[20]\tvalidation_0-auc:0.87803\tvalidation_1-auc:0.83169\n",
            "[21]\tvalidation_0-auc:0.87901\tvalidation_1-auc:0.83161\n",
            "[22]\tvalidation_0-auc:0.87988\tvalidation_1-auc:0.83191\n",
            "[23]\tvalidation_0-auc:0.88081\tvalidation_1-auc:0.83134\n",
            "[24]\tvalidation_0-auc:0.88141\tvalidation_1-auc:0.83177\n",
            "[25]\tvalidation_0-auc:0.88164\tvalidation_1-auc:0.83199\n",
            "[26]\tvalidation_0-auc:0.88227\tvalidation_1-auc:0.83186\n",
            "[27]\tvalidation_0-auc:0.88277\tvalidation_1-auc:0.83157\n",
            "[28]\tvalidation_0-auc:0.88360\tvalidation_1-auc:0.83143\n",
            "[29]\tvalidation_0-auc:0.88410\tvalidation_1-auc:0.83213\n",
            "[30]\tvalidation_0-auc:0.88465\tvalidation_1-auc:0.83226\n",
            "[31]\tvalidation_0-auc:0.88536\tvalidation_1-auc:0.83237\n",
            "[32]\tvalidation_0-auc:0.88556\tvalidation_1-auc:0.83250\n",
            "[33]\tvalidation_0-auc:0.88611\tvalidation_1-auc:0.83251\n",
            "[34]\tvalidation_0-auc:0.88641\tvalidation_1-auc:0.83252\n",
            "[35]\tvalidation_0-auc:0.88716\tvalidation_1-auc:0.83280\n",
            "[36]\tvalidation_0-auc:0.88764\tvalidation_1-auc:0.83269\n",
            "[37]\tvalidation_0-auc:0.88792\tvalidation_1-auc:0.83290\n",
            "[38]\tvalidation_0-auc:0.88835\tvalidation_1-auc:0.83288\n",
            "[39]\tvalidation_0-auc:0.88852\tvalidation_1-auc:0.83297\n",
            "[40]\tvalidation_0-auc:0.88880\tvalidation_1-auc:0.83303\n",
            "[41]\tvalidation_0-auc:0.88894\tvalidation_1-auc:0.83298\n",
            "[42]\tvalidation_0-auc:0.89010\tvalidation_1-auc:0.83282\n",
            "[43]\tvalidation_0-auc:0.89080\tvalidation_1-auc:0.83268\n",
            "[44]\tvalidation_0-auc:0.89121\tvalidation_1-auc:0.83239\n",
            "[45]\tvalidation_0-auc:0.89153\tvalidation_1-auc:0.83227\n",
            "[46]\tvalidation_0-auc:0.89224\tvalidation_1-auc:0.83215\n",
            "[47]\tvalidation_0-auc:0.89280\tvalidation_1-auc:0.83213\n",
            "[48]\tvalidation_0-auc:0.89332\tvalidation_1-auc:0.83186\n",
            "[49]\tvalidation_0-auc:0.89359\tvalidation_1-auc:0.83142\n",
            "[50]\tvalidation_0-auc:0.89380\tvalidation_1-auc:0.83123\n",
            "[51]\tvalidation_0-auc:0.89486\tvalidation_1-auc:0.83163\n",
            "[52]\tvalidation_0-auc:0.89508\tvalidation_1-auc:0.83160\n",
            "[53]\tvalidation_0-auc:0.89531\tvalidation_1-auc:0.83165\n",
            "[54]\tvalidation_0-auc:0.89566\tvalidation_1-auc:0.83149\n",
            "[55]\tvalidation_0-auc:0.89607\tvalidation_1-auc:0.83126\n",
            "[56]\tvalidation_0-auc:0.89669\tvalidation_1-auc:0.83119\n",
            "[57]\tvalidation_0-auc:0.89705\tvalidation_1-auc:0.83081\n",
            "[58]\tvalidation_0-auc:0.89713\tvalidation_1-auc:0.83087\n",
            "[59]\tvalidation_0-auc:0.89738\tvalidation_1-auc:0.83049\n",
            "[60]\tvalidation_0-auc:0.89753\tvalidation_1-auc:0.83038\n",
            "[61]\tvalidation_0-auc:0.89769\tvalidation_1-auc:0.83042\n",
            "[62]\tvalidation_0-auc:0.89817\tvalidation_1-auc:0.83039\n",
            "[63]\tvalidation_0-auc:0.89834\tvalidation_1-auc:0.83019\n",
            "[64]\tvalidation_0-auc:0.89870\tvalidation_1-auc:0.83025\n",
            "[65]\tvalidation_0-auc:0.89924\tvalidation_1-auc:0.83013\n",
            "[66]\tvalidation_0-auc:0.89943\tvalidation_1-auc:0.83003\n",
            "[67]\tvalidation_0-auc:0.89961\tvalidation_1-auc:0.82987\n",
            "[68]\tvalidation_0-auc:0.89967\tvalidation_1-auc:0.82973\n",
            "[69]\tvalidation_0-auc:0.90003\tvalidation_1-auc:0.82967\n",
            "[70]\tvalidation_0-auc:0.90040\tvalidation_1-auc:0.82956\n",
            "[0]\tvalidation_0-auc:0.83277\tvalidation_1-auc:0.81511\n",
            "[1]\tvalidation_0-auc:0.84037\tvalidation_1-auc:0.81945\n",
            "[2]\tvalidation_0-auc:0.83939\tvalidation_1-auc:0.81657\n",
            "[3]\tvalidation_0-auc:0.84877\tvalidation_1-auc:0.82172\n",
            "[4]\tvalidation_0-auc:0.85347\tvalidation_1-auc:0.82437\n",
            "[5]\tvalidation_0-auc:0.85598\tvalidation_1-auc:0.82784\n",
            "[6]\tvalidation_0-auc:0.85854\tvalidation_1-auc:0.82916\n",
            "[7]\tvalidation_0-auc:0.86050\tvalidation_1-auc:0.82762\n",
            "[8]\tvalidation_0-auc:0.86180\tvalidation_1-auc:0.82871\n",
            "[9]\tvalidation_0-auc:0.86074\tvalidation_1-auc:0.82703\n",
            "[10]\tvalidation_0-auc:0.86423\tvalidation_1-auc:0.83025\n",
            "[11]\tvalidation_0-auc:0.86548\tvalidation_1-auc:0.83101\n",
            "[12]\tvalidation_0-auc:0.86747\tvalidation_1-auc:0.83214\n",
            "[13]\tvalidation_0-auc:0.86908\tvalidation_1-auc:0.83239\n",
            "[14]\tvalidation_0-auc:0.87085\tvalidation_1-auc:0.83375\n",
            "[15]\tvalidation_0-auc:0.87220\tvalidation_1-auc:0.83467\n",
            "[16]\tvalidation_0-auc:0.87332\tvalidation_1-auc:0.83512\n",
            "[17]\tvalidation_0-auc:0.87443\tvalidation_1-auc:0.83637\n",
            "[18]\tvalidation_0-auc:0.87578\tvalidation_1-auc:0.83671\n",
            "[19]\tvalidation_0-auc:0.87696\tvalidation_1-auc:0.83669\n",
            "[20]\tvalidation_0-auc:0.87858\tvalidation_1-auc:0.83625\n",
            "[21]\tvalidation_0-auc:0.87991\tvalidation_1-auc:0.83570\n",
            "[22]\tvalidation_0-auc:0.88058\tvalidation_1-auc:0.83615\n",
            "[23]\tvalidation_0-auc:0.88130\tvalidation_1-auc:0.83630\n",
            "[24]\tvalidation_0-auc:0.88172\tvalidation_1-auc:0.83635\n",
            "[25]\tvalidation_0-auc:0.88232\tvalidation_1-auc:0.83631\n",
            "[26]\tvalidation_0-auc:0.88256\tvalidation_1-auc:0.83661\n",
            "[27]\tvalidation_0-auc:0.88269\tvalidation_1-auc:0.83662\n",
            "[28]\tvalidation_0-auc:0.88409\tvalidation_1-auc:0.83618\n",
            "[29]\tvalidation_0-auc:0.88434\tvalidation_1-auc:0.83619\n",
            "[30]\tvalidation_0-auc:0.88506\tvalidation_1-auc:0.83576\n",
            "[31]\tvalidation_0-auc:0.88564\tvalidation_1-auc:0.83608\n",
            "[32]\tvalidation_0-auc:0.88591\tvalidation_1-auc:0.83589\n",
            "[33]\tvalidation_0-auc:0.88666\tvalidation_1-auc:0.83592\n",
            "[34]\tvalidation_0-auc:0.88691\tvalidation_1-auc:0.83586\n",
            "[35]\tvalidation_0-auc:0.88716\tvalidation_1-auc:0.83611\n",
            "[36]\tvalidation_0-auc:0.88752\tvalidation_1-auc:0.83600\n",
            "[37]\tvalidation_0-auc:0.88796\tvalidation_1-auc:0.83603\n",
            "[38]\tvalidation_0-auc:0.88867\tvalidation_1-auc:0.83635\n",
            "[39]\tvalidation_0-auc:0.88895\tvalidation_1-auc:0.83604\n",
            "[40]\tvalidation_0-auc:0.88915\tvalidation_1-auc:0.83605\n",
            "[41]\tvalidation_0-auc:0.88965\tvalidation_1-auc:0.83589\n",
            "[42]\tvalidation_0-auc:0.89103\tvalidation_1-auc:0.83579\n",
            "[43]\tvalidation_0-auc:0.89152\tvalidation_1-auc:0.83566\n",
            "[44]\tvalidation_0-auc:0.89171\tvalidation_1-auc:0.83567\n",
            "[45]\tvalidation_0-auc:0.89200\tvalidation_1-auc:0.83571\n",
            "[46]\tvalidation_0-auc:0.89227\tvalidation_1-auc:0.83563\n",
            "[47]\tvalidation_0-auc:0.89297\tvalidation_1-auc:0.83565\n",
            "[48]\tvalidation_0-auc:0.89317\tvalidation_1-auc:0.83559\n",
            "[0]\tvalidation_0-auc:0.83554\tvalidation_1-auc:0.81040\n",
            "[1]\tvalidation_0-auc:0.84394\tvalidation_1-auc:0.82307\n",
            "[2]\tvalidation_0-auc:0.84817\tvalidation_1-auc:0.82096\n",
            "[3]\tvalidation_0-auc:0.85226\tvalidation_1-auc:0.82537\n",
            "[4]\tvalidation_0-auc:0.85389\tvalidation_1-auc:0.82553\n",
            "[5]\tvalidation_0-auc:0.85610\tvalidation_1-auc:0.82666\n",
            "[6]\tvalidation_0-auc:0.85911\tvalidation_1-auc:0.82710\n",
            "[7]\tvalidation_0-auc:0.86039\tvalidation_1-auc:0.82658\n",
            "[8]\tvalidation_0-auc:0.86202\tvalidation_1-auc:0.82967\n",
            "[9]\tvalidation_0-auc:0.86269\tvalidation_1-auc:0.82883\n",
            "[10]\tvalidation_0-auc:0.86517\tvalidation_1-auc:0.83106\n",
            "[11]\tvalidation_0-auc:0.86640\tvalidation_1-auc:0.83204\n",
            "[12]\tvalidation_0-auc:0.86843\tvalidation_1-auc:0.83201\n",
            "[13]\tvalidation_0-auc:0.86970\tvalidation_1-auc:0.83278\n",
            "[14]\tvalidation_0-auc:0.87137\tvalidation_1-auc:0.83399\n",
            "[15]\tvalidation_0-auc:0.87294\tvalidation_1-auc:0.83529\n",
            "[16]\tvalidation_0-auc:0.87412\tvalidation_1-auc:0.83544\n",
            "[17]\tvalidation_0-auc:0.87492\tvalidation_1-auc:0.83620\n",
            "[18]\tvalidation_0-auc:0.87592\tvalidation_1-auc:0.83633\n",
            "[19]\tvalidation_0-auc:0.87673\tvalidation_1-auc:0.83698\n",
            "[20]\tvalidation_0-auc:0.87799\tvalidation_1-auc:0.83686\n",
            "[21]\tvalidation_0-auc:0.87968\tvalidation_1-auc:0.83681\n",
            "[22]\tvalidation_0-auc:0.88127\tvalidation_1-auc:0.83675\n",
            "[23]\tvalidation_0-auc:0.88196\tvalidation_1-auc:0.83679\n",
            "[24]\tvalidation_0-auc:0.88277\tvalidation_1-auc:0.83657\n",
            "[25]\tvalidation_0-auc:0.88397\tvalidation_1-auc:0.83697\n",
            "[26]\tvalidation_0-auc:0.88454\tvalidation_1-auc:0.83713\n",
            "[27]\tvalidation_0-auc:0.88561\tvalidation_1-auc:0.83724\n",
            "[28]\tvalidation_0-auc:0.88694\tvalidation_1-auc:0.83675\n",
            "[29]\tvalidation_0-auc:0.88751\tvalidation_1-auc:0.83694\n",
            "[30]\tvalidation_0-auc:0.88861\tvalidation_1-auc:0.83692\n",
            "[31]\tvalidation_0-auc:0.88928\tvalidation_1-auc:0.83661\n",
            "[32]\tvalidation_0-auc:0.88966\tvalidation_1-auc:0.83634\n",
            "[33]\tvalidation_0-auc:0.89037\tvalidation_1-auc:0.83632\n",
            "[34]\tvalidation_0-auc:0.89124\tvalidation_1-auc:0.83583\n",
            "[35]\tvalidation_0-auc:0.89158\tvalidation_1-auc:0.83647\n",
            "[36]\tvalidation_0-auc:0.89189\tvalidation_1-auc:0.83648\n",
            "[37]\tvalidation_0-auc:0.89248\tvalidation_1-auc:0.83629\n",
            "[38]\tvalidation_0-auc:0.89293\tvalidation_1-auc:0.83663\n",
            "[39]\tvalidation_0-auc:0.89382\tvalidation_1-auc:0.83657\n",
            "[40]\tvalidation_0-auc:0.89407\tvalidation_1-auc:0.83655\n",
            "[41]\tvalidation_0-auc:0.89431\tvalidation_1-auc:0.83644\n",
            "[42]\tvalidation_0-auc:0.89467\tvalidation_1-auc:0.83622\n",
            "[43]\tvalidation_0-auc:0.89488\tvalidation_1-auc:0.83632\n",
            "[44]\tvalidation_0-auc:0.89568\tvalidation_1-auc:0.83609\n",
            "[45]\tvalidation_0-auc:0.89592\tvalidation_1-auc:0.83636\n",
            "[46]\tvalidation_0-auc:0.89608\tvalidation_1-auc:0.83636\n",
            "[47]\tvalidation_0-auc:0.89707\tvalidation_1-auc:0.83648\n",
            "[48]\tvalidation_0-auc:0.89715\tvalidation_1-auc:0.83646\n",
            "[49]\tvalidation_0-auc:0.89774\tvalidation_1-auc:0.83645\n",
            "[50]\tvalidation_0-auc:0.89782\tvalidation_1-auc:0.83637\n",
            "[51]\tvalidation_0-auc:0.89834\tvalidation_1-auc:0.83640\n",
            "[52]\tvalidation_0-auc:0.89868\tvalidation_1-auc:0.83639\n",
            "[53]\tvalidation_0-auc:0.89899\tvalidation_1-auc:0.83637\n",
            "[54]\tvalidation_0-auc:0.89920\tvalidation_1-auc:0.83634\n",
            "[55]\tvalidation_0-auc:0.90023\tvalidation_1-auc:0.83637\n",
            "[56]\tvalidation_0-auc:0.90040\tvalidation_1-auc:0.83638\n",
            "[0]\tvalidation_0-auc:0.84695\tvalidation_1-auc:0.80694\n",
            "[1]\tvalidation_0-auc:0.85994\tvalidation_1-auc:0.81906\n",
            "[2]\tvalidation_0-auc:0.86563\tvalidation_1-auc:0.81686\n",
            "[3]\tvalidation_0-auc:0.87247\tvalidation_1-auc:0.82399\n",
            "[4]\tvalidation_0-auc:0.87621\tvalidation_1-auc:0.82514\n",
            "[5]\tvalidation_0-auc:0.87830\tvalidation_1-auc:0.82708\n",
            "[6]\tvalidation_0-auc:0.88058\tvalidation_1-auc:0.82762\n",
            "[7]\tvalidation_0-auc:0.88263\tvalidation_1-auc:0.82576\n",
            "[8]\tvalidation_0-auc:0.88540\tvalidation_1-auc:0.82702\n",
            "[9]\tvalidation_0-auc:0.88756\tvalidation_1-auc:0.82848\n",
            "[10]\tvalidation_0-auc:0.88952\tvalidation_1-auc:0.82895\n",
            "[11]\tvalidation_0-auc:0.89126\tvalidation_1-auc:0.82945\n",
            "[12]\tvalidation_0-auc:0.89302\tvalidation_1-auc:0.82937\n",
            "[13]\tvalidation_0-auc:0.89386\tvalidation_1-auc:0.83032\n",
            "[14]\tvalidation_0-auc:0.89552\tvalidation_1-auc:0.83137\n",
            "[15]\tvalidation_0-auc:0.89666\tvalidation_1-auc:0.83233\n",
            "[16]\tvalidation_0-auc:0.89788\tvalidation_1-auc:0.83184\n",
            "[17]\tvalidation_0-auc:0.89868\tvalidation_1-auc:0.83152\n",
            "[18]\tvalidation_0-auc:0.89889\tvalidation_1-auc:0.83171\n",
            "[19]\tvalidation_0-auc:0.89907\tvalidation_1-auc:0.83155\n",
            "[20]\tvalidation_0-auc:0.90049\tvalidation_1-auc:0.83192\n",
            "[21]\tvalidation_0-auc:0.90182\tvalidation_1-auc:0.83190\n",
            "[22]\tvalidation_0-auc:0.90235\tvalidation_1-auc:0.83150\n",
            "[23]\tvalidation_0-auc:0.90311\tvalidation_1-auc:0.83145\n",
            "[24]\tvalidation_0-auc:0.90341\tvalidation_1-auc:0.83188\n",
            "[25]\tvalidation_0-auc:0.90412\tvalidation_1-auc:0.83205\n",
            "[26]\tvalidation_0-auc:0.90506\tvalidation_1-auc:0.83173\n",
            "[27]\tvalidation_0-auc:0.90632\tvalidation_1-auc:0.83145\n",
            "[28]\tvalidation_0-auc:0.90667\tvalidation_1-auc:0.83074\n",
            "[29]\tvalidation_0-auc:0.90711\tvalidation_1-auc:0.83010\n",
            "[30]\tvalidation_0-auc:0.90859\tvalidation_1-auc:0.83018\n",
            "[31]\tvalidation_0-auc:0.90925\tvalidation_1-auc:0.83000\n",
            "[32]\tvalidation_0-auc:0.90935\tvalidation_1-auc:0.82987\n",
            "[33]\tvalidation_0-auc:0.90984\tvalidation_1-auc:0.82927\n",
            "[34]\tvalidation_0-auc:0.91015\tvalidation_1-auc:0.82918\n",
            "[35]\tvalidation_0-auc:0.91067\tvalidation_1-auc:0.82870\n",
            "[36]\tvalidation_0-auc:0.91128\tvalidation_1-auc:0.82813\n",
            "[37]\tvalidation_0-auc:0.91165\tvalidation_1-auc:0.82795\n",
            "[38]\tvalidation_0-auc:0.91195\tvalidation_1-auc:0.82759\n",
            "[39]\tvalidation_0-auc:0.91215\tvalidation_1-auc:0.82751\n",
            "[40]\tvalidation_0-auc:0.91250\tvalidation_1-auc:0.82738\n",
            "[41]\tvalidation_0-auc:0.91264\tvalidation_1-auc:0.82728\n",
            "[42]\tvalidation_0-auc:0.91332\tvalidation_1-auc:0.82708\n",
            "[43]\tvalidation_0-auc:0.91342\tvalidation_1-auc:0.82699\n",
            "[44]\tvalidation_0-auc:0.91385\tvalidation_1-auc:0.82679\n",
            "[45]\tvalidation_0-auc:0.91405\tvalidation_1-auc:0.82659\n",
            "[0]\tvalidation_0-auc:0.84938\tvalidation_1-auc:0.81624\n",
            "[1]\tvalidation_0-auc:0.85944\tvalidation_1-auc:0.82343\n",
            "[2]\tvalidation_0-auc:0.86460\tvalidation_1-auc:0.81992\n",
            "[3]\tvalidation_0-auc:0.87359\tvalidation_1-auc:0.82499\n",
            "[4]\tvalidation_0-auc:0.87626\tvalidation_1-auc:0.82672\n",
            "[5]\tvalidation_0-auc:0.87872\tvalidation_1-auc:0.82921\n",
            "[6]\tvalidation_0-auc:0.88180\tvalidation_1-auc:0.82985\n",
            "[7]\tvalidation_0-auc:0.88408\tvalidation_1-auc:0.82688\n",
            "[8]\tvalidation_0-auc:0.88616\tvalidation_1-auc:0.82846\n",
            "[9]\tvalidation_0-auc:0.88776\tvalidation_1-auc:0.83003\n",
            "[10]\tvalidation_0-auc:0.88993\tvalidation_1-auc:0.83093\n",
            "[11]\tvalidation_0-auc:0.89115\tvalidation_1-auc:0.83154\n",
            "[12]\tvalidation_0-auc:0.89330\tvalidation_1-auc:0.83132\n",
            "[13]\tvalidation_0-auc:0.89444\tvalidation_1-auc:0.83186\n",
            "[14]\tvalidation_0-auc:0.89542\tvalidation_1-auc:0.83247\n",
            "[15]\tvalidation_0-auc:0.89642\tvalidation_1-auc:0.83266\n",
            "[16]\tvalidation_0-auc:0.89831\tvalidation_1-auc:0.83308\n",
            "[17]\tvalidation_0-auc:0.89925\tvalidation_1-auc:0.83280\n",
            "[18]\tvalidation_0-auc:0.90019\tvalidation_1-auc:0.83339\n",
            "[19]\tvalidation_0-auc:0.90119\tvalidation_1-auc:0.83298\n",
            "[20]\tvalidation_0-auc:0.90228\tvalidation_1-auc:0.83299\n",
            "[21]\tvalidation_0-auc:0.90343\tvalidation_1-auc:0.83297\n",
            "[22]\tvalidation_0-auc:0.90377\tvalidation_1-auc:0.83305\n",
            "[23]\tvalidation_0-auc:0.90416\tvalidation_1-auc:0.83269\n",
            "[24]\tvalidation_0-auc:0.90474\tvalidation_1-auc:0.83273\n",
            "[25]\tvalidation_0-auc:0.90526\tvalidation_1-auc:0.83253\n",
            "[26]\tvalidation_0-auc:0.90580\tvalidation_1-auc:0.83248\n",
            "[27]\tvalidation_0-auc:0.90629\tvalidation_1-auc:0.83229\n",
            "[28]\tvalidation_0-auc:0.90725\tvalidation_1-auc:0.83231\n",
            "[29]\tvalidation_0-auc:0.90793\tvalidation_1-auc:0.83218\n",
            "[30]\tvalidation_0-auc:0.90882\tvalidation_1-auc:0.83184\n",
            "[31]\tvalidation_0-auc:0.90924\tvalidation_1-auc:0.83175\n",
            "[32]\tvalidation_0-auc:0.91078\tvalidation_1-auc:0.83131\n",
            "[33]\tvalidation_0-auc:0.91130\tvalidation_1-auc:0.83092\n",
            "[34]\tvalidation_0-auc:0.91165\tvalidation_1-auc:0.83111\n",
            "[35]\tvalidation_0-auc:0.91195\tvalidation_1-auc:0.83143\n",
            "[36]\tvalidation_0-auc:0.91250\tvalidation_1-auc:0.83139\n",
            "[37]\tvalidation_0-auc:0.91276\tvalidation_1-auc:0.83163\n",
            "[38]\tvalidation_0-auc:0.91330\tvalidation_1-auc:0.83125\n",
            "[39]\tvalidation_0-auc:0.91378\tvalidation_1-auc:0.83067\n",
            "[40]\tvalidation_0-auc:0.91392\tvalidation_1-auc:0.83058\n",
            "[41]\tvalidation_0-auc:0.91457\tvalidation_1-auc:0.83077\n",
            "[42]\tvalidation_0-auc:0.91495\tvalidation_1-auc:0.83043\n",
            "[43]\tvalidation_0-auc:0.91524\tvalidation_1-auc:0.83003\n",
            "[44]\tvalidation_0-auc:0.91610\tvalidation_1-auc:0.82956\n",
            "[45]\tvalidation_0-auc:0.91646\tvalidation_1-auc:0.82957\n",
            "[46]\tvalidation_0-auc:0.91667\tvalidation_1-auc:0.82960\n",
            "[47]\tvalidation_0-auc:0.91702\tvalidation_1-auc:0.82963\n",
            "[0]\tvalidation_0-auc:0.85075\tvalidation_1-auc:0.81191\n",
            "[1]\tvalidation_0-auc:0.85987\tvalidation_1-auc:0.82346\n",
            "[2]\tvalidation_0-auc:0.86484\tvalidation_1-auc:0.81850\n",
            "[3]\tvalidation_0-auc:0.87069\tvalidation_1-auc:0.82272\n",
            "[4]\tvalidation_0-auc:0.87362\tvalidation_1-auc:0.82507\n",
            "[5]\tvalidation_0-auc:0.87796\tvalidation_1-auc:0.83011\n",
            "[6]\tvalidation_0-auc:0.88222\tvalidation_1-auc:0.83091\n",
            "[7]\tvalidation_0-auc:0.88463\tvalidation_1-auc:0.82762\n",
            "[8]\tvalidation_0-auc:0.88550\tvalidation_1-auc:0.82888\n",
            "[9]\tvalidation_0-auc:0.88867\tvalidation_1-auc:0.83144\n",
            "[10]\tvalidation_0-auc:0.89051\tvalidation_1-auc:0.83205\n",
            "[11]\tvalidation_0-auc:0.89159\tvalidation_1-auc:0.83273\n",
            "[12]\tvalidation_0-auc:0.89330\tvalidation_1-auc:0.83325\n",
            "[13]\tvalidation_0-auc:0.89564\tvalidation_1-auc:0.83423\n",
            "[14]\tvalidation_0-auc:0.89703\tvalidation_1-auc:0.83415\n",
            "[15]\tvalidation_0-auc:0.89869\tvalidation_1-auc:0.83479\n",
            "[16]\tvalidation_0-auc:0.90046\tvalidation_1-auc:0.83538\n",
            "[17]\tvalidation_0-auc:0.90117\tvalidation_1-auc:0.83539\n",
            "[18]\tvalidation_0-auc:0.90150\tvalidation_1-auc:0.83530\n",
            "[19]\tvalidation_0-auc:0.90274\tvalidation_1-auc:0.83575\n",
            "[20]\tvalidation_0-auc:0.90406\tvalidation_1-auc:0.83554\n",
            "[21]\tvalidation_0-auc:0.90509\tvalidation_1-auc:0.83461\n",
            "[22]\tvalidation_0-auc:0.90552\tvalidation_1-auc:0.83504\n",
            "[23]\tvalidation_0-auc:0.90605\tvalidation_1-auc:0.83529\n",
            "[24]\tvalidation_0-auc:0.90645\tvalidation_1-auc:0.83550\n",
            "[25]\tvalidation_0-auc:0.90705\tvalidation_1-auc:0.83594\n",
            "[26]\tvalidation_0-auc:0.90766\tvalidation_1-auc:0.83567\n",
            "[27]\tvalidation_0-auc:0.90911\tvalidation_1-auc:0.83575\n",
            "[28]\tvalidation_0-auc:0.90990\tvalidation_1-auc:0.83555\n",
            "[29]\tvalidation_0-auc:0.91027\tvalidation_1-auc:0.83545\n",
            "[30]\tvalidation_0-auc:0.91106\tvalidation_1-auc:0.83479\n",
            "[31]\tvalidation_0-auc:0.91160\tvalidation_1-auc:0.83450\n",
            "[32]\tvalidation_0-auc:0.91203\tvalidation_1-auc:0.83442\n",
            "[33]\tvalidation_0-auc:0.91237\tvalidation_1-auc:0.83398\n",
            "[34]\tvalidation_0-auc:0.91305\tvalidation_1-auc:0.83397\n",
            "[35]\tvalidation_0-auc:0.91359\tvalidation_1-auc:0.83423\n",
            "[36]\tvalidation_0-auc:0.91382\tvalidation_1-auc:0.83420\n",
            "[37]\tvalidation_0-auc:0.91479\tvalidation_1-auc:0.83360\n",
            "[38]\tvalidation_0-auc:0.91522\tvalidation_1-auc:0.83353\n",
            "[39]\tvalidation_0-auc:0.91565\tvalidation_1-auc:0.83363\n",
            "[40]\tvalidation_0-auc:0.91596\tvalidation_1-auc:0.83309\n",
            "[41]\tvalidation_0-auc:0.91628\tvalidation_1-auc:0.83289\n",
            "[42]\tvalidation_0-auc:0.91660\tvalidation_1-auc:0.83282\n",
            "[43]\tvalidation_0-auc:0.91680\tvalidation_1-auc:0.83280\n",
            "[44]\tvalidation_0-auc:0.91721\tvalidation_1-auc:0.83253\n",
            "[45]\tvalidation_0-auc:0.91723\tvalidation_1-auc:0.83245\n",
            "[46]\tvalidation_0-auc:0.91801\tvalidation_1-auc:0.83185\n",
            "[47]\tvalidation_0-auc:0.91813\tvalidation_1-auc:0.83192\n",
            "[48]\tvalidation_0-auc:0.91879\tvalidation_1-auc:0.83180\n",
            "[49]\tvalidation_0-auc:0.91908\tvalidation_1-auc:0.83147\n",
            "[50]\tvalidation_0-auc:0.91993\tvalidation_1-auc:0.83134\n",
            "[51]\tvalidation_0-auc:0.92012\tvalidation_1-auc:0.83138\n",
            "[52]\tvalidation_0-auc:0.92077\tvalidation_1-auc:0.83096\n",
            "[53]\tvalidation_0-auc:0.92202\tvalidation_1-auc:0.83001\n",
            "[54]\tvalidation_0-auc:0.92240\tvalidation_1-auc:0.82990\n",
            "[0]\tvalidation_0-auc:0.85068\tvalidation_1-auc:0.81409\n",
            "[1]\tvalidation_0-auc:0.85196\tvalidation_1-auc:0.81460\n",
            "[2]\tvalidation_0-auc:0.85542\tvalidation_1-auc:0.82072\n",
            "[3]\tvalidation_0-auc:0.85814\tvalidation_1-auc:0.82157\n",
            "[4]\tvalidation_0-auc:0.85887\tvalidation_1-auc:0.82172\n",
            "[5]\tvalidation_0-auc:0.86120\tvalidation_1-auc:0.82282\n",
            "[6]\tvalidation_0-auc:0.86173\tvalidation_1-auc:0.82300\n",
            "[7]\tvalidation_0-auc:0.86590\tvalidation_1-auc:0.82692\n",
            "[8]\tvalidation_0-auc:0.86638\tvalidation_1-auc:0.82646\n",
            "[9]\tvalidation_0-auc:0.86720\tvalidation_1-auc:0.82692\n",
            "[10]\tvalidation_0-auc:0.86833\tvalidation_1-auc:0.82743\n",
            "[11]\tvalidation_0-auc:0.86897\tvalidation_1-auc:0.82759\n",
            "[12]\tvalidation_0-auc:0.86994\tvalidation_1-auc:0.82769\n",
            "[13]\tvalidation_0-auc:0.87164\tvalidation_1-auc:0.82896\n",
            "[14]\tvalidation_0-auc:0.87220\tvalidation_1-auc:0.82967\n",
            "[15]\tvalidation_0-auc:0.87323\tvalidation_1-auc:0.82942\n",
            "[16]\tvalidation_0-auc:0.87402\tvalidation_1-auc:0.82916\n",
            "[17]\tvalidation_0-auc:0.87435\tvalidation_1-auc:0.82887\n",
            "[18]\tvalidation_0-auc:0.87486\tvalidation_1-auc:0.82851\n",
            "[19]\tvalidation_0-auc:0.87570\tvalidation_1-auc:0.82876\n",
            "[20]\tvalidation_0-auc:0.87632\tvalidation_1-auc:0.82865\n",
            "[21]\tvalidation_0-auc:0.87691\tvalidation_1-auc:0.82870\n",
            "[22]\tvalidation_0-auc:0.87734\tvalidation_1-auc:0.82857\n",
            "[23]\tvalidation_0-auc:0.87772\tvalidation_1-auc:0.82826\n",
            "[24]\tvalidation_0-auc:0.87824\tvalidation_1-auc:0.82817\n",
            "[25]\tvalidation_0-auc:0.87850\tvalidation_1-auc:0.82793\n",
            "[26]\tvalidation_0-auc:0.87886\tvalidation_1-auc:0.82807\n",
            "[27]\tvalidation_0-auc:0.88011\tvalidation_1-auc:0.82796\n",
            "[28]\tvalidation_0-auc:0.88099\tvalidation_1-auc:0.82788\n",
            "[29]\tvalidation_0-auc:0.88151\tvalidation_1-auc:0.82839\n",
            "[30]\tvalidation_0-auc:0.88205\tvalidation_1-auc:0.82837\n",
            "[31]\tvalidation_0-auc:0.88272\tvalidation_1-auc:0.82832\n",
            "[32]\tvalidation_0-auc:0.88345\tvalidation_1-auc:0.82832\n",
            "[33]\tvalidation_0-auc:0.88400\tvalidation_1-auc:0.82809\n",
            "[34]\tvalidation_0-auc:0.88440\tvalidation_1-auc:0.82789\n",
            "[35]\tvalidation_0-auc:0.88477\tvalidation_1-auc:0.82836\n",
            "[36]\tvalidation_0-auc:0.88531\tvalidation_1-auc:0.82867\n",
            "[37]\tvalidation_0-auc:0.88583\tvalidation_1-auc:0.82890\n",
            "[38]\tvalidation_0-auc:0.88623\tvalidation_1-auc:0.82931\n",
            "[39]\tvalidation_0-auc:0.88665\tvalidation_1-auc:0.82962\n",
            "[40]\tvalidation_0-auc:0.88724\tvalidation_1-auc:0.82976\n",
            "[41]\tvalidation_0-auc:0.88781\tvalidation_1-auc:0.82965\n",
            "[42]\tvalidation_0-auc:0.88845\tvalidation_1-auc:0.82988\n",
            "[43]\tvalidation_0-auc:0.88887\tvalidation_1-auc:0.83058\n",
            "[44]\tvalidation_0-auc:0.88923\tvalidation_1-auc:0.83081\n",
            "[45]\tvalidation_0-auc:0.88946\tvalidation_1-auc:0.83094\n",
            "[46]\tvalidation_0-auc:0.88989\tvalidation_1-auc:0.83096\n",
            "[47]\tvalidation_0-auc:0.89026\tvalidation_1-auc:0.83106\n",
            "[48]\tvalidation_0-auc:0.89074\tvalidation_1-auc:0.83113\n",
            "[49]\tvalidation_0-auc:0.89103\tvalidation_1-auc:0.83131\n",
            "[50]\tvalidation_0-auc:0.89149\tvalidation_1-auc:0.83154\n",
            "[51]\tvalidation_0-auc:0.89187\tvalidation_1-auc:0.83154\n",
            "[52]\tvalidation_0-auc:0.89219\tvalidation_1-auc:0.83168\n",
            "[53]\tvalidation_0-auc:0.89256\tvalidation_1-auc:0.83162\n",
            "[54]\tvalidation_0-auc:0.89291\tvalidation_1-auc:0.83167\n",
            "[55]\tvalidation_0-auc:0.89328\tvalidation_1-auc:0.83188\n",
            "[56]\tvalidation_0-auc:0.89369\tvalidation_1-auc:0.83193\n",
            "[57]\tvalidation_0-auc:0.89396\tvalidation_1-auc:0.83201\n",
            "[58]\tvalidation_0-auc:0.89438\tvalidation_1-auc:0.83195\n",
            "[59]\tvalidation_0-auc:0.89467\tvalidation_1-auc:0.83195\n",
            "[60]\tvalidation_0-auc:0.89504\tvalidation_1-auc:0.83213\n",
            "[61]\tvalidation_0-auc:0.89550\tvalidation_1-auc:0.83213\n",
            "[62]\tvalidation_0-auc:0.89576\tvalidation_1-auc:0.83215\n",
            "[63]\tvalidation_0-auc:0.89617\tvalidation_1-auc:0.83222\n",
            "[64]\tvalidation_0-auc:0.89647\tvalidation_1-auc:0.83224\n",
            "[65]\tvalidation_0-auc:0.89664\tvalidation_1-auc:0.83234\n",
            "[66]\tvalidation_0-auc:0.89685\tvalidation_1-auc:0.83225\n",
            "[67]\tvalidation_0-auc:0.89713\tvalidation_1-auc:0.83256\n",
            "[68]\tvalidation_0-auc:0.89734\tvalidation_1-auc:0.83241\n",
            "[69]\tvalidation_0-auc:0.89752\tvalidation_1-auc:0.83249\n",
            "[70]\tvalidation_0-auc:0.89760\tvalidation_1-auc:0.83240\n",
            "[71]\tvalidation_0-auc:0.89778\tvalidation_1-auc:0.83237\n",
            "[72]\tvalidation_0-auc:0.89790\tvalidation_1-auc:0.83234\n",
            "[73]\tvalidation_0-auc:0.89816\tvalidation_1-auc:0.83220\n",
            "[74]\tvalidation_0-auc:0.89836\tvalidation_1-auc:0.83226\n",
            "[75]\tvalidation_0-auc:0.89863\tvalidation_1-auc:0.83217\n",
            "[76]\tvalidation_0-auc:0.89885\tvalidation_1-auc:0.83209\n",
            "[77]\tvalidation_0-auc:0.89903\tvalidation_1-auc:0.83215\n",
            "[78]\tvalidation_0-auc:0.89929\tvalidation_1-auc:0.83205\n",
            "[79]\tvalidation_0-auc:0.89947\tvalidation_1-auc:0.83195\n",
            "[80]\tvalidation_0-auc:0.89969\tvalidation_1-auc:0.83191\n",
            "[81]\tvalidation_0-auc:0.89986\tvalidation_1-auc:0.83197\n",
            "[82]\tvalidation_0-auc:0.90031\tvalidation_1-auc:0.83181\n",
            "[83]\tvalidation_0-auc:0.90056\tvalidation_1-auc:0.83177\n",
            "[84]\tvalidation_0-auc:0.90078\tvalidation_1-auc:0.83179\n",
            "[85]\tvalidation_0-auc:0.90087\tvalidation_1-auc:0.83172\n",
            "[86]\tvalidation_0-auc:0.90105\tvalidation_1-auc:0.83173\n",
            "[87]\tvalidation_0-auc:0.90113\tvalidation_1-auc:0.83167\n",
            "[88]\tvalidation_0-auc:0.90129\tvalidation_1-auc:0.83161\n",
            "[89]\tvalidation_0-auc:0.90141\tvalidation_1-auc:0.83148\n",
            "[90]\tvalidation_0-auc:0.90158\tvalidation_1-auc:0.83143\n",
            "[91]\tvalidation_0-auc:0.90187\tvalidation_1-auc:0.83120\n",
            "[92]\tvalidation_0-auc:0.90190\tvalidation_1-auc:0.83122\n",
            "[93]\tvalidation_0-auc:0.90214\tvalidation_1-auc:0.83116\n",
            "[94]\tvalidation_0-auc:0.90219\tvalidation_1-auc:0.83115\n",
            "[95]\tvalidation_0-auc:0.90247\tvalidation_1-auc:0.83107\n",
            "[96]\tvalidation_0-auc:0.90255\tvalidation_1-auc:0.83112\n",
            "[0]\tvalidation_0-auc:0.84819\tvalidation_1-auc:0.82454\n",
            "[1]\tvalidation_0-auc:0.85322\tvalidation_1-auc:0.82679\n",
            "[2]\tvalidation_0-auc:0.85735\tvalidation_1-auc:0.82666\n",
            "[3]\tvalidation_0-auc:0.86209\tvalidation_1-auc:0.82846\n",
            "[4]\tvalidation_0-auc:0.86262\tvalidation_1-auc:0.82993\n",
            "[5]\tvalidation_0-auc:0.86270\tvalidation_1-auc:0.83043\n",
            "[6]\tvalidation_0-auc:0.86334\tvalidation_1-auc:0.83121\n",
            "[7]\tvalidation_0-auc:0.86672\tvalidation_1-auc:0.83191\n",
            "[8]\tvalidation_0-auc:0.86821\tvalidation_1-auc:0.83193\n",
            "[9]\tvalidation_0-auc:0.86895\tvalidation_1-auc:0.83261\n",
            "[10]\tvalidation_0-auc:0.87015\tvalidation_1-auc:0.83222\n",
            "[11]\tvalidation_0-auc:0.87138\tvalidation_1-auc:0.83255\n",
            "[12]\tvalidation_0-auc:0.87248\tvalidation_1-auc:0.83302\n",
            "[13]\tvalidation_0-auc:0.87322\tvalidation_1-auc:0.83336\n",
            "[14]\tvalidation_0-auc:0.87413\tvalidation_1-auc:0.83360\n",
            "[15]\tvalidation_0-auc:0.87499\tvalidation_1-auc:0.83376\n",
            "[16]\tvalidation_0-auc:0.87576\tvalidation_1-auc:0.83412\n",
            "[17]\tvalidation_0-auc:0.87606\tvalidation_1-auc:0.83470\n",
            "[18]\tvalidation_0-auc:0.87667\tvalidation_1-auc:0.83492\n",
            "[19]\tvalidation_0-auc:0.87689\tvalidation_1-auc:0.83451\n",
            "[20]\tvalidation_0-auc:0.87705\tvalidation_1-auc:0.83422\n",
            "[21]\tvalidation_0-auc:0.87728\tvalidation_1-auc:0.83414\n",
            "[22]\tvalidation_0-auc:0.87741\tvalidation_1-auc:0.83394\n",
            "[23]\tvalidation_0-auc:0.87777\tvalidation_1-auc:0.83383\n",
            "[24]\tvalidation_0-auc:0.87864\tvalidation_1-auc:0.83347\n",
            "[25]\tvalidation_0-auc:0.87943\tvalidation_1-auc:0.83346\n",
            "[26]\tvalidation_0-auc:0.87993\tvalidation_1-auc:0.83364\n",
            "[27]\tvalidation_0-auc:0.88062\tvalidation_1-auc:0.83344\n",
            "[28]\tvalidation_0-auc:0.88133\tvalidation_1-auc:0.83354\n",
            "[29]\tvalidation_0-auc:0.88246\tvalidation_1-auc:0.83416\n",
            "[30]\tvalidation_0-auc:0.88308\tvalidation_1-auc:0.83458\n",
            "[31]\tvalidation_0-auc:0.88348\tvalidation_1-auc:0.83452\n",
            "[32]\tvalidation_0-auc:0.88414\tvalidation_1-auc:0.83500\n",
            "[33]\tvalidation_0-auc:0.88452\tvalidation_1-auc:0.83474\n",
            "[34]\tvalidation_0-auc:0.88497\tvalidation_1-auc:0.83474\n",
            "[35]\tvalidation_0-auc:0.88530\tvalidation_1-auc:0.83498\n",
            "[36]\tvalidation_0-auc:0.88580\tvalidation_1-auc:0.83471\n",
            "[37]\tvalidation_0-auc:0.88648\tvalidation_1-auc:0.83441\n",
            "[38]\tvalidation_0-auc:0.88702\tvalidation_1-auc:0.83470\n",
            "[39]\tvalidation_0-auc:0.88720\tvalidation_1-auc:0.83434\n",
            "[40]\tvalidation_0-auc:0.88765\tvalidation_1-auc:0.83425\n",
            "[41]\tvalidation_0-auc:0.88829\tvalidation_1-auc:0.83429\n",
            "[42]\tvalidation_0-auc:0.88872\tvalidation_1-auc:0.83402\n",
            "[43]\tvalidation_0-auc:0.88912\tvalidation_1-auc:0.83446\n",
            "[44]\tvalidation_0-auc:0.88952\tvalidation_1-auc:0.83454\n",
            "[45]\tvalidation_0-auc:0.89015\tvalidation_1-auc:0.83504\n",
            "[46]\tvalidation_0-auc:0.89081\tvalidation_1-auc:0.83507\n",
            "[47]\tvalidation_0-auc:0.89145\tvalidation_1-auc:0.83548\n",
            "[48]\tvalidation_0-auc:0.89203\tvalidation_1-auc:0.83571\n",
            "[49]\tvalidation_0-auc:0.89243\tvalidation_1-auc:0.83585\n",
            "[50]\tvalidation_0-auc:0.89279\tvalidation_1-auc:0.83578\n",
            "[51]\tvalidation_0-auc:0.89307\tvalidation_1-auc:0.83587\n",
            "[52]\tvalidation_0-auc:0.89357\tvalidation_1-auc:0.83602\n",
            "[53]\tvalidation_0-auc:0.89394\tvalidation_1-auc:0.83629\n",
            "[54]\tvalidation_0-auc:0.89436\tvalidation_1-auc:0.83616\n",
            "[55]\tvalidation_0-auc:0.89472\tvalidation_1-auc:0.83635\n",
            "[56]\tvalidation_0-auc:0.89493\tvalidation_1-auc:0.83627\n",
            "[57]\tvalidation_0-auc:0.89547\tvalidation_1-auc:0.83631\n",
            "[58]\tvalidation_0-auc:0.89591\tvalidation_1-auc:0.83630\n",
            "[59]\tvalidation_0-auc:0.89615\tvalidation_1-auc:0.83630\n",
            "[60]\tvalidation_0-auc:0.89661\tvalidation_1-auc:0.83629\n",
            "[61]\tvalidation_0-auc:0.89689\tvalidation_1-auc:0.83650\n",
            "[62]\tvalidation_0-auc:0.89720\tvalidation_1-auc:0.83653\n",
            "[63]\tvalidation_0-auc:0.89739\tvalidation_1-auc:0.83665\n",
            "[64]\tvalidation_0-auc:0.89776\tvalidation_1-auc:0.83693\n",
            "[65]\tvalidation_0-auc:0.89802\tvalidation_1-auc:0.83707\n",
            "[66]\tvalidation_0-auc:0.89817\tvalidation_1-auc:0.83689\n",
            "[67]\tvalidation_0-auc:0.89830\tvalidation_1-auc:0.83690\n",
            "[68]\tvalidation_0-auc:0.89846\tvalidation_1-auc:0.83689\n",
            "[69]\tvalidation_0-auc:0.89875\tvalidation_1-auc:0.83704\n",
            "[70]\tvalidation_0-auc:0.89899\tvalidation_1-auc:0.83700\n",
            "[71]\tvalidation_0-auc:0.89915\tvalidation_1-auc:0.83700\n",
            "[72]\tvalidation_0-auc:0.89934\tvalidation_1-auc:0.83702\n",
            "[73]\tvalidation_0-auc:0.89965\tvalidation_1-auc:0.83693\n",
            "[74]\tvalidation_0-auc:0.89972\tvalidation_1-auc:0.83691\n",
            "[75]\tvalidation_0-auc:0.89976\tvalidation_1-auc:0.83693\n",
            "[76]\tvalidation_0-auc:0.89993\tvalidation_1-auc:0.83695\n",
            "[77]\tvalidation_0-auc:0.90046\tvalidation_1-auc:0.83696\n",
            "[78]\tvalidation_0-auc:0.90058\tvalidation_1-auc:0.83689\n",
            "[79]\tvalidation_0-auc:0.90071\tvalidation_1-auc:0.83686\n",
            "[80]\tvalidation_0-auc:0.90084\tvalidation_1-auc:0.83695\n",
            "[81]\tvalidation_0-auc:0.90096\tvalidation_1-auc:0.83696\n",
            "[82]\tvalidation_0-auc:0.90107\tvalidation_1-auc:0.83693\n",
            "[83]\tvalidation_0-auc:0.90138\tvalidation_1-auc:0.83681\n",
            "[84]\tvalidation_0-auc:0.90153\tvalidation_1-auc:0.83664\n",
            "[85]\tvalidation_0-auc:0.90180\tvalidation_1-auc:0.83645\n",
            "[86]\tvalidation_0-auc:0.90185\tvalidation_1-auc:0.83654\n",
            "[87]\tvalidation_0-auc:0.90195\tvalidation_1-auc:0.83656\n",
            "[88]\tvalidation_0-auc:0.90239\tvalidation_1-auc:0.83679\n",
            "[89]\tvalidation_0-auc:0.90255\tvalidation_1-auc:0.83673\n",
            "[90]\tvalidation_0-auc:0.90280\tvalidation_1-auc:0.83685\n",
            "[91]\tvalidation_0-auc:0.90299\tvalidation_1-auc:0.83670\n",
            "[92]\tvalidation_0-auc:0.90316\tvalidation_1-auc:0.83673\n",
            "[93]\tvalidation_0-auc:0.90334\tvalidation_1-auc:0.83693\n",
            "[94]\tvalidation_0-auc:0.90355\tvalidation_1-auc:0.83701\n",
            "[95]\tvalidation_0-auc:0.90383\tvalidation_1-auc:0.83692\n",
            "[0]\tvalidation_0-auc:0.84503\tvalidation_1-auc:0.81746\n",
            "[1]\tvalidation_0-auc:0.84642\tvalidation_1-auc:0.81854\n",
            "[2]\tvalidation_0-auc:0.85270\tvalidation_1-auc:0.82355\n",
            "[3]\tvalidation_0-auc:0.85582\tvalidation_1-auc:0.82390\n",
            "[4]\tvalidation_0-auc:0.85742\tvalidation_1-auc:0.82528\n",
            "[5]\tvalidation_0-auc:0.85848\tvalidation_1-auc:0.82582\n",
            "[6]\tvalidation_0-auc:0.85982\tvalidation_1-auc:0.82644\n",
            "[7]\tvalidation_0-auc:0.86399\tvalidation_1-auc:0.82735\n",
            "[8]\tvalidation_0-auc:0.86514\tvalidation_1-auc:0.82771\n",
            "[9]\tvalidation_0-auc:0.86596\tvalidation_1-auc:0.82803\n",
            "[10]\tvalidation_0-auc:0.86696\tvalidation_1-auc:0.82872\n",
            "[11]\tvalidation_0-auc:0.86756\tvalidation_1-auc:0.82883\n",
            "[12]\tvalidation_0-auc:0.86858\tvalidation_1-auc:0.82926\n",
            "[13]\tvalidation_0-auc:0.86910\tvalidation_1-auc:0.82987\n",
            "[14]\tvalidation_0-auc:0.86998\tvalidation_1-auc:0.82951\n",
            "[15]\tvalidation_0-auc:0.87052\tvalidation_1-auc:0.82991\n",
            "[16]\tvalidation_0-auc:0.87126\tvalidation_1-auc:0.83029\n",
            "[17]\tvalidation_0-auc:0.87211\tvalidation_1-auc:0.83126\n",
            "[18]\tvalidation_0-auc:0.87298\tvalidation_1-auc:0.83093\n",
            "[19]\tvalidation_0-auc:0.87400\tvalidation_1-auc:0.83136\n",
            "[20]\tvalidation_0-auc:0.87530\tvalidation_1-auc:0.83224\n",
            "[21]\tvalidation_0-auc:0.87642\tvalidation_1-auc:0.83209\n",
            "[22]\tvalidation_0-auc:0.87752\tvalidation_1-auc:0.83186\n",
            "[23]\tvalidation_0-auc:0.87892\tvalidation_1-auc:0.83219\n",
            "[24]\tvalidation_0-auc:0.87953\tvalidation_1-auc:0.83169\n",
            "[25]\tvalidation_0-auc:0.88042\tvalidation_1-auc:0.83230\n",
            "[26]\tvalidation_0-auc:0.88091\tvalidation_1-auc:0.83248\n",
            "[27]\tvalidation_0-auc:0.88191\tvalidation_1-auc:0.83200\n",
            "[28]\tvalidation_0-auc:0.88258\tvalidation_1-auc:0.83210\n",
            "[29]\tvalidation_0-auc:0.88350\tvalidation_1-auc:0.83249\n",
            "[30]\tvalidation_0-auc:0.88445\tvalidation_1-auc:0.83245\n",
            "[31]\tvalidation_0-auc:0.88517\tvalidation_1-auc:0.83264\n",
            "[32]\tvalidation_0-auc:0.88573\tvalidation_1-auc:0.83219\n",
            "[33]\tvalidation_0-auc:0.88649\tvalidation_1-auc:0.83215\n",
            "[34]\tvalidation_0-auc:0.88714\tvalidation_1-auc:0.83239\n",
            "[35]\tvalidation_0-auc:0.88762\tvalidation_1-auc:0.83292\n",
            "[36]\tvalidation_0-auc:0.88802\tvalidation_1-auc:0.83294\n",
            "[37]\tvalidation_0-auc:0.88865\tvalidation_1-auc:0.83284\n",
            "[38]\tvalidation_0-auc:0.88910\tvalidation_1-auc:0.83312\n",
            "[39]\tvalidation_0-auc:0.88984\tvalidation_1-auc:0.83325\n",
            "[40]\tvalidation_0-auc:0.89030\tvalidation_1-auc:0.83359\n",
            "[41]\tvalidation_0-auc:0.89087\tvalidation_1-auc:0.83411\n",
            "[42]\tvalidation_0-auc:0.89143\tvalidation_1-auc:0.83426\n",
            "[43]\tvalidation_0-auc:0.89169\tvalidation_1-auc:0.83445\n",
            "[44]\tvalidation_0-auc:0.89212\tvalidation_1-auc:0.83471\n",
            "[45]\tvalidation_0-auc:0.89274\tvalidation_1-auc:0.83468\n",
            "[46]\tvalidation_0-auc:0.89319\tvalidation_1-auc:0.83481\n",
            "[47]\tvalidation_0-auc:0.89384\tvalidation_1-auc:0.83467\n",
            "[48]\tvalidation_0-auc:0.89452\tvalidation_1-auc:0.83475\n",
            "[49]\tvalidation_0-auc:0.89493\tvalidation_1-auc:0.83491\n",
            "[50]\tvalidation_0-auc:0.89552\tvalidation_1-auc:0.83494\n",
            "[51]\tvalidation_0-auc:0.89597\tvalidation_1-auc:0.83468\n",
            "[52]\tvalidation_0-auc:0.89629\tvalidation_1-auc:0.83469\n",
            "[53]\tvalidation_0-auc:0.89674\tvalidation_1-auc:0.83483\n",
            "[54]\tvalidation_0-auc:0.89721\tvalidation_1-auc:0.83489\n",
            "[55]\tvalidation_0-auc:0.89758\tvalidation_1-auc:0.83520\n",
            "[56]\tvalidation_0-auc:0.89800\tvalidation_1-auc:0.83527\n",
            "[57]\tvalidation_0-auc:0.89831\tvalidation_1-auc:0.83535\n",
            "[58]\tvalidation_0-auc:0.89865\tvalidation_1-auc:0.83528\n",
            "[59]\tvalidation_0-auc:0.89884\tvalidation_1-auc:0.83526\n",
            "[60]\tvalidation_0-auc:0.89922\tvalidation_1-auc:0.83521\n",
            "[61]\tvalidation_0-auc:0.89949\tvalidation_1-auc:0.83532\n",
            "[62]\tvalidation_0-auc:0.89978\tvalidation_1-auc:0.83515\n",
            "[63]\tvalidation_0-auc:0.90007\tvalidation_1-auc:0.83524\n",
            "[64]\tvalidation_0-auc:0.90034\tvalidation_1-auc:0.83528\n",
            "[65]\tvalidation_0-auc:0.90073\tvalidation_1-auc:0.83548\n",
            "[66]\tvalidation_0-auc:0.90098\tvalidation_1-auc:0.83551\n",
            "[67]\tvalidation_0-auc:0.90121\tvalidation_1-auc:0.83533\n",
            "[68]\tvalidation_0-auc:0.90134\tvalidation_1-auc:0.83539\n",
            "[69]\tvalidation_0-auc:0.90156\tvalidation_1-auc:0.83536\n",
            "[70]\tvalidation_0-auc:0.90178\tvalidation_1-auc:0.83527\n",
            "[71]\tvalidation_0-auc:0.90201\tvalidation_1-auc:0.83540\n",
            "[72]\tvalidation_0-auc:0.90215\tvalidation_1-auc:0.83551\n",
            "[73]\tvalidation_0-auc:0.90258\tvalidation_1-auc:0.83569\n",
            "[74]\tvalidation_0-auc:0.90275\tvalidation_1-auc:0.83570\n",
            "[75]\tvalidation_0-auc:0.90288\tvalidation_1-auc:0.83552\n",
            "[76]\tvalidation_0-auc:0.90299\tvalidation_1-auc:0.83545\n",
            "[77]\tvalidation_0-auc:0.90309\tvalidation_1-auc:0.83538\n",
            "[78]\tvalidation_0-auc:0.90332\tvalidation_1-auc:0.83541\n",
            "[79]\tvalidation_0-auc:0.90348\tvalidation_1-auc:0.83544\n",
            "[80]\tvalidation_0-auc:0.90396\tvalidation_1-auc:0.83562\n",
            "[81]\tvalidation_0-auc:0.90418\tvalidation_1-auc:0.83558\n",
            "[82]\tvalidation_0-auc:0.90437\tvalidation_1-auc:0.83570\n",
            "[83]\tvalidation_0-auc:0.90474\tvalidation_1-auc:0.83580\n",
            "[84]\tvalidation_0-auc:0.90504\tvalidation_1-auc:0.83561\n",
            "[85]\tvalidation_0-auc:0.90519\tvalidation_1-auc:0.83570\n",
            "[86]\tvalidation_0-auc:0.90540\tvalidation_1-auc:0.83566\n",
            "[87]\tvalidation_0-auc:0.90571\tvalidation_1-auc:0.83578\n",
            "[88]\tvalidation_0-auc:0.90583\tvalidation_1-auc:0.83580\n",
            "[89]\tvalidation_0-auc:0.90610\tvalidation_1-auc:0.83589\n",
            "[90]\tvalidation_0-auc:0.90645\tvalidation_1-auc:0.83597\n",
            "[91]\tvalidation_0-auc:0.90660\tvalidation_1-auc:0.83593\n",
            "[92]\tvalidation_0-auc:0.90682\tvalidation_1-auc:0.83600\n",
            "[93]\tvalidation_0-auc:0.90711\tvalidation_1-auc:0.83601\n",
            "[94]\tvalidation_0-auc:0.90721\tvalidation_1-auc:0.83615\n",
            "[95]\tvalidation_0-auc:0.90732\tvalidation_1-auc:0.83604\n",
            "[96]\tvalidation_0-auc:0.90759\tvalidation_1-auc:0.83623\n",
            "[97]\tvalidation_0-auc:0.90773\tvalidation_1-auc:0.83628\n",
            "[98]\tvalidation_0-auc:0.90800\tvalidation_1-auc:0.83636\n",
            "[99]\tvalidation_0-auc:0.90811\tvalidation_1-auc:0.83657\n",
            "[0]\tvalidation_0-auc:0.86268\tvalidation_1-auc:0.79663\n",
            "[1]\tvalidation_0-auc:0.87137\tvalidation_1-auc:0.80953\n",
            "[2]\tvalidation_0-auc:0.87278\tvalidation_1-auc:0.80494\n",
            "[3]\tvalidation_0-auc:0.88044\tvalidation_1-auc:0.81267\n",
            "[4]\tvalidation_0-auc:0.88481\tvalidation_1-auc:0.81614\n",
            "[5]\tvalidation_0-auc:0.88765\tvalidation_1-auc:0.81885\n",
            "[6]\tvalidation_0-auc:0.88959\tvalidation_1-auc:0.81987\n",
            "[7]\tvalidation_0-auc:0.89290\tvalidation_1-auc:0.82035\n",
            "[8]\tvalidation_0-auc:0.89500\tvalidation_1-auc:0.82151\n",
            "[9]\tvalidation_0-auc:0.89483\tvalidation_1-auc:0.82190\n",
            "[10]\tvalidation_0-auc:0.89718\tvalidation_1-auc:0.82487\n",
            "[11]\tvalidation_0-auc:0.89872\tvalidation_1-auc:0.82558\n",
            "[12]\tvalidation_0-auc:0.90155\tvalidation_1-auc:0.82562\n",
            "[13]\tvalidation_0-auc:0.90329\tvalidation_1-auc:0.82593\n",
            "[14]\tvalidation_0-auc:0.90418\tvalidation_1-auc:0.82670\n",
            "[15]\tvalidation_0-auc:0.90527\tvalidation_1-auc:0.82680\n",
            "[16]\tvalidation_0-auc:0.90709\tvalidation_1-auc:0.82613\n",
            "[17]\tvalidation_0-auc:0.90873\tvalidation_1-auc:0.82597\n",
            "[18]\tvalidation_0-auc:0.90976\tvalidation_1-auc:0.82693\n",
            "[19]\tvalidation_0-auc:0.91177\tvalidation_1-auc:0.82719\n",
            "[20]\tvalidation_0-auc:0.91268\tvalidation_1-auc:0.82757\n",
            "[21]\tvalidation_0-auc:0.91403\tvalidation_1-auc:0.82720\n",
            "[22]\tvalidation_0-auc:0.91548\tvalidation_1-auc:0.82738\n",
            "[23]\tvalidation_0-auc:0.91668\tvalidation_1-auc:0.82798\n",
            "[24]\tvalidation_0-auc:0.91737\tvalidation_1-auc:0.82847\n",
            "[25]\tvalidation_0-auc:0.91786\tvalidation_1-auc:0.82872\n",
            "[26]\tvalidation_0-auc:0.91868\tvalidation_1-auc:0.82863\n",
            "[27]\tvalidation_0-auc:0.91983\tvalidation_1-auc:0.82915\n",
            "[28]\tvalidation_0-auc:0.92092\tvalidation_1-auc:0.82918\n",
            "[29]\tvalidation_0-auc:0.92192\tvalidation_1-auc:0.82912\n",
            "[30]\tvalidation_0-auc:0.92273\tvalidation_1-auc:0.82851\n",
            "[31]\tvalidation_0-auc:0.92401\tvalidation_1-auc:0.82823\n",
            "[32]\tvalidation_0-auc:0.92475\tvalidation_1-auc:0.82849\n",
            "[33]\tvalidation_0-auc:0.92563\tvalidation_1-auc:0.82821\n",
            "[34]\tvalidation_0-auc:0.92648\tvalidation_1-auc:0.82770\n",
            "[35]\tvalidation_0-auc:0.92669\tvalidation_1-auc:0.82804\n",
            "[36]\tvalidation_0-auc:0.92747\tvalidation_1-auc:0.82826\n",
            "[37]\tvalidation_0-auc:0.92792\tvalidation_1-auc:0.82803\n",
            "[38]\tvalidation_0-auc:0.92837\tvalidation_1-auc:0.82802\n",
            "[39]\tvalidation_0-auc:0.92858\tvalidation_1-auc:0.82822\n",
            "[40]\tvalidation_0-auc:0.92887\tvalidation_1-auc:0.82796\n",
            "[41]\tvalidation_0-auc:0.92926\tvalidation_1-auc:0.82738\n",
            "[42]\tvalidation_0-auc:0.92964\tvalidation_1-auc:0.82673\n",
            "[43]\tvalidation_0-auc:0.92976\tvalidation_1-auc:0.82701\n",
            "[44]\tvalidation_0-auc:0.93011\tvalidation_1-auc:0.82718\n",
            "[45]\tvalidation_0-auc:0.93029\tvalidation_1-auc:0.82722\n",
            "[46]\tvalidation_0-auc:0.93040\tvalidation_1-auc:0.82695\n",
            "[47]\tvalidation_0-auc:0.93067\tvalidation_1-auc:0.82714\n",
            "[48]\tvalidation_0-auc:0.93091\tvalidation_1-auc:0.82728\n",
            "[49]\tvalidation_0-auc:0.93156\tvalidation_1-auc:0.82699\n",
            "[50]\tvalidation_0-auc:0.93178\tvalidation_1-auc:0.82688\n",
            "[51]\tvalidation_0-auc:0.93196\tvalidation_1-auc:0.82653\n",
            "[52]\tvalidation_0-auc:0.93234\tvalidation_1-auc:0.82626\n",
            "[53]\tvalidation_0-auc:0.93246\tvalidation_1-auc:0.82620\n",
            "[54]\tvalidation_0-auc:0.93270\tvalidation_1-auc:0.82594\n",
            "[55]\tvalidation_0-auc:0.93294\tvalidation_1-auc:0.82583\n",
            "[56]\tvalidation_0-auc:0.93313\tvalidation_1-auc:0.82579\n",
            "[57]\tvalidation_0-auc:0.93347\tvalidation_1-auc:0.82564\n",
            "[58]\tvalidation_0-auc:0.93373\tvalidation_1-auc:0.82543\n",
            "[0]\tvalidation_0-auc:0.86214\tvalidation_1-auc:0.81111\n",
            "[1]\tvalidation_0-auc:0.87134\tvalidation_1-auc:0.81916\n",
            "[2]\tvalidation_0-auc:0.87485\tvalidation_1-auc:0.81109\n",
            "[3]\tvalidation_0-auc:0.88195\tvalidation_1-auc:0.82072\n",
            "[4]\tvalidation_0-auc:0.88443\tvalidation_1-auc:0.82268\n",
            "[5]\tvalidation_0-auc:0.88810\tvalidation_1-auc:0.82627\n",
            "[6]\tvalidation_0-auc:0.89230\tvalidation_1-auc:0.82808\n",
            "[7]\tvalidation_0-auc:0.89533\tvalidation_1-auc:0.82660\n",
            "[8]\tvalidation_0-auc:0.89673\tvalidation_1-auc:0.82772\n",
            "[9]\tvalidation_0-auc:0.89641\tvalidation_1-auc:0.82583\n",
            "[10]\tvalidation_0-auc:0.89941\tvalidation_1-auc:0.82695\n",
            "[11]\tvalidation_0-auc:0.90113\tvalidation_1-auc:0.82861\n",
            "[12]\tvalidation_0-auc:0.90417\tvalidation_1-auc:0.83003\n",
            "[13]\tvalidation_0-auc:0.90515\tvalidation_1-auc:0.82996\n",
            "[14]\tvalidation_0-auc:0.90622\tvalidation_1-auc:0.83048\n",
            "[15]\tvalidation_0-auc:0.90759\tvalidation_1-auc:0.82999\n",
            "[16]\tvalidation_0-auc:0.90974\tvalidation_1-auc:0.83028\n",
            "[17]\tvalidation_0-auc:0.91141\tvalidation_1-auc:0.83038\n",
            "[18]\tvalidation_0-auc:0.91245\tvalidation_1-auc:0.83052\n",
            "[19]\tvalidation_0-auc:0.91380\tvalidation_1-auc:0.82976\n",
            "[20]\tvalidation_0-auc:0.91530\tvalidation_1-auc:0.82927\n",
            "[21]\tvalidation_0-auc:0.91595\tvalidation_1-auc:0.82911\n",
            "[22]\tvalidation_0-auc:0.91721\tvalidation_1-auc:0.83012\n",
            "[23]\tvalidation_0-auc:0.91756\tvalidation_1-auc:0.83052\n",
            "[24]\tvalidation_0-auc:0.91822\tvalidation_1-auc:0.83109\n",
            "[25]\tvalidation_0-auc:0.91882\tvalidation_1-auc:0.83158\n",
            "[26]\tvalidation_0-auc:0.92029\tvalidation_1-auc:0.83156\n",
            "[27]\tvalidation_0-auc:0.92120\tvalidation_1-auc:0.83136\n",
            "[28]\tvalidation_0-auc:0.92243\tvalidation_1-auc:0.83119\n",
            "[29]\tvalidation_0-auc:0.92293\tvalidation_1-auc:0.83143\n",
            "[30]\tvalidation_0-auc:0.92401\tvalidation_1-auc:0.83219\n",
            "[31]\tvalidation_0-auc:0.92543\tvalidation_1-auc:0.83172\n",
            "[32]\tvalidation_0-auc:0.92619\tvalidation_1-auc:0.83199\n",
            "[33]\tvalidation_0-auc:0.92684\tvalidation_1-auc:0.83185\n",
            "[34]\tvalidation_0-auc:0.92759\tvalidation_1-auc:0.83152\n",
            "[35]\tvalidation_0-auc:0.92785\tvalidation_1-auc:0.83187\n",
            "[36]\tvalidation_0-auc:0.92835\tvalidation_1-auc:0.83200\n",
            "[37]\tvalidation_0-auc:0.92913\tvalidation_1-auc:0.83219\n",
            "[38]\tvalidation_0-auc:0.92942\tvalidation_1-auc:0.83214\n",
            "[39]\tvalidation_0-auc:0.93018\tvalidation_1-auc:0.83215\n",
            "[40]\tvalidation_0-auc:0.93060\tvalidation_1-auc:0.83170\n",
            "[41]\tvalidation_0-auc:0.93095\tvalidation_1-auc:0.83178\n",
            "[42]\tvalidation_0-auc:0.93132\tvalidation_1-auc:0.83166\n",
            "[43]\tvalidation_0-auc:0.93143\tvalidation_1-auc:0.83173\n",
            "[44]\tvalidation_0-auc:0.93160\tvalidation_1-auc:0.83172\n",
            "[45]\tvalidation_0-auc:0.93180\tvalidation_1-auc:0.83193\n",
            "[46]\tvalidation_0-auc:0.93249\tvalidation_1-auc:0.83188\n",
            "[47]\tvalidation_0-auc:0.93336\tvalidation_1-auc:0.83212\n",
            "[48]\tvalidation_0-auc:0.93369\tvalidation_1-auc:0.83194\n",
            "[49]\tvalidation_0-auc:0.93402\tvalidation_1-auc:0.83177\n",
            "[50]\tvalidation_0-auc:0.93415\tvalidation_1-auc:0.83206\n",
            "[51]\tvalidation_0-auc:0.93457\tvalidation_1-auc:0.83211\n",
            "[52]\tvalidation_0-auc:0.93491\tvalidation_1-auc:0.83207\n",
            "[53]\tvalidation_0-auc:0.93518\tvalidation_1-auc:0.83197\n",
            "[54]\tvalidation_0-auc:0.93540\tvalidation_1-auc:0.83175\n",
            "[55]\tvalidation_0-auc:0.93579\tvalidation_1-auc:0.83178\n",
            "[56]\tvalidation_0-auc:0.93628\tvalidation_1-auc:0.83201\n",
            "[57]\tvalidation_0-auc:0.93637\tvalidation_1-auc:0.83199\n",
            "[58]\tvalidation_0-auc:0.93665\tvalidation_1-auc:0.83200\n",
            "[59]\tvalidation_0-auc:0.93674\tvalidation_1-auc:0.83202\n",
            "[0]\tvalidation_0-auc:0.86422\tvalidation_1-auc:0.80399\n",
            "[1]\tvalidation_0-auc:0.87197\tvalidation_1-auc:0.81849\n",
            "[2]\tvalidation_0-auc:0.87642\tvalidation_1-auc:0.81477\n",
            "[3]\tvalidation_0-auc:0.88068\tvalidation_1-auc:0.81968\n",
            "[4]\tvalidation_0-auc:0.88331\tvalidation_1-auc:0.82227\n",
            "[5]\tvalidation_0-auc:0.88684\tvalidation_1-auc:0.82395\n",
            "[6]\tvalidation_0-auc:0.88968\tvalidation_1-auc:0.82457\n",
            "[7]\tvalidation_0-auc:0.89303\tvalidation_1-auc:0.82212\n",
            "[8]\tvalidation_0-auc:0.89486\tvalidation_1-auc:0.82311\n",
            "[9]\tvalidation_0-auc:0.89640\tvalidation_1-auc:0.82242\n",
            "[10]\tvalidation_0-auc:0.89996\tvalidation_1-auc:0.82374\n",
            "[11]\tvalidation_0-auc:0.90262\tvalidation_1-auc:0.82468\n",
            "[12]\tvalidation_0-auc:0.90560\tvalidation_1-auc:0.82583\n",
            "[13]\tvalidation_0-auc:0.90775\tvalidation_1-auc:0.82678\n",
            "[14]\tvalidation_0-auc:0.90882\tvalidation_1-auc:0.82771\n",
            "[15]\tvalidation_0-auc:0.91016\tvalidation_1-auc:0.82678\n",
            "[16]\tvalidation_0-auc:0.91177\tvalidation_1-auc:0.82680\n",
            "[17]\tvalidation_0-auc:0.91337\tvalidation_1-auc:0.82738\n",
            "[18]\tvalidation_0-auc:0.91406\tvalidation_1-auc:0.82747\n",
            "[19]\tvalidation_0-auc:0.91543\tvalidation_1-auc:0.82878\n",
            "[20]\tvalidation_0-auc:0.91677\tvalidation_1-auc:0.82759\n",
            "[21]\tvalidation_0-auc:0.91812\tvalidation_1-auc:0.82633\n",
            "[22]\tvalidation_0-auc:0.91928\tvalidation_1-auc:0.82757\n",
            "[23]\tvalidation_0-auc:0.92003\tvalidation_1-auc:0.82822\n",
            "[24]\tvalidation_0-auc:0.92025\tvalidation_1-auc:0.82868\n",
            "[25]\tvalidation_0-auc:0.92060\tvalidation_1-auc:0.82902\n",
            "[26]\tvalidation_0-auc:0.92130\tvalidation_1-auc:0.82961\n",
            "[27]\tvalidation_0-auc:0.92215\tvalidation_1-auc:0.82971\n",
            "[28]\tvalidation_0-auc:0.92300\tvalidation_1-auc:0.82976\n",
            "[29]\tvalidation_0-auc:0.92357\tvalidation_1-auc:0.82952\n",
            "[30]\tvalidation_0-auc:0.92398\tvalidation_1-auc:0.82991\n",
            "[31]\tvalidation_0-auc:0.92470\tvalidation_1-auc:0.82978\n",
            "[32]\tvalidation_0-auc:0.92514\tvalidation_1-auc:0.82981\n",
            "[33]\tvalidation_0-auc:0.92573\tvalidation_1-auc:0.82936\n",
            "[34]\tvalidation_0-auc:0.92639\tvalidation_1-auc:0.82907\n",
            "[35]\tvalidation_0-auc:0.92675\tvalidation_1-auc:0.82959\n",
            "[36]\tvalidation_0-auc:0.92752\tvalidation_1-auc:0.82963\n",
            "[37]\tvalidation_0-auc:0.92833\tvalidation_1-auc:0.82907\n",
            "[38]\tvalidation_0-auc:0.92896\tvalidation_1-auc:0.82907\n",
            "[39]\tvalidation_0-auc:0.92934\tvalidation_1-auc:0.82945\n",
            "[40]\tvalidation_0-auc:0.92986\tvalidation_1-auc:0.82917\n",
            "[41]\tvalidation_0-auc:0.93013\tvalidation_1-auc:0.82902\n",
            "[42]\tvalidation_0-auc:0.93081\tvalidation_1-auc:0.82893\n",
            "[43]\tvalidation_0-auc:0.93100\tvalidation_1-auc:0.82916\n",
            "[44]\tvalidation_0-auc:0.93144\tvalidation_1-auc:0.82878\n",
            "[45]\tvalidation_0-auc:0.93170\tvalidation_1-auc:0.82898\n",
            "[46]\tvalidation_0-auc:0.93221\tvalidation_1-auc:0.82878\n",
            "[47]\tvalidation_0-auc:0.93279\tvalidation_1-auc:0.82878\n",
            "[48]\tvalidation_0-auc:0.93305\tvalidation_1-auc:0.82908\n",
            "[49]\tvalidation_0-auc:0.93340\tvalidation_1-auc:0.82930\n",
            "[50]\tvalidation_0-auc:0.93354\tvalidation_1-auc:0.82929\n",
            "[51]\tvalidation_0-auc:0.93410\tvalidation_1-auc:0.82907\n",
            "[52]\tvalidation_0-auc:0.93431\tvalidation_1-auc:0.82910\n",
            "[53]\tvalidation_0-auc:0.93466\tvalidation_1-auc:0.82916\n",
            "[54]\tvalidation_0-auc:0.93493\tvalidation_1-auc:0.82893\n",
            "[55]\tvalidation_0-auc:0.93504\tvalidation_1-auc:0.82891\n",
            "[56]\tvalidation_0-auc:0.93551\tvalidation_1-auc:0.82912\n",
            "[57]\tvalidation_0-auc:0.93584\tvalidation_1-auc:0.82898\n",
            "[58]\tvalidation_0-auc:0.93628\tvalidation_1-auc:0.82899\n",
            "[59]\tvalidation_0-auc:0.93672\tvalidation_1-auc:0.82921\n",
            "[60]\tvalidation_0-auc:0.93684\tvalidation_1-auc:0.82912\n",
            "[0]\tvalidation_0-auc:0.86256\tvalidation_1-auc:0.79824\n",
            "[1]\tvalidation_0-auc:0.87612\tvalidation_1-auc:0.81300\n",
            "[2]\tvalidation_0-auc:0.88481\tvalidation_1-auc:0.80671\n",
            "[3]\tvalidation_0-auc:0.89106\tvalidation_1-auc:0.81468\n",
            "[4]\tvalidation_0-auc:0.89525\tvalidation_1-auc:0.81842\n",
            "[5]\tvalidation_0-auc:0.89668\tvalidation_1-auc:0.82163\n",
            "[6]\tvalidation_0-auc:0.89991\tvalidation_1-auc:0.82436\n",
            "[7]\tvalidation_0-auc:0.90304\tvalidation_1-auc:0.82198\n",
            "[8]\tvalidation_0-auc:0.90454\tvalidation_1-auc:0.82540\n",
            "[9]\tvalidation_0-auc:0.90532\tvalidation_1-auc:0.82803\n",
            "[10]\tvalidation_0-auc:0.90670\tvalidation_1-auc:0.82810\n",
            "[11]\tvalidation_0-auc:0.90705\tvalidation_1-auc:0.82855\n",
            "[12]\tvalidation_0-auc:0.90906\tvalidation_1-auc:0.82845\n",
            "[13]\tvalidation_0-auc:0.91076\tvalidation_1-auc:0.82863\n",
            "[14]\tvalidation_0-auc:0.91145\tvalidation_1-auc:0.82886\n",
            "[15]\tvalidation_0-auc:0.91325\tvalidation_1-auc:0.82829\n",
            "[16]\tvalidation_0-auc:0.91487\tvalidation_1-auc:0.82719\n",
            "[17]\tvalidation_0-auc:0.91617\tvalidation_1-auc:0.82751\n",
            "[18]\tvalidation_0-auc:0.91723\tvalidation_1-auc:0.82847\n",
            "[19]\tvalidation_0-auc:0.91838\tvalidation_1-auc:0.82833\n",
            "[20]\tvalidation_0-auc:0.91986\tvalidation_1-auc:0.82746\n",
            "[21]\tvalidation_0-auc:0.92120\tvalidation_1-auc:0.82749\n",
            "[22]\tvalidation_0-auc:0.92252\tvalidation_1-auc:0.82760\n",
            "[23]\tvalidation_0-auc:0.92308\tvalidation_1-auc:0.82782\n",
            "[24]\tvalidation_0-auc:0.92373\tvalidation_1-auc:0.82835\n",
            "[25]\tvalidation_0-auc:0.92430\tvalidation_1-auc:0.82885\n",
            "[26]\tvalidation_0-auc:0.92538\tvalidation_1-auc:0.82822\n",
            "[27]\tvalidation_0-auc:0.92636\tvalidation_1-auc:0.82825\n",
            "[28]\tvalidation_0-auc:0.92744\tvalidation_1-auc:0.82817\n",
            "[29]\tvalidation_0-auc:0.92817\tvalidation_1-auc:0.82794\n",
            "[30]\tvalidation_0-auc:0.92862\tvalidation_1-auc:0.82789\n",
            "[31]\tvalidation_0-auc:0.92933\tvalidation_1-auc:0.82756\n",
            "[32]\tvalidation_0-auc:0.92966\tvalidation_1-auc:0.82750\n",
            "[33]\tvalidation_0-auc:0.93026\tvalidation_1-auc:0.82766\n",
            "[34]\tvalidation_0-auc:0.93085\tvalidation_1-auc:0.82743\n",
            "[35]\tvalidation_0-auc:0.93119\tvalidation_1-auc:0.82691\n",
            "[36]\tvalidation_0-auc:0.93158\tvalidation_1-auc:0.82640\n",
            "[37]\tvalidation_0-auc:0.93188\tvalidation_1-auc:0.82642\n",
            "[38]\tvalidation_0-auc:0.93255\tvalidation_1-auc:0.82614\n",
            "[39]\tvalidation_0-auc:0.93288\tvalidation_1-auc:0.82599\n",
            "[40]\tvalidation_0-auc:0.93335\tvalidation_1-auc:0.82582\n",
            "[41]\tvalidation_0-auc:0.93352\tvalidation_1-auc:0.82543\n",
            "[42]\tvalidation_0-auc:0.93399\tvalidation_1-auc:0.82485\n",
            "[43]\tvalidation_0-auc:0.93436\tvalidation_1-auc:0.82469\n",
            "[44]\tvalidation_0-auc:0.93500\tvalidation_1-auc:0.82443\n",
            "[0]\tvalidation_0-auc:0.86537\tvalidation_1-auc:0.80715\n",
            "[1]\tvalidation_0-auc:0.87360\tvalidation_1-auc:0.81359\n",
            "[2]\tvalidation_0-auc:0.88133\tvalidation_1-auc:0.80656\n",
            "[3]\tvalidation_0-auc:0.88719\tvalidation_1-auc:0.81490\n",
            "[4]\tvalidation_0-auc:0.89150\tvalidation_1-auc:0.81845\n",
            "[5]\tvalidation_0-auc:0.89471\tvalidation_1-auc:0.82366\n",
            "[6]\tvalidation_0-auc:0.89732\tvalidation_1-auc:0.82611\n",
            "[7]\tvalidation_0-auc:0.90053\tvalidation_1-auc:0.82398\n",
            "[8]\tvalidation_0-auc:0.90363\tvalidation_1-auc:0.82627\n",
            "[9]\tvalidation_0-auc:0.90589\tvalidation_1-auc:0.82867\n",
            "[10]\tvalidation_0-auc:0.90760\tvalidation_1-auc:0.82950\n",
            "[11]\tvalidation_0-auc:0.90873\tvalidation_1-auc:0.82955\n",
            "[12]\tvalidation_0-auc:0.91074\tvalidation_1-auc:0.82969\n",
            "[13]\tvalidation_0-auc:0.91276\tvalidation_1-auc:0.82966\n",
            "[14]\tvalidation_0-auc:0.91383\tvalidation_1-auc:0.82986\n",
            "[15]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.82978\n",
            "[16]\tvalidation_0-auc:0.91757\tvalidation_1-auc:0.82896\n",
            "[17]\tvalidation_0-auc:0.91882\tvalidation_1-auc:0.82853\n",
            "[18]\tvalidation_0-auc:0.91951\tvalidation_1-auc:0.82948\n",
            "[19]\tvalidation_0-auc:0.92035\tvalidation_1-auc:0.82854\n",
            "[20]\tvalidation_0-auc:0.92211\tvalidation_1-auc:0.82743\n",
            "[21]\tvalidation_0-auc:0.92399\tvalidation_1-auc:0.82665\n",
            "[22]\tvalidation_0-auc:0.92517\tvalidation_1-auc:0.82726\n",
            "[23]\tvalidation_0-auc:0.92573\tvalidation_1-auc:0.82817\n",
            "[24]\tvalidation_0-auc:0.92623\tvalidation_1-auc:0.82928\n",
            "[25]\tvalidation_0-auc:0.92694\tvalidation_1-auc:0.82979\n",
            "[26]\tvalidation_0-auc:0.92791\tvalidation_1-auc:0.83013\n",
            "[27]\tvalidation_0-auc:0.92884\tvalidation_1-auc:0.83059\n",
            "[28]\tvalidation_0-auc:0.93022\tvalidation_1-auc:0.83015\n",
            "[29]\tvalidation_0-auc:0.93060\tvalidation_1-auc:0.83008\n",
            "[30]\tvalidation_0-auc:0.93127\tvalidation_1-auc:0.83010\n",
            "[31]\tvalidation_0-auc:0.93218\tvalidation_1-auc:0.82994\n",
            "[32]\tvalidation_0-auc:0.93280\tvalidation_1-auc:0.82966\n",
            "[33]\tvalidation_0-auc:0.93322\tvalidation_1-auc:0.82974\n",
            "[34]\tvalidation_0-auc:0.93422\tvalidation_1-auc:0.82924\n",
            "[35]\tvalidation_0-auc:0.93482\tvalidation_1-auc:0.82892\n",
            "[36]\tvalidation_0-auc:0.93496\tvalidation_1-auc:0.82892\n",
            "[37]\tvalidation_0-auc:0.93526\tvalidation_1-auc:0.82940\n",
            "[38]\tvalidation_0-auc:0.93561\tvalidation_1-auc:0.82965\n",
            "[39]\tvalidation_0-auc:0.93597\tvalidation_1-auc:0.83021\n",
            "[40]\tvalidation_0-auc:0.93651\tvalidation_1-auc:0.83013\n",
            "[41]\tvalidation_0-auc:0.93722\tvalidation_1-auc:0.82993\n",
            "[42]\tvalidation_0-auc:0.93793\tvalidation_1-auc:0.82971\n",
            "[43]\tvalidation_0-auc:0.93832\tvalidation_1-auc:0.82965\n",
            "[44]\tvalidation_0-auc:0.93884\tvalidation_1-auc:0.82974\n",
            "[45]\tvalidation_0-auc:0.93921\tvalidation_1-auc:0.82947\n",
            "[46]\tvalidation_0-auc:0.93964\tvalidation_1-auc:0.82927\n",
            "[47]\tvalidation_0-auc:0.93984\tvalidation_1-auc:0.82917\n",
            "[48]\tvalidation_0-auc:0.94012\tvalidation_1-auc:0.82903\n",
            "[49]\tvalidation_0-auc:0.94030\tvalidation_1-auc:0.82897\n",
            "[50]\tvalidation_0-auc:0.94053\tvalidation_1-auc:0.82879\n",
            "[51]\tvalidation_0-auc:0.94084\tvalidation_1-auc:0.82860\n",
            "[52]\tvalidation_0-auc:0.94110\tvalidation_1-auc:0.82861\n",
            "[53]\tvalidation_0-auc:0.94137\tvalidation_1-auc:0.82825\n",
            "[54]\tvalidation_0-auc:0.94157\tvalidation_1-auc:0.82803\n",
            "[55]\tvalidation_0-auc:0.94182\tvalidation_1-auc:0.82813\n",
            "[56]\tvalidation_0-auc:0.94231\tvalidation_1-auc:0.82791\n",
            "[0]\tvalidation_0-auc:0.86741\tvalidation_1-auc:0.80602\n",
            "[1]\tvalidation_0-auc:0.87596\tvalidation_1-auc:0.81922\n",
            "[2]\tvalidation_0-auc:0.88226\tvalidation_1-auc:0.81570\n",
            "[3]\tvalidation_0-auc:0.88781\tvalidation_1-auc:0.81924\n",
            "[4]\tvalidation_0-auc:0.88928\tvalidation_1-auc:0.82067\n",
            "[5]\tvalidation_0-auc:0.89144\tvalidation_1-auc:0.82339\n",
            "[6]\tvalidation_0-auc:0.89422\tvalidation_1-auc:0.82283\n",
            "[7]\tvalidation_0-auc:0.89755\tvalidation_1-auc:0.82081\n",
            "[8]\tvalidation_0-auc:0.90055\tvalidation_1-auc:0.82271\n",
            "[9]\tvalidation_0-auc:0.90288\tvalidation_1-auc:0.82391\n",
            "[10]\tvalidation_0-auc:0.90513\tvalidation_1-auc:0.82323\n",
            "[11]\tvalidation_0-auc:0.90578\tvalidation_1-auc:0.82459\n",
            "[12]\tvalidation_0-auc:0.90773\tvalidation_1-auc:0.82480\n",
            "[13]\tvalidation_0-auc:0.90950\tvalidation_1-auc:0.82452\n",
            "[14]\tvalidation_0-auc:0.91035\tvalidation_1-auc:0.82525\n",
            "[15]\tvalidation_0-auc:0.91187\tvalidation_1-auc:0.82520\n",
            "[16]\tvalidation_0-auc:0.91333\tvalidation_1-auc:0.82518\n",
            "[17]\tvalidation_0-auc:0.91498\tvalidation_1-auc:0.82562\n",
            "[18]\tvalidation_0-auc:0.91596\tvalidation_1-auc:0.82606\n",
            "[19]\tvalidation_0-auc:0.91760\tvalidation_1-auc:0.82713\n",
            "[20]\tvalidation_0-auc:0.91955\tvalidation_1-auc:0.82669\n",
            "[21]\tvalidation_0-auc:0.92163\tvalidation_1-auc:0.82556\n",
            "[22]\tvalidation_0-auc:0.92260\tvalidation_1-auc:0.82582\n",
            "[23]\tvalidation_0-auc:0.92326\tvalidation_1-auc:0.82609\n",
            "[24]\tvalidation_0-auc:0.92423\tvalidation_1-auc:0.82634\n",
            "[25]\tvalidation_0-auc:0.92462\tvalidation_1-auc:0.82687\n",
            "[26]\tvalidation_0-auc:0.92574\tvalidation_1-auc:0.82723\n",
            "[27]\tvalidation_0-auc:0.92662\tvalidation_1-auc:0.82783\n",
            "[28]\tvalidation_0-auc:0.92752\tvalidation_1-auc:0.82741\n",
            "[29]\tvalidation_0-auc:0.92786\tvalidation_1-auc:0.82702\n",
            "[30]\tvalidation_0-auc:0.92866\tvalidation_1-auc:0.82718\n",
            "[31]\tvalidation_0-auc:0.92972\tvalidation_1-auc:0.82643\n",
            "[32]\tvalidation_0-auc:0.93045\tvalidation_1-auc:0.82694\n",
            "[33]\tvalidation_0-auc:0.93126\tvalidation_1-auc:0.82670\n",
            "[34]\tvalidation_0-auc:0.93188\tvalidation_1-auc:0.82678\n",
            "[35]\tvalidation_0-auc:0.93209\tvalidation_1-auc:0.82679\n",
            "[36]\tvalidation_0-auc:0.93249\tvalidation_1-auc:0.82690\n",
            "[37]\tvalidation_0-auc:0.93306\tvalidation_1-auc:0.82743\n",
            "[38]\tvalidation_0-auc:0.93346\tvalidation_1-auc:0.82727\n",
            "[39]\tvalidation_0-auc:0.93405\tvalidation_1-auc:0.82726\n",
            "[40]\tvalidation_0-auc:0.93465\tvalidation_1-auc:0.82730\n",
            "[41]\tvalidation_0-auc:0.93490\tvalidation_1-auc:0.82692\n",
            "[42]\tvalidation_0-auc:0.93516\tvalidation_1-auc:0.82658\n",
            "[43]\tvalidation_0-auc:0.93557\tvalidation_1-auc:0.82663\n",
            "[44]\tvalidation_0-auc:0.93606\tvalidation_1-auc:0.82643\n",
            "[45]\tvalidation_0-auc:0.93645\tvalidation_1-auc:0.82671\n",
            "[46]\tvalidation_0-auc:0.93694\tvalidation_1-auc:0.82678\n",
            "[47]\tvalidation_0-auc:0.93749\tvalidation_1-auc:0.82694\n",
            "[48]\tvalidation_0-auc:0.93826\tvalidation_1-auc:0.82730\n",
            "[49]\tvalidation_0-auc:0.93891\tvalidation_1-auc:0.82742\n",
            "[50]\tvalidation_0-auc:0.93950\tvalidation_1-auc:0.82759\n",
            "[51]\tvalidation_0-auc:0.93969\tvalidation_1-auc:0.82728\n",
            "[52]\tvalidation_0-auc:0.94011\tvalidation_1-auc:0.82696\n",
            "[53]\tvalidation_0-auc:0.94069\tvalidation_1-auc:0.82704\n",
            "[54]\tvalidation_0-auc:0.94110\tvalidation_1-auc:0.82676\n",
            "[55]\tvalidation_0-auc:0.94122\tvalidation_1-auc:0.82647\n",
            "[56]\tvalidation_0-auc:0.94163\tvalidation_1-auc:0.82609\n",
            "[57]\tvalidation_0-auc:0.94178\tvalidation_1-auc:0.82614\n",
            "[0]\tvalidation_0-auc:0.85612\tvalidation_1-auc:0.80162\n",
            "[1]\tvalidation_0-auc:0.86370\tvalidation_1-auc:0.81198\n",
            "[2]\tvalidation_0-auc:0.87211\tvalidation_1-auc:0.81162\n",
            "[3]\tvalidation_0-auc:0.87596\tvalidation_1-auc:0.81912\n",
            "[4]\tvalidation_0-auc:0.87791\tvalidation_1-auc:0.82311\n",
            "[5]\tvalidation_0-auc:0.87929\tvalidation_1-auc:0.82403\n",
            "[6]\tvalidation_0-auc:0.88115\tvalidation_1-auc:0.82575\n",
            "[7]\tvalidation_0-auc:0.88304\tvalidation_1-auc:0.82487\n",
            "[8]\tvalidation_0-auc:0.88576\tvalidation_1-auc:0.82762\n",
            "[9]\tvalidation_0-auc:0.88562\tvalidation_1-auc:0.82896\n",
            "[10]\tvalidation_0-auc:0.88759\tvalidation_1-auc:0.82942\n",
            "[11]\tvalidation_0-auc:0.88782\tvalidation_1-auc:0.82978\n",
            "[12]\tvalidation_0-auc:0.88932\tvalidation_1-auc:0.82956\n",
            "[13]\tvalidation_0-auc:0.89040\tvalidation_1-auc:0.82964\n",
            "[14]\tvalidation_0-auc:0.89120\tvalidation_1-auc:0.82964\n",
            "[15]\tvalidation_0-auc:0.89237\tvalidation_1-auc:0.82995\n",
            "[16]\tvalidation_0-auc:0.89333\tvalidation_1-auc:0.82924\n",
            "[17]\tvalidation_0-auc:0.89429\tvalidation_1-auc:0.82971\n",
            "[18]\tvalidation_0-auc:0.89428\tvalidation_1-auc:0.83035\n",
            "[19]\tvalidation_0-auc:0.89499\tvalidation_1-auc:0.82963\n",
            "[20]\tvalidation_0-auc:0.89580\tvalidation_1-auc:0.82982\n",
            "[21]\tvalidation_0-auc:0.89723\tvalidation_1-auc:0.82969\n",
            "[22]\tvalidation_0-auc:0.89904\tvalidation_1-auc:0.82984\n",
            "[23]\tvalidation_0-auc:0.90004\tvalidation_1-auc:0.82955\n",
            "[24]\tvalidation_0-auc:0.90073\tvalidation_1-auc:0.82922\n",
            "[25]\tvalidation_0-auc:0.90149\tvalidation_1-auc:0.82866\n",
            "[26]\tvalidation_0-auc:0.90228\tvalidation_1-auc:0.82802\n",
            "[27]\tvalidation_0-auc:0.90298\tvalidation_1-auc:0.82811\n",
            "[28]\tvalidation_0-auc:0.90416\tvalidation_1-auc:0.82745\n",
            "[29]\tvalidation_0-auc:0.90540\tvalidation_1-auc:0.82785\n",
            "[30]\tvalidation_0-auc:0.90692\tvalidation_1-auc:0.82737\n",
            "[31]\tvalidation_0-auc:0.90758\tvalidation_1-auc:0.82746\n",
            "[32]\tvalidation_0-auc:0.90843\tvalidation_1-auc:0.82782\n",
            "[33]\tvalidation_0-auc:0.90924\tvalidation_1-auc:0.82783\n",
            "[34]\tvalidation_0-auc:0.90986\tvalidation_1-auc:0.82767\n",
            "[35]\tvalidation_0-auc:0.91046\tvalidation_1-auc:0.82780\n",
            "[36]\tvalidation_0-auc:0.91154\tvalidation_1-auc:0.82779\n",
            "[37]\tvalidation_0-auc:0.91212\tvalidation_1-auc:0.82815\n",
            "[38]\tvalidation_0-auc:0.91249\tvalidation_1-auc:0.82845\n",
            "[39]\tvalidation_0-auc:0.91326\tvalidation_1-auc:0.82871\n",
            "[40]\tvalidation_0-auc:0.91403\tvalidation_1-auc:0.82884\n",
            "[41]\tvalidation_0-auc:0.91472\tvalidation_1-auc:0.82909\n",
            "[42]\tvalidation_0-auc:0.91553\tvalidation_1-auc:0.82874\n",
            "[43]\tvalidation_0-auc:0.91631\tvalidation_1-auc:0.82877\n",
            "[44]\tvalidation_0-auc:0.91708\tvalidation_1-auc:0.82857\n",
            "[45]\tvalidation_0-auc:0.91796\tvalidation_1-auc:0.82827\n",
            "[46]\tvalidation_0-auc:0.91846\tvalidation_1-auc:0.82878\n",
            "[47]\tvalidation_0-auc:0.91916\tvalidation_1-auc:0.82851\n",
            "[48]\tvalidation_0-auc:0.91979\tvalidation_1-auc:0.82820\n",
            "[0]\tvalidation_0-auc:0.85773\tvalidation_1-auc:0.81493\n",
            "[1]\tvalidation_0-auc:0.86833\tvalidation_1-auc:0.81808\n",
            "[2]\tvalidation_0-auc:0.87304\tvalidation_1-auc:0.81250\n",
            "[3]\tvalidation_0-auc:0.87776\tvalidation_1-auc:0.82009\n",
            "[4]\tvalidation_0-auc:0.87999\tvalidation_1-auc:0.82398\n",
            "[5]\tvalidation_0-auc:0.88212\tvalidation_1-auc:0.82840\n",
            "[6]\tvalidation_0-auc:0.88421\tvalidation_1-auc:0.83027\n",
            "[7]\tvalidation_0-auc:0.88650\tvalidation_1-auc:0.82777\n",
            "[8]\tvalidation_0-auc:0.88769\tvalidation_1-auc:0.82928\n",
            "[9]\tvalidation_0-auc:0.88964\tvalidation_1-auc:0.83031\n",
            "[10]\tvalidation_0-auc:0.89107\tvalidation_1-auc:0.83049\n",
            "[11]\tvalidation_0-auc:0.89196\tvalidation_1-auc:0.83098\n",
            "[12]\tvalidation_0-auc:0.89367\tvalidation_1-auc:0.83184\n",
            "[13]\tvalidation_0-auc:0.89451\tvalidation_1-auc:0.83214\n",
            "[14]\tvalidation_0-auc:0.89476\tvalidation_1-auc:0.83236\n",
            "[15]\tvalidation_0-auc:0.89524\tvalidation_1-auc:0.83237\n",
            "[16]\tvalidation_0-auc:0.89603\tvalidation_1-auc:0.83262\n",
            "[17]\tvalidation_0-auc:0.89702\tvalidation_1-auc:0.83328\n",
            "[18]\tvalidation_0-auc:0.89794\tvalidation_1-auc:0.83298\n",
            "[19]\tvalidation_0-auc:0.89862\tvalidation_1-auc:0.83275\n",
            "[20]\tvalidation_0-auc:0.89990\tvalidation_1-auc:0.83294\n",
            "[21]\tvalidation_0-auc:0.90052\tvalidation_1-auc:0.83242\n",
            "[22]\tvalidation_0-auc:0.90233\tvalidation_1-auc:0.83314\n",
            "[23]\tvalidation_0-auc:0.90344\tvalidation_1-auc:0.83332\n",
            "[24]\tvalidation_0-auc:0.90420\tvalidation_1-auc:0.83384\n",
            "[25]\tvalidation_0-auc:0.90447\tvalidation_1-auc:0.83379\n",
            "[26]\tvalidation_0-auc:0.90537\tvalidation_1-auc:0.83377\n",
            "[27]\tvalidation_0-auc:0.90627\tvalidation_1-auc:0.83420\n",
            "[28]\tvalidation_0-auc:0.90708\tvalidation_1-auc:0.83348\n",
            "[29]\tvalidation_0-auc:0.90750\tvalidation_1-auc:0.83347\n",
            "[30]\tvalidation_0-auc:0.90856\tvalidation_1-auc:0.83368\n",
            "[31]\tvalidation_0-auc:0.90958\tvalidation_1-auc:0.83340\n",
            "[32]\tvalidation_0-auc:0.91049\tvalidation_1-auc:0.83308\n",
            "[33]\tvalidation_0-auc:0.91103\tvalidation_1-auc:0.83299\n",
            "[34]\tvalidation_0-auc:0.91185\tvalidation_1-auc:0.83234\n",
            "[35]\tvalidation_0-auc:0.91280\tvalidation_1-auc:0.83286\n",
            "[36]\tvalidation_0-auc:0.91404\tvalidation_1-auc:0.83299\n",
            "[37]\tvalidation_0-auc:0.91527\tvalidation_1-auc:0.83306\n",
            "[38]\tvalidation_0-auc:0.91591\tvalidation_1-auc:0.83328\n",
            "[39]\tvalidation_0-auc:0.91686\tvalidation_1-auc:0.83337\n",
            "[40]\tvalidation_0-auc:0.91737\tvalidation_1-auc:0.83317\n",
            "[41]\tvalidation_0-auc:0.91804\tvalidation_1-auc:0.83295\n",
            "[42]\tvalidation_0-auc:0.91900\tvalidation_1-auc:0.83333\n",
            "[43]\tvalidation_0-auc:0.91951\tvalidation_1-auc:0.83362\n",
            "[44]\tvalidation_0-auc:0.92062\tvalidation_1-auc:0.83345\n",
            "[45]\tvalidation_0-auc:0.92136\tvalidation_1-auc:0.83350\n",
            "[46]\tvalidation_0-auc:0.92162\tvalidation_1-auc:0.83385\n",
            "[47]\tvalidation_0-auc:0.92214\tvalidation_1-auc:0.83395\n",
            "[48]\tvalidation_0-auc:0.92267\tvalidation_1-auc:0.83398\n",
            "[49]\tvalidation_0-auc:0.92310\tvalidation_1-auc:0.83405\n",
            "[50]\tvalidation_0-auc:0.92334\tvalidation_1-auc:0.83407\n",
            "[51]\tvalidation_0-auc:0.92355\tvalidation_1-auc:0.83424\n",
            "[52]\tvalidation_0-auc:0.92413\tvalidation_1-auc:0.83439\n",
            "[53]\tvalidation_0-auc:0.92466\tvalidation_1-auc:0.83475\n",
            "[54]\tvalidation_0-auc:0.92502\tvalidation_1-auc:0.83458\n",
            "[55]\tvalidation_0-auc:0.92530\tvalidation_1-auc:0.83441\n",
            "[56]\tvalidation_0-auc:0.92549\tvalidation_1-auc:0.83456\n",
            "[57]\tvalidation_0-auc:0.92583\tvalidation_1-auc:0.83493\n",
            "[58]\tvalidation_0-auc:0.92622\tvalidation_1-auc:0.83478\n",
            "[59]\tvalidation_0-auc:0.92638\tvalidation_1-auc:0.83507\n",
            "[60]\tvalidation_0-auc:0.92676\tvalidation_1-auc:0.83496\n",
            "[61]\tvalidation_0-auc:0.92691\tvalidation_1-auc:0.83508\n",
            "[62]\tvalidation_0-auc:0.92719\tvalidation_1-auc:0.83527\n",
            "[63]\tvalidation_0-auc:0.92738\tvalidation_1-auc:0.83528\n",
            "[64]\tvalidation_0-auc:0.92749\tvalidation_1-auc:0.83537\n",
            "[65]\tvalidation_0-auc:0.92809\tvalidation_1-auc:0.83531\n",
            "[66]\tvalidation_0-auc:0.92832\tvalidation_1-auc:0.83551\n",
            "[67]\tvalidation_0-auc:0.92850\tvalidation_1-auc:0.83542\n",
            "[68]\tvalidation_0-auc:0.92892\tvalidation_1-auc:0.83518\n",
            "[69]\tvalidation_0-auc:0.92942\tvalidation_1-auc:0.83518\n",
            "[70]\tvalidation_0-auc:0.92963\tvalidation_1-auc:0.83524\n",
            "[71]\tvalidation_0-auc:0.92981\tvalidation_1-auc:0.83525\n",
            "[72]\tvalidation_0-auc:0.92992\tvalidation_1-auc:0.83506\n",
            "[73]\tvalidation_0-auc:0.93019\tvalidation_1-auc:0.83485\n",
            "[74]\tvalidation_0-auc:0.93033\tvalidation_1-auc:0.83495\n",
            "[75]\tvalidation_0-auc:0.93058\tvalidation_1-auc:0.83491\n",
            "[76]\tvalidation_0-auc:0.93070\tvalidation_1-auc:0.83498\n",
            "[77]\tvalidation_0-auc:0.93089\tvalidation_1-auc:0.83511\n",
            "[78]\tvalidation_0-auc:0.93109\tvalidation_1-auc:0.83542\n",
            "[79]\tvalidation_0-auc:0.93117\tvalidation_1-auc:0.83537\n",
            "[80]\tvalidation_0-auc:0.93138\tvalidation_1-auc:0.83524\n",
            "[81]\tvalidation_0-auc:0.93146\tvalidation_1-auc:0.83523\n",
            "[82]\tvalidation_0-auc:0.93175\tvalidation_1-auc:0.83508\n",
            "[83]\tvalidation_0-auc:0.93207\tvalidation_1-auc:0.83506\n",
            "[84]\tvalidation_0-auc:0.93213\tvalidation_1-auc:0.83507\n",
            "[85]\tvalidation_0-auc:0.93222\tvalidation_1-auc:0.83512\n",
            "[86]\tvalidation_0-auc:0.93236\tvalidation_1-auc:0.83517\n",
            "[87]\tvalidation_0-auc:0.93252\tvalidation_1-auc:0.83521\n",
            "[88]\tvalidation_0-auc:0.93273\tvalidation_1-auc:0.83504\n",
            "[89]\tvalidation_0-auc:0.93300\tvalidation_1-auc:0.83492\n",
            "[90]\tvalidation_0-auc:0.93367\tvalidation_1-auc:0.83465\n",
            "[91]\tvalidation_0-auc:0.93377\tvalidation_1-auc:0.83456\n",
            "[92]\tvalidation_0-auc:0.93381\tvalidation_1-auc:0.83456\n",
            "[93]\tvalidation_0-auc:0.93399\tvalidation_1-auc:0.83456\n",
            "[94]\tvalidation_0-auc:0.93416\tvalidation_1-auc:0.83449\n",
            "[95]\tvalidation_0-auc:0.93435\tvalidation_1-auc:0.83434\n",
            "[0]\tvalidation_0-auc:0.85741\tvalidation_1-auc:0.81330\n",
            "[1]\tvalidation_0-auc:0.86482\tvalidation_1-auc:0.82272\n",
            "[2]\tvalidation_0-auc:0.86997\tvalidation_1-auc:0.81537\n",
            "[3]\tvalidation_0-auc:0.87569\tvalidation_1-auc:0.82051\n",
            "[4]\tvalidation_0-auc:0.87682\tvalidation_1-auc:0.82365\n",
            "[5]\tvalidation_0-auc:0.87902\tvalidation_1-auc:0.82524\n",
            "[6]\tvalidation_0-auc:0.88140\tvalidation_1-auc:0.82579\n",
            "[7]\tvalidation_0-auc:0.88327\tvalidation_1-auc:0.82419\n",
            "[8]\tvalidation_0-auc:0.88428\tvalidation_1-auc:0.82512\n",
            "[9]\tvalidation_0-auc:0.88501\tvalidation_1-auc:0.82574\n",
            "[10]\tvalidation_0-auc:0.88548\tvalidation_1-auc:0.82522\n",
            "[11]\tvalidation_0-auc:0.88627\tvalidation_1-auc:0.82694\n",
            "[12]\tvalidation_0-auc:0.88712\tvalidation_1-auc:0.82641\n",
            "[13]\tvalidation_0-auc:0.88849\tvalidation_1-auc:0.82686\n",
            "[14]\tvalidation_0-auc:0.89120\tvalidation_1-auc:0.82729\n",
            "[15]\tvalidation_0-auc:0.89251\tvalidation_1-auc:0.82783\n",
            "[16]\tvalidation_0-auc:0.89380\tvalidation_1-auc:0.82789\n",
            "[17]\tvalidation_0-auc:0.89559\tvalidation_1-auc:0.82875\n",
            "[18]\tvalidation_0-auc:0.89704\tvalidation_1-auc:0.82938\n",
            "[19]\tvalidation_0-auc:0.89794\tvalidation_1-auc:0.82917\n",
            "[20]\tvalidation_0-auc:0.89903\tvalidation_1-auc:0.82834\n",
            "[21]\tvalidation_0-auc:0.90068\tvalidation_1-auc:0.82745\n",
            "[22]\tvalidation_0-auc:0.90169\tvalidation_1-auc:0.82791\n",
            "[23]\tvalidation_0-auc:0.90289\tvalidation_1-auc:0.82838\n",
            "[24]\tvalidation_0-auc:0.90402\tvalidation_1-auc:0.82892\n",
            "[25]\tvalidation_0-auc:0.90439\tvalidation_1-auc:0.82948\n",
            "[26]\tvalidation_0-auc:0.90552\tvalidation_1-auc:0.82919\n",
            "[27]\tvalidation_0-auc:0.90661\tvalidation_1-auc:0.82931\n",
            "[28]\tvalidation_0-auc:0.90739\tvalidation_1-auc:0.82898\n",
            "[29]\tvalidation_0-auc:0.90858\tvalidation_1-auc:0.82915\n",
            "[30]\tvalidation_0-auc:0.90991\tvalidation_1-auc:0.82948\n",
            "[31]\tvalidation_0-auc:0.91101\tvalidation_1-auc:0.82931\n",
            "[32]\tvalidation_0-auc:0.91216\tvalidation_1-auc:0.82986\n",
            "[33]\tvalidation_0-auc:0.91275\tvalidation_1-auc:0.82976\n",
            "[34]\tvalidation_0-auc:0.91336\tvalidation_1-auc:0.82900\n",
            "[35]\tvalidation_0-auc:0.91399\tvalidation_1-auc:0.82939\n",
            "[36]\tvalidation_0-auc:0.91484\tvalidation_1-auc:0.82986\n",
            "[37]\tvalidation_0-auc:0.91577\tvalidation_1-auc:0.83002\n",
            "[38]\tvalidation_0-auc:0.91653\tvalidation_1-auc:0.83063\n",
            "[39]\tvalidation_0-auc:0.91688\tvalidation_1-auc:0.83113\n",
            "[40]\tvalidation_0-auc:0.91737\tvalidation_1-auc:0.83120\n",
            "[41]\tvalidation_0-auc:0.91808\tvalidation_1-auc:0.83169\n",
            "[42]\tvalidation_0-auc:0.91870\tvalidation_1-auc:0.83216\n",
            "[43]\tvalidation_0-auc:0.91932\tvalidation_1-auc:0.83248\n",
            "[44]\tvalidation_0-auc:0.92005\tvalidation_1-auc:0.83217\n",
            "[45]\tvalidation_0-auc:0.92059\tvalidation_1-auc:0.83224\n",
            "[46]\tvalidation_0-auc:0.92097\tvalidation_1-auc:0.83194\n",
            "[47]\tvalidation_0-auc:0.92158\tvalidation_1-auc:0.83185\n",
            "[48]\tvalidation_0-auc:0.92205\tvalidation_1-auc:0.83204\n",
            "[49]\tvalidation_0-auc:0.92262\tvalidation_1-auc:0.83198\n",
            "[50]\tvalidation_0-auc:0.92306\tvalidation_1-auc:0.83183\n",
            "[51]\tvalidation_0-auc:0.92356\tvalidation_1-auc:0.83160\n",
            "[52]\tvalidation_0-auc:0.92393\tvalidation_1-auc:0.83151\n",
            "[53]\tvalidation_0-auc:0.92466\tvalidation_1-auc:0.83169\n",
            "[54]\tvalidation_0-auc:0.92506\tvalidation_1-auc:0.83153\n",
            "[55]\tvalidation_0-auc:0.92541\tvalidation_1-auc:0.83127\n",
            "[56]\tvalidation_0-auc:0.92585\tvalidation_1-auc:0.83134\n",
            "[57]\tvalidation_0-auc:0.92627\tvalidation_1-auc:0.83137\n",
            "[58]\tvalidation_0-auc:0.92659\tvalidation_1-auc:0.83135\n",
            "[59]\tvalidation_0-auc:0.92679\tvalidation_1-auc:0.83134\n",
            "[60]\tvalidation_0-auc:0.92708\tvalidation_1-auc:0.83086\n",
            "[61]\tvalidation_0-auc:0.92721\tvalidation_1-auc:0.83112\n",
            "[62]\tvalidation_0-auc:0.92745\tvalidation_1-auc:0.83117\n",
            "[63]\tvalidation_0-auc:0.92778\tvalidation_1-auc:0.83107\n",
            "[64]\tvalidation_0-auc:0.92802\tvalidation_1-auc:0.83114\n",
            "[65]\tvalidation_0-auc:0.92836\tvalidation_1-auc:0.83109\n",
            "[66]\tvalidation_0-auc:0.92872\tvalidation_1-auc:0.83129\n",
            "[67]\tvalidation_0-auc:0.92888\tvalidation_1-auc:0.83141\n",
            "[68]\tvalidation_0-auc:0.92922\tvalidation_1-auc:0.83133\n",
            "[69]\tvalidation_0-auc:0.92960\tvalidation_1-auc:0.83109\n",
            "[70]\tvalidation_0-auc:0.92998\tvalidation_1-auc:0.83108\n",
            "[71]\tvalidation_0-auc:0.93018\tvalidation_1-auc:0.83122\n",
            "[72]\tvalidation_0-auc:0.93042\tvalidation_1-auc:0.83122\n",
            "[73]\tvalidation_0-auc:0.93060\tvalidation_1-auc:0.83134\n",
            "[0]\tvalidation_0-auc:0.84072\tvalidation_1-auc:0.80316\n",
            "[1]\tvalidation_0-auc:0.84728\tvalidation_1-auc:0.81205\n",
            "[2]\tvalidation_0-auc:0.85014\tvalidation_1-auc:0.81788\n",
            "[3]\tvalidation_0-auc:0.84994\tvalidation_1-auc:0.81749\n",
            "[4]\tvalidation_0-auc:0.85061\tvalidation_1-auc:0.81746\n",
            "[5]\tvalidation_0-auc:0.85209\tvalidation_1-auc:0.81966\n",
            "[6]\tvalidation_0-auc:0.85284\tvalidation_1-auc:0.81933\n",
            "[7]\tvalidation_0-auc:0.85594\tvalidation_1-auc:0.82429\n",
            "[8]\tvalidation_0-auc:0.85587\tvalidation_1-auc:0.82423\n",
            "[9]\tvalidation_0-auc:0.85663\tvalidation_1-auc:0.82439\n",
            "[10]\tvalidation_0-auc:0.85658\tvalidation_1-auc:0.82440\n",
            "[11]\tvalidation_0-auc:0.85672\tvalidation_1-auc:0.82453\n",
            "[12]\tvalidation_0-auc:0.85705\tvalidation_1-auc:0.82425\n",
            "[13]\tvalidation_0-auc:0.85826\tvalidation_1-auc:0.82459\n",
            "[14]\tvalidation_0-auc:0.85842\tvalidation_1-auc:0.82423\n",
            "[15]\tvalidation_0-auc:0.85899\tvalidation_1-auc:0.82516\n",
            "[16]\tvalidation_0-auc:0.85915\tvalidation_1-auc:0.82508\n",
            "[17]\tvalidation_0-auc:0.85932\tvalidation_1-auc:0.82487\n",
            "[18]\tvalidation_0-auc:0.85947\tvalidation_1-auc:0.82493\n",
            "[19]\tvalidation_0-auc:0.85973\tvalidation_1-auc:0.82511\n",
            "[20]\tvalidation_0-auc:0.86062\tvalidation_1-auc:0.82707\n",
            "[21]\tvalidation_0-auc:0.86181\tvalidation_1-auc:0.82841\n",
            "[22]\tvalidation_0-auc:0.86201\tvalidation_1-auc:0.82796\n",
            "[23]\tvalidation_0-auc:0.86227\tvalidation_1-auc:0.82792\n",
            "[24]\tvalidation_0-auc:0.86228\tvalidation_1-auc:0.82834\n",
            "[25]\tvalidation_0-auc:0.86232\tvalidation_1-auc:0.82847\n",
            "[26]\tvalidation_0-auc:0.86287\tvalidation_1-auc:0.82855\n",
            "[27]\tvalidation_0-auc:0.86308\tvalidation_1-auc:0.82853\n",
            "[28]\tvalidation_0-auc:0.86379\tvalidation_1-auc:0.82880\n",
            "[29]\tvalidation_0-auc:0.86401\tvalidation_1-auc:0.82897\n",
            "[30]\tvalidation_0-auc:0.86495\tvalidation_1-auc:0.82937\n",
            "[31]\tvalidation_0-auc:0.86561\tvalidation_1-auc:0.82958\n",
            "[32]\tvalidation_0-auc:0.86594\tvalidation_1-auc:0.82975\n",
            "[33]\tvalidation_0-auc:0.86588\tvalidation_1-auc:0.82971\n",
            "[34]\tvalidation_0-auc:0.86625\tvalidation_1-auc:0.83007\n",
            "[35]\tvalidation_0-auc:0.86655\tvalidation_1-auc:0.83011\n",
            "[36]\tvalidation_0-auc:0.86672\tvalidation_1-auc:0.82999\n",
            "[37]\tvalidation_0-auc:0.86693\tvalidation_1-auc:0.83008\n",
            "[38]\tvalidation_0-auc:0.86723\tvalidation_1-auc:0.83015\n",
            "[39]\tvalidation_0-auc:0.86735\tvalidation_1-auc:0.83004\n",
            "[40]\tvalidation_0-auc:0.86795\tvalidation_1-auc:0.83029\n",
            "[41]\tvalidation_0-auc:0.86828\tvalidation_1-auc:0.83046\n",
            "[42]\tvalidation_0-auc:0.86874\tvalidation_1-auc:0.83080\n",
            "[43]\tvalidation_0-auc:0.86866\tvalidation_1-auc:0.83094\n",
            "[44]\tvalidation_0-auc:0.86901\tvalidation_1-auc:0.83122\n",
            "[45]\tvalidation_0-auc:0.86923\tvalidation_1-auc:0.83145\n",
            "[46]\tvalidation_0-auc:0.86939\tvalidation_1-auc:0.83173\n",
            "[47]\tvalidation_0-auc:0.86954\tvalidation_1-auc:0.83171\n",
            "[48]\tvalidation_0-auc:0.86985\tvalidation_1-auc:0.83171\n",
            "[49]\tvalidation_0-auc:0.87009\tvalidation_1-auc:0.83201\n",
            "[50]\tvalidation_0-auc:0.87012\tvalidation_1-auc:0.83212\n",
            "[51]\tvalidation_0-auc:0.87056\tvalidation_1-auc:0.83200\n",
            "[52]\tvalidation_0-auc:0.87075\tvalidation_1-auc:0.83227\n",
            "[53]\tvalidation_0-auc:0.87097\tvalidation_1-auc:0.83218\n",
            "[54]\tvalidation_0-auc:0.87113\tvalidation_1-auc:0.83226\n",
            "[55]\tvalidation_0-auc:0.87134\tvalidation_1-auc:0.83241\n",
            "[56]\tvalidation_0-auc:0.87147\tvalidation_1-auc:0.83221\n",
            "[57]\tvalidation_0-auc:0.87153\tvalidation_1-auc:0.83232\n",
            "[58]\tvalidation_0-auc:0.87164\tvalidation_1-auc:0.83224\n",
            "[59]\tvalidation_0-auc:0.87168\tvalidation_1-auc:0.83234\n",
            "[60]\tvalidation_0-auc:0.87189\tvalidation_1-auc:0.83236\n",
            "[61]\tvalidation_0-auc:0.87202\tvalidation_1-auc:0.83231\n",
            "[62]\tvalidation_0-auc:0.87214\tvalidation_1-auc:0.83224\n",
            "[63]\tvalidation_0-auc:0.87232\tvalidation_1-auc:0.83205\n",
            "[64]\tvalidation_0-auc:0.87247\tvalidation_1-auc:0.83212\n",
            "[65]\tvalidation_0-auc:0.87270\tvalidation_1-auc:0.83223\n",
            "[66]\tvalidation_0-auc:0.87285\tvalidation_1-auc:0.83236\n",
            "[67]\tvalidation_0-auc:0.87299\tvalidation_1-auc:0.83198\n",
            "[68]\tvalidation_0-auc:0.87316\tvalidation_1-auc:0.83187\n",
            "[69]\tvalidation_0-auc:0.87339\tvalidation_1-auc:0.83215\n",
            "[70]\tvalidation_0-auc:0.87353\tvalidation_1-auc:0.83218\n",
            "[71]\tvalidation_0-auc:0.87391\tvalidation_1-auc:0.83206\n",
            "[72]\tvalidation_0-auc:0.87413\tvalidation_1-auc:0.83205\n",
            "[73]\tvalidation_0-auc:0.87431\tvalidation_1-auc:0.83199\n",
            "[74]\tvalidation_0-auc:0.87448\tvalidation_1-auc:0.83181\n",
            "[75]\tvalidation_0-auc:0.87466\tvalidation_1-auc:0.83166\n",
            "[76]\tvalidation_0-auc:0.87482\tvalidation_1-auc:0.83163\n",
            "[77]\tvalidation_0-auc:0.87507\tvalidation_1-auc:0.83151\n",
            "[78]\tvalidation_0-auc:0.87539\tvalidation_1-auc:0.83162\n",
            "[79]\tvalidation_0-auc:0.87552\tvalidation_1-auc:0.83173\n",
            "[80]\tvalidation_0-auc:0.87571\tvalidation_1-auc:0.83157\n",
            "[81]\tvalidation_0-auc:0.87591\tvalidation_1-auc:0.83171\n",
            "[82]\tvalidation_0-auc:0.87608\tvalidation_1-auc:0.83178\n",
            "[83]\tvalidation_0-auc:0.87616\tvalidation_1-auc:0.83202\n",
            "[84]\tvalidation_0-auc:0.87616\tvalidation_1-auc:0.83200\n",
            "[0]\tvalidation_0-auc:0.83899\tvalidation_1-auc:0.81707\n",
            "[1]\tvalidation_0-auc:0.84774\tvalidation_1-auc:0.82194\n",
            "[2]\tvalidation_0-auc:0.85232\tvalidation_1-auc:0.82345\n",
            "[3]\tvalidation_0-auc:0.85326\tvalidation_1-auc:0.82435\n",
            "[4]\tvalidation_0-auc:0.85422\tvalidation_1-auc:0.82472\n",
            "[5]\tvalidation_0-auc:0.85498\tvalidation_1-auc:0.82703\n",
            "[6]\tvalidation_0-auc:0.85526\tvalidation_1-auc:0.82793\n",
            "[7]\tvalidation_0-auc:0.85881\tvalidation_1-auc:0.82946\n",
            "[8]\tvalidation_0-auc:0.86015\tvalidation_1-auc:0.82939\n",
            "[9]\tvalidation_0-auc:0.86019\tvalidation_1-auc:0.83046\n",
            "[10]\tvalidation_0-auc:0.86127\tvalidation_1-auc:0.83053\n",
            "[11]\tvalidation_0-auc:0.86108\tvalidation_1-auc:0.83125\n",
            "[12]\tvalidation_0-auc:0.86118\tvalidation_1-auc:0.83106\n",
            "[13]\tvalidation_0-auc:0.86138\tvalidation_1-auc:0.83091\n",
            "[14]\tvalidation_0-auc:0.86138\tvalidation_1-auc:0.83100\n",
            "[15]\tvalidation_0-auc:0.86213\tvalidation_1-auc:0.83106\n",
            "[16]\tvalidation_0-auc:0.86214\tvalidation_1-auc:0.83092\n",
            "[17]\tvalidation_0-auc:0.86236\tvalidation_1-auc:0.83124\n",
            "[18]\tvalidation_0-auc:0.86291\tvalidation_1-auc:0.83182\n",
            "[19]\tvalidation_0-auc:0.86313\tvalidation_1-auc:0.83212\n",
            "[20]\tvalidation_0-auc:0.86408\tvalidation_1-auc:0.83199\n",
            "[21]\tvalidation_0-auc:0.86427\tvalidation_1-auc:0.83167\n",
            "[22]\tvalidation_0-auc:0.86497\tvalidation_1-auc:0.83235\n",
            "[23]\tvalidation_0-auc:0.86493\tvalidation_1-auc:0.83283\n",
            "[24]\tvalidation_0-auc:0.86493\tvalidation_1-auc:0.83299\n",
            "[25]\tvalidation_0-auc:0.86493\tvalidation_1-auc:0.83313\n",
            "[26]\tvalidation_0-auc:0.86539\tvalidation_1-auc:0.83300\n",
            "[27]\tvalidation_0-auc:0.86596\tvalidation_1-auc:0.83340\n",
            "[28]\tvalidation_0-auc:0.86613\tvalidation_1-auc:0.83340\n",
            "[29]\tvalidation_0-auc:0.86635\tvalidation_1-auc:0.83349\n",
            "[30]\tvalidation_0-auc:0.86674\tvalidation_1-auc:0.83328\n",
            "[31]\tvalidation_0-auc:0.86709\tvalidation_1-auc:0.83324\n",
            "[32]\tvalidation_0-auc:0.86760\tvalidation_1-auc:0.83359\n",
            "[33]\tvalidation_0-auc:0.86794\tvalidation_1-auc:0.83389\n",
            "[34]\tvalidation_0-auc:0.86808\tvalidation_1-auc:0.83397\n",
            "[35]\tvalidation_0-auc:0.86833\tvalidation_1-auc:0.83413\n",
            "[36]\tvalidation_0-auc:0.86855\tvalidation_1-auc:0.83412\n",
            "[37]\tvalidation_0-auc:0.86864\tvalidation_1-auc:0.83399\n",
            "[38]\tvalidation_0-auc:0.86887\tvalidation_1-auc:0.83384\n",
            "[39]\tvalidation_0-auc:0.86913\tvalidation_1-auc:0.83387\n",
            "[40]\tvalidation_0-auc:0.86941\tvalidation_1-auc:0.83381\n",
            "[41]\tvalidation_0-auc:0.86973\tvalidation_1-auc:0.83386\n",
            "[42]\tvalidation_0-auc:0.87009\tvalidation_1-auc:0.83387\n",
            "[43]\tvalidation_0-auc:0.87021\tvalidation_1-auc:0.83397\n",
            "[44]\tvalidation_0-auc:0.87059\tvalidation_1-auc:0.83409\n",
            "[45]\tvalidation_0-auc:0.87074\tvalidation_1-auc:0.83440\n",
            "[46]\tvalidation_0-auc:0.87104\tvalidation_1-auc:0.83415\n",
            "[47]\tvalidation_0-auc:0.87131\tvalidation_1-auc:0.83426\n",
            "[48]\tvalidation_0-auc:0.87150\tvalidation_1-auc:0.83444\n",
            "[49]\tvalidation_0-auc:0.87175\tvalidation_1-auc:0.83450\n",
            "[50]\tvalidation_0-auc:0.87180\tvalidation_1-auc:0.83447\n",
            "[51]\tvalidation_0-auc:0.87184\tvalidation_1-auc:0.83456\n",
            "[52]\tvalidation_0-auc:0.87204\tvalidation_1-auc:0.83451\n",
            "[53]\tvalidation_0-auc:0.87218\tvalidation_1-auc:0.83443\n",
            "[54]\tvalidation_0-auc:0.87238\tvalidation_1-auc:0.83419\n",
            "[55]\tvalidation_0-auc:0.87251\tvalidation_1-auc:0.83397\n",
            "[56]\tvalidation_0-auc:0.87266\tvalidation_1-auc:0.83372\n",
            "[57]\tvalidation_0-auc:0.87290\tvalidation_1-auc:0.83387\n",
            "[58]\tvalidation_0-auc:0.87308\tvalidation_1-auc:0.83387\n",
            "[59]\tvalidation_0-auc:0.87314\tvalidation_1-auc:0.83401\n",
            "[60]\tvalidation_0-auc:0.87320\tvalidation_1-auc:0.83396\n",
            "[61]\tvalidation_0-auc:0.87322\tvalidation_1-auc:0.83414\n",
            "[62]\tvalidation_0-auc:0.87344\tvalidation_1-auc:0.83398\n",
            "[63]\tvalidation_0-auc:0.87360\tvalidation_1-auc:0.83400\n",
            "[64]\tvalidation_0-auc:0.87394\tvalidation_1-auc:0.83409\n",
            "[65]\tvalidation_0-auc:0.87398\tvalidation_1-auc:0.83400\n",
            "[66]\tvalidation_0-auc:0.87419\tvalidation_1-auc:0.83390\n",
            "[67]\tvalidation_0-auc:0.87436\tvalidation_1-auc:0.83380\n",
            "[68]\tvalidation_0-auc:0.87448\tvalidation_1-auc:0.83370\n",
            "[69]\tvalidation_0-auc:0.87464\tvalidation_1-auc:0.83349\n",
            "[70]\tvalidation_0-auc:0.87482\tvalidation_1-auc:0.83345\n",
            "[71]\tvalidation_0-auc:0.87511\tvalidation_1-auc:0.83363\n",
            "[72]\tvalidation_0-auc:0.87529\tvalidation_1-auc:0.83350\n",
            "[73]\tvalidation_0-auc:0.87561\tvalidation_1-auc:0.83348\n",
            "[74]\tvalidation_0-auc:0.87578\tvalidation_1-auc:0.83353\n",
            "[75]\tvalidation_0-auc:0.87596\tvalidation_1-auc:0.83347\n",
            "[76]\tvalidation_0-auc:0.87610\tvalidation_1-auc:0.83346\n",
            "[77]\tvalidation_0-auc:0.87627\tvalidation_1-auc:0.83344\n",
            "[78]\tvalidation_0-auc:0.87649\tvalidation_1-auc:0.83362\n",
            "[79]\tvalidation_0-auc:0.87666\tvalidation_1-auc:0.83350\n",
            "[80]\tvalidation_0-auc:0.87677\tvalidation_1-auc:0.83337\n",
            "[0]\tvalidation_0-auc:0.84223\tvalidation_1-auc:0.81368\n",
            "[1]\tvalidation_0-auc:0.84705\tvalidation_1-auc:0.82198\n",
            "[2]\tvalidation_0-auc:0.85136\tvalidation_1-auc:0.82334\n",
            "[3]\tvalidation_0-auc:0.85222\tvalidation_1-auc:0.82365\n",
            "[4]\tvalidation_0-auc:0.85212\tvalidation_1-auc:0.82357\n",
            "[5]\tvalidation_0-auc:0.85305\tvalidation_1-auc:0.82595\n",
            "[6]\tvalidation_0-auc:0.85306\tvalidation_1-auc:0.82584\n",
            "[7]\tvalidation_0-auc:0.85675\tvalidation_1-auc:0.82685\n",
            "[8]\tvalidation_0-auc:0.85705\tvalidation_1-auc:0.82792\n",
            "[9]\tvalidation_0-auc:0.85675\tvalidation_1-auc:0.82866\n",
            "[10]\tvalidation_0-auc:0.85737\tvalidation_1-auc:0.82902\n",
            "[11]\tvalidation_0-auc:0.85722\tvalidation_1-auc:0.82903\n",
            "[12]\tvalidation_0-auc:0.85753\tvalidation_1-auc:0.82969\n",
            "[13]\tvalidation_0-auc:0.85821\tvalidation_1-auc:0.82947\n",
            "[14]\tvalidation_0-auc:0.85832\tvalidation_1-auc:0.82935\n",
            "[15]\tvalidation_0-auc:0.85904\tvalidation_1-auc:0.82985\n",
            "[16]\tvalidation_0-auc:0.85906\tvalidation_1-auc:0.82974\n",
            "[17]\tvalidation_0-auc:0.85941\tvalidation_1-auc:0.83015\n",
            "[18]\tvalidation_0-auc:0.85949\tvalidation_1-auc:0.83061\n",
            "[19]\tvalidation_0-auc:0.85955\tvalidation_1-auc:0.83051\n",
            "[20]\tvalidation_0-auc:0.86072\tvalidation_1-auc:0.82978\n",
            "[21]\tvalidation_0-auc:0.86203\tvalidation_1-auc:0.82994\n",
            "[22]\tvalidation_0-auc:0.86219\tvalidation_1-auc:0.83002\n",
            "[23]\tvalidation_0-auc:0.86233\tvalidation_1-auc:0.83032\n",
            "[24]\tvalidation_0-auc:0.86270\tvalidation_1-auc:0.83064\n",
            "[25]\tvalidation_0-auc:0.86279\tvalidation_1-auc:0.83068\n",
            "[26]\tvalidation_0-auc:0.86339\tvalidation_1-auc:0.83072\n",
            "[27]\tvalidation_0-auc:0.86393\tvalidation_1-auc:0.83069\n",
            "[28]\tvalidation_0-auc:0.86436\tvalidation_1-auc:0.83071\n",
            "[29]\tvalidation_0-auc:0.86465\tvalidation_1-auc:0.83065\n",
            "[30]\tvalidation_0-auc:0.86499\tvalidation_1-auc:0.83073\n",
            "[31]\tvalidation_0-auc:0.86536\tvalidation_1-auc:0.83082\n",
            "[32]\tvalidation_0-auc:0.86576\tvalidation_1-auc:0.83075\n",
            "[33]\tvalidation_0-auc:0.86578\tvalidation_1-auc:0.83099\n",
            "[34]\tvalidation_0-auc:0.86591\tvalidation_1-auc:0.83095\n",
            "[35]\tvalidation_0-auc:0.86607\tvalidation_1-auc:0.83086\n",
            "[36]\tvalidation_0-auc:0.86625\tvalidation_1-auc:0.83095\n",
            "[37]\tvalidation_0-auc:0.86649\tvalidation_1-auc:0.83098\n",
            "[38]\tvalidation_0-auc:0.86677\tvalidation_1-auc:0.83114\n",
            "[39]\tvalidation_0-auc:0.86687\tvalidation_1-auc:0.83102\n",
            "[40]\tvalidation_0-auc:0.86728\tvalidation_1-auc:0.83128\n",
            "[41]\tvalidation_0-auc:0.86743\tvalidation_1-auc:0.83153\n",
            "[42]\tvalidation_0-auc:0.86773\tvalidation_1-auc:0.83183\n",
            "[43]\tvalidation_0-auc:0.86847\tvalidation_1-auc:0.83239\n",
            "[44]\tvalidation_0-auc:0.86880\tvalidation_1-auc:0.83240\n",
            "[45]\tvalidation_0-auc:0.86910\tvalidation_1-auc:0.83264\n",
            "[46]\tvalidation_0-auc:0.86930\tvalidation_1-auc:0.83284\n",
            "[47]\tvalidation_0-auc:0.86980\tvalidation_1-auc:0.83301\n",
            "[48]\tvalidation_0-auc:0.87007\tvalidation_1-auc:0.83291\n",
            "[49]\tvalidation_0-auc:0.87021\tvalidation_1-auc:0.83304\n",
            "[50]\tvalidation_0-auc:0.87046\tvalidation_1-auc:0.83308\n",
            "[51]\tvalidation_0-auc:0.87070\tvalidation_1-auc:0.83306\n",
            "[52]\tvalidation_0-auc:0.87097\tvalidation_1-auc:0.83307\n",
            "[53]\tvalidation_0-auc:0.87127\tvalidation_1-auc:0.83321\n",
            "[54]\tvalidation_0-auc:0.87177\tvalidation_1-auc:0.83331\n",
            "[55]\tvalidation_0-auc:0.87204\tvalidation_1-auc:0.83331\n",
            "[56]\tvalidation_0-auc:0.87223\tvalidation_1-auc:0.83323\n",
            "[57]\tvalidation_0-auc:0.87317\tvalidation_1-auc:0.83369\n",
            "[58]\tvalidation_0-auc:0.87338\tvalidation_1-auc:0.83362\n",
            "[59]\tvalidation_0-auc:0.87375\tvalidation_1-auc:0.83361\n",
            "[60]\tvalidation_0-auc:0.87381\tvalidation_1-auc:0.83370\n",
            "[61]\tvalidation_0-auc:0.87415\tvalidation_1-auc:0.83394\n",
            "[62]\tvalidation_0-auc:0.87447\tvalidation_1-auc:0.83397\n",
            "[63]\tvalidation_0-auc:0.87481\tvalidation_1-auc:0.83424\n",
            "[64]\tvalidation_0-auc:0.87508\tvalidation_1-auc:0.83433\n",
            "[65]\tvalidation_0-auc:0.87528\tvalidation_1-auc:0.83405\n",
            "[66]\tvalidation_0-auc:0.87548\tvalidation_1-auc:0.83416\n",
            "[67]\tvalidation_0-auc:0.87572\tvalidation_1-auc:0.83411\n",
            "[68]\tvalidation_0-auc:0.87599\tvalidation_1-auc:0.83426\n",
            "[69]\tvalidation_0-auc:0.87604\tvalidation_1-auc:0.83393\n",
            "[70]\tvalidation_0-auc:0.87605\tvalidation_1-auc:0.83400\n",
            "[71]\tvalidation_0-auc:0.87617\tvalidation_1-auc:0.83416\n",
            "[72]\tvalidation_0-auc:0.87627\tvalidation_1-auc:0.83393\n",
            "[73]\tvalidation_0-auc:0.87663\tvalidation_1-auc:0.83428\n",
            "[74]\tvalidation_0-auc:0.87670\tvalidation_1-auc:0.83427\n",
            "[75]\tvalidation_0-auc:0.87697\tvalidation_1-auc:0.83436\n",
            "[76]\tvalidation_0-auc:0.87709\tvalidation_1-auc:0.83433\n",
            "[77]\tvalidation_0-auc:0.87720\tvalidation_1-auc:0.83452\n",
            "[78]\tvalidation_0-auc:0.87752\tvalidation_1-auc:0.83482\n",
            "[79]\tvalidation_0-auc:0.87777\tvalidation_1-auc:0.83483\n",
            "[80]\tvalidation_0-auc:0.87813\tvalidation_1-auc:0.83477\n",
            "[81]\tvalidation_0-auc:0.87840\tvalidation_1-auc:0.83440\n",
            "[82]\tvalidation_0-auc:0.87857\tvalidation_1-auc:0.83447\n",
            "[83]\tvalidation_0-auc:0.87871\tvalidation_1-auc:0.83422\n",
            "[84]\tvalidation_0-auc:0.87881\tvalidation_1-auc:0.83416\n",
            "[85]\tvalidation_0-auc:0.87893\tvalidation_1-auc:0.83433\n",
            "[86]\tvalidation_0-auc:0.87904\tvalidation_1-auc:0.83455\n",
            "[87]\tvalidation_0-auc:0.87946\tvalidation_1-auc:0.83475\n",
            "[88]\tvalidation_0-auc:0.87967\tvalidation_1-auc:0.83475\n",
            "[89]\tvalidation_0-auc:0.87980\tvalidation_1-auc:0.83500\n",
            "[90]\tvalidation_0-auc:0.88002\tvalidation_1-auc:0.83485\n",
            "[91]\tvalidation_0-auc:0.88035\tvalidation_1-auc:0.83490\n",
            "[92]\tvalidation_0-auc:0.88061\tvalidation_1-auc:0.83474\n",
            "[93]\tvalidation_0-auc:0.88086\tvalidation_1-auc:0.83475\n",
            "[94]\tvalidation_0-auc:0.88111\tvalidation_1-auc:0.83481\n",
            "[95]\tvalidation_0-auc:0.88136\tvalidation_1-auc:0.83482\n",
            "[96]\tvalidation_0-auc:0.88156\tvalidation_1-auc:0.83486\n",
            "[97]\tvalidation_0-auc:0.88172\tvalidation_1-auc:0.83475\n",
            "[98]\tvalidation_0-auc:0.88207\tvalidation_1-auc:0.83484\n",
            "[99]\tvalidation_0-auc:0.88231\tvalidation_1-auc:0.83490\n",
            "[0]\tvalidation_0-auc:0.85815\tvalidation_1-auc:0.80122\n",
            "[1]\tvalidation_0-auc:0.86874\tvalidation_1-auc:0.81500\n",
            "[2]\tvalidation_0-auc:0.86932\tvalidation_1-auc:0.81179\n",
            "[3]\tvalidation_0-auc:0.87335\tvalidation_1-auc:0.82098\n",
            "[4]\tvalidation_0-auc:0.87561\tvalidation_1-auc:0.82276\n",
            "[5]\tvalidation_0-auc:0.87825\tvalidation_1-auc:0.82486\n",
            "[6]\tvalidation_0-auc:0.88128\tvalidation_1-auc:0.82651\n",
            "[7]\tvalidation_0-auc:0.88511\tvalidation_1-auc:0.82570\n",
            "[8]\tvalidation_0-auc:0.88815\tvalidation_1-auc:0.82668\n",
            "[9]\tvalidation_0-auc:0.88849\tvalidation_1-auc:0.82568\n",
            "[10]\tvalidation_0-auc:0.89119\tvalidation_1-auc:0.82844\n",
            "[11]\tvalidation_0-auc:0.89195\tvalidation_1-auc:0.83016\n",
            "[12]\tvalidation_0-auc:0.89405\tvalidation_1-auc:0.83043\n",
            "[13]\tvalidation_0-auc:0.89530\tvalidation_1-auc:0.83110\n",
            "[14]\tvalidation_0-auc:0.89613\tvalidation_1-auc:0.83120\n",
            "[15]\tvalidation_0-auc:0.89813\tvalidation_1-auc:0.82999\n",
            "[16]\tvalidation_0-auc:0.89944\tvalidation_1-auc:0.82928\n",
            "[17]\tvalidation_0-auc:0.90089\tvalidation_1-auc:0.82952\n",
            "[18]\tvalidation_0-auc:0.90151\tvalidation_1-auc:0.82975\n",
            "[19]\tvalidation_0-auc:0.90274\tvalidation_1-auc:0.82997\n",
            "[20]\tvalidation_0-auc:0.90377\tvalidation_1-auc:0.82981\n",
            "[21]\tvalidation_0-auc:0.90465\tvalidation_1-auc:0.82954\n",
            "[22]\tvalidation_0-auc:0.90638\tvalidation_1-auc:0.82978\n",
            "[23]\tvalidation_0-auc:0.90727\tvalidation_1-auc:0.83038\n",
            "[24]\tvalidation_0-auc:0.90778\tvalidation_1-auc:0.83103\n",
            "[25]\tvalidation_0-auc:0.90792\tvalidation_1-auc:0.83119\n",
            "[26]\tvalidation_0-auc:0.90876\tvalidation_1-auc:0.83099\n",
            "[27]\tvalidation_0-auc:0.90945\tvalidation_1-auc:0.83091\n",
            "[28]\tvalidation_0-auc:0.91059\tvalidation_1-auc:0.83035\n",
            "[29]\tvalidation_0-auc:0.91157\tvalidation_1-auc:0.83012\n",
            "[30]\tvalidation_0-auc:0.91235\tvalidation_1-auc:0.83011\n",
            "[31]\tvalidation_0-auc:0.91336\tvalidation_1-auc:0.82968\n",
            "[32]\tvalidation_0-auc:0.91433\tvalidation_1-auc:0.82962\n",
            "[33]\tvalidation_0-auc:0.91530\tvalidation_1-auc:0.82995\n",
            "[34]\tvalidation_0-auc:0.91623\tvalidation_1-auc:0.82991\n",
            "[35]\tvalidation_0-auc:0.91678\tvalidation_1-auc:0.82986\n",
            "[36]\tvalidation_0-auc:0.91730\tvalidation_1-auc:0.82959\n",
            "[37]\tvalidation_0-auc:0.91802\tvalidation_1-auc:0.82999\n",
            "[38]\tvalidation_0-auc:0.91857\tvalidation_1-auc:0.83025\n",
            "[39]\tvalidation_0-auc:0.91915\tvalidation_1-auc:0.83036\n",
            "[40]\tvalidation_0-auc:0.91971\tvalidation_1-auc:0.83029\n",
            "[41]\tvalidation_0-auc:0.92028\tvalidation_1-auc:0.83019\n",
            "[42]\tvalidation_0-auc:0.92067\tvalidation_1-auc:0.83008\n",
            "[43]\tvalidation_0-auc:0.92098\tvalidation_1-auc:0.83014\n",
            "[0]\tvalidation_0-auc:0.86128\tvalidation_1-auc:0.80753\n",
            "[1]\tvalidation_0-auc:0.86928\tvalidation_1-auc:0.81549\n",
            "[2]\tvalidation_0-auc:0.87324\tvalidation_1-auc:0.81048\n",
            "[3]\tvalidation_0-auc:0.87991\tvalidation_1-auc:0.81627\n",
            "[4]\tvalidation_0-auc:0.88252\tvalidation_1-auc:0.82234\n",
            "[5]\tvalidation_0-auc:0.88416\tvalidation_1-auc:0.82631\n",
            "[6]\tvalidation_0-auc:0.88717\tvalidation_1-auc:0.82814\n",
            "[7]\tvalidation_0-auc:0.88942\tvalidation_1-auc:0.82715\n",
            "[8]\tvalidation_0-auc:0.89132\tvalidation_1-auc:0.82810\n",
            "[9]\tvalidation_0-auc:0.89143\tvalidation_1-auc:0.82596\n",
            "[10]\tvalidation_0-auc:0.89353\tvalidation_1-auc:0.82723\n",
            "[11]\tvalidation_0-auc:0.89506\tvalidation_1-auc:0.82902\n",
            "[12]\tvalidation_0-auc:0.89690\tvalidation_1-auc:0.83010\n",
            "[13]\tvalidation_0-auc:0.89855\tvalidation_1-auc:0.83132\n",
            "[14]\tvalidation_0-auc:0.89932\tvalidation_1-auc:0.83148\n",
            "[15]\tvalidation_0-auc:0.90062\tvalidation_1-auc:0.83093\n",
            "[16]\tvalidation_0-auc:0.90195\tvalidation_1-auc:0.83113\n",
            "[17]\tvalidation_0-auc:0.90275\tvalidation_1-auc:0.83172\n",
            "[18]\tvalidation_0-auc:0.90367\tvalidation_1-auc:0.83249\n",
            "[19]\tvalidation_0-auc:0.90511\tvalidation_1-auc:0.83261\n",
            "[20]\tvalidation_0-auc:0.90635\tvalidation_1-auc:0.83150\n",
            "[21]\tvalidation_0-auc:0.90736\tvalidation_1-auc:0.83052\n",
            "[22]\tvalidation_0-auc:0.90865\tvalidation_1-auc:0.83051\n",
            "[23]\tvalidation_0-auc:0.90913\tvalidation_1-auc:0.83079\n",
            "[24]\tvalidation_0-auc:0.90962\tvalidation_1-auc:0.83150\n",
            "[25]\tvalidation_0-auc:0.91001\tvalidation_1-auc:0.83201\n",
            "[26]\tvalidation_0-auc:0.91079\tvalidation_1-auc:0.83236\n",
            "[27]\tvalidation_0-auc:0.91184\tvalidation_1-auc:0.83251\n",
            "[28]\tvalidation_0-auc:0.91305\tvalidation_1-auc:0.83182\n",
            "[29]\tvalidation_0-auc:0.91408\tvalidation_1-auc:0.83151\n",
            "[30]\tvalidation_0-auc:0.91482\tvalidation_1-auc:0.83188\n",
            "[31]\tvalidation_0-auc:0.91578\tvalidation_1-auc:0.83100\n",
            "[32]\tvalidation_0-auc:0.91661\tvalidation_1-auc:0.83139\n",
            "[33]\tvalidation_0-auc:0.91733\tvalidation_1-auc:0.83097\n",
            "[34]\tvalidation_0-auc:0.91811\tvalidation_1-auc:0.83106\n",
            "[35]\tvalidation_0-auc:0.91850\tvalidation_1-auc:0.83146\n",
            "[36]\tvalidation_0-auc:0.91885\tvalidation_1-auc:0.83142\n",
            "[37]\tvalidation_0-auc:0.91967\tvalidation_1-auc:0.83084\n",
            "[38]\tvalidation_0-auc:0.92014\tvalidation_1-auc:0.83148\n",
            "[39]\tvalidation_0-auc:0.92024\tvalidation_1-auc:0.83200\n",
            "[40]\tvalidation_0-auc:0.92081\tvalidation_1-auc:0.83175\n",
            "[41]\tvalidation_0-auc:0.92148\tvalidation_1-auc:0.83187\n",
            "[42]\tvalidation_0-auc:0.92199\tvalidation_1-auc:0.83197\n",
            "[43]\tvalidation_0-auc:0.92249\tvalidation_1-auc:0.83188\n",
            "[44]\tvalidation_0-auc:0.92316\tvalidation_1-auc:0.83151\n",
            "[45]\tvalidation_0-auc:0.92322\tvalidation_1-auc:0.83153\n",
            "[46]\tvalidation_0-auc:0.92382\tvalidation_1-auc:0.83132\n",
            "[47]\tvalidation_0-auc:0.92414\tvalidation_1-auc:0.83123\n",
            "[48]\tvalidation_0-auc:0.92444\tvalidation_1-auc:0.83126\n",
            "[49]\tvalidation_0-auc:0.92449\tvalidation_1-auc:0.83130\n",
            "[0]\tvalidation_0-auc:0.86327\tvalidation_1-auc:0.80869\n",
            "[1]\tvalidation_0-auc:0.87028\tvalidation_1-auc:0.82293\n",
            "[2]\tvalidation_0-auc:0.87324\tvalidation_1-auc:0.81790\n",
            "[3]\tvalidation_0-auc:0.87733\tvalidation_1-auc:0.82290\n",
            "[4]\tvalidation_0-auc:0.87817\tvalidation_1-auc:0.82548\n",
            "[5]\tvalidation_0-auc:0.88045\tvalidation_1-auc:0.82702\n",
            "[6]\tvalidation_0-auc:0.88365\tvalidation_1-auc:0.82608\n",
            "[7]\tvalidation_0-auc:0.88681\tvalidation_1-auc:0.82431\n",
            "[8]\tvalidation_0-auc:0.88820\tvalidation_1-auc:0.82513\n",
            "[9]\tvalidation_0-auc:0.88897\tvalidation_1-auc:0.82473\n",
            "[10]\tvalidation_0-auc:0.89167\tvalidation_1-auc:0.82593\n",
            "[11]\tvalidation_0-auc:0.89363\tvalidation_1-auc:0.82780\n",
            "[12]\tvalidation_0-auc:0.89583\tvalidation_1-auc:0.82776\n",
            "[13]\tvalidation_0-auc:0.89730\tvalidation_1-auc:0.82951\n",
            "[14]\tvalidation_0-auc:0.89805\tvalidation_1-auc:0.82901\n",
            "[15]\tvalidation_0-auc:0.89971\tvalidation_1-auc:0.82773\n",
            "[16]\tvalidation_0-auc:0.90136\tvalidation_1-auc:0.82799\n",
            "[17]\tvalidation_0-auc:0.90246\tvalidation_1-auc:0.82834\n",
            "[18]\tvalidation_0-auc:0.90315\tvalidation_1-auc:0.82856\n",
            "[19]\tvalidation_0-auc:0.90425\tvalidation_1-auc:0.82863\n",
            "[20]\tvalidation_0-auc:0.90582\tvalidation_1-auc:0.82748\n",
            "[21]\tvalidation_0-auc:0.90718\tvalidation_1-auc:0.82629\n",
            "[22]\tvalidation_0-auc:0.90853\tvalidation_1-auc:0.82728\n",
            "[23]\tvalidation_0-auc:0.90911\tvalidation_1-auc:0.82771\n",
            "[24]\tvalidation_0-auc:0.90946\tvalidation_1-auc:0.82826\n",
            "[25]\tvalidation_0-auc:0.90971\tvalidation_1-auc:0.82888\n",
            "[26]\tvalidation_0-auc:0.91072\tvalidation_1-auc:0.82965\n",
            "[27]\tvalidation_0-auc:0.91128\tvalidation_1-auc:0.83014\n",
            "[28]\tvalidation_0-auc:0.91218\tvalidation_1-auc:0.82967\n",
            "[29]\tvalidation_0-auc:0.91332\tvalidation_1-auc:0.82962\n",
            "[30]\tvalidation_0-auc:0.91440\tvalidation_1-auc:0.82983\n",
            "[31]\tvalidation_0-auc:0.91526\tvalidation_1-auc:0.82932\n",
            "[32]\tvalidation_0-auc:0.91595\tvalidation_1-auc:0.82962\n",
            "[33]\tvalidation_0-auc:0.91642\tvalidation_1-auc:0.82923\n",
            "[34]\tvalidation_0-auc:0.91717\tvalidation_1-auc:0.82897\n",
            "[35]\tvalidation_0-auc:0.91760\tvalidation_1-auc:0.82963\n",
            "[36]\tvalidation_0-auc:0.91772\tvalidation_1-auc:0.82940\n",
            "[37]\tvalidation_0-auc:0.91829\tvalidation_1-auc:0.82881\n",
            "[38]\tvalidation_0-auc:0.91876\tvalidation_1-auc:0.82929\n",
            "[39]\tvalidation_0-auc:0.91943\tvalidation_1-auc:0.82928\n",
            "[40]\tvalidation_0-auc:0.91980\tvalidation_1-auc:0.82901\n",
            "[41]\tvalidation_0-auc:0.92045\tvalidation_1-auc:0.82864\n",
            "[42]\tvalidation_0-auc:0.92116\tvalidation_1-auc:0.82817\n",
            "[43]\tvalidation_0-auc:0.92147\tvalidation_1-auc:0.82882\n",
            "[44]\tvalidation_0-auc:0.92209\tvalidation_1-auc:0.82819\n",
            "[45]\tvalidation_0-auc:0.92229\tvalidation_1-auc:0.82854\n",
            "[46]\tvalidation_0-auc:0.92309\tvalidation_1-auc:0.82861\n",
            "[47]\tvalidation_0-auc:0.92367\tvalidation_1-auc:0.82871\n",
            "[48]\tvalidation_0-auc:0.92403\tvalidation_1-auc:0.82877\n",
            "[49]\tvalidation_0-auc:0.92432\tvalidation_1-auc:0.82915\n",
            "[50]\tvalidation_0-auc:0.92445\tvalidation_1-auc:0.82908\n",
            "[51]\tvalidation_0-auc:0.92474\tvalidation_1-auc:0.82911\n",
            "[52]\tvalidation_0-auc:0.92495\tvalidation_1-auc:0.82909\n",
            "[53]\tvalidation_0-auc:0.92514\tvalidation_1-auc:0.82945\n",
            "[54]\tvalidation_0-auc:0.92556\tvalidation_1-auc:0.82924\n",
            "[55]\tvalidation_0-auc:0.92584\tvalidation_1-auc:0.82905\n",
            "[56]\tvalidation_0-auc:0.92609\tvalidation_1-auc:0.82902\n",
            "[0]\tvalidation_0-auc:0.87018\tvalidation_1-auc:0.79340\n",
            "[1]\tvalidation_0-auc:0.87664\tvalidation_1-auc:0.80769\n",
            "[2]\tvalidation_0-auc:0.87872\tvalidation_1-auc:0.80984\n",
            "[3]\tvalidation_0-auc:0.87971\tvalidation_1-auc:0.81098\n",
            "[4]\tvalidation_0-auc:0.88310\tvalidation_1-auc:0.81443\n",
            "[5]\tvalidation_0-auc:0.88430\tvalidation_1-auc:0.81758\n",
            "[6]\tvalidation_0-auc:0.88596\tvalidation_1-auc:0.81875\n",
            "[7]\tvalidation_0-auc:0.89244\tvalidation_1-auc:0.82002\n",
            "[8]\tvalidation_0-auc:0.89431\tvalidation_1-auc:0.82149\n",
            "[9]\tvalidation_0-auc:0.89429\tvalidation_1-auc:0.82258\n",
            "[10]\tvalidation_0-auc:0.89535\tvalidation_1-auc:0.82339\n",
            "[11]\tvalidation_0-auc:0.89676\tvalidation_1-auc:0.82397\n",
            "[12]\tvalidation_0-auc:0.89797\tvalidation_1-auc:0.82330\n",
            "[13]\tvalidation_0-auc:0.89903\tvalidation_1-auc:0.82434\n",
            "[14]\tvalidation_0-auc:0.89980\tvalidation_1-auc:0.82517\n",
            "[15]\tvalidation_0-auc:0.90003\tvalidation_1-auc:0.82554\n",
            "[16]\tvalidation_0-auc:0.90108\tvalidation_1-auc:0.82551\n",
            "[17]\tvalidation_0-auc:0.90176\tvalidation_1-auc:0.82549\n",
            "[18]\tvalidation_0-auc:0.90167\tvalidation_1-auc:0.82599\n",
            "[19]\tvalidation_0-auc:0.90202\tvalidation_1-auc:0.82606\n",
            "[20]\tvalidation_0-auc:0.90371\tvalidation_1-auc:0.82703\n",
            "[21]\tvalidation_0-auc:0.90538\tvalidation_1-auc:0.82737\n",
            "[22]\tvalidation_0-auc:0.90573\tvalidation_1-auc:0.82805\n",
            "[23]\tvalidation_0-auc:0.90664\tvalidation_1-auc:0.82805\n",
            "[24]\tvalidation_0-auc:0.90720\tvalidation_1-auc:0.82854\n",
            "[25]\tvalidation_0-auc:0.90763\tvalidation_1-auc:0.82902\n",
            "[26]\tvalidation_0-auc:0.90840\tvalidation_1-auc:0.82899\n",
            "[27]\tvalidation_0-auc:0.90889\tvalidation_1-auc:0.82871\n",
            "[28]\tvalidation_0-auc:0.90971\tvalidation_1-auc:0.82800\n",
            "[29]\tvalidation_0-auc:0.90992\tvalidation_1-auc:0.82790\n",
            "[30]\tvalidation_0-auc:0.91093\tvalidation_1-auc:0.82839\n",
            "[31]\tvalidation_0-auc:0.91139\tvalidation_1-auc:0.82841\n",
            "[32]\tvalidation_0-auc:0.91167\tvalidation_1-auc:0.82828\n",
            "[33]\tvalidation_0-auc:0.91181\tvalidation_1-auc:0.82789\n",
            "[34]\tvalidation_0-auc:0.91224\tvalidation_1-auc:0.82761\n",
            "[35]\tvalidation_0-auc:0.91233\tvalidation_1-auc:0.82779\n",
            "[36]\tvalidation_0-auc:0.91289\tvalidation_1-auc:0.82755\n",
            "[37]\tvalidation_0-auc:0.91344\tvalidation_1-auc:0.82745\n",
            "[38]\tvalidation_0-auc:0.91401\tvalidation_1-auc:0.82740\n",
            "[39]\tvalidation_0-auc:0.91456\tvalidation_1-auc:0.82726\n",
            "[40]\tvalidation_0-auc:0.91497\tvalidation_1-auc:0.82730\n",
            "[41]\tvalidation_0-auc:0.91562\tvalidation_1-auc:0.82704\n",
            "[42]\tvalidation_0-auc:0.91614\tvalidation_1-auc:0.82717\n",
            "[43]\tvalidation_0-auc:0.91649\tvalidation_1-auc:0.82726\n",
            "[44]\tvalidation_0-auc:0.91732\tvalidation_1-auc:0.82750\n",
            "[45]\tvalidation_0-auc:0.91797\tvalidation_1-auc:0.82748\n",
            "[46]\tvalidation_0-auc:0.91853\tvalidation_1-auc:0.82738\n",
            "[47]\tvalidation_0-auc:0.91919\tvalidation_1-auc:0.82714\n",
            "[48]\tvalidation_0-auc:0.91980\tvalidation_1-auc:0.82719\n",
            "[49]\tvalidation_0-auc:0.92048\tvalidation_1-auc:0.82724\n",
            "[50]\tvalidation_0-auc:0.92072\tvalidation_1-auc:0.82778\n",
            "[51]\tvalidation_0-auc:0.92147\tvalidation_1-auc:0.82810\n",
            "[52]\tvalidation_0-auc:0.92193\tvalidation_1-auc:0.82840\n",
            "[53]\tvalidation_0-auc:0.92246\tvalidation_1-auc:0.82881\n",
            "[54]\tvalidation_0-auc:0.92313\tvalidation_1-auc:0.82882\n",
            "[0]\tvalidation_0-auc:0.86731\tvalidation_1-auc:0.80815\n",
            "[1]\tvalidation_0-auc:0.87580\tvalidation_1-auc:0.81518\n",
            "[2]\tvalidation_0-auc:0.88032\tvalidation_1-auc:0.81637\n",
            "[3]\tvalidation_0-auc:0.88468\tvalidation_1-auc:0.81818\n",
            "[4]\tvalidation_0-auc:0.88605\tvalidation_1-auc:0.82032\n",
            "[5]\tvalidation_0-auc:0.88737\tvalidation_1-auc:0.82453\n",
            "[6]\tvalidation_0-auc:0.88892\tvalidation_1-auc:0.82510\n",
            "[7]\tvalidation_0-auc:0.89316\tvalidation_1-auc:0.82640\n",
            "[8]\tvalidation_0-auc:0.89566\tvalidation_1-auc:0.82617\n",
            "[9]\tvalidation_0-auc:0.89564\tvalidation_1-auc:0.82728\n",
            "[10]\tvalidation_0-auc:0.89650\tvalidation_1-auc:0.82637\n",
            "[11]\tvalidation_0-auc:0.89804\tvalidation_1-auc:0.82740\n",
            "[12]\tvalidation_0-auc:0.89934\tvalidation_1-auc:0.82742\n",
            "[13]\tvalidation_0-auc:0.90006\tvalidation_1-auc:0.82813\n",
            "[14]\tvalidation_0-auc:0.90057\tvalidation_1-auc:0.82861\n",
            "[15]\tvalidation_0-auc:0.90188\tvalidation_1-auc:0.82862\n",
            "[16]\tvalidation_0-auc:0.90290\tvalidation_1-auc:0.82947\n",
            "[17]\tvalidation_0-auc:0.90327\tvalidation_1-auc:0.82924\n",
            "[18]\tvalidation_0-auc:0.90397\tvalidation_1-auc:0.83013\n",
            "[19]\tvalidation_0-auc:0.90458\tvalidation_1-auc:0.83021\n",
            "[20]\tvalidation_0-auc:0.90635\tvalidation_1-auc:0.83012\n",
            "[21]\tvalidation_0-auc:0.90689\tvalidation_1-auc:0.82991\n",
            "[22]\tvalidation_0-auc:0.90749\tvalidation_1-auc:0.83003\n",
            "[23]\tvalidation_0-auc:0.90840\tvalidation_1-auc:0.82989\n",
            "[24]\tvalidation_0-auc:0.90872\tvalidation_1-auc:0.83045\n",
            "[25]\tvalidation_0-auc:0.90873\tvalidation_1-auc:0.83058\n",
            "[26]\tvalidation_0-auc:0.90943\tvalidation_1-auc:0.83048\n",
            "[27]\tvalidation_0-auc:0.91042\tvalidation_1-auc:0.83053\n",
            "[28]\tvalidation_0-auc:0.91112\tvalidation_1-auc:0.83038\n",
            "[29]\tvalidation_0-auc:0.91113\tvalidation_1-auc:0.83064\n",
            "[30]\tvalidation_0-auc:0.91179\tvalidation_1-auc:0.83026\n",
            "[31]\tvalidation_0-auc:0.91248\tvalidation_1-auc:0.82994\n",
            "[32]\tvalidation_0-auc:0.91291\tvalidation_1-auc:0.82981\n",
            "[33]\tvalidation_0-auc:0.91338\tvalidation_1-auc:0.83022\n",
            "[34]\tvalidation_0-auc:0.91393\tvalidation_1-auc:0.83042\n",
            "[35]\tvalidation_0-auc:0.91447\tvalidation_1-auc:0.83060\n",
            "[36]\tvalidation_0-auc:0.91514\tvalidation_1-auc:0.83069\n",
            "[37]\tvalidation_0-auc:0.91568\tvalidation_1-auc:0.83063\n",
            "[38]\tvalidation_0-auc:0.91629\tvalidation_1-auc:0.83089\n",
            "[39]\tvalidation_0-auc:0.91673\tvalidation_1-auc:0.83097\n",
            "[40]\tvalidation_0-auc:0.91723\tvalidation_1-auc:0.83102\n",
            "[41]\tvalidation_0-auc:0.91787\tvalidation_1-auc:0.83096\n",
            "[42]\tvalidation_0-auc:0.91830\tvalidation_1-auc:0.83139\n",
            "[43]\tvalidation_0-auc:0.91872\tvalidation_1-auc:0.83180\n",
            "[44]\tvalidation_0-auc:0.91958\tvalidation_1-auc:0.83172\n",
            "[45]\tvalidation_0-auc:0.92023\tvalidation_1-auc:0.83156\n",
            "[46]\tvalidation_0-auc:0.92083\tvalidation_1-auc:0.83152\n",
            "[47]\tvalidation_0-auc:0.92135\tvalidation_1-auc:0.83143\n",
            "[48]\tvalidation_0-auc:0.92188\tvalidation_1-auc:0.83114\n",
            "[49]\tvalidation_0-auc:0.92229\tvalidation_1-auc:0.83142\n",
            "[50]\tvalidation_0-auc:0.92253\tvalidation_1-auc:0.83134\n",
            "[51]\tvalidation_0-auc:0.92303\tvalidation_1-auc:0.83127\n",
            "[52]\tvalidation_0-auc:0.92373\tvalidation_1-auc:0.83142\n",
            "[53]\tvalidation_0-auc:0.92414\tvalidation_1-auc:0.83125\n",
            "[54]\tvalidation_0-auc:0.92489\tvalidation_1-auc:0.83094\n",
            "[55]\tvalidation_0-auc:0.92536\tvalidation_1-auc:0.83067\n",
            "[56]\tvalidation_0-auc:0.92592\tvalidation_1-auc:0.83069\n",
            "[57]\tvalidation_0-auc:0.92645\tvalidation_1-auc:0.83071\n",
            "[58]\tvalidation_0-auc:0.92704\tvalidation_1-auc:0.83059\n",
            "[59]\tvalidation_0-auc:0.92751\tvalidation_1-auc:0.83059\n",
            "[60]\tvalidation_0-auc:0.92789\tvalidation_1-auc:0.83068\n",
            "[61]\tvalidation_0-auc:0.92821\tvalidation_1-auc:0.83050\n",
            "[62]\tvalidation_0-auc:0.92856\tvalidation_1-auc:0.83044\n",
            "[63]\tvalidation_0-auc:0.92890\tvalidation_1-auc:0.83029\n",
            "[64]\tvalidation_0-auc:0.92933\tvalidation_1-auc:0.83030\n",
            "[65]\tvalidation_0-auc:0.92975\tvalidation_1-auc:0.83022\n",
            "[66]\tvalidation_0-auc:0.93012\tvalidation_1-auc:0.83031\n",
            "[67]\tvalidation_0-auc:0.93059\tvalidation_1-auc:0.83035\n",
            "[68]\tvalidation_0-auc:0.93103\tvalidation_1-auc:0.83011\n",
            "[69]\tvalidation_0-auc:0.93141\tvalidation_1-auc:0.83003\n",
            "[70]\tvalidation_0-auc:0.93165\tvalidation_1-auc:0.82994\n",
            "[71]\tvalidation_0-auc:0.93198\tvalidation_1-auc:0.82985\n",
            "[72]\tvalidation_0-auc:0.93243\tvalidation_1-auc:0.82961\n",
            "[0]\tvalidation_0-auc:0.87117\tvalidation_1-auc:0.80649\n",
            "[1]\tvalidation_0-auc:0.87776\tvalidation_1-auc:0.81317\n",
            "[2]\tvalidation_0-auc:0.88153\tvalidation_1-auc:0.81684\n",
            "[3]\tvalidation_0-auc:0.88429\tvalidation_1-auc:0.81583\n",
            "[4]\tvalidation_0-auc:0.88445\tvalidation_1-auc:0.81900\n",
            "[5]\tvalidation_0-auc:0.88494\tvalidation_1-auc:0.82284\n",
            "[6]\tvalidation_0-auc:0.88619\tvalidation_1-auc:0.82231\n",
            "[7]\tvalidation_0-auc:0.89240\tvalidation_1-auc:0.82226\n",
            "[8]\tvalidation_0-auc:0.89332\tvalidation_1-auc:0.82222\n",
            "[9]\tvalidation_0-auc:0.89343\tvalidation_1-auc:0.82374\n",
            "[10]\tvalidation_0-auc:0.89450\tvalidation_1-auc:0.82416\n",
            "[11]\tvalidation_0-auc:0.89542\tvalidation_1-auc:0.82420\n",
            "[12]\tvalidation_0-auc:0.89690\tvalidation_1-auc:0.82411\n",
            "[13]\tvalidation_0-auc:0.89752\tvalidation_1-auc:0.82331\n",
            "[14]\tvalidation_0-auc:0.89847\tvalidation_1-auc:0.82337\n",
            "[15]\tvalidation_0-auc:0.89946\tvalidation_1-auc:0.82422\n",
            "[16]\tvalidation_0-auc:0.90004\tvalidation_1-auc:0.82472\n",
            "[17]\tvalidation_0-auc:0.90085\tvalidation_1-auc:0.82505\n",
            "[18]\tvalidation_0-auc:0.90145\tvalidation_1-auc:0.82542\n",
            "[19]\tvalidation_0-auc:0.90174\tvalidation_1-auc:0.82529\n",
            "[20]\tvalidation_0-auc:0.90305\tvalidation_1-auc:0.82480\n",
            "[21]\tvalidation_0-auc:0.90467\tvalidation_1-auc:0.82430\n",
            "[22]\tvalidation_0-auc:0.90596\tvalidation_1-auc:0.82506\n",
            "[23]\tvalidation_0-auc:0.90662\tvalidation_1-auc:0.82534\n",
            "[24]\tvalidation_0-auc:0.90703\tvalidation_1-auc:0.82601\n",
            "[25]\tvalidation_0-auc:0.90746\tvalidation_1-auc:0.82642\n",
            "[26]\tvalidation_0-auc:0.90802\tvalidation_1-auc:0.82624\n",
            "[27]\tvalidation_0-auc:0.90911\tvalidation_1-auc:0.82615\n",
            "[28]\tvalidation_0-auc:0.91017\tvalidation_1-auc:0.82592\n",
            "[29]\tvalidation_0-auc:0.91045\tvalidation_1-auc:0.82605\n",
            "[30]\tvalidation_0-auc:0.91119\tvalidation_1-auc:0.82579\n",
            "[31]\tvalidation_0-auc:0.91161\tvalidation_1-auc:0.82570\n",
            "[32]\tvalidation_0-auc:0.91217\tvalidation_1-auc:0.82563\n",
            "[33]\tvalidation_0-auc:0.91267\tvalidation_1-auc:0.82590\n",
            "[34]\tvalidation_0-auc:0.91305\tvalidation_1-auc:0.82571\n",
            "[35]\tvalidation_0-auc:0.91332\tvalidation_1-auc:0.82615\n",
            "[36]\tvalidation_0-auc:0.91420\tvalidation_1-auc:0.82621\n",
            "[37]\tvalidation_0-auc:0.91479\tvalidation_1-auc:0.82566\n",
            "[38]\tvalidation_0-auc:0.91535\tvalidation_1-auc:0.82520\n",
            "[39]\tvalidation_0-auc:0.91615\tvalidation_1-auc:0.82542\n",
            "[40]\tvalidation_0-auc:0.91663\tvalidation_1-auc:0.82529\n",
            "[41]\tvalidation_0-auc:0.91732\tvalidation_1-auc:0.82536\n",
            "[42]\tvalidation_0-auc:0.91794\tvalidation_1-auc:0.82571\n",
            "[43]\tvalidation_0-auc:0.91809\tvalidation_1-auc:0.82625\n",
            "[44]\tvalidation_0-auc:0.91919\tvalidation_1-auc:0.82584\n",
            "[45]\tvalidation_0-auc:0.91959\tvalidation_1-auc:0.82590\n",
            "[46]\tvalidation_0-auc:0.92023\tvalidation_1-auc:0.82608\n",
            "[47]\tvalidation_0-auc:0.92065\tvalidation_1-auc:0.82608\n",
            "[48]\tvalidation_0-auc:0.92105\tvalidation_1-auc:0.82648\n",
            "[49]\tvalidation_0-auc:0.92142\tvalidation_1-auc:0.82668\n",
            "[50]\tvalidation_0-auc:0.92171\tvalidation_1-auc:0.82681\n",
            "[51]\tvalidation_0-auc:0.92237\tvalidation_1-auc:0.82714\n",
            "[52]\tvalidation_0-auc:0.92300\tvalidation_1-auc:0.82737\n",
            "[53]\tvalidation_0-auc:0.92363\tvalidation_1-auc:0.82746\n",
            "[54]\tvalidation_0-auc:0.92427\tvalidation_1-auc:0.82699\n",
            "[55]\tvalidation_0-auc:0.92462\tvalidation_1-auc:0.82730\n",
            "[56]\tvalidation_0-auc:0.92507\tvalidation_1-auc:0.82771\n",
            "[57]\tvalidation_0-auc:0.92564\tvalidation_1-auc:0.82851\n",
            "[58]\tvalidation_0-auc:0.92607\tvalidation_1-auc:0.82870\n",
            "[59]\tvalidation_0-auc:0.92633\tvalidation_1-auc:0.82885\n",
            "[60]\tvalidation_0-auc:0.92684\tvalidation_1-auc:0.82899\n",
            "[61]\tvalidation_0-auc:0.92703\tvalidation_1-auc:0.82920\n",
            "[62]\tvalidation_0-auc:0.92751\tvalidation_1-auc:0.82942\n",
            "[63]\tvalidation_0-auc:0.92796\tvalidation_1-auc:0.82957\n",
            "[64]\tvalidation_0-auc:0.92823\tvalidation_1-auc:0.82951\n",
            "[65]\tvalidation_0-auc:0.92868\tvalidation_1-auc:0.82979\n",
            "[66]\tvalidation_0-auc:0.92898\tvalidation_1-auc:0.82983\n",
            "[67]\tvalidation_0-auc:0.92947\tvalidation_1-auc:0.83005\n",
            "[68]\tvalidation_0-auc:0.92985\tvalidation_1-auc:0.82994\n",
            "[69]\tvalidation_0-auc:0.93054\tvalidation_1-auc:0.82960\n",
            "[70]\tvalidation_0-auc:0.93081\tvalidation_1-auc:0.82957\n",
            "[71]\tvalidation_0-auc:0.93114\tvalidation_1-auc:0.82960\n",
            "[72]\tvalidation_0-auc:0.93144\tvalidation_1-auc:0.82946\n",
            "[73]\tvalidation_0-auc:0.93167\tvalidation_1-auc:0.82954\n",
            "[74]\tvalidation_0-auc:0.93198\tvalidation_1-auc:0.82960\n",
            "[75]\tvalidation_0-auc:0.93232\tvalidation_1-auc:0.82962\n",
            "[76]\tvalidation_0-auc:0.93251\tvalidation_1-auc:0.82965\n",
            "[77]\tvalidation_0-auc:0.93283\tvalidation_1-auc:0.82951\n",
            "[78]\tvalidation_0-auc:0.93304\tvalidation_1-auc:0.82955\n",
            "[79]\tvalidation_0-auc:0.93348\tvalidation_1-auc:0.82918\n",
            "[80]\tvalidation_0-auc:0.93377\tvalidation_1-auc:0.82924\n",
            "[81]\tvalidation_0-auc:0.93434\tvalidation_1-auc:0.82907\n",
            "[82]\tvalidation_0-auc:0.93450\tvalidation_1-auc:0.82911\n",
            "[83]\tvalidation_0-auc:0.93482\tvalidation_1-auc:0.82904\n",
            "[84]\tvalidation_0-auc:0.93509\tvalidation_1-auc:0.82880\n",
            "[85]\tvalidation_0-auc:0.93522\tvalidation_1-auc:0.82879\n",
            "[86]\tvalidation_0-auc:0.93547\tvalidation_1-auc:0.82868\n",
            "[87]\tvalidation_0-auc:0.93576\tvalidation_1-auc:0.82859\n",
            "[88]\tvalidation_0-auc:0.93597\tvalidation_1-auc:0.82855\n",
            "[89]\tvalidation_0-auc:0.93616\tvalidation_1-auc:0.82867\n",
            "[90]\tvalidation_0-auc:0.93645\tvalidation_1-auc:0.82861\n",
            "[91]\tvalidation_0-auc:0.93669\tvalidation_1-auc:0.82873\n",
            "[92]\tvalidation_0-auc:0.93699\tvalidation_1-auc:0.82881\n",
            "[93]\tvalidation_0-auc:0.93716\tvalidation_1-auc:0.82899\n",
            "[94]\tvalidation_0-auc:0.93734\tvalidation_1-auc:0.82904\n",
            "[95]\tvalidation_0-auc:0.93768\tvalidation_1-auc:0.82885\n",
            "[96]\tvalidation_0-auc:0.93784\tvalidation_1-auc:0.82876\n",
            "100%|██████████| 50/50 [53:59<00:00, 64.80s/trial, best loss: -0.8382516761288219]\n",
            "best: {'colsample_bytree': np.float64(0.6848964687546426), 'learning_rate': np.float64(0.0709453695953271), 'max_depth': np.float64(6.0), 'min_child_weight': np.float64(5.0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6 최적값으로 Tuning 실시후 재평가\n",
        "\n",
        "# n_estimators를 100으로 설정 후 최적으로 찾은 하이퍼 파라미터를 기반으로 학습과 예측 수행.\n",
        "xgb_clf = XGBClassifier(n_estimators=100, learning_rate=round(best['learning_rate'], 7),\n",
        "                        max_depth=int(best['max_depth']), min_child_weight=int(best['min_child_weight']),\n",
        "                        colsample_bytree=round(best['colsample_bytree'], 5),\n",
        "                        eval_metric=\"auc\",  # Move eval_metric here\n",
        "                        early_stopping_rounds=100  # Move early_stopping_rounds here\n",
        "                       )\n",
        "\n",
        "# evaluation metric을 auc로, early stopping은 100 으로 설정하고 학습 수행.\n",
        "# Remove eval_metric and early_stopping_rounds from fit()\n",
        "xgb_clf.fit(X_tr, y_tr,\n",
        "            eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
        "\n",
        "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
        "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))\n",
        "\n",
        "# ROC AUC 0.8458 로 상승"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy04wP1Zxxk3",
        "outputId": "02192e3a-1842-4621-9275-55e1506f8146"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83045\tvalidation_1-auc:0.80645\n",
            "[1]\tvalidation_0-auc:0.83974\tvalidation_1-auc:0.81870\n",
            "[2]\tvalidation_0-auc:0.84078\tvalidation_1-auc:0.81272\n",
            "[3]\tvalidation_0-auc:0.84938\tvalidation_1-auc:0.82092\n",
            "[4]\tvalidation_0-auc:0.85063\tvalidation_1-auc:0.82243\n",
            "[5]\tvalidation_0-auc:0.85195\tvalidation_1-auc:0.82649\n",
            "[6]\tvalidation_0-auc:0.85325\tvalidation_1-auc:0.82755\n",
            "[7]\tvalidation_0-auc:0.85389\tvalidation_1-auc:0.82722\n",
            "[8]\tvalidation_0-auc:0.85439\tvalidation_1-auc:0.82783\n",
            "[9]\tvalidation_0-auc:0.85543\tvalidation_1-auc:0.82861\n",
            "[10]\tvalidation_0-auc:0.85612\tvalidation_1-auc:0.82910\n",
            "[11]\tvalidation_0-auc:0.85650\tvalidation_1-auc:0.82989\n",
            "[12]\tvalidation_0-auc:0.85704\tvalidation_1-auc:0.82973\n",
            "[13]\tvalidation_0-auc:0.85759\tvalidation_1-auc:0.82963\n",
            "[14]\tvalidation_0-auc:0.85790\tvalidation_1-auc:0.83023\n",
            "[15]\tvalidation_0-auc:0.85846\tvalidation_1-auc:0.83092\n",
            "[16]\tvalidation_0-auc:0.85894\tvalidation_1-auc:0.83188\n",
            "[17]\tvalidation_0-auc:0.85936\tvalidation_1-auc:0.83268\n",
            "[18]\tvalidation_0-auc:0.85985\tvalidation_1-auc:0.83276\n",
            "[19]\tvalidation_0-auc:0.86068\tvalidation_1-auc:0.83362\n",
            "[20]\tvalidation_0-auc:0.86146\tvalidation_1-auc:0.83407\n",
            "[21]\tvalidation_0-auc:0.86218\tvalidation_1-auc:0.83401\n",
            "[22]\tvalidation_0-auc:0.86274\tvalidation_1-auc:0.83370\n",
            "[23]\tvalidation_0-auc:0.86319\tvalidation_1-auc:0.83379\n",
            "[24]\tvalidation_0-auc:0.86366\tvalidation_1-auc:0.83429\n",
            "[25]\tvalidation_0-auc:0.86409\tvalidation_1-auc:0.83515\n",
            "[26]\tvalidation_0-auc:0.86449\tvalidation_1-auc:0.83576\n",
            "[27]\tvalidation_0-auc:0.86528\tvalidation_1-auc:0.83633\n",
            "[28]\tvalidation_0-auc:0.86570\tvalidation_1-auc:0.83617\n",
            "[29]\tvalidation_0-auc:0.86638\tvalidation_1-auc:0.83667\n",
            "[30]\tvalidation_0-auc:0.86732\tvalidation_1-auc:0.83686\n",
            "[31]\tvalidation_0-auc:0.86823\tvalidation_1-auc:0.83689\n",
            "[32]\tvalidation_0-auc:0.86877\tvalidation_1-auc:0.83700\n",
            "[33]\tvalidation_0-auc:0.86913\tvalidation_1-auc:0.83734\n",
            "[34]\tvalidation_0-auc:0.86969\tvalidation_1-auc:0.83722\n",
            "[35]\tvalidation_0-auc:0.87017\tvalidation_1-auc:0.83770\n",
            "[36]\tvalidation_0-auc:0.87087\tvalidation_1-auc:0.83797\n",
            "[37]\tvalidation_0-auc:0.87135\tvalidation_1-auc:0.83793\n",
            "[38]\tvalidation_0-auc:0.87187\tvalidation_1-auc:0.83846\n",
            "[39]\tvalidation_0-auc:0.87244\tvalidation_1-auc:0.83854\n",
            "[40]\tvalidation_0-auc:0.87298\tvalidation_1-auc:0.83850\n",
            "[41]\tvalidation_0-auc:0.87327\tvalidation_1-auc:0.83809\n",
            "[42]\tvalidation_0-auc:0.87390\tvalidation_1-auc:0.83780\n",
            "[43]\tvalidation_0-auc:0.87435\tvalidation_1-auc:0.83767\n",
            "[44]\tvalidation_0-auc:0.87465\tvalidation_1-auc:0.83750\n",
            "[45]\tvalidation_0-auc:0.87526\tvalidation_1-auc:0.83763\n",
            "[46]\tvalidation_0-auc:0.87570\tvalidation_1-auc:0.83744\n",
            "[47]\tvalidation_0-auc:0.87626\tvalidation_1-auc:0.83761\n",
            "[48]\tvalidation_0-auc:0.87680\tvalidation_1-auc:0.83793\n",
            "[49]\tvalidation_0-auc:0.87715\tvalidation_1-auc:0.83825\n",
            "[50]\tvalidation_0-auc:0.87738\tvalidation_1-auc:0.83845\n",
            "[51]\tvalidation_0-auc:0.87760\tvalidation_1-auc:0.83875\n",
            "[52]\tvalidation_0-auc:0.87786\tvalidation_1-auc:0.83855\n",
            "[53]\tvalidation_0-auc:0.87811\tvalidation_1-auc:0.83857\n",
            "[54]\tvalidation_0-auc:0.87842\tvalidation_1-auc:0.83854\n",
            "[55]\tvalidation_0-auc:0.87885\tvalidation_1-auc:0.83863\n",
            "[56]\tvalidation_0-auc:0.87904\tvalidation_1-auc:0.83872\n",
            "[57]\tvalidation_0-auc:0.87915\tvalidation_1-auc:0.83889\n",
            "[58]\tvalidation_0-auc:0.87935\tvalidation_1-auc:0.83893\n",
            "[59]\tvalidation_0-auc:0.87957\tvalidation_1-auc:0.83912\n",
            "[60]\tvalidation_0-auc:0.87973\tvalidation_1-auc:0.83899\n",
            "[61]\tvalidation_0-auc:0.87983\tvalidation_1-auc:0.83925\n",
            "[62]\tvalidation_0-auc:0.88012\tvalidation_1-auc:0.83962\n",
            "[63]\tvalidation_0-auc:0.88030\tvalidation_1-auc:0.83959\n",
            "[64]\tvalidation_0-auc:0.88058\tvalidation_1-auc:0.83975\n",
            "[65]\tvalidation_0-auc:0.88095\tvalidation_1-auc:0.83967\n",
            "[66]\tvalidation_0-auc:0.88108\tvalidation_1-auc:0.83987\n",
            "[67]\tvalidation_0-auc:0.88128\tvalidation_1-auc:0.84026\n",
            "[68]\tvalidation_0-auc:0.88182\tvalidation_1-auc:0.84008\n",
            "[69]\tvalidation_0-auc:0.88213\tvalidation_1-auc:0.84005\n",
            "[70]\tvalidation_0-auc:0.88226\tvalidation_1-auc:0.84022\n",
            "[71]\tvalidation_0-auc:0.88232\tvalidation_1-auc:0.84033\n",
            "[72]\tvalidation_0-auc:0.88278\tvalidation_1-auc:0.84017\n",
            "[73]\tvalidation_0-auc:0.88288\tvalidation_1-auc:0.84005\n",
            "[74]\tvalidation_0-auc:0.88302\tvalidation_1-auc:0.84006\n",
            "[75]\tvalidation_0-auc:0.88311\tvalidation_1-auc:0.84022\n",
            "[76]\tvalidation_0-auc:0.88338\tvalidation_1-auc:0.84018\n",
            "[77]\tvalidation_0-auc:0.88373\tvalidation_1-auc:0.84031\n",
            "[78]\tvalidation_0-auc:0.88413\tvalidation_1-auc:0.84022\n",
            "[79]\tvalidation_0-auc:0.88422\tvalidation_1-auc:0.84023\n",
            "[80]\tvalidation_0-auc:0.88449\tvalidation_1-auc:0.84024\n",
            "[81]\tvalidation_0-auc:0.88469\tvalidation_1-auc:0.84034\n",
            "[82]\tvalidation_0-auc:0.88477\tvalidation_1-auc:0.84026\n",
            "[83]\tvalidation_0-auc:0.88484\tvalidation_1-auc:0.84022\n",
            "[84]\tvalidation_0-auc:0.88490\tvalidation_1-auc:0.84021\n",
            "[85]\tvalidation_0-auc:0.88498\tvalidation_1-auc:0.84038\n",
            "[86]\tvalidation_0-auc:0.88529\tvalidation_1-auc:0.84052\n",
            "[87]\tvalidation_0-auc:0.88558\tvalidation_1-auc:0.84052\n",
            "[88]\tvalidation_0-auc:0.88581\tvalidation_1-auc:0.84056\n",
            "[89]\tvalidation_0-auc:0.88608\tvalidation_1-auc:0.84061\n",
            "[90]\tvalidation_0-auc:0.88664\tvalidation_1-auc:0.84059\n",
            "[91]\tvalidation_0-auc:0.88695\tvalidation_1-auc:0.84080\n",
            "[92]\tvalidation_0-auc:0.88734\tvalidation_1-auc:0.84084\n",
            "[93]\tvalidation_0-auc:0.88763\tvalidation_1-auc:0.84099\n",
            "[94]\tvalidation_0-auc:0.88785\tvalidation_1-auc:0.84101\n",
            "[95]\tvalidation_0-auc:0.88814\tvalidation_1-auc:0.84101\n",
            "[96]\tvalidation_0-auc:0.88825\tvalidation_1-auc:0.84097\n",
            "[97]\tvalidation_0-auc:0.88834\tvalidation_1-auc:0.84100\n",
            "[98]\tvalidation_0-auc:0.88841\tvalidation_1-auc:0.84101\n",
            "[99]\tvalidation_0-auc:0.88864\tvalidation_1-auc:0.84103\n",
            "ROC AUC: 0.8458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra :  XGBoost에서 중요한 feature는 var38 & var15\n",
        "from xgboost import plot_importance\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "plot_importance(xgb_clf, ax=ax , max_num_features=20,height=0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "32J7f6dKySVV",
        "outputId": "48e7ba6d-6bbd-4840-f255-ede4275681d8"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/gAAAK9CAYAAACQOcf8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3XlcTfn/B/DXbXHbd1S0UFFMkjIkM5JoGU1kGWkQYZjB2LPLlD1iZPka+6hhxjozsmQJQ2WNYRJFkyX7KBVt9/7+8Oj8XHVzreV6PR+P+9A9n8/5nPe5fUrv8/mczxFJpVIpiIiIiIiIiOiDplLdARARERERERHRm2OCT0RERERERKQEmOATERERERERKQEm+ERERERERERKgAk+ERERERERkRJggk9ERERERESkBJjgExERERERESkBJvhERERERERESoAJPhEREREREZESYIJPRERE9J6sW7cOIpEIWVlZ1R0KEREpISb4RERE9M6UJ7SVvSZMmPBOjnn8+HGEh4fj0aNH76T9j1lhYSHCw8ORmJhY3aEQEVEl1Ko7ACIiIlJ+P/zwAxo0aCCz7ZNPPnknxzp+/DhmzJiBkJAQGBgYvJNjvK4+ffqgV69eEIvF1R3KayksLMSMGTMAAB4eHtUbDBERVcAEn4iIiN45X19fuLq6VncYb6SgoADa2tpv1IaqqipUVVXfUkTvj0QiQXFxcXWHQUREL8Ep+kRERFTtdu/ejc8++wza2trQ1dXFF198gYsXL8rUOX/+PEJCQtCwYUNoaGjA1NQUAwYMwIMHD4Q64eHhGDduHACgQYMGwu0AWVlZyMrKgkgkwrp16yocXyQSITw8XKYdkUiEf/75B71794ahoSHatm0rlG/cuBEuLi7Q1NSEkZERevXqhevXr7/0PCu7B9/a2hqdO3dGYmIiXF1doampCUdHR2Ea/LZt2+Do6AgNDQ24uLjg7NmzMm2GhIRAR0cHV69ehbe3N7S1tWFubo4ffvgBUqlUpm5BQQHGjBkDCwsLiMViNG7cGFFRURXqiUQiDBs2DLGxsWjatCnEYjFWrFiB2rVrAwBmzJghfLbln5si35/nP9uMjAxhloW+vj769++PwsLCCp/Zxo0b8emnn0JLSwuGhob4/PPPsW/fPpk6ivQfIqKPAUfwiYiI6J3Lzc3F/fv3ZbaZmJgAAH7++Wf069cP3t7emDt3LgoLC7F8+XK0bdsWZ8+ehbW1NQAgISEBV69eRf/+/WFqaoqLFy9i5cqVuHjxIpKTkyESiRAYGIjLly/jl19+QXR0tHCM2rVr4969e68cd48ePWBnZ4dZs2YJSfDMmTMxdepU9OzZEwMHDsS9e/ewZMkSfP755zh79uxr3RaQkZGB3r1745tvvsHXX3+NqKgo+Pv7Y8WKFZg0aRK+/fZbAMDs2bPRs2dPpKenQ0Xl/8dpysrK4OPjg9atW2PevHnYs2cPpk+fjtLSUvzwww8AAKlUii+//BKHDh1CaGgomjdvjr1792LcuHG4efMmoqOjZWI6ePAgfv31VwwbNgwmJiZwcnLC8uXLMXToUHTt2hWBgYEAgGbNmgFQ7PvzvJ49e6JBgwaYPXs2zpw5g1WrVqFOnTqYO3euUGfGjBkIDw9HmzZt8MMPP6BWrVpISUnBwYMH0alTJwCK9x8ioo+ClIiIiOgdWbt2rRRApS+pVCp9/Pix1MDAQDpo0CCZ/W7fvi3V19eX2V5YWFih/V9++UUKQHrkyBFh2/z586UApNeuXZOpe+3aNSkA6dq1ayu0A0A6ffp04f306dOlAKRBQUEy9bKysqSqqqrSmTNnymz/+++/pWpqahW2y/s8no/NyspKCkB6/PhxYdvevXulAKSamprSf//9V9j+v//9TwpAeujQIWFbv379pACkw4cPF7ZJJBLpF198Ia1Vq5b03r17UqlUKt2xY4cUgDQyMlImpu7du0tFIpE0IyND5vNQUVGRXrx4UabuvXv3KnxW5RT9/pR/tgMGDJCp27VrV6mxsbHw/sqVK1IVFRVp165dpWVlZTJ1JRKJVCp9tf5DRPQx4BR9IiIieueWLl2KhIQEmRfwbNT30aNHCAoKwv3794WXqqoqWrVqhUOHDgltaGpqCl8/ffoU9+/fR+vWrQEAZ86ceSdxDxkyROb9tm3bIJFI0LNnT5l4TU1NYWdnJxPvq2jSpAnc3NyE961atQIAeHp6wtLSssL2q1evVmhj2LBhwtflU+yLi4uxf/9+AEB8fDxUVVUxYsQImf3GjBkDqVSK3bt3y2xv164dmjRpovA5vOr358XP9rPPPsODBw+Ql5cHANixYwckEgmmTZsmM1uh/PyAV+s/REQfA07RJyIionfu008/rXSRvStXrgB4lshWRk9PT/j64cOHmDFjBjZt2oS7d+/K1MvNzX2L0f6/F1f+v3LlCqRSKezs7Cqtr66u/lrHeT6JBwB9fX0AgIWFRaXb//vvP5ntKioqaNiwocy2Ro0aAYBwv/+///4Lc3Nz6OrqytRzcHAQyp/34rm/zKt+f148Z0NDQwDPzk1PTw+ZmZlQUVGp8iLDq/QfIqKPARN8IiIiqjYSiQTAs/uoTU1NK5Srqf3/nyo9e/bE8ePHMW7cODRv3hw6OjqQSCTw8fER2qnKi/eAlysrK5O7z/Oj0uXxikQi7N69u9LV8HV0dF4aR2Xkrawvb7v0hUXx3oUXz/1lXvX78zbO7VX6DxHRx4C/9YiIiKja2NjYAADq1KkDLy8vufX+++8/HDhwADNmzMC0adOE7eUjuM+Tl8iXjxA/evRIZvuLI9cvi1cqlaJBgwbCCHlNIJFIcPXqVZmYLl++DADCInNWVlbYv38/Hj9+LDOKf+nSJaH8ZeR9tq/y/VGUjY0NJBIJ/vnnHzRv3lxuHeDl/YeI6GPBe/CJiIio2nh7e0NPTw+zZs1CSUlJhfLyle/LR3tfHN1dtGhRhX3Kn1X/YiKvp6cHExMTHDlyRGb7smXLFI43MDAQqqqqmDFjRoVYpFJphUfCvU8xMTEyscTExEBdXR0dOnQAAPj5+aGsrEymHgBER0dDJBLB19f3pcfQ0tICUPGzfZXvj6K6dOkCFRUV/PDDDxVmAJQfR9H+Q0T0seAIPhEREVUbPT09LF++HH369EGLFi3Qq1cv1K5dG9nZ2di1axfc3d0RExMDPT09fP7555g3bx5KSkpQr1497Nu3D9euXavQpouLCwBg8uTJ6NWrF9TV1eHv7w9tbW0MHDgQc+bMwcCBA+Hq6oojR44II92KsLGxQWRkJCZOnIisrCx06dIFurq6uHbtGrZv347Bgwdj7Nixb+3zUZSGhgb27NmDfv36oVWrVti9ezd27dqFSZMmCc+u9/f3R/v27TF58mRkZWXByckJ+/btw86dOzFy5EhhNLwqmpqaaNKkCTZv3oxGjRrByMgIn3zyCT755BOFvz+KsrW1xeTJkxEREYHPPvsMgYGBEIvFOHnyJMzNzTF79myF+w8R0ceCCT4RERFVq969e8Pc3Bxz5szB/PnzUVRUhHr16uGzzz5D//79hXpxcXEYPnw4li5dCqlUik6dOmH37t0wNzeXaa9ly5aIiIjAihUrsGfPHkgkEly7dg3a2tqYNm0a7t27hy1btuDXX3+Fr68vdu/ejTp16igc74QJE9CoUSNER0djxowZAJ4thtepUyd8+eWXb+dDeUWqqqrYs2cPhg4dinHjxkFXVxfTp0+XmS6voqKC33//HdOmTcPmzZuxdu1aWFtbY/78+RgzZozCx1q1ahWGDx+OUaNGobi4GNOnT8cnn3yi8PfnVfzwww9o0KABlixZgsmTJ0NLSwvNmjVDnz59hDqK9h8ioo+BSPo+VmkhIiIionciJCQEW7ZsQX5+fnWHQkRE1Yz34BMREREREREpASb4REREREREREqACT4RERERERGREuA9+ERERERERERKgCP4REREREREREqACT4RERERERGRElCr7gCIqCKJRIJbt25BV1cXIpGousMhIiIiIqJqIpVK8fjxY5ibm0NFpeoxeib4RDXQrVu3YGFhUd1hEBERERFRDXH9+nXUr1+/yjpM8IlqIF1dXQDAtWvXYGRkVM3RUE1WUlKCffv2oVOnTlBXV6/ucKgGY18hRbGvkKLYV0hR7CtvJi8vDxYWFkKOUBUm+EQ1UPm0fF1dXejp6VVzNFSTlZSUQEtLC3p6evwPk6rEvkKKYl8hRbGvkKLYV94ORW7d5SJ7REREREREREqACT4RERERERGREmCCT0RERERERKQEmOATERERERERKQEm+ERERERERERKgAk+ERERERERkRJggk9ERERERESkBJjgExERERERESkBJvhERERERERESoAJPhEREREREZESYIJPREREREREpASY4BMREREREREpASb4REREREREREqACT4RERERERGREmCCT0RERERERKQEmOATERERERERKQEm+ERERERERERKgAk+ERERERERkRJggk9ERERERESkBJjgExERERERESkBkVQqlVZ3EEQkKy8vD/r6+rAZsxmlatrVHQ7VYGJVKeZ9WobxJ1RRVCaq7nCoBmNfIUWxr5Ci2FdIUa/SV7LmfPGeovpwlOcGubm50NPTq7IuR/CJiIiIiIioRgkPD4dIJJJ52dvbC+VPnz7Fd999B2NjY+jo6KBbt264c+eOUL5u3boK+5e/7t69K/e4Dx8+RHBwMPT09GBgYIDQ0FDk5+e/03N9m5jgE72iL7/8EpaWltDQ0ICZmRn69OmDW7duydTZu3cvWrduDV1dXdSuXRvdunVDVlZW9QRMRERERPQBatq0KXJycoTXX3/9JZSNGjUKf/zxB3777TccPnwYt27dQmBgoFD+1Vdfyeybk5MDb29vtGvXDnXq1JF7zODgYFy8eBEJCQn4888/ceTIEQwePPidnufbxASfSEHFxcUAgPbt2+PXX39Feno6tm7diszMTHTv3l2od+3aNQQEBMDT0xOpqanYu3cv7t+/L/MLh4iIiIiIqqampgZTU1PhZWJiAgDIzc3F6tWrsXDhQnh6esLFxQVr167F8ePHkZycDADQ1NSU2VdVVRUHDx5EaGio3OOlpaVhz549WLVqFVq1aoW2bdtiyZIl2LRpU4UBvZqKCT4ppZUrV8Lc3BwSiURme0BAAAYMGIDMzEwEBASgbt260NHRQcuWLbF//36ZutbW1oiIiEDfvn2hp6cnXLkbNWoUWrduDSsrK7Rp0wYTJkxAcnIySkpKAACnT59GWVkZIiMjYWNjgxYtWmDs2LFITU0V6hARERERUdWuXLkCc3NzNGzYEMHBwcjOzgbw7O/tkpISeHl5CXXt7e1haWmJpKSkStvasGEDtLS0ZAbmXpSUlAQDAwO4uroK27y8vKCiooKUlJS3dFbvllp1B0D0LvTo0QPDhw/HoUOH0KFDBwDP7qfZs2cP4uPjkZ+fDz8/P8ycORNisRgbNmyAv78/0tPTYWlpKbQTFRWFadOmYfr06ZUe5+HDh4iNjUWbNm2grq4OAHBxcYGKigrWrl2LkJAQ5Ofn4+eff4aXl5dQ50VFRUUoKioS3ufl5QEAxCpSqKpyHUyST6wilfmXSB72FVIU+wopin2FFPUqfaV8QMzFxQWrVq1Co0aNcPv2bURGRuKzzz7D2bNncePGDdSqVQva2toyA2h16tTBzZs3Kx1UW7VqFXr16gU1NTW5g243b95E7dq1K5QbGRnJbfd9eJXjchV9UlpdunSBsbExVq9eDeDZqP6MGTNw/fp1qKhUnLzyySefYMiQIRg2bBiAZyP4zs7O2L59e4W6YWFhiImJQWFhIVq3bo0///wTxsbGQvnhw4fRs2dPPHjwAGVlZXBzc0N8fDwMDAwqjTU8PBwzZsyosD0uLg5aWlqvc/pEREREREojPz8fgwcPRv/+/VGrVi0sWbIEW7Zskakzbtw4fPLJJ+jXr5/M9kuXLmHChAmIioqCra2t3GP89ttvOHToEJYtWyazvV+/fujVqxd8fX3f3gm9gsLCQvTu3VuhVfSZ4JPS+u233zBo0CDcuXMHYrEY7dq1g6urKxYsWID8/HyEh4dj165dyMnJQWlpKZ48eYIxY8Zg3rx5AJ4l+IMGDcLkyZMrtH3//n08fPgQ//77L2bMmAF9fX38+eefEIlEuH37Nj7//HN06dIFQUFBePz4MaZNmwY1NTUkJCRAJKr4aJDKRvAtLCzQZNwmlKrzMXkkn1hFighXCaaeUkGRhI8oIvnYV0hR7CukKPYVUtSr9JUL4d5yy9zc3ODp6QkvLy94e3vj7t27MgNotra2GD58OL7//nuZ/QYPHoyzZ8/i5MmTVR573bp1GD9+vMwq+6WlpdDV1cUvv/yCLl26VLn/u5KXlwcTExOFEnxO0Sel5e/vD6lUil27dqFly5Y4evQooqOjAQBjx45FQkKCcBVPU1MT3bt3FxbSK6etXXlybWJiAhMTEzRq1AgODg6wsLBAcnIy3NzcsHTpUujr6wsXCgBg48aNsLCwQEpKClq3bl2hPbFYDLFYXGF7kUSEUj5XlhRQJBHxGcSkEPYVUhT7CimKfYUUpUhfkXdLa35+Pq5evYq+ffuiVatWUFdXx5EjR9CtWzcAQHp6OrKzs9G2bVuZNvLz87FlyxbMnj1bbtvl2rZti0ePHuH8+fNwcXEBABw6dAgSiQTu7u4v3f9deZXjMsEnpaWhoYHAwEDExsYiIyMDjRs3RosWLQAAx44dQ0hICLp27Qrg2Q/+6z7Grnwhv/IR+MLCwgq3AKiqqsrUJSIiIiIi+caOHQt/f39YWVnh1q1bmD59OlRVVREUFAR9fX2EhoZi9OjRMDIygp6eHoYPHw43N7cKg2mbN29GaWkpvv766wrHOHHiBPr27YsDBw6gXr16cHBwgI+PDwYNGoQVK1agpKQEw4YNQ69evWBubv6+Tv2NMMEnpRYcHIzOnTvj4sWLMj/UdnZ22LZtG/z9/SESiTB16lSFku+UlBScPHkSbdu2haGhITIzMzF16lTY2NjAzc0NAPDFF18gOjoaP/zwgzBFf9KkSbCysoKzs/M7O1ciIiIiImVx48YNBAUF4cGDB6hduzbatm2L5ORk1K5dGwAQHR0NFRUVdOvWDUVFRfD29q5w7zwArF69GoGBgZWuhVVYWIj09HSZRexiY2MxbNgwdOjQQWj/xx9/fGfn+bYxwSel5unpCSMjI6Snp6N3797C9oULF2LAgAFo06YNTExMEBYWJqxcXxUtLS1s27YN06dPR0FBAczMzODj44MpU6YIU+w9PT0RFxeHefPmYd68edDS0oKbmxv27NkDTU3Nd3auRERERETKYtOmTVWWa2hoYOnSpVi6dGmV9Y4fPy63zMPDAy8uSWdkZIS4uDjFA61huMgeUQ2Ul5cHfX193L9/X2Z1fqIXlZSUID4+Hn5+ftV2Xxh9GNhXSFHsK6Qo9hVSFPvKmynPDRRZZK/is8KIiIiIiIiI6IPDBJ+IiIiIiIhICTDBJyIiIiIiIlICTPCJiIiIiIiIlAATfCIiIiIiIiIlwASfiIiIiIiISAkwwSciIiIiIiJSAkzwiYiIiIiIiJQAE3wiIiIiIiIiJcAEn4iIiIiIiEgJMMEnIiIiIiIiUgJM8ImIiIiIiIiUABN8IiIiIiIiIiXABJ+IiIiIiIhICTDBJyIiIiIiIlICTPCJiIiIiIiIlAATfCIiIiIiIiIloFbdARCRfK1mH0CpmnZ1h0E1mFhVinmfAp+E70VRmai6w6EajH2FFMW+8kzWnC+Er5cvX47ly5cjKysLANC0aVNMmzYNvr6+MvtIpVL4+flhz5492L59O7p06QIAWLduHfr371/pce7cuYM6depUWvbw4UMMHz4cf/zxB1RUVNCtWzcsXrwYOjo6b36CRKSUOIJP9IpmzpyJNm3aQEtLCwYGBpXWEYlEFV6bNm16v4ESERHRW1G/fn3MmTMHp0+fxqlTp+Dp6YmAgABcvHhRpt6iRYsgElW8KPLVV18hJydH5uXt7Y127drJTe4BIDg4GBcvXkRCQgL+/PNPHDlyBIMHD37r50dEyoMj+EQKKi4uRq1atVBcXIwePXrAzc0Nq1evllt/7dq18PHxEd7LuxhARERENZu/v7/M+5kzZ2L58uVITk5G06ZNAQCpqalYsGABTp06BTMzM5n6mpqa0NTUFN7fu3cPBw8erPLviLS0NOzZswcnT56Eq6srAGDJkiXw8/NDVFQUzM3N39bpEZES4Qg+KaWVK1fC3NwcEolEZntAQAAGDBiAzMxMBAQEoG7dutDR0UHLli2xf/9+mbrW1taIiIhA3759oaenJ1wxnzFjBkaNGgVHR8cqYzAwMICpqanw0tDQeLsnSURERO9dWVkZNm3ahIKCAri5uQEACgsL0bt3byxduhSmpqYvbWPDhg3Q0tJC9+7d5dZJSkqCgYGBkNwDgJeXF1RUVJCSkvLmJ0JESokj+KSUevTogeHDh+PQoUPo0KEDgGf3se3Zswfx8fHIz8+Hn58fZs6cCbFYjA0bNsDf3x/p6emwtLQU2omKisK0adMwffr0V47hu+++w8CBA9GwYUMMGTIE/fv3r3TaHgAUFRWhqKhIeJ+XlwcAEKtIoaoqfeVj08dDrCKV+ZdIHvYVUhT7yjMlJSUy7//++298/vnnePr0KXR0dPDbb7/Bzs4OJSUl+P7779G6dWv4+fkJ+5WWllZoo9yqVavQq1cvqKmpya1z8+ZN1K5du0K5kZERbt68KXe/96k8hpoQC9Vs7Ctv5lU+Nyb4pJQMDQ3h6+uLuLg4IcHfsmULTExM0L59e6ioqMDJyUmoHxERge3bt+P333/HsGHDhO2enp4YM2bMKx//hx9+gKenJ7S0tLBv3z58++23yM/Px4gRIyqtP3v2bMyYMaPC9inOEmhplb3y8enjE+EqeXklIrCvkOI+9r4SHx8v876kpARRUVEoKChAUlIS+vTpg5kzZyInJwe7du3CwoULZfY5ffo01NXVK7R76dIlXLp0CQMHDqxwjOelp6ejoKCgQp3i4mJcuHChyn3ft4SEhOoOgT4Q7Cuvp7CwUOG6TPBJaQUHB2PQoEFYtmwZxGIxYmNj0atXL6ioqCA/Px/h4eHYtWsXcnJyUFpaiidPniA7O1umjeenxb2KqVOnCl87OzujoKAA8+fPl5vgT5w4EaNHjxbe5+XlwcLCApFnVVCqrvpaMdDHQawiRYSrBFNPqaBI8vGudk0vx75CimJfeeZCuLfcshEjRsDHxwfnzp2DpqYmbt++ja+//lqmzrx589C2bdsKtwDu2LEDTk5Ocv8mKHf37l3s2rULfn5+wrbS0lLk5+ejQ4cOMturS0lJCRISEtCxY8dKL2YQlWNfeTPls3sVwQSflJa/vz+kUil27dqFli1b4ujRo4iOjgYAjB07FgkJCYiKioKtrS00NTXRvXt3FBcXy7Shrf12HlHXqlUrREREoKioCGKxuEK5WCyudHuRRITSj/gRRaS4Ionoo36cFSmOfYUU9bH3lZclIVKpFCUlJYiIiKiwsr2joyOio6Ph7+8v005+fj62bNmC2bNnv7T9tm3b4tGjRzh//jxcXFwAAIcOHYJEIoG7u3uNSpLU1dVrVDxUc7GvvJ5X+cyY4JPS0tDQQGBgIGJjY5GRkYHGjRujRYsWAIBjx44hJCQEXbt2BfDsP9zyZ9u+C6mpqTA0NKw0iSciIqKabeLEifD19YWlpSUeP36MuLg4JCYmYu/evcJiui+ytLREgwYNZLZt3rwZpaWlFUb7AeDEiRPo27cvDhw4gHr16sHBwQE+Pj4YNGgQVqxYgZKSEgwbNgy9evXiCvpEJBcTfFJqwcHB6Ny5My5evCjzn6mdnR22bdsGf39/iEQiTJ06tcKK+/JkZ2fj4cOHyM7ORllZGVJTUwEAtra20NHRwR9//IE7d+6gdevW0NDQQEJCAmbNmoWxY8e+i1MkIiKid+zu3bvo27cvcnJyoK+vj2bNmmHv3r3o2LHjK7WzevVqBAYGVvro3MLCQqSnp8ssphUbG4thw4ahQ4cOUFFRQbdu3fDjjz++6ekQkRJjgk9KzdPTE0ZGRkhPT0fv3r2F7QsXLsSAAQPQpk0bmJiYICwsTOF7W6ZNm4b169cL752dnQE8mzbn4eEBdXV1LF26FKNGjYJUKoWtrS0WLlyIQYMGvd2TIyIioveiqufVV0YqrfwJBMePH5e7j4eHR4X9jIyMEBcX90rHJqKPm0gq7zcQEVWbvLw86Ovr4/79+zA2Nq7ucKgGKykpQXx8PPz8/HhPG1WJfYUUxb5CimJfIUWxr7yZ8twgNzcXenp6VdZVeU8xEREREREREdE7xASfiIiIiIiISAkwwSciIiIiIiJSAkzwiYiIiIiIiJQAE3wiIiIiIiIiJcAEn4iIiIiIiEgJMMEnIiIiIiIiUgJM8ImIiIiIiIiUABN8IiIiIiIiIiXABJ+IiIiIiIhICTDBJyIiIiIiIlICTPCJiIiIiIiIlAATfCIiIiIiIiIlwASfiIiIiIiISAkwwSciIiIiIiJSAkzwiYiIiIiIiJQAE3wiIiIiIiIiJaBW3QEQkXytZh9AqZp2dYdBNZhYVYp5nwKfhO9FUZmousP5oGXN+UL4+siRI5g/fz5Onz6NnJwcbN++HV26dBHKQ0JCsH79epn9vb29sWfPHuH9mTNnEBYWhpMnT0JVVRXdunXDwoULoaOjIzcGqVSK6dOn46effsKjR4/g7u6O5cuXw87O7u2dKBERESmtj3oEXyQSYceOHXLLs7KyIBKJkJqa+t5iels8PDwwcuRI4b21tTUWLVpUbfG8Dx/y94uIapaCggI4OTlh6dKlcuv4+PggJydHeP3yyy9C2a1bt+Dl5QVbW1ukpKRgz549uHjxIkJCQqo87rx58/Djjz9ixYoVSElJgba2Nry9vfH06dO3dWpERESkxD7qBP9jcvLkSQwePLi6w3ipkJAQiEQimZePj091h/VKtm3bBldXVxgYGEBbWxvNmzfHzz//XN1hEdEr8PX1RWRkJLp27Sq3jlgshqmpqfAyNDQUyv7880+oq6tj6dKlaNy4MVq2bIkVK1Zg69atyMjIqLQ9qVSKRYsWYcqUKQgICECzZs2wYcMG3Lp1q8qL0URERETlmOB/JGrXrg0tLa3qDkOu4uJi4euqRsU+BEZGRpg8eTKSkpJw/vx59O/fH/3798fevXurOzQieosSExNRp04dNG7cGEOHDsWDBw+EsqKiItSqVQsqKv//36ympiYA4K+//qq0vWvXruH27dvw8vIStunr66NVq1ZISkp6R2dBREREyuSDT/C3bNkCR0dHaGpqwtjYGF5eXigoKMDJkyfRsWNHmJiYQF9fH+3atcOZM2eqbOvEiRNwdnaGhoYGXF1dcfbs2Qp1Dh8+jE8//RRisRhmZmaYMGECSktLFYrVw8MDw4cPx8iRI2FoaIi6devip59+QkFBAfr37w9dXV3Y2tpi9+7dMvtduHABvr6+0NHRQd26ddGnTx/cv39fKC8oKEDfvn2ho6MDMzMzLFiwoMKxX5yin52djYCAAOjo6EBPTw89e/bEnTt3XnoOly9fhkgkwqVLl2S2R0dHw8bGBgBQVlaG0NBQNGjQAJqammjcuDEWL14sUz8kJARdunTBzJkzYW5ujsaNGwtlVY2KKeLq1ato3749tLS04OTkJPOH8YMHDxAUFIR69epBS0sLjo6OFS4gSCQSzJs3D7a2thCLxbC0tMTMmTOF8uvXr6Nnz54wMDCAkZERAgICkJWVJZR7eHiga9eucHBwgI2NDb7//ns0a9ZM7h/1RPTh8fHxwYYNG3DgwAHMnTsXhw8fhq+vL8rKygAAnp6euH37NubPn4/i4mL8999/mDBhAgAgJyen0jZv374NAKhbt67M9rp16wplRERERFX5oBfZy8nJQVBQEObNm4euXbvi8ePHOHr0KKRSKR4/fox+/fphyZIlkEqlWLBgAfz8/HDlyhXo6upWaCs/Px+dO3dGx44dsXHjRly7dg3ff/+9TJ2bN2/Cz88PISEh2LBhAy5duoRBgwZBQ0MD4eHhCsW8fv16jB8/HidOnMDmzZsxdOhQbN++HV27dsWkSZMQHR2NPn36IDs7G1paWnj06BE8PT0xcOBAREdH48mTJwgLC0PPnj1x8OBBAMC4ceNw+PBh7Ny5E3Xq1MGkSZNw5swZNG/evNIYJBKJkNwfPnwYpaWl+O677/DVV18hMTGxyvgbNWoEV1dXxMbGIiIiQtgeGxuL3r17C+3Xr18fv/32G4yNjXH8+HEMHjwYZmZm6Nmzp7DPgQMHoKenh4SEBJljlI+KGRoawtPTE5GRkTA2Nlbo8wWAyZMnIyoqCnZ2dpg8eTKCgoKQkZEBNTU1PH36FC4uLggLC4Oenh527dqFPn36wMbGBp9++ikAYOLEifjpp58QHR2Ntm3bIicnR7igUVJSAm9vb7i5ueHo0aNQU1NDZGQkfHx8cP78edSqVUsmFqlUioMHDyI9PR1z586VG3NRURGKioqE93l5eQAAsYoUqqpShc+dPj5iFanMv/T6SkpK5JaVlpbKlHfr1k342t7eHg4ODrC3t8f+/fvh6emJRo0aYfXq1Rg/fjwmTpwIVVVVDBs2DHXr1oVUKq30WOUXi0tKSmTKJRIJRCJRlfG9yvm9aTuk/NhXSFHsK6Qo9pU38yqfm0gqlX6wfxWeOXMGLi4uyMrKgpWVVZV1JRIJDAwMEBcXh86dOwN4tshe+crIK1euxKRJk3Djxg1oaGgAAFasWIGhQ4fi7NmzaN68OSZPnoytW7ciLS0NItGz1aqXLVuGsLAw5ObmykzFrIyHhwfKyspw9OhRAM9GuvX19REYGIgNGzYAeDaCY2ZmhqSkJLRu3RqRkZE4evSozPTuGzduwMLCAunp6TA3N4exsTE2btyIHj16AAAePnyI+vXrY/DgwcKovbW1NUaOHImRI0ciISEBvr6+uHbtGiwsLAAA//zzD5o2bYoTJ06gZcuWVZ7HokWLEBMTI9xHevnyZTRu3BhpaWmwt7evdJ9hw4bh9u3b2LJlC4BnI/h79uxBdna2TFK8adMmaGlpoUGDBsjMzMSkSZOgo6ODpKQkqKqqVhlXVlYWGjRogFWrViE0NFTmvKqKrXPnzrC3t0dUVBQeP36M2rVrIyYmBgMHDqxQd+PGjYiMjJTpA8XFxTAwMMCOHTvQqVMnAEBubi7q1auHoqIiqKqqYtmyZRgwYIDc2MPDwzFjxowK2+Pi4mr0rRVEH4MuXbpgwoQJaN26dZX1+vbti+DgYHh7e8tsf/ToEcRiMUQiEXr37o0xY8bA3d29wv63b9/GkCFDsHDhQjRs2FDYPnnyZDRo0KDS30lERESk/AoLC9G7d2/k5uZCT0+vyrof9Ai+k5MTOnToAEdHR3h7e6NTp07o3r07DA0NcefOHUyZMgWJiYm4e/cuysrKUFhYiOzs7ErbSktLQ7NmzYTkHgDc3Nwq1HFzcxMSOwBwd3dHfn4+bty4AUtLy5fG3KxZM+FrVVVVGBsbw9HRUdhWPjXz7t27AIBz587h0KFDlT5WKTMzE0+ePEFxcTFatWolbDcyMpKZ8l7ZuVpYWAjJPQA0adIEBgYGSEtLe2mC36tXL4wdOxbJyclo3bo1YmNj0aJFC5kEeunSpVizZg2ys7OFGF+cUeDo6FhhxLtXr14y5c2aNYONjQ0SExPRoUOHKuMq9/xnbGZmBuDZ52lvb4+ysjLMmjULv/76K27evIni4mIUFRUJSXRaWhqKiorkHuvcuXPIyMioMAvk6dOnyMzMFN7r6uoiNTUV+fn5OHDgAEaPHo2GDRvCw8Oj0nYnTpyI0aNHC+/z8vJgYWGByLMqKFWv+sIGfdzEKlJEuEow9ZQKiiR8TN6buBDuLbfMxcUFfn5+cstv3LiBx48fw8vLS269devWQUNDA+PGjYOBgUGFcqlUivDwcJSUlAht5OXlISMjAxMmTKjy+IooKSlBQkICOnbsCHV19Tdqi5Qb+wopin2FFMW+8mbKZ/cq4oNO8FVVVZGQkIDjx49j3759WLJkCSZPnoyUlBRhwaPFixfDysoKYrEYbm5uMou5VYcXO7RIJJLZVn7xQCKRAHh264C/v3+l07vNzMzkrsb8LpmamsLT0xNxcXFo3bo14uLiMHToUKF806ZNGDt2LBYsWAA3Nzfo6upi/vz5SElJkWlHW/vlz3dv2LAhTExMkJGRoXCCX9XnOX/+fCxevBiLFi2Co6MjtLW1MXLkSKFflC+CJU9+fj5cXFwQGxtboax27drC1yoqKrC1tQUANG/eHGlpaZg9e7bcBF8sFkMsFlfYXiQRoZTPNicFFElEKGJfeSPP/+7Iz8+X+f16/fp1XLx4EUZGRjAyMsKMGTPQrVs3mJqaIjMzE+PHj4etrS2++OILoZ2YmBi0adMGOjo6SEhIwLhx4zBnzhyZ3xX29vaYPXu2sFr/yJEjMXv2bNjb26NBgwaYOnUqzM3N0b1797f2B5G6ujr/uCKFsK+QothXSFHsK6/nVT6zDzrBB54lcO7u7nB3d8e0adNgZWWF7du349ixY1i2bJkw4nH9+nWZhele5ODggJ9//hlPnz4VRvGTk5Mr1Nm6dSukUqmQOB47dgy6urqoX7/+Ozm/Fi1aYOvWrbC2toaaWsVvl42NDdTV1ZGSkiLMIPjvv/9w+fJltGvXrtI2HRwccP36dVy/fl1miv6jR4/QpEkTheIKDg7G+PHjERQUhKtXr8qMvB87dgxt2rTBt99+K2x7fnT7Vdy4cQMPHjwQRuLf1LFjxxAQEICvv/4awLPE//Lly8J529nZQVNTEwcOHKh0OmyLFi2wefNm1KlT56XTY54nkUhk7rEnoprt1KlTaN++vfC+fIZNv379sHz5cpw/fx7r16/Ho0ePYG5ujk6dOiEiIkLmQt2JEycwffp05Ofnw97eHv/73//Qp08fmeOkp6cjNzdXeD9+/HgUFBRg8ODBePToEdq2bYs9e/bIzC4jIiIikueDXkU/JSUFs2bNwqlTp5CdnY1t27bh3r17cHBwgJ2dHX7++WekpaUhJSUFwcHBVY7O9u7dGyKRCIMGDcI///yD+Ph4REVFydT59ttvcf36dQwfPhyXLl3Czp07MX36dIwePfql99+/ru+++w4PHz5EUFAQTp48iczMTOzduxf9+/dHWVkZdHR0EBoainHjxuHgwYO4cOECQkJCqozHy8sLjo6OCA4OxpkzZ3DixAn07dsX7dq1g6urq0JxBQYG4vHjxxg6dCjat28Pc3NzoczOzg6nTp3C3r17cfnyZUydOhUnT558aZv5+fkYN24ckpOTkZWVhQMHDiAgIAC2trYV7ml9XXZ2dsKsj7S0NHzzzTcyTw/Q0NBAWFgYxo8fjw0bNiAzMxPJyclYvXo1gGcXNkxMTBAQEICjR4/i2rVrSExMxIgRI3Djxg0AwOzZs5GQkICrV68iLS0NCxYswM8//yxcVCCims/DwwNSqbTCa926ddDU1MTevXtx9+5dFBcXIysrCytXrqyw+v2GDRvw4MEDFBUV4dy5cxWSe+DZtPyQkBDhvUgkwg8//IDbt2/j6dOn2L9/Pxo1avSuT5eIiIiUxAed4Ovp6eHIkSPw8/NDo0aNMGXKFCxYsAC+vr5YvXo1/vvvP7Ro0QJ9+vTBiBEjUKdOHblt6ejo4I8//sDff/8NZ2dnTJ48ucK0+Hr16iE+Ph4nTpyAk5MThgwZgtDQUEyZMuWdnaO5uTmOHTuGsrIydOrUCY6Ojhg5ciQMDAyEJH7+/Pn47LPP4O/vDy8vL7Rt2xYuLi5y2xSJRNi5cycMDQ3x+eefw8vLCw0bNsTmzZsVjktXVxf+/v44d+4cgoODZcq++eYbBAYG4quvvkKrVq3w4MEDmdF8eVRVVXH+/Hl8+eWXaNSoEUJDQ+Hi4oKjR49WOn39dUyZMgUtWrSAt7c3PDw8YGpqii5dusjUmTp1KsaMGYNp06bBwcEBX331lbAmgpaWFo4cOQJLS0sEBgbCwcEBoaGhePr0qTCiX1BQgG+//RZNmzaFu7s7tm7dio0bN3KBLCIiIiIieqc+6FX0iZRVXl4e9PX1cf/+/Vd6RCB9fEpKShAfHw8/Pz/e00ZVYl8hRbGvkKLYV0hR7Ctvpjw3UGQV/Q96BJ+IiIiIiIiInmGC/5ZkZ2dDR0dH7kve4/lqoqZNm8o9j8pWj39fZs2aJTcuX1/faouLiIiIiIioJvjgV9GvKczNzZGamlpl+YciPj4eJSUllZa9uIjU+zRkyBD07Nmz0rKXPd6OiIiIiIhI2THBf0vU1NSE555/6KysrKo7hEqVP3+aiIiIiIiIKuIUfSIiIiIiIiIlwASfiIiIiIiISAkwwSciIiIiIiJSAkzwiYiIiIiIiJQAE3wiIiIiIiIiJcAEn4iIiIiIiEgJMMEnIiIiIiIiUgJM8ImIiIiIiIiUABN8IiIiIiIiIiXABJ+IiIiIiIhICTDBJyIiIiIiIlICTPCJiIiIiIiIlIBadQdARPK1mn0ApWra1R0G1WBiVSnmfQp8Er4XRWWi6g7nvcua80V1h0BERERUY3AEn94LkUiEHTt2yC3PysqCSCRCamrqe4uJiJTLkSNH4O/vD3Nz85f+zhkyZAhEIhEWLVoks93a2hoikUjmNWfOnCqP+/TpU3z33XcwNjaGjo4OunXrhjt37ryFMyIiIiJ6NUzwiV7Rl19+CUtLS2hoaMDMzAx9+vTBrVu3ZOqcP38en332GTQ0NGBhYYF58+ZVU7REH4+CggI4OTlh6dKlVdbbvn07kpOTYW5uXmn5Dz/8gJycHOE1fPjwKtsbNWoU/vjjD/z22284fPgwbt26hcDAwNc+DyIiIqLXxSn6RAoqLi5GrVq10L59e0yaNAlmZma4efMmxo4di+7du+P48eMAgLy8PHTq1AleXl5YsWIF/v77bwwYMAAGBgYYPHhwNZ8FkfLy9fWFr69vlXVu3ryJ4cOHY+/evfjii8qn9+vq6sLU1FShY+bm5mL16tWIi4uDp6cnAGDt2rVwcHBAcnIyWrdu/WonQURERPQGOIJPCtuyZQscHR2hqakJY2NjeHl5oaCgACdPnkTHjh1hYmICfX19tGvXDmfOnKmyrRMnTsDZ2RkaGhpwdXXF2bNnK9Q5fPgwPv30U4jFYpiZmWHChAkoLS19aZwrV66Eubk5JBKJzPaAgAAMGDAAAJCZmYmAgADUrVsXOjo6aNmyJfbv3y9T39raGhEREejbty/09PSE5HzUqFFo3bo1rKys0KZNG0yYMAHJyckoKSkBAMTGxqK4uBhr1qxB06ZN0atXL4wYMQILFy58aexE9O5IJBL06dMH48aNQ9OmTeXWmzNnDoyNjeHs7Iz58+dX+Xvn9OnTKCkpgZeXl7DN3t4elpaWSEpKeqvxExEREb0MR/BJITk5OQgKCsK8efPQtWtXPH78GEePHoVUKsXjx4/Rr18/LFmyBFKpFAsWLICfnx+uXLkCXV3dCm3l5+ejc+fO6NixIzZu3Ihr167h+++/l6lz8+ZN+Pn5ISQkBBs2bMClS5cwaNAgaGhoIDw8vMpYe/TogeHDh+PQoUPo0KEDAODhw4fYs2cP4uPjhRj8/Pwwc+ZMiMVibNiwAf7+/khPT4elpaXQVlRUFKZNm4bp06dXeqyHDx8iNjYWbdq0gbq6OgAgKSkJn3/+OWrVqiXU8/b2xty5c/Hff//B0NCwQjtFRUUoKioS3ufl5QEAxCpSqKpKqzxf+riJVaQy/35syi+sVaa0tFSmfO7cuVBVVcXQoUOF7WVlZTJ1vvvuOzg7O8PQ0BDJycmYMmUKbt68ifnz51d6jBs3bqBWrVrQ1taWaadOnTq4efNmlfG9b+Wx1KSYqGZiXyFFsa+QothX3syrfG5M8EkhOTk5KC0tRWBgIKysrAAAjo6OACBMSy23cuVKGBgY4PDhw+jcuXOFtuLi4iCRSLB69WpoaGigadOmuHHjBoYOHSrUWbZsGSwsLBATEwORSAR7e3vcunULYWFhmDZtGlRU5E8+MTQ0hK+vL+Li4oQEf8uWLTAxMUH79u0BAE5OTnBychL2iYiIwPbt2/H7779j2LBhwnZPT0+MGTOmwjHCwsIQExODwsJCtG7dGn/++adQdvv2bTRo0ECmft26dYWyyhL82bNnY8aMGRW2T3GWQEurTO65EpWLcJW8vJISKr9oV5nTp08LF94yMjKwYMECLFy4ELt37wYAFBYW4p9//pFpo1GjRigoKEBBQQHq16+Pr7/+GjExMWjbtq3Q1vNSU1MhkUgqxJGbm4urV69WGV91SUhIqO4Q6APBvkKKYl8hRbGvvJ7CwkKF6zLBJ4U4OTmhQ4cOcHR0hLe3Nzp16oTu3bvD0NAQd+7cwZQpU5CYmIi7d++irKwMhYWFyM7OrrSttLQ0NGvWDBoaGsI2Nze3CnXc3NwgEv3/Y7/c3d2Rn5+PGzduyIyyVyY4OBiDBg3CsmXLIBaLERsbi169egkXBvLz8xEeHo5du3YJFy+ePHlSIWZXV9dK2x83bhxCQ0Px77//YsaMGejbty/+/PNPmXhfxcSJEzF69GjhfV5eHiwsLBB5VgWl6qqv1SZ9HMQqUkS4SjD1lAqKJB/fY/IuhHvLLXNxcYGfnx8A4Mcff0Rubi4GDRoklJeVlWHdunU4cOAArly5UmkbVlZWiImJgb29PRo3blyhXFNTE9HR0WjTpg0MDAyE7SNGjECbNm2E49cEJSUlSEhIQMeOHSu9WEFUjn2FFMW+QopiX3kz5bN7FcEEnxSiqqqKhIQEHD9+HPv27cOSJUswefJkpKSkYOjQoXjw4AEWL14MKysriMViuLm5obi4uNri9ff3h1Qqxa5du9CyZUscPXoU0dHRQvnYsWORkJCAqKgo2NraQlNTE927d68Qs7Z25c+gNzExgYmJCRo1agQHBwdYWFggOTkZbm5uMDU1rfCIrPL38hbuEovFEIvFFbYXSUQo/QifbU6vrkgiQtFH2Feq+iNBTU1NKA8JCYG3t+zFAG9vb/Tp0wf9+/eX287FixehoqKCevXqVVqnVatWUFdXx5EjR9CtWzcAQHp6OrKzs+WO+lc3dXX1GhkX1TzsK6Qo9hVSFPvK63mVz4wJPilMJBLB3d0d7u7umDZtGqysrLB9+3YcO3YMy5YtE0aqrl+/jvv378ttx8HBAT///DOePn0qjOInJydXqLN161ZIpVJhVPzYsWPQ1dVF/fr1XxqrhoYGAgMDERsbi4yMDDRu3BgtWrQQyo8dO4aQkBB07doVwLMR/aysrFf6PMqVL+ZXfg+9m5sbJk+ejJKSEuGHMSEhAY0bN650ej4RvR35+fnIyMgQ3l+7dg2pqakwMjKCpaUljI2NZeqrq6vD1NRUGJlPSkpCSkoK2rdvD11dXSQlJWHUqFH4+uuvhZ/dmzdvokOHDtiwYQM+/fRT6OvrIzQ0FKNHj4aRkRH09PQwfPhwuLm5cQV9IiIieu+4ij4pJCUlBbNmzcKpU6eQnZ2Nbdu24d69e3BwcICdnR1+/vlnpKWlISUlBcHBwdDU1JTbVu/evSESiTBo0CDh/teoqCiZOt9++y2uX7+O4cOH49KlS9i5cyemT5+O0aNHV3n//fOCg4Oxa9curFmzBsHBwTJldnZ22LZtG1JTU3Hu3Dn07t27wqr78j6HmJgYpKam4t9//8XBgwcRFBQEGxsb4TaD3r17o1atWggNDcXFixexefNmLF68WGYKPhG9fadOnYKzszOcnZ0BAKNHj4azszOmTZum0P5isRibNm1Cu3bt0LRpU8ycOROjRo3CypUrhTolJSVIT0+XuRcuOjoanTt3Rrdu3fD555/D1NQU27Zte7snR0RERKQAjuCTQvT09HDkyBEsWrQIeXl5sLKywoIFC+Dr6wtTU1MMHjwYLVq0gIWFBWbNmoWxY8fKbUtHRwd//PEHhgwZAmdnZzRp0gRz584VprcCQL169RAfH49x48bByckJRkZGCA0NxZQpUxSO2dPTE0ZGRkhPT0fv3r1lyhYuXIgBAwagTZs2MDExQVhYmEL3tmhpaWHbtm2YPn06CgoKYGZmBh8fH0yZMkWYYq+vr499+/bhu+++g4uLC0xMTDBt2jThMXtE9G54eHhAKlX8aQIvztpp0aJFhdlEL7K2tq5wDA0NDSxduhRLly5V+NhERERE74JI+ip/DRHRe5GXlwd9fX3cv3+/wrRioueVlJQgPj4efn5+vKeNqsS+QopiXyFFsa+QothX3kx5bpCbmws9Pb0q63KKPhEREREREZESYIJPH5zs7Gzo6OjIfcl7PB8REREREZEy4z349MExNzdHampqleVEREREREQfGyb49MFRU1ODra1tdYdBRERERERUo3CKPhEREREREZESYIJPREREREREpASY4BMREREREREpASb4REREREREREqACT4RERERERGREmCCT0RERERERKQEmOATERERERERKQEm+ERERERERERKgAk+ERERERERkRJggk9ERERERESkBJjgExERERERESkBJvhERERERERESoAJPhEREREREZESUKvuAIhIvlazD6BUTbu6w6AaTKwqxbxPgU/C96KoTFTd4VQpa84XwtdHjhzB/Pnzcfr0aeTk5GD79u3o0qWLUB4eHo5Nmzbh+vXrqFWrFlxcXDBz5ky0atVKqPPw4UMMHz4cf/zxB1RUVNCtWzcsXrwYOjo6cmN4+vQpxowZg02bNqGoqAje3t5YtmwZ6tat+07OmYiIiOh9+qhH8EUiEXbs2CG3PCsrCyKRCKmpqe8tprfFw8MDI0eOFN5bW1tj0aJF1RbP+/Ahf7+IPjYFBQVwcnLC0qVLKy1v1KgRYmJi8Pfff+Ovv/6CtbU1OnXqhHv37gl1goODcfHiRSQkJODPP//EkSNHMHjw4CqPO2rUKPzxxx/47bffcPjwYdy6dQuBgYFv9dyIiIiIqstHneB/TE6ePPnSP3xrgpCQEIhEIpmXj49PdYf1Sn766Sd89tlnMDQ0hKGhIby8vHDixInqDouoRvH19UVkZCS6du1aaXnv3r3h5eWFhg0bomnTpli4cCHy8vJw/vx5AEBaWhr27NmDVatWoVWrVmjbti2WLFmCTZs24datW5W2mZubi9WrV2PhwoXw9PSEi4sL1q5di+PHjyM5OfmdnSsRERHR+8IE/yNRu3ZtaGlpVXcYchUXFwtf+/j4ICcnR3j98ssv1RjZq0tMTERQUBAOHTqEpKQkWFhYoFOnTrh582Z1h0b0QSouLsbKlSuhr68PJycnAEBSUhIMDAzg6uoq1PPy8oKKigpSUlIqbef06dMoKSmBl5eXsM3e3h6WlpZISkp6tydBRERE9B588Pfgb9myBTNmzEBGRga0tLTg7OyMnTt34p9//sGkSZNw9uxZlJSUoHnz5oiOjkaLFi3ktnXixAl88803SEtLwyeffILJkydXqHP48GGMGzcO586dg5GREfr164fIyEioqb38o/Tw8ICjoyNUVVWxfv161KpVC5GRkejduzeGDRuGLVu2oG7duliyZAl8fX2F/S5cuIBx48bh6NGj0NbWRqdOnRAdHQ0TExMAz6a6Dh06FNu2bYOuri7Gjh1b4djW1tYYOXKkMG0/Ozsbw4cPx4EDB6CiogIfHx8sWbLkpfehXr58GY0bN0ZaWhrs7e2F7dHR0YiJiUFmZibKysowePBgHDx4ELdv34alpSW+/fZbfP/990L9kJAQPHr0CC1btsTSpUshFotx7do1AIBYLIapqelLP095rl69ilGjRiElJQV2dnZYsWIF3NzcAAAPHjzAsGHDcOTIEfz333+wsbHBpEmTEBQUJOwvkUgQFRWFlStX4vr166hbty6++eYboT9cv34dY8aMwb59+6CiooLPPvsMixcvhrW1NQAgNjZWJp5Vq1Zh69atOHDgAPr27VtpzEVFRSgqKhLe5+XlPfssVKRQVZW+9mdByk+sIpX5tyYrKSmRW1ZaWlqhfNeuXfj6669RWFgIMzMz7N69G/r6+igpKcHNmzdRu3btCvsYGRnh5s2blR7rxo0bqFWrFrS1tWXK69SpI3cfZVJ+fsp+nvTm2FdIUewrpCj2lTfzKp/bB53g5+TkICgoCPPmzUPXrl3x+PFjHD16FFKpFI8fP0a/fv2wZMkSSKVSLFiwAH5+frhy5Qp0dXUrtJWfn4/OnTujY8eO2LhxI65duyaTkALAzZs34efnh5CQEGzYsAGXLl3CoEGDoKGhgfDwcIViXr9+PcaPH48TJ05g8+bNGDp0KLZv346uXbti0qRJiI6ORp8+fZCdnQ0tLS08evQInp6eGDhwIKKjo/HkyROEhYWhZ8+eOHjwIABg3LhxOHz4MHbu3Ik6depg0qRJOHPmDJo3b15pDBKJBAEBAdDR0cHhw4dRWlqK7777Dl999RUSExOrjL9Ro0ZwdXVFbGwsIiIihO2xsbHo3bu30H79+vXx22+/wdjYGMePH8fgwYNhZmaGnj17CvscOHAAenp6SEhIkDlGYmIi6tSpA0NDQ3h6eiIyMhLGxsYKfb4AMHnyZERFRcHOzg6TJ09GUFAQMjIyoKamhqdPn8LFxQVhYWHQ09PDrl270KdPH9jY2ODTTz8FAEycOBE//fQToqOj0bZtW+Tk5ODSpUsAnv1weXt7w83NDUePHoWamhoiIyPh4+OD8+fPo1atWhXiKSwsRElJCYyMjOTGPHv2bMyYMaPC9inOEmhplSl87vTxinCVVHcILxUfHy+37PTp01BXV5fZVlRUhKioKOTl5WHfvn3o0qUL5s2bBwMDA6Snp6OgoKBCm8XFxbhw4UKlx0pNTYVEIqlQlpubi6tXr1YZnzJ58XcukTzsK6Qo9hVSFPvK6yksLFS4rkgqldb8YR85zpw5AxcXF2RlZcHKyqrKuhKJBAYGBoiLi0Pnzp0BPFtkr3zl5pUrV2LSpEm4ceMGNDQ0AAArVqzA0KFDcfbsWTRv3hyTJ0/G1q1bkZaWBpHo2WrVy5YtQ1hYGHJzc6GiUvUdDx4eHigrK8PRo0cBAGVlZdDX10dgYCA2bNgAALh9+zbMzMyQlJSE1q1bIzIyEkePHsXevXuFdm7cuAELCwukp6fD3NwcxsbG2LhxI3r06AHg2crS9evXx+DBg4WF9Z4fwU9ISICvry+uXbsGCwsLAMA///yDpk2b4sSJE2jZsmWV57Fo0SLExMQgIyMDgPxR/ecNGzYMt2/fxpYtWwA8G8Hfs2cPsrOzZZLiTZs2QUtLCw0aNEBmZiYmTZoEHR0dJCUlQVVVtcq4srKy0KBBA6xatQqhoaEy51VVbJ07d4a9vT2ioqLw+PFj1K5dGzExMRg4cGCFuhs3bkRkZKRMHyguLoaBgQF27NiBTp06Vdjn22+/xd69e3Hx4kWhb72oshF8CwsLNBm3CaXqXEWf5BOrSBHhKsHUUyooktTsVfQvhHtXur1WrVr47bffEBAQUOX+TZo0Qb9+/RAWFoZ169Zh/PjxuHv3rlBeWloKXV1d/PLLLzIr8pc7dOgQvL29cffuXRgYGAjbbW1tMXz48AoXdZVNSUkJEhIS0LFjxwoXU4iex75CimJfIUWxr7yZvLw8mJiYIDc3F3p6elXW/aBH8J2cnNChQwc4OjrC29sbnTp1Qvfu3WFoaIg7d+5gypQpSExMxN27d1FWVobCwkJkZ2dX2lZaWhqaNWsmk4CVT+t+vo6bm5uQ2AGAu7s78vPzcePGDVhaWr405mbNmglfq6qqwtjYGI6OjsK28iny5X+0njt3DocOHar0sU+ZmZl48uQJiouLZR4dZWRkhMaNG8uNIS0tDRYWFkJyDzz7w9nAwABpaWkvTfB79eqFsWPHIjk5Ga1bt0ZsbCxatGghk0AvXboUa9asQXZ2thDjizMKHB0dK4x49+rVS6a8WbNmsLGxQWJiIjp06FBlXOWe/4zNzMwAPPs87e3tUVZWhlmzZuHXX3/FzZs3UVxcjKKiImF9grS0NBQVFck91rlz55CRkVFhFsjTp0+RmZlZof6cOXOwadMmJCYmyk3ugWe3JYjF4grbiyQilNbwR59RzVAkEdX4x+RV9R+6mpraS//Dl0gkKC0thbq6Otq2bYtHjx7h/PnzcHFxAfAsgZdIJHB3d6+0rVatWkFdXR1HjhxBt27dAADp6enIzs5G27ZtP5o/ONTV1T+ac6U3w75CimJfIUWxr7yeV/nMPugEX1VVFQkJCTh+/Dj27duHJUuWYPLkyUhJScHQoUPx4MEDLF68GFZWVhCLxXBzc5NZzK06vPjNEYlEMtvKLx5IJM+m2+bn58Pf3x9z586t0JaZmZkwiv4+mZqawtPTE3FxcWjdujXi4uIwdOhQoXzTpk0YO3YsFixYADc3N+jq6mL+/PkVFr7S1n75yHTDhg1hYmKCjIwMhRP8qj7P+fPnY/HixVi0aBEcHR2hra2NkSNHCv1CU1Ozyrbz8/Ph4uJS4T574NlChs+LiorCnDlzsH//fpmLDkT07Gfp+d9f165dQ2pqKoyMjGBsbIyZM2fiyy+/hJmZGe7fv4+lS5fi5s2bwkwlBwcH+Pj4YNCgQVixYgVKSkowbNgw9OrVC+bm5gCe3VbVoUMHbNiwAZ9++in09fURGhqK0aNHw8jICHp6ehg+fDjc3NzQunXravkciIiIiN6mDzrBB54lcO7u7nB3d8e0adNgZWWF7du349ixY1i2bBn8/PwAPFsY7f79+3LbcXBwwM8//4ynT58KI60vPjbJwcEBW7duhVQqFRLHY8eOQVdXF/Xr138n59eiRQts3boV1tbWlS7kZ2NjA3V1daSkpAgzCP777z9cvnwZ7dq1q7RNBwcHXL9+HdevX5eZov/o0SM0adJEobiCg4Mxfvx4BAUF4erVqzIj78eOHUObNm3w7bffCtsqG91WxI0bN/DgwQNhJP5NHTt2DAEBAfj6668BPEv8L1++LJy3nZ0dNDU1ceDAgUqn6Ldo0QKbN29GnTp1qpweM2/ePMycORN79+6VWeWbiJ45deoU2rdvL7wfPXo0AKBfv35YsWIFLl26hPXr1+P+/fswNjZGy5YtcfToUTRt2lTYJzY2FsOGDUOHDh2goqKCbt264ccffxTKS0pKkJ6eLnPfWnR0tFC3qKgI3t7eWLZs2Xs4YyIiIqJ374N+TF5KSgpmzZqFU6dOITs7G9u2bcO9e/fg4OAAOzs7/Pzzz0hLS0NKSgqCg4OrHJ3t3bs3RCIRBg0ahH/++Qfx8fGIioqSqfPtt9/i+vXrGD58OC5duoSdO3di+vTpGD169Evvv39d3333HR4+fIigoCCcPHkSmZmZ2Lt3L/r374+ysjLo6OggNDQU48aNw8GDB3HhwgWEhIRUGY+XlxccHR0RHByMM2fO4MSJE+jbty/atWuncDIaGBiIx48fY+jQoWjfvr0wYgY8S5JPnTqFvXv34vLly5g6dSpOnjz50jbz8/Mxbtw4JCcnIysrCwcOHEBAQABsbW3h7V35vbuvys7OTpj1kZaWhm+++QZ37twRyjU0NBAWFobx48djw4YNyMzMRHJyMlavXg3g2YUNExMTBAQE4OjRo7h27RoSExMxYsQI3LhxAwAwd+5cTJ06FWvWrIG1tTVu376N27dvIz8//62cA5Ey8PDwgFQqrfBat24dNDQ0sG3bNty8eRNFRUW4desWdu7cWeH2ISMjI8TFxeHx48fIzc3FmjVrZG5nsra2hlQqhYeHh7BNQ0MDS5cuxcOHD1FQUIBt27a90VM7iIiIiGqSD3oEX09PD0eOHMGiRYuQl5cHKysrLFiwAL6+vjA1NcXgwYPRokULWFhYYNasWZU+Pq6cjo4O/vjjDwwZMgTOzs5o0qQJ5s6dK9ynCQD16tVDfHw8xo0bBycnJxgZGSE0NBRTpkx5Z+dobm6OY8eOISwsDJ06dUJRURGsrKzg4+MjJPHz588XpvLr6upizJgxyM3NldumSCTCzp07MXz4cHz++ecyj8lTlK6uLvz9/fHrr79izZo1MmXffPMNzp49i6+++goikQhBQUH49ttvsXv37irbVFVVxfnz57F+/Xo8evQI5ubm6NSpEyIiIiq9P/11TJkyBVevXoW3tze0tLQwePBgdOnSRebzmjp1KtTU1DBt2jTcunULZmZmGDJkCABAS0sLR44cQVhYmHCRo169eujQoYMwor98+XIUFxeje/fuMseePn26wk9bKJcyscMrPUGAPj4lJSWIj4/HhXBv3tNGRERE9JH7oFfRJ1JWeXl50NfXF6YnE8lTnuD7+fkxwacqsa+QothXSFHsK6Qo9pU3U54bKLKK/gc9RZ+IiIiIiIiInmGC/5ZkZ2dDR0dH7kve4/lqoqZNm8o9j8pWj39fZs2aJTcuX1/faouLiIiIiIioJvig78GvSczNzZGamlpl+YciPj4eJSUllZbVrVv3PUfz/4YMGYKePXtWWvayx9sREREREREpOyb4b4mamhpsbW2rO4y3wsrKqrpDqJSRkRGMjIyqOwwiIiIiIqIaiVP0iYiIiIiIiJQAE3wiIiIiIiIiJcAEn4iIiIiIiEgJMMEnIiIiIiIiUgJM8ImIiIiIiIiUABN8IiIiIiIiIiXABJ+IiIiIiIhICTDBJyIiIiIiIlICTPCJiIiIiIiIlAATfCIiIiIiIiIlwASfiIiIiIiISAkwwSciIiIiIiJSAmrVHQARyddq9gGUqmlXdxhUg4lVpZj3KfBJ+F4UlYmqOxwZWXO+EL4+cuQI5s+fj9OnTyMnJwfbt29Hly5dAAAlJSWYMmUK4uPjcfXqVejr68PLywtz5syBubk5ACAxMRHt27ev9DgnTpxAy5YtKy17+vQpxowZg02bNqGoqAje3t5YtmwZ6tat+3ZPloiIiKgG4Aj+GxCJRNixY4fc8qysLIhEIqSmpr63mN4WDw8PjBw5UnhvbW2NRYsWVVs8NcW6detgYGBQ3WEQfXAKCgrg5OSEpUuXVigrLCzEmTNnMHXqVJw5cwbbtm1Deno6vvzyS6FOmzZtkJOTI/MaOHAgGjRoAFdXV7nHHTVqFP744w/89ttvOHz4MG7duoXAwMB3co5ERERE1Y0j+KSQkydPQlu75o8kh4SEYP369TLbvL29sWfPnndyvPDwcOzYsaPCRZxvvvkG+/fvx61bt6Cjo4M2bdpg7ty5sLe3fydxENV0vr6+8PX1rbRMX18fCQkJMttiYmLw6aefIjs7G5aWlqhVqxZMTU2F8pKSEuzcuRPDhw+HSFT5zIXc3FysXr0acXFx8PT0BACsXbsWDg4OSE5ORuvWrd/S2RERERHVDBzBJ4XUrl0bWlpa1R2GXMXFxcLXPj4+MqN8v/zyy3uPx8XFBWvXrkVaWhr27t0LqVSKTp06oays7L3HQvQhys3NhUgkkjtj5vfff8eDBw/Qv39/uW2cPn0aJSUl8PLyErbZ29vD0tISSUlJbztkIiIiomr30Sf4W7ZsgaOjIzQ1NWFsbAwvLy8UFBTg5MmT6NixI0xMTKCvr4927drhzJkzVbZ14sQJODs7Q0NDA66urjh79myFOocPH8ann34KsVgMMzMzTJgwAaWlpQrF6uHhgeHDh2PkyJEwNDRE3bp18dNPP6GgoAD9+/eHrq4ubG1tsXv3bpn9Lly4AF9fX+jo6KBu3bro06cP7t+/L5QXFBSgb9++0NHRgZmZGRYsWFDh2C9O0c/OzkZAQAB0dHSgp6eHnj174s6dOy89h8uXL0MkEuHSpUsy26Ojo2FjYwMAKCsrQ2hoKBo0aABNTU00btwYixcvlqkfEhKCLl26YObMmTA3N0fjxo2FMrFYDFNTU+FlaGj40riAZ/f4ikQiPHr0SNiWmpoKkUiErKysCvXXrVuHGTNm4Ny5cxCJRBCJRFi3bh0AYPDgwfj8889hbW2NFi1aIDIyEtevX6+0HSKS9fTpU4SFhSEoKAh6enqV1lm9ejW8vb1Rv359ue3cvn0btWrVqnCRoG7durh9+/bbDJmIiIioRviop+jn5OQgKCgI8+bNQ9euXfH48WMcPXoUUqkUjx8/Rr9+/bBkyRJIpVIsWLAAfn5+uHLlCnR1dSu0lZ+fj86dO6Njx47YuHEjrl27hu+//16mzs2bN+Hn54eQkBBs2LABly5dwqBBg6ChoYHw8HCFYl6/fj3Gjx+PEydOYPPmzRg6dCi2b9+Orl27YtKkSYiOjkafPn2QnZ0NLS0tPHr0CJ6enhg4cCCio6Px5MkThIWFoWfPnjh48CAAYNy4cTh8+DB27tyJOnXqYNKkSThz5gyaN29eaQwSiURI7g8fPozS0lJ89913+Oqrr5CYmFhl/I0aNYKrqytiY2MREREhbI+NjUXv3r2F9uvXr4/ffvsNxsbGOH78OAYPHgwzMzP07NlT2OfAgQPQ09OrMLU3MTERderUgaGhITw9PREZGQljY2OFPt9X8dVXX+HChQvYs2cP9u/fD+DZVOMXFRQUYO3atWjQoAEsLCwqbauoqAhFRUXC+7y8PACAWEUKVVXpW4+dlIdYRSrzb01SUlIit6y0tLTS8pKSEvTs2RMSiQQ//vhjpXVu3LiBvXv3Ii4u7qXHqCwOqVSKsrKyKvdVRuXn+7GdN7069hVSFPsKKYp95c28yuf20Sf4paWlCAwMhJWVFQDA0dERAIT7NcutXLkSBgYGOHz4MDp37lyhrbi4OEgkEqxevRoaGhpo2rQpbty4gaFDhwp1li1bBgsLC8TExEAkEsHe3h63bt1CWFgYpk2bBhWVl0+ocHJywpQpUwAAEydOxJw5c2BiYoJBgwYBAKZNm4bly5fj/PnzaN26NWJiYuDs7IxZs2YJbaxZswYWFha4fPkyzM3NsXr1amzcuBEdOnQA8OwiQlWjYgcOHMDff/+Na9euCQnrhg0b0LRpU5w8eVLuatblgoODERMTIyT4ly9fxunTp7Fx40YAgLq6OmbMmCHUb9CgAZKSkvDrr7/KJPja2tpYtWoVatWqJWzz8fFBYGAgGjRogMzMTEyaNAm+vr5ISkqCqqrqSz/fV6GpqQkdHR2oqanJ3BtcbtmyZRg/fjwKCgrQuHFjJCQkyMT6vNmzZ8ucc7kpzhJoaXFaP71chKukukOoID4+Xm7Z6dOnoa6uLrOttLQU8+fPx507d/DDDz/gr7/+qnTfzZs3Q1dXF2pqalUe499//0VxcTF+/fVX6OjoyGz/77//qtxXmb14UZRIHvYVUhT7CimKfeX1FBYWKlz3o07wnZyc0KFDBzg6OsLb2xudOnVC9+7dYWhoiDt37mDKlClITEzE3bt3UVZWhsLCQmRnZ1faVlpaGpo1awYNDQ1hm5ubW4U6bm5uMgtCubu7Iz8/Hzdu3IClpeVLY27WrJnwtaqqKoyNjYWLEgCERz/dvXsXAHDu3DkcOnRI5o/bcpmZmXjy5AmKi4vRqlUrYbuRkZHMlPfKztXCwkJmNLpJkyYwMDBAWlraSxP8Xr16YezYscIiV7GxsWjRooXMAnRLly7FmjVrkJ2dLcT44owCR0fHCglzr169ZMqbNWsGGxsbJCYmChcw3pfg4GB07NgROTk5iIqKQs+ePXHs2DGZPlJu4sSJGD16tPA+Ly8PFhYWiDyrglL1t3thgpSLWEWKCFcJpp5SQZGkZj0m70K4t9wyFxcX+Pn5Ce9LSkoQFBSEx48f49ixY6hdu3al+0mlUowaNQoDBgyQWWW/Mu7u7oiIiICamppwrPT0dNy7dw/9+/eX+b33MSgpKUFCQgI6duxY4eIK0fPYV0hR7CukKPaVN1M+u1cRH3WCr6qqioSEBBw/fhz79u3DkiVLMHnyZKSkpGDo0KF48OABFi9eDCsrK4jFYri5ucks5lYdXvyBEIlEMtvKLx5IJM9G8/Lz8+Hv74+5c+dWaMvMzAwZGRnvMNrKmZqawtPTE3FxcWjdujXi4uJkZjps2rQJY8eOxYIFC+Dm5gZdXV3Mnz8fKSkpMu0osqp/w4YNYWJigoyMjJcm+OUzKKTS/5/q/CbTiPT19aGvrw87Ozu0bt0ahoaG2L59O4KCgirUFYvFEIvFFbYXSUQorWHPNqeaqUgiQlEN6yvP/27Kz8+X+X1z/fp1XLx4EUZGRjAzM0NQUBDOnDmDP//8EyoqKnjw4AGAZxccn7+Qd+DAAVy7dg2DBw+u8Pvw5s2b6NChAzZs2IBPP/0UJiYmCA0Nxfjx41GnTh3o6elh+PDhcHNzQ9u2bd/x2ddc6urq/OOKFMK+QopiXyFFsa+8nlf5zD7qBB94lhC7u7vD3d0d06ZNg5WVFbZv345jx45h2bJlwqjP9evXZRame5GDgwN+/vlnPH36VBihTU5OrlBn69atkEqlQiJ+7Ngx6OrqVjkl/k20aNECW7duhbW1NdTUKn67bWxsoK6ujpSUFGEGwX///YfLly+jXbt2lbbp4OCA69ev4/r168Io/j///INHjx6hSZMmCsUVHByM8ePHIygoCFevXpUZeT927BjatGmDb7/9VtiWmZmp8Dk/78aNG3jw4AHMzMxeWrd8xDAnJ0dYmO/Fx9+9qFatWgqtjC+VSiGVSmXusyf6mJw6dQrt27cX3pfPWOnXrx/Cw8Px+++/A0CFmTqHDh2Ch4eH8H716tVo06ZNpY+cLCkpQXp6usw0tujoaKioqKBbt24oKiqCt7c3li1b9hbPjIiIiKjm+KhX0U9JScGsWbNw6tQpZGdnY9u2bbh37x4cHBxgZ2eHn3/+GWlpaUhJSUFwcDA0NTXlttW7d2+IRCIMGjQI//zzD+Lj4xEVFSVT59tvv8X169cxfPhwXLp0CTt37sT06dMxevRohe6/fx3fffcdHj58iKCgIJw8eRKZmZnYu3cv+vfvj7KyMujo6CA0NBTjxo3DwYMHceHCBYSEhFQZj5eXFxwdHREcHIwzZ87gxIkT6Nu3L9q1awdXV1eF4goMDMTjx48xdOhQtG/fHubm5kKZnZ0dTp06hb179+Ly5cuYOnUqTp48+dI28/PzMW7cOCQnJyMrKwsHDhxAQEAAbG1t4e0tf6pwOVtbW1hYWCA8PBxXrlzBrl27Kn2iwPOsra1x7do1pKam4v79+ygqKsLVq1cxe/ZsnD59GtnZ2Th+/Dh69OgBTU1NmSnJRB8TDw8P4ULX869169bB2tq60jKpVCqT3APP1js5duxYpccob+f5fTQ0NLB06VI8fPgQBQUF2LZtW6VrZhAREREpg486wdfT08ORI0fg5+eHRo0aYcqUKViwYAF8fX2xevVq/Pfff2jRogX69OmDESNGoE6dOnLb0tHRwR9//IG///4bzs7OmDx5coVp8fXq1UN8fDxOnDgBJycnDBkyBKGhocKiee+Cubk5jh07hrKyMnTq1AmOjo4YOXIkDAwMhCR+/vz5+Oyzz+Dv7w8vLy+0bdsWLi4uctsUiUTYuXMnDA0N8fnnn8PLywsNGzbE5s2bFY5LV1cX/v7+OHfuHIKDg2XKvvnmGwQGBuKrr75Cq1at8ODBA5nRfHlUVVVx/vx5fPnll2jUqBFCQ0Ph4uKCo0ePVjr9/UXq6ur45ZdfcOnSJTRr1gxz585FZGRklft069YNPj4+aN++PWrXro1ffvkFGhoaOHr0KPz8/GBra4uvvvoKurq6OH78eJV9iIiIiIiI6E2IpM/fcExENUJeXh709fVx//79d/KIP1IeJSUliI+Ph5+fH+9poyqxr5Ci2FdIUewrpCj2lTdTnhvk5uZCT0+vyrof9Qg+ERERERERkbJggl9DZGdnQ0dHR+5L3uP5aqKmTZvKPY/Y2Nhqi2vWrFly4/L19a22uIiIiIiIiN6Gj34V/ZrC3Ny8yhXbn1+ErqaLj4+X+3i5unXrvudo/t+QIUPQs2fPSsuqWkCRiIiIiIjoQ8AEv4ZQU1ODra1tdYfxVlhZWVV3CJUyMjKCkZFRdYdBRERERET0TnCKPhEREREREZESYIJPREREREREpASY4BMREREREREpASb4REREREREREqACT4RERERERGREmCCT0RERERERKQEmOATERERERERKQEm+ERERERERERKgAk+ERERERERkRJggk9ERERERESkBJjgExERERERESkBJvhERERERERESkCtugMgIvlazT6AUjXt6g6DajCxqhTzPgU+Cd+L9JmdqzscIiIiIqpGHMEnegXW1tZYtGhRdYdBVKUjR47A398f5ubmEIlE2LFjh0y5VCrFtGnTYGZmBk1NTXh5eeHKlSsydWbOnIk2bdpAS0sLBgYGCh1XkXaJiIiI6N1hgk8fnKKiIjRv3hwikQipqanC9qysLIhEogqv5OTkdxZLZcnTX3/9BXd3dxgbG0NTUxP29vaIjo5+ZzEQvaigoABOTk5YunRppeXz5s3Djz/+iBUrViAlJQXa2trw9vbG06dPhTrFxcXo0aMHhg4dqvBxFWmXiIiIiN4dTtGnGq+4uBi1atUS3o8fPx7m5uY4d+5cpfX379+Ppk2bCu+NjY3feYzP09bWxrBhw9CsWTNoa2vjr7/+wjfffANtbW0MHjz4vcZCHydfX1/4+vpWWiaVSrFo0SJMmTIFAQEBAIANGzagbt262LFjB3r16gUAmDFjBgBg3bp1Ch1T0XaJiIiI6N3hCP4HzMPDAyNGjMD48eNhZGQEU1NThIeHA/j/0eznR7gfPXoEkUiExMREAEBiYiJEIhH27t0LZ2dnaGpqwtPTE3fv3sXu3bvh4OAAPT099O7dG4WFhS+NZ+XKlTA3N4dEIpHZHhAQgAEDBgAAMjMzERAQgLp160JHRwctW7bE/v37ZepbW1sjIiICffv2hZ6enkxSvHv3buzbtw9RUVFy4zA2NoapqanwUldXf2nswLPPc+TIkTLbunTpgpCQkErrW1tbAwC6du0KkUgkvHd2dkZQUBCaNm0Ka2trfP311/D29sbRo0cVioPoXbp27Rpu374NLy8vYZu+vj5atWqFpKSkGtcuERERESmOI/gfuPXr12P06NFISUlBUlISQkJC4O7uDjs7O4XbCA8PR0xMDLS0tNCzZ0/07NkTYrEYcXFxyM/PR9euXbFkyRKEhYVV2U6PHj0wfPhwHDp0CB06dAAAPHz4EHv27EF8fDwAID8/H35+fpg5cybEYjE2bNgAf39/pKenw9LSUmgrKioK06ZNw/Tp04Vtd+7cwaBBg7Bjxw5oaWnJjePLL7/E06dP0ahRI4wfPx5ffvmlwp/Fqzh58iTq1KmDtWvXwsfHB6qqqpXWO3v2LI4fP47IyEi5bRUVFaGoqEh4n5eXBwAQq0ihqip9u4GTUhGrSIV/S0pKKq1TWloqlN24cQMAYGRkJFO/du3auHXrVoU2ysrKAEBu2+VetV16/8q/B/xe0Muwr5Ci2FdIUewrb+ZVPjcm+B+4Zs2aCUmwnZ0dYmJicODAgVdK8CMjI+Hu7g4ACA0NxcSJE5GZmYmGDRsCALp3745Dhw69NME3NDSEr68v4uLihAR/y5YtMDExQfv27QEATk5OcHJyEvaJiIjA9u3b8fvvv2PYsGHCdk9PT4wZM0Z4L5VKERISgiFDhsDV1RVZWVkVjq+jo4MFCxbA3d0dKioq2Lp1K7p06YIdO3a8kyS/du3aAAADAwOYmppWKK9fvz7u3buH0tJShIeHY+DAgXLbmj17tjAl+nlTnCXQ0ip7e0GT0opwlQgX0l50+vRpYSbLpUuXAAAHDhyAkZGRUCcnJwcikahCG+fOnUNJSYnctsu9artUfRISEqo7BPpAsK+QothXSFHsK69HkdnU5Zjgf+CaNWsm897MzAx379597Tbq1q0LLS0tIbkv33bixAmF2goODsagQYOwbNkyiMVixMbGolevXlBReXY3SH5+PsLDw7Fr1y7k5OSgtLQUT548QXZ2tkw7rq6uMu+XLFmCx48fY+LEiXKPbWJigtGjRwvvW7ZsiVu3bmH+/PnvbBS/KkePHkV+fj6Sk5MxYcIE2NraIigoqNK6EydOlIk9Ly8PFhYWiDyrglL1ymcGEAHPRu4jXCWYekoFp6f5VFrHxcUFfn5+AAB7e3tMmDABn3zyCZo3by7UWbBgAZycnIR65e7fvw91dfUK21/0qu3S+1dSUoKEhAR07NhR4VuX6OPEvkKKYl8hRbGvvJny2b2KYIL/gXvxB0QkEkEikQgJtVT6/9O75U3teL4NkUgkt01F+Pv7QyqVYteuXWjZsiWOHj0qs4L82LFjkZCQgKioKNja2kJTUxPdu3dHcXGxTDva2rLPfj948CCSkpIgFotltru6uiI4OBjr16+vNJ5WrVopfKVQRUVF5vMC3mwaUYMGDQAAjo6OuHPnDsLDw+Um+GKxuMK5AUCRRITSMtFrx0AfjyJJxZ/dcmpqakJZo0aNYGpqiiNHjqBly5YAnv2nceLECXz77bcV2ii/9eRl/xm/artUfdTV1fn9IIWwr5Ci2FdIUewrr+dVPjMm+EqqfPp4Tk4OnJ2dAUBmwb13RUNDA4GBgYiNjUVGRgYaN26MFi1aCOXHjh1DSEgIunbtCuDZiH5l0+1f9OOPP8rcw37r1i14e3tj8+bNaNWqldz9UlNTYWZmplDstWvXRk5OjvC+rKwMFy5cEG4vqIy6urpwj3JVJBKJzD32RO9Sfn4+MjIyhPfXrl1DamoqjIyMYGlpiZEjRyIyMhJ2dnZo0KABpk6dCnNzc3Tp0kXYJzs7Gw8fPkR2djbKysqE3x+2trbQ0dEB8GzUfvbs2cJCk4q0S0RERETvDhN8JaWpqYnWrVtjzpw5aNCgAe7evYspU6a8l2MHBwejc+fOuHjxIr7++muZMjs7O2zbtg3+/v4QiUSYOnWqQrMDnl+AD4CQYNjY2KB+/foAni04WKtWLeGCxrZt27BmzRqsWrVKobg9PT0xevRo7Nq1CzY2Nli4cCEePXpU5T7W1tY4cOAA3N3dIRaLYWhoiKVLl8LS0hL29vYAgCNHjiAqKgojRoxQKA6iN3Xq1CmZC1Plt3/069cP69atw/jx41FQUIDBgwfj0aNHaNu2Lfbs2QMNDQ1hn2nTpsnMjCn/uTp06BA8PDwAAOnp6cjNzRXqKNIuEREREb07TPCV2Jo1axAaGgoXFxc0btwY8+bNQ6dOnd75cT09PWFkZIT09HT07t1bpmzhwoUYMGAA2rRpAxMTE4SFhb3SPSUvExERgX///Rdqamqwt7fH5s2b0b17d4X2HTBgAM6dO4e+fftCTU0No0aNqnL0Hnh2f/Ho0aPx008/oV69esjKyoJEIsHEiRNx7do1qKmpwcbGBnPnzsU333zzNk6R6KU8PDwq3G7yPJFIhB9++AE//PCD3Drr1q3DunXrqjzOi8dQpF0iIiIiendE0qr+CiSiapGXlwd9fX3cv38fxsbG1R0O1WDlK9z7+fnxnjaqEvsKKYp9hRTFvkKKYl95M+W5QW5uLvT09Kqsq/KeYiIiIiIiIiKid4gJPiksOzsbOjo6cl8vPuqupqkq9qNHj1Z3eERERERERG+E9+CTwszNzatcid/c3Pz9BfMaqoq9Xr167y8QIiIiIiKid4AJPilMTU0Ntra21R3Ga/uQYyciIiIiInoZTtEnIiIiIiIiUgJM8ImIiIiIiIiUABN8IiIiIiIiIiXABJ+IiIiIiIhICTDBJyIiIiIiIlICTPCJiIiIiIiIlAATfCIiIiIiIiIlwASfiIiIiIiISAkwwSciIiIiIiJSAkzwiYiIiIiIiJQAE3wiIiIiIiIiJcAEn4iIiIiIiEgJMMEnIiIiIiIiUgJq1R0AEcnXavYBlKppV3cYVINdiegkfP348WNMnToV27dvx927d+Hs7IzFixejZcuWAIA7d+4gLCwM+/btw6NHj/D5559jyZIlsLOzq/IYv/32G6ZOnYqsrCzY2dlh7ty58PPze6fnRURERESvjiP4RK/A2toaixYtqu4wiCo1cOBAJCQk4Oeff8bff/+NTp06wcvLCzdv3oRUKkWXLl1w9epV7Ny5E2fPnoWVlRW8vLxQUFAgt83jx48jKCgIoaGhOHv2LLp06YIuXbrgwoUL7/HMiIiIiEgRTPDpg5CVlYXQ0FA0aNAAmpqasLGxwfTp01FcXCzUSUxMREBAAMzMzKCtrY3mzZsjNjb2ncYlEomwY8cOmW1//fUX3N3dYWxsDE1NTdjb2yM6OvqdxkH05MkTbN26FfPmzcPnn38OW1tbhIeHw9bWFsuXL8eVK1eQnJyM5cuXo2XLlmjcuDGWL1+OJ0+e4JdffpHb7uLFi+Hj44Nx48bBwcEBERERaNGiBWJiYt7j2RERERGRIpjgU41XXFyMS5cuQSKR4H//+x8uXryI6OhorFixApMmTRLqHT9+HM2aNcPWrVtx/vx59O/fH3379sWff/75XuPV1tbGsGHDcOTIEaSlpWHKlCmYMmUKVq5c+V7joI9LaWkpysrKoKGhIbNdU1MTf/31F4qKigBAplxFRQVisRh//fWX3HaTkpLg5eUls83b2xtJSUlvMXoiIiIieht4D/4HzMPDA82aNYOGhgZWrVqFWrVqYciQIQgPD0dWVhYaNGiAs2fPonnz5gCAR48ewdDQEIcOHYKHhwcSExPRvn177NmzBxMmTMClS5fg5uaGTZs24fTp0xg9ejRu3ryJzp07Y9WqVdDS0qoynpUrVyI8PBw3btyAisr/XzsKCAiAsbEx1qxZg8zMTIwePRrJyckoKCiAg4MDZs+eLZNAWFtbIzQ0FFeuXMGOHTsQGBiIdevWwcfHR6jTsGFDpKenY/ny5YiKigIAmWQfAL7//nvs27cP27ZtQ+fOnRX6PJs3by4zBb9Lly4wMDDAunXrKtS3trYGAHTt2hUAYGVlhaysLDg7O8PZ2Vmm3rZt23D06FEMHjy40mMXFRUJCRgA5OXlAQDEKlKoqkpfGjt9vEpKSgA8S9xbt26NH374Aba2tqhbty42bdqEpKQk2NjYwMbGBpaWlggLC8OyZcugra2NxYsX48aNG7h165bQzotu374NY2NjmXITExPcvn1b7j5UM5V/v/h9o5dhXyFFsa+QothX3syrfG5M8D9w69evx+jRo5GSkoKkpCSEhITA3d39pYtmPS88PBwxMTHQ0tJCz5490bNnT4jFYsTFxSE/Px9du3bFkiVLEBYWVmU7PXr0wPDhw3Ho0CF06NABAPDw4UPs2bMH8fHxAID8/Hz4+flh5syZEIvF2LBhA/z9/ZGeng5LS0uhraioKEybNg3Tp0+Xe7zc3FwYGRlVGVNubi4cHBwU/SheycmTJ1GnTh2sXbsWPj4+UFVVrbTe2bNncfz4cURGRspta/bs2ZgxY0aF7VOcJdDSKntrMZPySUhIEP7t168fYmJiYG1tDRUVFdjY2OCzzz5DZmYmEhISMGLECMTExKBu3bpQUVGBk5MTWrRogQcPHgg/oy+SSqVITU2Fnp6esO3ChQsoKiqSuw/VbOV9huhl2FdIUewrpCj2lddTWFiocF0m+B+4Zs2aCUmwnZ0dYmJicODAgVdK8CMjI+Hu7g4ACA0NxcSJE5GZmYmGDRsCALp3745Dhw69NME3NDSEr68v4uLihAR/y5YtMDExQfv27QEATk5OcHJyEvaJiIjA9u3b8fvvv2PYsGHCdk9PT4wZM0busTIyMrBkyRJh9L4yv/76K06ePIn//e9/L/kEXk/t2rUBAAYGBjA1Na1QXr9+fdy7dw+lpaUIDw/HwIED5bY1ceJEjB49Wnifl5cHCwsLRJ5VQal65RcOiADg7GRPJCQkoGPHjlBXV0doaCgKCgqQl5cHMzMz9O7dG1paWsKq9yNGjEBubi6Ki4tRu3ZtuLu7w8XFRe6q+GZmZjA3N5cpP3nyJCwtLbmS/gempKREpq8QycO+QopiXyFFsa+8mfLZvYpggv+Ba9asmcx7MzMz3L1797XbqFu3LrS0tITkvnzbiRMnFGorODgYgwYNwrJlyyAWixEbG4tevXoJU/bz8/MRHh6OXbt2IScnB6WlpXjy5Amys7Nl2nF1dZV7jJs3b8LHxwc9evTAoEGDKq1z6NAh9O/fHz/99BOaNm2qUOxv29GjR5Gfn4/k5GRMmDABtra2CAoKqrSuWCyGWCyusL1IIkJpmehdh0ofsPL/JNXV1YWvDQwMYGBggP/++w8JCQmYN2+ezH+mJiYmAIArV67g9OnTiIyMlPufrZubGxITE2UuuB08eBBt2rThf9AfqOf7ClFV2FdIUewrpCj2ldfzKp8ZE/wP3IvfbJFIBIlEIiTUUun/378t796N59sQiURy21SEv78/pFIpdu3ahZYtW+Lo0aMyK8iPHTsWCQkJiIqKgq2tLTQ1NdG9e3eZ1fCBZwvVVebWrVto37492rRpI3fRusOHD8Pf3x/R0dHo27evQnEDzxYce/7zAt7sPqEGDRoAABwdHXHnzh2Eh4fLTfCJ3oa9e/dCKpWicePGyMjIwLhx42Bvb4/+/fsDePY8+9q1a8PS0hJ///03vv/+e3Tp0gWdOnUS2ujbty/q1auH2bNnA3i2lkW7du2wYMECfPHFF9i0aRNOnTrFRSOJiIiIaiAm+EqqfPp4Tk6OsOBbamrqOz+uhoYGAgMDERsbi4yMDDRu3BgtWrQQyo8dO4aQkBBhYbr8/HxkZWUp1PbNmzfRvn17uLi4YO3atTIL+ZVLTExE586dMXfuXLkL2slTu3Zt5OTkCO/Lyspw4cIF4faCyqirq6Os7OX3yEskEplF9IjehdzcXEycOBE3btyAkZERunXrhpkzZwoX7XJycjB69GjcuXMHZmZm6Nu3L6ZOnSrTRnZ2tszPVps2bRAXF4cpU6Zg0qRJsLOzw44dO/DJJ5+813MjIiIiopdjgq+kNDU10bp1a8yZMwcNGjTA3bt3MWXKlPdy7ODgYHTu3BkXL17E119/LVNmZ2eHbdu2wd/fHyKRCFOnTlVodsDNmzfh4eEBKysrREVF4d69e0JZ+f3vhw4dQufOnfH999+jW7duuH37NgCgVq1aL12MD3h23//o0aOxa9cu2NjYYOHChXj06FGV+1hbW+PAgQNwd3eHWCyGoaEhli5dCktLS9jb2wMAjhw5gqioKIwYMeKlMRC9ifJFMuUZMWLES/thYmJihW09evRAjx493jQ8IiIiInrHmOArsTVr1iA0NBQuLi5o3Lgx5s2bJzMV913x9PSEkZER0tPT0bt3b5myhQsXYsCAAWjTpg1MTEwQFham0KIRCQkJyMjIQEZGBurXry9TVj6tfv369SgsLMTs2bOF6cUA0K5du0qTlhcNGDAA586dQ9++faGmpoZRo0ZVOXoPAAsWLMDo0aPx008/oV69esjKyoJEIsHEiRNx7do1qKmpwcbGBnPnzsU333zz0hhelDKxA4yNjV95P/p48HEzRERERFROJH3xpmMiqnZ5eXnQ19fH/fv3meBTlUpKShAfHw8/Pz8uWkNVYl8hRbGvkKLYV0hR7Ctvpjw3yM3NlXl0cWUq3sRMRERERERERB8cJviksOzsbOjo6Mh9vfiou5qmqtiPHj1a3eERERERERG9Ed6DTwozNzevciV+c3Pz9xfMa6gq9nr16r2/QIiIiIiIiN4BJvikMDU1Ndja2lZ3GK/tQ46diIiIiIjoZThFn4iIiIiIiEgJMMEnIiIiIiIiUgJM8ImIiIiIiIiUABN8IiIiIiIiIiXABJ+IiIiIiIhICTDBJyIiIiIiIlICTPCJiIiIiIiIlAATfCIiIiIiIiIlwASfiIiIiIiISAkwwSciIiIiIiJSAkzwiYiIiIiIiJQAE3wiIiIiIiIiJaBW3QEQkXytZh9AqZp2dYdBNUjWnC+Erx8/fozJkydj06ZNePz4MZydnbF48WK0bNlSqJOWloawsDAcPnwYpaWlaNKkCbZu3QpLS0u5x/jtt98wdepUZGVlwc7ODnPnzoWfn987PS8iIiIienMcwSelERISgi5dulR3GETvzcCBA7F//36MHDkSZ86cQadOneDl5YWbN28CADIzM9G2bVvY29sjMTER58+fx9SpU6GhoSG3zePHjyMoKAihoaE4e/YsunTpgi5duuDChQvv67SIiIiI6DUxwaf3rqioCM2bN4dIJEJqaqqwPSsrCyKRqMIrOTm5+oJ9DV9++SUsLS2hoaEBMzMz9OnTB7du3arusEjJPHnyBFu3bsXs2bPRtGlT2NraIjw8HLa2tli+fDkAYPLkyfDz88O8efPg7OwMGxsbfPnll6hTp47cdhcvXgwfHx+MGzcODg4OiIiIQIsWLRATE/O+To2IiIiIXhMTfHrniouLZd6PHz8e5ubmcuvv378fOTk5wsvFxeVdh/hWtW/fHr/++ivS09OxdetWZGZmonv37tUdFimZ0tJSlJWVVRiN19TUxF9//QWJRIJdu3ahUaNG8Pb2Rp06ddCqVSvs2LGjynaTkpLg5eUls83b2xtJSUlv+xSIiIiI6C1jgl+NPDw8MGLECIwfPx5GRkYwNTVFeHg4gP8fzX5+hPvRo0cQiURITEwEACQmJkIkEmHv3r1wdnaGpqYmPD09cffuXezevRsODg7Q09ND7969UVhY+NJ4Vq5cCXNzc0gkEpntAQEBGDBgAIBnU34DAgJQt25d6OjooGXLlti/f79MfWtra0RERKBv377Q09PD4MGDhbLdu3dj3759iIqKkhuHsbExTE1NhZe6uvpLY39eVFQUzMzMYGxsjO+++w4lJSVC2c8//wxXV1fo6urC1NQUvXv3xt27d2X2v3jxIjp37gw9PT3o6uris88+Q2ZmplC+atUqODg4QENDA/b29li2bJnM/qNGjULr1q1hZWWFNm3aYMKECUhOTpaJg+hN6erqws3NDbNmzcLDhw9RVlaGjRs3IikpCTk5Obh79y7y8/MxZ84c+Pj4YN++fejatSsCAwNx+PBhue3evn0bdevWldlWt25d3L59+12fEhERERG9IS6yV83Wr1+P0aNHIyUlBUlJSQgJCYG7uzvs7OwUbiM8PBwxMTHQ0tJCz5490bNnT4jFYsTFxSE/Px9du3bFkiVLEBYWVmU7PXr0wPDhw3Ho0CF06NABAPDw4UPs2bMH8fHxAID8/Hz4+flh5syZEIvF2LBhA/z9/ZGeni6zaFdUVBSmTZuG6dOnC9vu3LmDQYMGYceOHdDS0pIbx5dffomnT5+iUaNGGD9+PL788kuFP4tDhw7BzMwMhw4dQkZGBr766is0b94cgwYNAgCUlJQgIiICjRs3xt27dzF69GiEhIQI53fz5k18/vnn8PDwwMGDB6Gnp4djx46htLQUABAbG4tp06YhJiYGzs7OOHv2LAYNGgRtbW3069evQjwPHz5EbGws2rRpU+WFiqKiIhQVFQnv8/LyAABiFSlUVaUKnz8pv+cvFK1ZswaDBg3CgAEDMGjQIDg7O+Orr77CmTNnhP7k7++PYcOGAQCaNm2Kv/76C8uWLUObNm3kHqO0tFTmOGVlZRWOTR+e8u8fv4/0MuwrpCj2FVIU+8qbeZXPjQl+NWvWrJmQBNvZ2SEmJgYHDhx4pQQ/MjIS7u7uAIDQ0FBMnDgRmZmZaNiwIQCge/fuOHTo0EsTfENDQ/j6+iIuLk5I8Lds2QITExO0b98eAODk5AQnJydhn4iICGzfvh2///67kEQAgKenJ8aMGSO8l0qlCAkJwZAhQ+Dq6oqsrKwKx9fR0cGCBQvg7u4OFRUVbN26FV26dMGOHTsUTvINDQ0RExMDVVVV2Nvb44svvsCBAweEBL98JgIANGzYED/++CNatmyJ/Px86OjoYOnSpdDX18emTZuEhLxRo0bCPtOnT8eCBQsQGBgIAGjQoAH++ecf/O9//5NJ8MPCwhATE4PCwkK0bt0af/75Z5Vxz549GzNmzKiwfYqzBFpaZQqdO30cyi9GlRs7diyGDRuGwsJCGBkZYf78+dDR0cHJkyehqqoKVVVVmX1q1aqF8+fPV2innL6+PhITE6GnpydsO3bsGLS0tOTuQx+WhISE6g6BPhDsK6Qo9hVSFPvK61FkNnY5JvjVrFmzZjLvzczMKkwZf5U26tatCy0tLSG5L9924sQJhdoKDg7GoEGDsGzZMojFYsTGxqJXr15QUXl2N0d+fj7Cw8Oxa9cu5OTkoLS0FE+ePEF2drZMO66urjLvlyxZgsePH2PixIlyj21iYoLRo0cL71u2bIlbt25h/vz5Cif4TZs2haqqqvDezMwMf//9t/D+9OnTCA8Px7lz5/Dff/8JtyNkZ2ejSZMmSE1NxWeffVbpaHtBQQEyMzMRGhoqXDAAno126uvry9QdN24cQkND8e+//2LGjBno27cv/vzzT4hEokrjnjhxosy55+XlwcLCApFnVVCqrlrpPvRxuhDuLfO+pKQECQkJ8Pf3R35+Pi5cuIDZs2cjICBAeFze84+4W7NmDZycnOQ+9s7DwwO3b9+WKZ8zZw46duzIR+V94Mr7SseOHV/51if6uLCvkKLYV0hR7Ctvpnx2ryKY4FezFzu4SCSCRCIREmqp9P+nZ8ubmvF8GyKRSG6bivD394dUKsWuXbvQsmVLHD16FNHR0UL52LFjkZCQgKioKNja2kJTUxPdu3evsJCetrbss9sPHjyIpKQkiMVime2urq4IDg7G+vXrK42nVatWr3Slr6pzLygogLe3N7y9vREbG4vatWsjOzsb3t7eQvyamppy287PzwcA/PTTT2jVqpVM2fMXFYBnFytMTEzQqFEjODg4wMLCAsnJyXBzc6u0bbFYXOGzAYAiiQilZZVfFKCP0/N9fO/evSgpKcGdO3dw+PBhTJw4Efb29hg4cCDU1dUxfvx4fPXVV/Dw8ED79u2xZ88e7Nq1C4mJiUI7ffv2Rb169TB79mwAz9aQaNeuHX788Ud88cUX2LRpE06fPo2ffvqJ/yErCXV1dX4vSSHsK6Qo9hVSFPvK63mVz4wJfg1Vu3ZtAEBOTg6cnZ0BQGbBvXdFQ0MDgYGBiI2NRUZGBho3bowWLVoI5ceOHUNISAi6du0K4FnSW9l0+xf9+OOPiIyMFN7funUL3t7e2Lx5c4Vk+XmpqakwMzN7/RN6zqVLl/DgwQPMmTMHFhYWAIBTp07J1GnWrBnWr1+PkpKSCj9IdevWhbm5Oa5evYrg4GCFj1t+geH5e+yJ3obc3FxMnDgR2dnZMDExQbdu3TBz5kyh73bt2hUrVqzA7NmzMWLECDRu3Bhbt25F27ZthTays7OFC4oA0KZNG8TFxWHKlCmYNGkS7OzssGPHDnzyySfv/fyIiIiI6NUwwa+hNDU10bp1a8yZMwcNGjTA3bt3MWXKlPdy7ODgYHTu3BkXL17E119/LVNmZ2eHbdu2wd/fHyKRCFOnTlVodsDzC/ABz+63BwAbGxvUr18fwLMFB2vVqiVc0Ni2bRvWrFmDVatWvY3TgqWlJWrVqoUlS5ZgyJAhuHDhAiIiImTqDBs2DEuWLEGvXr0wceJE6OvrIzk5GZ9++ikaN26MGTNmYMSIEdDX14ePjw+Kiopw6tQp/Pfff8JiiSdPnkTbtm1haGiIzMxMTJ06FTY2NnJH74leV8+ePdG1a1fEx8fDz8+v0qu7AwYMkFl74kXlT+V4Xo8ePdCjR4+3GSoRERERvQd8TF4NtmbNGpSWlsLFxQUjR46UGQF/lzw9PWFkZIT09HT07t1bpmzhwoUwNDREmzZt4O/vD29vb5kR/jcVEREBFxcXtGrVCjt37sTmzZvRv3//t9J27dq1sW7dOvz2229o0qQJ5syZU+FxfcbGxjh48CDy8/PRrl07uLi4yExNHjhwIFatWoW1a9fC0dER7dq1w7p169CgQQMAgJaWFrZt24YOHTqgcePGCA0NRbNmzfB/7N17XM73/z/wx9VB59JJB1KplhxKzmomOZRWTqNRQ61lsRzWkCwpISxEDZM5LmObw2zS1igzUk45jaboG8mcllSkw/X7w6/3x6XTVVLkcb/drtut6/V6vV/v5/u6Xly35/v9er/eR44cqXYKPhERERERUWMRiZ+/yZuIXgsFBQXQ0NDAvXv3oK2t3dzh0GustLS01iv4RJU4VkhaHCskLY4VkhbHysupzA0ePnwo8aSj6vAKPhEREREREVELwAT/LZKTkwNVVdUaXy8+6u51U1vsR48ebe7wiIiIiIiImhUX2XuLGBoa1roSv6GhYdMF0wC1xd62bdumC4SIiIiIiOg1xAT/LSInJwdzc/PmDqPB3uTYiYiIiIiIXjVO0SciIiIiIiJqAZjgExEREREREbUATPCJiIiIiIiIWgAm+EREREREREQtABN8IiIiIiIiohaACT4RERERERFRC9BoCX5+fn5jdUVERERERERE9dSgBH/ZsmXYtWuX8N7d3R3a2tpo27Ytzp0712jBEREREREREZF0GpTgr1+/HkZGRgCAxMREJCYm4uDBgxg2bBhmz57dqAESERERERERUd3kGrLR7du3hQT/119/hbu7O4YOHQoTExP06dOnUQMkIiIiIiIioro16Aq+pqYmbty4AQBISEjA4MGDAQBisRjl5eWNFx0RERERERERSaVBV/BHjx4NDw8PWFhY4P79+xg2bBgA4OzZszA3N2/UAImIiIiIiIiobg1K8FetWgUTExPcuHEDy5cvh6qqKgAgLy8PU6dObdQAid5mfSIOoUxOpbnDeOtkL32/uUMgIiIiIqq3Bk3Rl5eXx6xZs7B69WrY2toK5Z9//jk++eSTRguO6HVjYmKCqKio5g6DmlBubi4++ugjaGtrQ0lJCV27dsWpU6eE+sLCQvj7+6Ndu3ZQUlJCp06dsH79+jr7/fHHH9GxY0coKiqia9euiI+Pf5WHQURERERvgQYl+ACwfft2vPvuuzA0NMT//d//AQCioqLw888/N1pwRJWys7Ph4+MDU1NTKCkpwczMDAsWLMDTp0+FNsnJyRgxYgQMDAygoqKCbt26IS4u7pXGJRKJsG/fPomyvLw8eHh44J133oGMjAxmzpz5SmOgV+e///6Dvb095OXlcfDgQfz9999YsWIFNDU1hTYBAQFISEjAd999h8uXL2PmzJnw9/fH/v37a+z3+PHjGD9+PHx8fHD27FmMHDkSI0eOxMWLF5visIiIiIiohWpQgr9u3ToEBARg2LBhyM/PFxbWa926Na9uUqN7+vQprly5goqKCnzzzTe4dOkSVq1ahfXr12PevHlCu+PHj8Pa2hq7d+/G+fPn4e3tjYkTJ+LXX39t0nhLSkqgq6uL4OBg2NjYNOm+qXEtW7YMRkZG2Lx5M3r37g1TU1MMHToUZmZmQpvjx49j0qRJcHBwgImJCSZPngwbGxukpaXV2O/q1avh7OyM2bNnw8rKCuHh4ejevTtiYmKa4rCIiIiIqIVqUIIfHR2N2NhYfPnll5CVlRXKe/bsiQsXLjRacFQ7BwcHTJ8+HXPmzIGWlhb09fURGhoK4NkVb5FIhPT0dKF9fn4+RCIRkpOTATy74i0SifDbb7/B1tYWSkpKcHR0xJ07d3Dw4EFYWVlBXV0dHh4eKC4urjOeDRs2wNDQEBUVFRLlI0aMwMcffwwAyMrKwogRI6CnpwdVVVX06tULf/zxh0R7ExMThIeHY+LEiVBXV8fkyZPh7OyMzZs3Y+jQoejQoQOGDx+OWbNmYc+ePcJ28+bNQ3h4OOzs7GBmZoYZM2bA2dlZok1dn+eLV9tHjhwJLy+vatubmJgAAEaNGgWRSCS8NzExwerVqzFx4kRoaGhItW96Pe3fvx89e/bE2LFj0aZNG9ja2iI2NlaijZ2dHfbv34/c3FyIxWIkJSXhn3/+wdChQ2vsNyUlRXj6SCUnJyekpKS8kuMgIiIiordDgxbZu379usS995UUFBRQVFT00kGR9LZu3YqAgACkpqYiJSUFXl5esLe3h4WFhdR9hIaGIiYmBsrKynB3d4e7uzsUFBSwY8cOFBYWYtSoUYiOjkZgYGCt/YwdOxbTpk1DUlISBg0aBAB48OABEhIShPuLCwsL4eLigsWLF0NBQQHbtm2Dm5sbMjIy0L59e6GvyMhIhISEYMGCBTXu7+HDh9DS0qo1pocPH8LKykraj6JeTp48iTZt2mDz5s1wdnaWONlVXyUlJSgpKRHeFxQUAAAUZMSQlRW/dKxUP6WlpQCAa9euYd26dZgxYwZmz56N06dPY/r06ZCRkcHEiRMBACtXrsSUKVPQrl07yMnJQUZGBuvWrUO/fv2Efl50+/ZtaGtrS9Tr6Ojg9u3bNW5TV6z13Y7ePhwrJC2OFZIWxwpJi2Pl5dTnc2tQgm9qaor09HQYGxtLlCckJLyyZIqqZ21tLSTBFhYWiImJwaFDh+qV4C9atAj29vYAAB8fHwQFBSErKwsdOnQAAIwZMwZJSUl1JviampoYNmwYduzYIST4P/30E3R0dDBw4EAAgI2NjcS09fDwcOzduxf79++Hv7+/UO7o6Igvvviixn1lZmYiOjoakZGRNbb54YcfcPLkSXzzzTd1fAINo6urC+DZrSn6+vov1VdERATCwsKqlAfbVkBZufyl+qb6qzwhVV5eDjMzM9jZ2SEvLw+GhoYYNGgQvvrqK+jo6AAA9u3bh8OHD2PevHlo06YNLl26hM8++ww3b96s8RYNsViM9PR0qKurC2UXL15ESUlJgxfbS0xMbNB29PbhWCFpcayQtDhWSFocKw0jzWzqSg1K8AMCAvDZZ5/hyZMnEIvFSEtLw/fff4+IiAhs3LixIV1SA1lbW0u8NzAwwJ07dxrch56eHpSVlYXkvrKstvuJn+fp6QlfX1+sXbsWCgoKiIuLw7hx4yAj8+xukMLCQoSGhuLAgQPIy8tDWVkZHj9+jJycHIl+evbsWeM+cnNz4ezsjLFjx8LX17faNklJSfD29kZsbCw6d+4sVezNKSgoCAEBAcL7goICGBkZYdFZGZTJN3xmADXMxVAnAIChoSHs7Ozg4uIi1N24cQMRERFwcXHB48ePMXbsWPz4448SbcrKynDs2DEEBQVV27+BgQEMDQ0ltjl58iTat28vUSaN0tJSJCYmYsiQIZCXl6/XtvR24VghaXGskLQ4VkhaHCsvp3J2rzQalOB/8sknUFJSQnBwMIqLi+Hh4QFDQ0OsXr0a48aNa0iX1EAv/gMRiUSoqKgQEmqx+H/Tu2ua2vF8HyKRqMY+peHm5gaxWIwDBw6gV69eOHr0KFatWiXUz5o1C4mJiYiMjIS5uTmUlJQwZswYidXwAUBFpfpnv9+6dQsDBw6EnZ0dNmzYUG2bI0eOwM3NDatWrRKmUUtDRkZG4vMCmm4akYKCAhQUFKqUl1SIUFYuapIY6H8q/w3Y29vj6tWrEv8msrKyYGxsDHl5eTx+/BilpaVo1aqVRBt5eXmIxeIaf8D69euH5ORkiVkqhw8fhp2dXYN/9OTl5fmDSVLhWCFpcayQtDhWSFocKw1Tn8+s3gl+WVkZduzYAScnJ3h6eqK4uBiFhYVo06ZNfbuiV6hy+nheXp6wXsLzC+69KoqKihg9ejTi4uKQmZkJS0tLdO/eXag/duwYvLy8MGrUKADPruhnZ2dL1Xdubi4GDhyIHj16YPPmzcJJjOclJyfD1dUVy5Ytw+TJk+sVu66uLvLy8oT35eXluHjxonB7QXXk5eWFp0hQy/P555/Dzs4OS5Ysgbu7O9LS0rBhwwbh5JK6ujoGDBiA2bNnQ0lJCcbGxjhy5Ai2bduGlStXCv1MnDgRbdu2RUREBABgxowZGDBgAFasWIH3338fO3fuxKlTp2o8aUVEREREJI16J/hycnLw8/PD5cuXAQDKyspQVlZu9MDo5SgpKaFv375YunQpTE1NcefOHQQHBzfJvj09PeHq6opLly7ho48+kqizsLDAnj174ObmBpFIhPnz50s1OyA3NxcODg4wNjZGZGQk7t69K9RV3v+elJQEV1dXzJgxAx988AFu374NAGjVqlWdi/EBz+77DwgIwIEDB2BmZoaVK1ciPz+/1m1MTExw6NAh2NvbQ0FBQXg+euXJlMLCQty9exfp6elo1aoVOnXqVGcc9Pro1asX9u7di6CgICxcuBCmpqaIioqCp6en0Gbnzp0ICgqCp6cnHjx4AGNjYyxevBh+fn5Cm5ycHIkTUnZ2dtixYweCg4Mxb948WFhYYN++fejSpUuTHh8RERERtSwNmqLfu3dvnD17tsoie/R62bRpE3x8fNCjRw9YWlpi+fLltT66q7E4OjpCS0sLGRkZ8PDwkKhbuXIlPv74Y9jZ2UFHRweBgYFS3VOSmJiIzMxMZGZmol27dhJ1ldPqt27diuLiYkRERAhXSgFgwIABwqMBa/Pxxx/j3LlzmDhxIuTk5PD555/XevUeAFasWIGAgADExsaibdu2wmyE558ycfr0aezYsQPGxsZSz1ag14erqytcXV1rrNfX18fmzZtr7aO68Td27FiMHTv2ZcMjIiIiIhKIxC/edCyFH374AUFBQfj888/Ro0ePKvdLv7jwGxHVT0FBATQ0NHDv3j1oa2s3dzj0GistLUV8fDxcXFx4TxvVimOFpMWxQtLiWCFpcay8nMrc4OHDhxJPYapOg67gVy6kN336dKFMJBJBLBZDJBLxnmQiIiIiIiKiJtagBP/69euNHQe9AXJycmq9h/zvv/9G+/btmzCi+lFVVa2x7uDBg+jfv38TRkNERERERNS4GpTg8977t5OhoWGtK/EbGho2XTANUFvsbdu2bbpAiIiIiIiIXoEGJfjbtm2rtb4+zx6nN4ecnBzMzc2bO4wGe5NjJyIiIiIiqkuDEvwZM2ZIvC8tLUVxcTFatWoFZWVlJvhERERERERETUym7iZV/ffffxKvwsJCZGRk4N1338X333/f2DESERERERERUR0alOBXx8LCAkuXLq1ydZ+IiIiIiIiIXr1GS/CBZ/do37p1qzG7JCIiIiIiIiIpNOge/P3790u8F4vFyMvLQ0xMDOzt7RslMCIiIiIiIiKSXoMS/JEjR0q8F4lE0NXVhaOjI1asWNEYcRERERERERFRPTQowa+oqGjsOIiIiIiIiIjoJTToHvyFCxeiuLi4Svnjx4+xcOHClw6KiIiIiIiIiOqnQQl+WFgYCgsLq5QXFxcjLCzspYMiIiIiIiIiovppUIIvFoshEomqlJ87dw5aWlovHRQRERERERER1U+97sHX1NSESCSCSCTCO++8I5Hkl5eXo7CwEH5+fo0eJBERERERERHVrl4JflRUFMRiMT7++GOEhYVBQ0NDqGvVqhVMTEzQr1+/Rg+SiIiIiIiIiGpXrwR/0qRJAABTU1PY2dlBXl7+lQRFRERERERERPXToMfkDRgwQPj7yZMnePr0qUS9urr6y0VFRACAPhGHUCan0txhvHWyl74v/J2bm4vAwEAcPHgQxcXFMDc3x+bNm9GzZ08AQGFhIebOnYt9+/bh/v37MDU1xfTp0+u8XenHH3/E/PnzkZ2dDQsLCyxbtgwuLi6v9LiIiIiIqGVr0CJ7xcXF8Pf3R5s2baCiogJNTU2JF9GLRCIR9u3bV2N9dnY2RCIR0tPTmywmorr8999/sLe3h7y8PA4ePIi///4bK1askPh/LiAgAAkJCfjuu+9w+fJlzJw5E/7+/ti/f3+N/R4/fhzjx4+Hj48Pzp49i5EjR2LkyJG4ePFiUxwWEREREbVQDUrwZ8+ejcOHD2PdunVQUFDAxo0bERYWBkNDQ2zbtq2xYyR6LZWUlKBbt25VTkwkJydjxIgRMDAwgIqKCrp164a4uLjmC5QabNmyZTAyMsLmzZvRu3dvmJqaYujQoTAzMxPaHD9+HJMmTYKDgwNMTEwwefJk2NjYIC0trcZ+V69eDWdnZ8yePRtWVlYIDw9H9+7dERMT0xSHRUREREQtVIMS/F9++QVr167FBx98ADk5OfTv3x/BwcFYsmQJExlqsV68FWXOnDkwNDSs0u748eOwtrbG7t27cf78eXh7e2PixIn49ddfmypUaiT79+9Hz549MXbsWLRp0wa2traIjY2VaGNnZ4f9+/cjNzcXYrEYSUlJ+OeffzB06NAa+01JScHgwYMlypycnJCSkvJKjoOIiIiI3g4Nugf/wYMH6NChA4Bn99s/ePAAAPDuu+9iypQpjRcdvVZ++uknhIWFITMzE8rKyrC1tcXPP/+Mv//+G/PmzcPZs2dRWlqKbt26YdWqVejevXuNfaWlpeHTTz/F5cuX0aVLF3z55ZdV2hw5cgSzZ8/GuXPnoKWlhUmTJmHRokWQk6t92G7YsAGhoaG4efMmZGT+dw5rxIgR0NbWxqZNm5CVlYWAgACcOHECRUVFsLKyQkREhETSZWJiAh8fH1y9ehX79u3D6NGjsWXLFgDAwYMH8fvvv2P37t04ePCgxP7nzZsn8X7GjBn4/fffsWfPHri6ulYbc0lJCUpKSoT3BQUFAAAFGTFkZcW1Hi81vtLSUgDAtWvXsG7dOsyYMQOzZ8/G6dOnMX36dMjIyGDixIkAgJUrV2LKlClo164d5OTkICMjg3Xr1qFfv35CPy+6ffs2tLW1Jep1dHRw+/btGrepK9b6bkdvH44VkhbHCkmLY4WkxbHycurzuTUowe/QoQOuX7+O9u3bo2PHjvjhhx/Qu3dv/PLLL2jdunVDuqTXXF5eHsaPH4/ly5dj1KhRePToEY4ePQqxWIxHjx5h0qRJiI6OhlgsxooVK+Di4oKrV69CTU2tSl+FhYVwdXXFkCFD8N133+H69euYMWOGRJvc3Fy4uLjAy8sL27Ztw5UrV+Dr6wtFRUWEhobWGuvYsWMxbdo0JCUlYdCgQQCenZRKSEhAfHy8EIOLiwsWL14MBQUFbNu2DW5ubsjIyED79u2FviIjIxESEoIFCxYIZf/++y98fX2xb98+KCsrS/X5PXz4EFZWVjXWR0REICwsrEp5sG0FlJXLpdoHNZ7KcVJeXg4zMzPY2dkhLy8PhoaGGDRoEL766ivo6OgAAPbt24fDhw9j3rx5aNOmDS5duoTPPvsMN2/ehI2NTbX9i8VipKenSyxIevHiRZSUlAj7rq/ExMQGbUdvH44VkhbHCkmLY4WkxbHSMMXFxVK3bVCC7+3tjXPnzmHAgAGYO3cu3NzcEBMTg9LSUqxcubIhXdJrLi8vD2VlZRg9ejSMjY0BAF27dgUAODo6SrTdsGEDWrdujSNHjlR7xXrHjh2oqKjAt99+C0VFRXTu3Bk3b96UmP2xdu1aGBkZISYmBiKRCB07dsStW7cQGBiIkJAQiSvzL9LU1MSwYcOwY8cOIcH/6aefoKOjg4EDBwIAbGxsJJKv8PBw7N27F/v374e/v79Q7ujoiC+++EJ4LxaL4eXlBT8/P/Ts2RPZ2dl1fnY//PADTp48iW+++abGNkFBQQgICBDeFxQUwMjICIvOyqBMXrbOfVDjuhjqBAAwNDSEnZ2dxOr2N27cQEREBFxcXPD48WOMHTsWP/74o0SbsrIyHDt2DEFBQdX2b2BgAENDQ4ltTp48ifbt29d7Jf3S0lIkJiZiyJAhfHQp1YpjhaTFsULS4lghaXGsvJzK2b3SaFCC//nnnwt/Dx48GFeuXMHp06dhbm4Oa2vrhnRJrzkbGxsMGjQIXbt2hZOTE4YOHYoxY8ZAU1MT//77L4KDg5GcnIw7d+6gvLwcxcXFyMnJqbavy5cvw9raGoqKikJZv379qrTp168fRCKRUGZvb4/CwkLcvHlT4ip7dTw9PeHr64u1a9dCQUEBcXFxGDdunHBioLCwEKGhoThw4IBw8uLx48dVYq58FFql6OhoPHr0qMbE7UVJSUnw9vZGbGwsOnfuXGM7BQUFKCgoVCkvqRChrFxUzRb0KlX+8Njb2+Pq1asSP0RZWVkwNjaGvLw8Hj9+jNLSUrRq1Uqijby8PMRicY0/YP369UNycrLEyaPDhw/Dzs6uwT968vLy/MEkqXCskLQ4VkhaHCskLY6VhqnPZ9agBP95T548gbGxsXBVl1omWVlZJCYm4vjx4/j9998RHR2NL7/8EqmpqZgyZQru37+P1atXw9jYGAoKCujXr1+VRemakpubG8RiMQ4cOIBevXrh6NGjWLVqlVA/a9YsJCYmIjIyEubm5lBSUsKYMWOqxKyiIvkM+sOHDyMlJaVKMt6zZ094enpi69atQtmRI0fg5uaGVatWCfdr05vl888/h52dHZYsWQJ3d3ekpaVhw4YN2LBhA4Bna5AMGDAAs2fPhpKSEoyNjXHkyBFs27ZNYjbTxIkT0bZtW0RERAB4ti7DgAEDsGLFCrz//vvYuXMnTp06JfRLRERERNQQDVpFv7y8HOHh4Wjbti1UVVVx7do1AMD8+fPx7bffNmqA9PoQiUSwt7dHWFgYzp49i1atWmHv3r04duwYpk+fDhcXF3Tu3BkKCgq4d+9ejf1YWVnh/PnzePLkiVB24sSJKm1SUlIgFv9vgbljx45BTU0N7dq1qzNWRUVFjB49GnFxcfj+++9haWkpsejfsWPH4OXlhVGjRqFr167Q19eXarr9mjVrcO7cOaSnpyM9PV24X3rXrl1YvHix0C45ORnvv/8+li1bhsmTJ9fZL72eevXqhb179+L7779Hly5dEB4ejqioKHh6egptdu7ciV69esHT0xOdOnXC0qVLsXjxYvj5+QltcnJykJeXJ7y3s7PDjh07sGHDBtjY2OCnn37Cvn370KVLlyY9PiIiIiJqWRp0BX/x4sXYunUrli9fDl9fX6G8S5cuiIqKgo+PT6MFSK+H1NRUHDp0CEOHDkWbNm2QmpqKu3fvwsrKChYWFti+fTt69uyJgoIC4WpmTTw8PPDll1/C19cXQUFByM7ORmRkpESbqVOnIioqCtOmTYO/vz8yMjKwYMECBAQE1Hr//fM8PT3h6uqKS5cu4aOPPpKos7CwwJ49e+Dm5gaRSIT58+ejoqKizj5fvDVAVVUVAGBmZiaceEhKSoKrqytmzJiBDz74ALdv3wYAtGrVClpaWlLFTq8PV1fXGp9+AAD6+vrYvHlzrX0kJydXKRs7dizGjh37suEREREREQkalOBv27YNGzZswKBBgySuUtnY2ODKlSuNFhy9PtTV1fHnn38iKioKBQUFMDY2xooVKzBs2DDo6+tj8uTJ6N69O4yMjLBkyRLMmjWrxr5UVVXxyy+/wM/PD7a2tujUqROWLVuGDz74QGjTtm1bxMfHY/bs2bCxsYGWlhZ8fHwQHBwsdcyOjo7Q0tJCRkYGPDw8JOpWrlyJjz/+GHZ2dtDR0UFgYGC9Fq+ozdatW1FcXIyIiAhhSjYADBgwoNpErzapQYOgra3dKHEREREREVHL1qAEPzc3F+bm5lXKKyoq+GzDFsrKygoJCQnV1tna2uLkyZMSZWPGjJF4//xUewDo27cv0tPTa20zYMAApKWlNTBiQEZGBrdu3aq2zsTEBIcPH5Yo++yzzyTeSzNl38TEpErcW7ZswZYtW+oVKxERERER0ctq0D34nTp1wtGjR6uU//TTT7C1tX3poIiIiIiIiIiofhp0BT8kJASTJk1Cbm4uKioqsGfPHmRkZGDbtm349ddfGztGIgk5OTno1KlTjfV///13nY/RIyIiIiIiamnqleBfu3YNpqamGDFiBH755RcsXLgQKioqCAkJQffu3fHLL79gyJAhrypWIgCAoaFhlen9L9YTERERERG9beqV4FtYWCAvLw9t2rRB//79oaWlhQsXLkBPT+9VxUdUhZycXLVrQBAREREREb3N6nUP/ouLiR08eBBFRUWNGhARERERERER1V+DFtmr9GLCT0RERERERETNo14JvkgkgkgkqlJGRERERERERM2rXvfgi8VieHl5QUFBAQDw5MkT+Pn5QUVFRaLdnj17Gi9CIiIiIiIiIqpTvRL8SZMmSbz/6KOPGjUYIiIiIiIiImqYeiX4mzdvflVxEBEREREREdFLeKlF9oiIiIiIiIjo9cAEn4iIiIiIiKgFYIJPRERERERE1AIwwSciIiIiIiJqAZjgExEREREREbUATPCJiIiIiIiIWoB6PSaPiJpWn4hDKJNTae4wWqTspe8Lf+fm5iIwMBAHDx5EcXExzM3NsXnzZvTs2RMAEBoaip07d+LGjRto1aoVevTogcWLF6NPnz617uPrr7/GV199hdu3b8PGxgbR0dHo3bv3Kz0uIiIiInp78Qo+vbFCQ0PRrVu3Jt2nSCTCvn37mnSf9Gr9999/sLe3h7y8PA4ePIi///4bK1asgKamptDmnXfeQUxMDC5cuIC//voLJiYmGDp0KO7evVtjv7t27UJAQAAWLFiAM2fOwMbGBk5OTrhz505THBYRERERvYWY4FODZGRkYODAgdDT04OioiI6dOiA4OBglJaWCm1KS0uxcOFCmJmZQVFRETY2NkhISGi0GGbNmoVDhw41Wn/1lZ2dDZFIhPT0dInyPXv2oGfPnmjdujVUVFTQrVs3bN++vXmCpDotW7YMRkZG2Lx5M3r37g1TU1MMHToUZmZmQhsPDw8MHjwYHTp0QOfOnbFy5UoUFBTg/PnzNfa7cuVK+Pr6wtvbG506dcL69euhrKyMTZs2NcVhEREREdFbiAk+1VtpaSnk5eUxceJE/P7778jIyEBUVBRiY2OxYMECoV1wcDC++eYbREdH4++//4afnx9GjRqFs2fPNkocqqqq0NbWbpS+GpOWlha+/PJLpKSk4Pz58/D29oa3tzd+++235g6NqrF//3707NkTY8eORZs2bWBra4vY2Nga2z99+hQbNmyAhoYGbGxsamxz+vRpDB48WCiTkZHB4MGDkZKS0ujHQEREREQENHOC7+DggOnTp2POnDnQ0tKCvr4+QkNDAVR/dTQ/Px8ikQjJyckAgOTkZIhEIvz222+wtbWFkpISHB0dcefOHRw8eBBWVlZQV1eHh4cHiouLpY5p2rRpmDlzJjQ1NaGnp4fY2FgUFRXB29sbampqMDc3x8GDByW2u3jxIoYNGwZVVVXo6elhwoQJuHfvnlD/008/oWvXrlBSUoK2tjYGDx6MoqIioX7jxo2wsrKCoqIiOnbsiLVr1wp1T58+hb+/PwwMDKCoqAhjY2NERETUeSweHh748MMPJcpKS0uho6ODbdu2AQASEhLw7rvvonXr1tDW1oarqyuysrKE9pXfw65duzBgwAAoKioiLi4OHTp0gLe3N2xsbGBsbIzhw4fD09MTR48eFbbdvn075s2bBxcXF3To0AFTpkyBi4sLVqxYUWfsGzZsgKGhISoqKiTKR4wYgY8//hhA1Sn6ZWVlmD59unAsgYGBmDRpEkaOHFnn/gDAxMQEUVFREmXdunUTxuSLTE1NAQC2trYQiURwcHAA8GwMjRo1ClZWVjAzM8OMGTNgbW2Nv/76S6o4qGldu3YN69atg4WFBX777TdMmTIF06dPx9atWyXa/frrr1BVVYWioiJWrVqFxMRE6OjoVNvnvXv3UF5eDj09PYlyPT093L59+5UdCxERERG93Zp9kb2tW7ciICAAqampSElJgZeXF+zt7WFhYSF1H6GhoYiJiYGysjLc3d3h7u4OBQUF7NixA4WFhRg1ahSio6MRGBgodUxz5sxBWloadu3ahSlTpmDv3r0YNWoU5s2bh1WrVmHChAnIycmBsrIy8vPz4ejoiE8++QSrVq3C48ePERgYCHd3dxw+fBh5eXkYP348li9fjlGjRuHRo0c4evQoxGIxACAuLg4hISGIiYmBra0tzp49C19fX6ioqGDSpElYs2YN9u/fjx9++AHt27fHjRs3cOPGjTqPw9PTE2PHjkVhYSFUVVUBAL/99huKi4sxatQoAEBRURECAgJgbW2NwsJChISEYNSoUUhPT4eMzP/O/8ydOxcrVqyAra0tFBUVq+wrMzMTCQkJGD16tFBWUlJSpa2SkpJUie7YsWMxbdo0JCUlYdCgQQCABw8eICEhAfHx8dVus2zZMsTFxWHz5s2wsrLC6tWrsW/fPgwcOLDO/TVEWloaevfujT/++AOdO3dGq1atqrQRi8U4fPgwMjIysGzZshr7KikpQUlJifC+oKAAAKAgI4asrLjxgyfhdpKKigr06NEDYWFhAIAuXbrg/PnzWLduHTw8PIT27777Lk6ePIn79+/j22+/hbu7O/766y+0adOmxr7LysokblspLy+HWCyWKGus42jMPqll4lghaXGskLQ4VkhaHCsvpz6fW7Mn+NbW1sK0bgsLC8TExODQoUP1SvAXLVoEe3t7AICPjw+CgoKQlZWFDh06AADGjBmDpKQkqRN8GxsbBAcHAwCCgoKwdOlS6OjowNfXFwAQEhKCdevW4fz58+jbt6+QmC9ZskToY9OmTTAyMsI///yDwsJClJWVYfTo0TA2NgYAdO3aVWi7YMECrFixQkiOTU1N8ffff+Obb77BpEmTkJOTAwsLC7z77rsQiURCH3VxcnKCiooK9u7diwkTJgAAduzYgeHDh0NNTQ0A8MEHH0hss2nTJujq6uLvv/9Gly5dhPKZM2dKJO+V7OzscObMGZSUlGDy5MlYuHChxP5XrlyJ9957D2ZmZjh06BD27NmD8vLyOmPX1NTEsGHDsGPHDiHB/+mnn6Cjo1Njwh4dHY2goCDh5EVMTEyNJwMag66uLgBAW1sb+vr6EnUPHz5E27ZtUVJSAllZWaxduxZDhgypsa+IiAghwXxesG0FlJXr/ryo/irHRuvWraGqqioxVsrKynD16tUax8/IkSPx22+/Ye7cuRgzZkyV+tLSUsjIyCA+Ph4PHjwQys+ePQuRSPRKxmViYmKj90ktE8cKSYtjhaTFsULS4lhpGGlnowOvSYL/PAMDg3qvMv18H3p6elBWVhaS+8qytLS0BvUnKysLbW1tiYS8ctptZZznzp1DUlKScJX8eVlZWRg6dCgGDRqErl27wsnJCUOHDsWYMWOgqamJoqIiZGVlwcfHRziBADxLMDQ0NAAAXl5eGDJkCCwtLeHs7AxXV1cMHTq0zuOQk5ODu7s74uLiMGHCBBQVFeHnn3/Gzp07hTZXr15FSEgIUlNTce/ePWFKfE5OjkSCX/m4sBft2rULjx49wrlz5zB79mxERkZizpw5AIDVq1fD19cXHTt2hEgkgpmZGby9vaVeZMzT0xO+vr5Yu3YtFBQUEBcXh3HjxknMLKj08OFD/PvvvxKPIJOVlUWPHj2qTPNvCmpqakhPT0dhYSEOHTqEgIAAdOjQQZjG/6KgoCAEBAQI7wsKCmBkZIRFZ2VQJi/bRFG/XS6GOgEAHB0dcfPmTbi4uAh1hw8fxjvvvCNR9iIlJSWYmJjU2KZHjx4oKCgQ6isqKvDZZ58Jt6o0ltLSUiQmJmLIkCGQl5dvtH6p5eFYIWlxrJC0OFZIWhwrL6dydq80mj3Bf/ELFolEqKioEJK4ymnsQM1TE57vQyQS1djny8T04j4ACH0WFhbCzc2t2inYBgYGkJWVRWJiIo4fP47ff/8d0dHR+PLLL5GamgplZWUAQGxsbJVnasvKPkvsunfvjuvXr+PgwYP4448/4O7ujsGDB+Onn36q81g8PT0xYMAA3LlzB4mJiVBSUoKzs7NQ7+bmBmNjY8TGxgr3vHfp0gVPnz6V6EdFpfpnsRsZGQEAOnXqhPLyckyePBlffPEFZGVloauri3379uHJkye4f/8+DA0NMXfuXImTL7Vxc3ODWCzGgQMH0KtXLxw9ehSrVq2SatuGkJGRkRhvQMOnEcnIyMDc3BzAs/v4L1++jIiIiBoTfAUFBSgoKFQpL6kQoaxc1KAYqHaV/6a/+OIL2NnZ4auvvoK7uzvS0tKwceNGbNiwAfLy8igqKsLixYsxfPhwGBgY4N69e/j666+Rm5uLcePGCf0MGjQIo0aNgr+/v9DvpEmT0Lt3b/Tu3RtRUVEoKirCJ5988kp+2OTl5fmDSVLhWCFpcayQtDhWSFocKw1Tn8+s2RP8mlROf87Ly4OtrS0AVHkc2euie/fu2L17N0xMTCAnV/1HKhKJYG9vD3t7e4SEhMDY2Bh79+5FQEAADA0Nce3aNXh6eta4D3V1dXz44Yf48MMPMWbMGDg7O+PBgwfQ0tKqNTY7OzsYGRlh165dOHjwIMaOHSsMkPv37yMjIwOxsbHo378/ALzUQnAVFRUoLS1FRUWFcHICABQVFdG2bVuUlpZi9+7dcHd3l6o/RUVFjB49GnFxccjMzISlpSW6d+9ebVsNDQ3o6enh5MmTeO+99wA8u9/5zJkzEgvx1UZXVxd5eXnC+4KCAly/fr3G9pX33Etzy0FFRYXEPfb0+ujVqxf27t2LoKAgLFy4EKampoiKihL+PcrKyuLKlSvYunUr7t27B21tbeGEU+fOnYV+srKyJBbW/PDDD3H37l2EhITg9u3b6NatGxISEqosvEdERERE1Fhe2wRfSUkJffv2xdKlS2Fqaoo7d+4I98W/bj777DPExsZi/PjxwhMBMjMzsXPnTmzcuBGnTp3CoUOHMHToULRp0wapqam4e/curKysAABhYWGYPn06NDQ04OzsjJKSEpw6dQr//fcfAgICsHLlShgYGMDW1hYyMjL48ccfoa+vj9atW0sVn4eHB9avX49//vkHSUlJQrmmpia0tbWxYcMGGBgYICcnB3PnzpWqz7i4OMjLy6Nr165QUFDAqVOnEBQUhA8//FA4gZCamorc3Fx069YNubm5CA0NRUVFhTCFXxqenp5wdXXFpUuX8NFHH9Xadtq0aYiIiIC5uTk6duyI6Oho/Pfff8KMi7o4Ojpiy5YtcHNzQ+vWrRESEiJxouJFbdq0gZKSEhISEtCuXTsoKipCQ0MDERER6NmzJ8zMzFBSUoL4+Hhs374d69atk/q4qWm5urrC1dW12jpFRUXs2bOnzj6ys7OrlPn7+wtX9ImIiIiIXrXXNsEHni345uPjgx49esDS0hLLly+X6t7zpmZoaIhjx44hMDAQQ4cORUlJCYyNjeHs7AwZGRmoq6vjzz//RFRUFAoKCmBsbIwVK1Zg2LBhAIBPPvkEysrK+OqrrzB79myoqKiga9eumDlzJoBn93MvX74cV69ehaysLHr16oX4+Phq70WvjqenJxYvXgxjY2NhMULg2TTynTt3Yvr06ejSpQssLS2xZs2aGqeRP09OTg7Lli3DP//8A7FYDGNjY/j7++Pzzz8X2jx58gTBwcG4du0aVFVV4eLigu3bt0t9YgJ4lnRraWkhIyNDYkXz6gQGBuL27duYOHEiZGVlMXnyZDg5OdWapD8vKCgI169fh6urKzQ0NBAeHl7rFXw5OTmsWbMGCxcuREhICPr374/k5GQUFRVh6tSpuHnzJpSUlNCxY0d89913VR5ZSERERERE1JhE4hdvOiZqISoqKmBlZQV3d3eEh4c3dzj1UlBQAA0NDWFKOFFNSktLER8fDxcXF97TRrXiWCFpcayQtDhWSFocKy+nMjd4+PAh1NXVa237Wl/BJ6qP//u//8Pvv/+OAQMGoKSkBDExMbh+/XqdV/6JiIiIiIhaAunmeLcQOTk5UFVVrfGVk5PT3CHWS1xcXI3H8vziX6+jV/FdyMjIYMuWLejVqxfs7e1x4cIF/PHHH7Cysmpx3z0REREREdGL3qor+IaGhrWuxG9oaNh0wTSC4cOHV3m0XqXXferLq/gujIyMcOzYsSbbHxERERER0evkrUrw5eTkhGeTtwRqampQU1Nr7jAapKm/i5b23RMREREREb3orZqiT0RERERERNRSMcEnIiIiIiIiagGY4BMRERERERG1AEzwiYiIiIiIiFoAJvhERERERERELQATfCIiIiIiIqIWgAk+ERERERERUQvABJ+IiIiIiIioBWCCT0RERERERNQCMMEnIiIiIiIiagGY4BMRERERERG1AEzwiYiIiIiIiFoAueYOgIhq1ifiEMrkVJo7jDdW9tL3mzsEIiIiIqImwyv4L0EkEmHfvn011mdnZ0MkEiE9Pb3JYmosDg4OmDlzpvDexMQEUVFRzRbP62LLli1o3bp1c4dB9RQaGgqRSCTx6tixo1B/+/ZtTJgwAfr6+lBRUUH37t2xe/fuOvv9+uuvYWJiAkVFRfTp0wdpaWmv8jCIiIiIiGrFBJ+kcvLkSUyePLm5w6iTl5dXlUTO2dn5le0vNDQU3bp1q1K+YcMGODg4QF1dHSKRCPn5+a8sBpJO586dkZeXJ7z++usvoW7ixInIyMjA/v37ceHCBYwePRru7u44e/Zsjf3t2rULAQEBWLBgAc6cOQMbGxs4OTnhzp07TXE4RERERERVMMEnqejq6kJZWbm5w6jR06dPhb+dnZ0lErnvv/++yeMpLi6Gs7Mz5s2b1+T7purJyclBX19feOno6Ah1x48fx7Rp09C7d2906NABwcHBaN26NU6fPl1jfytXroSvry+8vb3RqVMnrF+/HsrKyti0aVNTHA4RERERURVvfYL/008/oWvXrlBSUoK2tjYGDx6MoqIinDx5EkOGDIGOjg40NDQwYMAAnDlzpta+0tLSYGtrC0VFRfTs2bPaq39HjhxB7969oaCgAAMDA8ydOxdlZWVSxerg4IBp06Zh5syZ0NTUhJ6eHmJjY1FUVARvb2+oqanB3NwcBw8elNju4sWLGDZsGFRVVaGnp4cJEybg3r17Qn1RUREmTpwIVVVVGBgYYMWKFVX2/eIU/ZycHIwYMQKqqqpQV1eHu7s7/v333zqP4Z9//oFIJMKVK1ckyletWgUzMzMAQHl5OXx8fGBqagolJSVYWlpi9erVEu29vLwwcuRILF68GIaGhrC0tBTqFBQUJBI5TU3NOuMCgOTk5CpX29PT0yESiZCdnV2l/ZYtWxAWFoZz584JswW2bNkCAJg5cybmzp2Lvn37SrVvevWuXr0KQ0NDdOjQAZ6ensjJyRHq7OzssGvXLjx48AAVFRXYuXMnnjx5AgcHh2r7evr0KU6fPo3BgwcLZTIyMhg8eDBSUlJe9aEQEREREVXrrV5kLy8vD+PHj8fy5csxatQoPHr0CEePHoVYLMajR48wadIkREdHQywWY8WKFXBxccHVq1ehpqZWpa/CwkK4urpiyJAh+O6773D9+nXMmDFDok1ubi5cXFzg5eWFbdu24cqVK/D19YWioiJCQ0Olinnr1q2YM2cO0tLSsGvXLkyZMgV79+7FqFGjMG/ePKxatQoTJkxATk4OlJWVkZ+fD0dHR3zyySdYtWoVHj9+jMDAQLi7u+Pw4cMAgNmzZ+PIkSP4+eef0aZNG8ybNw9nzpypduo5AFRUVAjJ/ZEjR1BWVobPPvsMH374IZKTk2uN/5133kHPnj0RFxeH8PBwoTwuLg4eHh5C/+3atcOPP/4IbW1tHD9+HJMnT4aBgQHc3d2FbQ4dOgR1dXUkJiZK7CM5ORlt2rSBpqYmHB0dsWjRImhra0v1+dbHhx9+iIsXLyIhIQF//PEHAEBDQ6NBfZWUlKCkpER4X1BQAABQkBFDVlb88sG+pUpLSwEAPXr0wMaNG/HOO+/g9u3bWLRoEfr374+zZ89CTU0NcXFx8PT0hLa2NuTk5KCsrIwff/wRxsbGQh/Py8vLQ3l5ObS1tSXqdXR0cPny5Wq3edXH2JT7pDcTxwpJi2OFpMWxQtLiWHk59fnc3voEv6ysDKNHj4axsTEAoGvXrgAAR0dHibYbNmxA69atceTIEbi6ulbpa8eOHaioqMC3334LRUVFdO7cGTdv3sSUKVOENmvXroWRkRFiYmKERb5u3bqFwMBAhISEQEam7gkVNjY2CA4OBgAEBQVh6dKl0NHRga+vLwAgJCQE69atw/nz59G3b1/ExMTA1tYWS5YsEfrYtGkTjIyM8M8//8DQ0BDffvstvvvuOwwaNAjAs5MI7dq1qzGGQ4cO4cKFC7h+/TqMjIwAANu2bUPnzp1x8uRJ9OrVq9Zj8PT0RExMjJDg//PPPzh9+jS+++47AIC8vDzCwsKE9qampkhJScEPP/wgkeCrqKhg48aNaNWqlVDm7OyM0aNHw9TUFFlZWZg3bx6GDRuGlJQUyMrK1vn51oeSkhJUVVWFqd8vIyIiQuKYKwXbVkBZufyl+n6bxcfHC38rKyvj5s2bAAB/f39MnjwZISEhGDJkCDZs2IDs7GyEhYVBXV0dqampGDt2LJYsWQITE5Mq/T548ADAs6n9lX8DwLVr15Cfny+x36by4okuoppwrJC0OFZIWhwrJC2OlYYpLi6Wuu1bneDb2Nhg0KBB6Nq1K5ycnDB06FCMGTMGmpqa+PfffxEcHIzk5GTcuXMH5eXlKC4ulpjW+7zLly/D2toaioqKQlm/fv2qtOnXrx9EIpFQZm9vj8LCQty8eRPt27evM2Zra2vhb1lZWWhrawsnJQBAT08PAISFvs6dO4ekpCSoqqpW6SsrKwuPHz/G06dP0adPH6FcS0tLYsp7dcdqZGQkJPcA0KlTJ7Ru3RqXL1+uM8EfN24cZs2ahRMnTqBv376Ii4tD9+7dJVY1//rrr7Fp0ybk5OQIMb44o6Br164SyX1l38/XW1tbw8zMDMnJycIJjNdRUFAQAgIChPcFBQUwMjLCorMyKJNv3BMTb5OLoU411q1atQrKysqwtLREfHw8zp49i86dOwMAPvvsMzg7O+PSpUuYOnVqlW2fPn0KX19fmJmZwcXFRSj/6aefYGlpKVH2qpWWliIxMRFDhgyBvLx8k+2X3jwcKyQtjhWSFscKSYtj5eVUzu6Vxlud4MvKyiIxMRHHjx/H77//jujoaHz55ZdITU3FlClTcP/+faxevRrGxsZQUFBAv379JBZzaw4v/oMQiUQSZZUnDyoqKgA8u3XAzc0Ny5Ytq9KXgYEBMjMzX2G01dPX14ejoyN27NiBvn37YseOHRIzHXbu3IlZs2ZhxYoV6NevH9TU1PDVV18hNTVVoh8VlbqfD9+hQwfo6OggMzOzzgS/cgaFWPy/KfFNNY1IQUEBCgoKVcpLKkQoKxdVswVJo6YfkMLCQly7dg0TJ04UvmMFBQWJ9nJycjX2IS8vjx49euDIkSMYM2YMgGf/5pKSkuDv798sP1zy8vL8wSSpcKyQtDhWSFocKyQtjpWGqc9n9tYvsicSiWBvb4+wsDCcPXsWrVq1wt69e3Hs2DFMnz4dLi4u6Ny5MxQUFCQWpnuRlZUVzp8/jydPnghlJ06cqNImJSVFIoE8duwY1NTUap0S/zK6d++OS5cuwcTEBObm5hIvFRUVmJmZQV5eXiJ5/u+///DPP//U2KeVlRVu3LiBGzduCGV///038vPz0alTJ6ni8vT0xK5du5CSkoJr165JXHk/duwY7OzsMHXqVNja2sLc3BxZWVkNOHrg5s2buH//PgwMDOpsq6urC+DZrRuV0tPTa92mVatWKC/nFPrX3axZs3DkyBFkZ2fj+PHjGDVqFGRlZTF+/Hh07NgR5ubm+PTTT5GWloasrCysWLECiYmJGDlypNDHoEGDEBMTI7wPCAhAbGwstm7disuXL2PKlCnCgpdERERERM3hrU7wU1NTsWTJEpw6dQo5OTnYs2cP7t69CysrK1hYWGD79u24fPkyUlNT4enpCSUlpRr78vDwgEgkgq+vL/7++2/Ex8cjMjJSos3UqVNx48YNTJs2DVeuXMHPP/+MBQsWICAgQKr77xvis88+w4MHDzB+/HicPHkSWVlZ+O233+Dt7Y3y8nKoqqrCx8cHs2fPxuHDh3Hx4kV4eXnVGs/gwYPRtWtXeHp64syZM0hLS8PEiRMxYMAA9OzZU6q4Ro8ejUePHmHKlCkYOHAgDA0NhToLCwucOnUKv/32G/755x/Mnz8fJ0+erLPPwsJCzJ49GydOnEB2djYOHTqEESNGwNzcHE5ONU/VrmRubg4jIyOEhobi6tWrOHDgQLVPFHieiYkJrl+/jvT0dNy7d09YKO/27dtIT08XZkhcuHAB6enpEvdrU9O5efMmxo8fD0tLS7i7u0NbWxsnTpyArq4u5OXlER8fD11dXbi5ucHa2hrbtm3D1q1bJabaZ2VlSZzk+/DDDxEZGYmQkBB069YN6enpSEhIEG6TISIiIiJqam/1FH11dXX8+eefiIqKQkFBAYyNjbFixQoMGzYM+vr6mDx5Mrp37w4jIyMsWbIEs2bNqrEvVVVV/PLLL/Dz84OtrS06deqEZcuW4YMPPhDatG3bFvHx8Zg9ezZsbGygpaUFHx8fYdG8V8HQ0BDHjh1DYGAghg4dipKSEhgbG8PZ2VlI4r/66ithKr+amhq++OILPHz4sMY+RSIRfv75Z0ybNg3vvfceZGRk4OzsjOjoaKnjUlNTg5ubG3744Ycqzw3/9NNPcfbsWXz44YcQiUQYP348pk6dWuXxfy+SlZXF+fPnsXXrVuTn58PQ0BBDhw5FeHh4tdPfXyQvL4/vv/8eU6ZMgbW1NXr16oVFixZh7NixNW7zwQcfYM+ePRg4cCDy8/OxefNmeHl5Yf369RKL5r333nsAINRT09q5c2et9RYWFti9e3etbap7VKK/vz/8/f1fJjQiIiIiokYjEj8/X5yIXgsFBQXQ0NDAvXv3Xskj/qjlKC0tRXx8PFxcXHhPG9WKY4WkxbFC0uJYIWlxrLycytzg4cOHUFdXr7XtWz1Fn4iIiIiIiKilYIL/msjJyYGqqmqNr5oez/c66ty5c43HERcX12xxLVmypMa4hg0b1mxxERERERERNYa3+h7814mhoWGtK7Y/vwjd6y4+Pr7Gx8s15wJkfn5+cHd3r7autgUUiYiIiIiI3gRM8F8TcnJyMDc3b+4wGoWxsXFzh1AtLS0taGlpNXcYRERERERErwSn6BMRERERERG1AEzwiYiIiIiIiFoAJvhERERERERELQATfCIiIiIiIqIWgAk+ERERERERUQvABJ+IiIiIiIioBWCCT0RERERERNQCMMEnIiIiIiIiagGY4BMRERERERG1AEzwiYiIiIiIiFoAJvhERERERERELQATfCIiIiIiIqIWgAk+ERERERERUQsg19wBEFHN+kQcQpmcSnOH8cbJXvq+8HdoaCjCwsIk6i0tLXHlyhVkZ2fD1NS02j5++OEHjB07tto6sViMBQsWIDY2Fvn5+bC3t8e6detgYWHReAdBRERERFRPvIJPLYaXlxdGjhzZ3GHQa6hz587Iy8sTXn/99RcAwMjISKI8Ly8PYWFhUFVVxbBhw2rsb/ny5VizZg3Wr1+P1NRUqKiowMnJCU+ePGmqQyIiIiIiqoIJPjWJ7Oxs+Pj4wNTUFEpKSjAzM8OCBQvw9OlToU1ycjJGjBgBAwMDqKiooFu3boiLi2vGqBtm+PDhaN++PRQVFWFgYIAJEybg1q1bzR3WW01OTg76+vrCS0dHBwAgKysrUa6vr4+9e/fC3d0dqqqq1fYlFosRFRWF4OBgjBgxAtbW1ti2bRtu3bqFffv2NeFRERERERFJYoJPr9zTp09x5coVVFRU4JtvvsGlS5ewatUqrF+/HvPmzRPaHT9+HNbW1ti9ezfOnz8Pb29vTJw4Eb/++mszRl9/AwcOxA8//ICMjAzs3r0bWVlZGDNmTHOH9Va7evUqDA0N0aFDB3h6eiInJ6fadqdPn0Z6ejp8fHxq7Ov69eu4ffs2Bg8eLJRpaGigT58+SElJafTYiYiIiIikxXvwm5GDgwOsra2hqKiIjRs3olWrVvDz80NoaKhwb/DZs2fRrVs3AEB+fj40NTWRlJQEBwcHJCcnY+DAgUhISMDcuXNx5coV9OvXDzt37sTp06cREBCA3NxcuLq6YuPGjVBWVq41ng0bNiA0NBQ3b96EjMz/zv2MGDEC2tra2LRpE7KyshAQEIATJ06gqKgIVlZWiIiIkEh2TExM4OPjg6tXr2Lfvn0YPXo0tmzZAmdnZ6FNhw4dkJGRgXXr1iEyMhIAJJJ9AJgxYwZ+//137NmzB66urlJ/rpGRkVixYgWePn2KcePGISoqCvLy8gCA7du3Y/Xq1cjIyICKigocHR0RFRWFNm3aCNtfunQJgYGB+PPPPyEWi9GtWzds2bIFZmZmAICNGzdixYoVuH79OkxMTDB9+nRMnTpV2P7zzz8X/jY2NsbcuXMxcuRIlJaWCnG8qKSkBCUlJcL7goICAICCjBiysmKpj52eKS0tFf7u0aMHNm7ciHfeeQe3b9/GokWL0L9/f5w9exZqamoS28XGxqJjx47o1auXRB/Pu3nzJgBAS0tLoo2uri5u3bpV43avSuX+mnq/9ObhWCFpcayQtDhWSFocKy+nPp8bE/xmtnXrVgQEBCA1NRUpKSnw8vKCvb19vRbrCg0NRUxMDJSVleHu7g53d3coKChgx44dKCwsxKhRoxAdHY3AwMBa+xk7diymTZuGpKQkDBo0CADw4MEDJCQkID4+HgBQWFgIFxcXLF68GAoKCti2bRvc3NyQkZGB9u3bC31FRkYiJCQECxYsqHF/Dx8+hJaWVq0xPXz4EFZWVtJ+FEhKSoKBgQGSkpKQmZmJDz/8EN26dYOvry+AZ/84wsPDYWlpiTt37iAgIABeXl7C8eXm5uK9996Dg4MDDh8+DHV1dRw7dgxlZWUAgLi4OISEhCAmJga2trY4e/YsfH19oaKigkmTJlWJ58GDB4iLi4OdnV2NyT0AREREVFkIDgCCbSugrFwu9fHTM5XfZyVlZWUhMff398fkyZMREhKCIUOGCG1KSkqwfft2uLu7V9n+eVeuXAEAHDp0SGL85uXlQSQS1brtq5SYmNgs+6U3D8cKSYtjhaTFsULS4lhpmOLiYqnbisRiMS8PNhMHBweUl5fj6NGjQlnv3r3h6OgIPz8/qa/g//HHH0JCvnTpUgQFBSErKwsdOnQAAPj5+SE7OxsJCQl1xjRy5Ehoa2vj22+/BfDsqn5YWBhu3LghcVX/eV26dIGfnx/8/f0BPLuCb2tri71799a4n8zMTPTo0QORkZFC8v2iH374ARMmTMCZM2fQuXPnOmP38vJCcnIysrKyICsrCwBwd3eHjIwMdu7cWe02p06dQq9evfDo0SOoqqpi3rx52LlzJzIyMqpNyM3NzREeHo7x48cLZYsWLUJ8fDyOHz8ulAUGBiImJgbFxcXo27cvfv31V2hra9cYe3VX8I2MjNBp9k6UyXMV/fq6GOpUa32/fv3g6OiIxYsXC2XfffcdPv30U2RnZ0NXV7fGba9du4aOHTsiLS1N+LcJAIMGDYKNjQ1Wrlz50vHXR2lpKRITEzFkyJBaTyIRcayQtDhWSFocKyQtjpWXU1BQAB0dHTx8+BDq6uq1tuUV/GZmbW0t8d7AwAB37txpcB96enpQVlYWkvvKsrS0NKn68vT0hK+vL9auXQsFBQXExcVh3LhxQnJfWFiI0NBQHDhwAHl5eSgrK8Pjx4+r3NPcs2fPGveRm5sLZ2dnjB07tsbkPikpCd7e3oiNjZUqua/UuXNnIbkHnn2eFy5cEN6fPn0aoaGhOHfuHP777z9UVFQAAHJyctCpUyekp6ejf//+1f7HU1RUhKysLPj4+EjEXVZWBg0NDYm2s2fPho+PD/7v//4PYWFhwloCIpGo2rgVFBSgoKBQpbykQoSy8uq3oZrV9sNRWFiIa9euYeLEiRLttm7diuHDh8PQ0LDWvt955x3o6+vjzz//RK9evQA8+083LS0NU6dObbYfLXl5ef5gklQ4VkhaHCskLY4VkhbHSsPU5zNjgt/MXvyyRCIRKioqhIT6+QkWNd178XwfIpGoxj6l4ebmBrFYjAMHDqBXr144evQoVq1aJdTPmjULiYmJiIyMhLm5OZSUlDBmzBiJ1fABQEWl+qvOt27dwsCBA2FnZ4cNGzZU2+bIkSNwc3PDqlWrMHHiRKnirlTbsRcVFcHJyQlOTk6Ii4uDrq4ucnJy4OTkJMSvpKRUY9+FhYUAnt2n3adPH4m6508qAICOjg50dHTwzjvvwMrKCkZGRjhx4gT69etXr+Ohlzdr1iy4ubnB2NgYt27dwoIFCyArKysxCyMzMxN//vlnjdPrO3bsiIiICIwaNQoikQgzZ87EokWLYGFhAVNTU8yfPx+GhoZ8TCMRERERNSsm+K+pyinCeXl5sLW1BQCkp6e/8v0qKipi9OjRiIuLQ2ZmJiwtLdG9e3eh/tixY/Dy8sKoUaMAPEt6s7Ozpeo7NzcXAwcORI8ePbB58+Zqp/wnJyfD1dUVy5Ytw+TJkxvlmCpduXIF9+/fx9KlS2FkZATg2RT951lbW2Pr1q3VLoinp6cHQ0NDXLt2DZ6enlLvt/IEw/NT8Knp3Lx5E+PHj8f9+/ehq6uLd999FydOnJCYhr9p0ya0a9cOQ4cOrbaPjIwMPHz4UHg/Z84cFBUVYfLkycjPz8e7776LhIQEKCoqvvLjISIiIiKqCRP815SSkhL69u2LpUuXwtTUFHfu3EFwcHCT7NvT0xOurq64dOkSPvroI4k6CwsL7NmzB25ubhCJRJg/f75UswNyc3Ph4OAAY2NjREZG4u7du0Kdvr4+gGfT8l1dXTFjxgx88MEHuH37NgCgVatWdS7GJ4327dujVatWiI6Ohp+fHy5evIjw8HCJNv7+/oiOjsa4ceMQFBQEDQ0NnDhxAr1794alpSXCwsIwffp0aGhowNnZGSUlJTh16hT+++8/YbHEkydP4t1334WmpiaysrIwf/58mJmZ8ep9M6lp/YXnLVmyBEuWLKmx/sWlSkQiERYuXIiFCxe+dHxERERERI2FCf5rbNOmTfDx8UGPHj1gaWmJ5cuX13iFsTE5OjpCS0sLGRkZ8PDwkKhbuXIlPv74Y9jZ2UFHRweBgYHCI91qk5iYiMzMTGRmZqJdu3YSdZXJ09atW1FcXIyIiAhEREQI9QMGDEBycvJLH5euri62bNmCefPmYc2aNejevTsiIyMxfPhwoY22tjYOHz6M2bNnY8CAAZCVlUW3bt1gb28PAPjkk0+grKyMr776CrNnz4aKigq6du2KmTNnAni2WvuePXuwYMECFBUVwcDAAM7OzggODq72Hvu6pAYNqnVxPiIiIiIiokpcRZ/oNVRQUAANDQ3cu3ePCT7VqrS0FPHx8XBxceGiNVQrjhWSFscKSYtjhaTFsfJyKnMDaVbRr/65Z0RERERERET0RmGC/xbJycmBqqpqja8XH3X3uqkt9qNHjzZ3eERERERERM2K9+C/RQwNDWtdib+u5383t9pib9u2bdMFQkRERERE9Bpigv8WkZOTg7m5eXOH0WBvcuxERERERESvGqfoExEREREREbUATPCJiIiIiIiIWgAm+EREREREREQtABN8IiIiIiIiohaACT4RERERERFRC8AEn4iIiIiIiKgFYIJPRERERERE1AIwwSciIiIiIiJqAZjgExEREREREbUATPCJiIiIiIiIWgAm+EREREREREQtABN8IiIiIiIiohZArrkDIKKa9Yk4hDI5leYO442RvfR9AEBoaCjCwsIk6iwtLXHlyhUAgIODA44cOSJR/+mnn2L9+vU19i0Wi7FgwQLExsYiPz8f9vb2WLduHSwsLBr5KIiIiIiIGoZX8Om1IRKJsG/fvhrrs7OzIRKJkJ6e3mQx0Zurc+fOyMvLE15//fWXRL2vr69E/fLly2vtb/ny5VizZg3Wr1+P1NRUqKiowMnJCU+ePHmVh0FEREREJDUm+ESvgImJCUQikcRr6dKlzR3WW0VOTg76+vrCS0dHR6JeWVlZol5dXb3GvsRiMaKiohAcHIwRI0bA2toa27Ztw61bt2o9KUVERERE1JSY4BM1oqdPnwp/L1y4UOIK8bRp05oxsrfP1atXYWhoiA4dOsDT0xM5OTkS9XFxcdDR0UGXLl0QFBSE4uLiGvu6fv06bt++jcGDBwtlGhoa6NOnD1JSUl7ZMRARERER1QcTfGpUP/30E7p27QolJSVoa2tj8ODBKCoqwsmTJzFkyBDo6OhAQ0MDAwYMwJkzZ2rtKy0tDba2tlBUVETPnj1x9uzZKm2OHDmC3r17Q0FBAQYGBpg7dy7KysrqjHPDhg0wNDRERUWFRPmIESPw8ccfAwCysrIwYsQI6OnpQVVVFb169cIff/wh0d7ExATh4eGYOHEi1NXVMXnyZKFOTU1N4gqxigrvpW8qffr0wZYtW5CQkIB169bh+vXr6N+/Px49egQA8PDwwHfffYekpCQEBQVh+/bt+Oijj2rs7/bt2wAAPT09iXI9PT2hjoiIiIiouXGRPWo0eXl5GD9+PJYvX45Ro0bh0aNHOHr0KMRiMR49eoRJkyYhOjoaYrEYK1asgIuLC65evQo1NbUqfRUWFsLV1RVDhgzBd999h+vXr2PGjBkSbXJzc+Hi4gIvLy9s27YNV65cga+vLxQVFREaGlprrGPHjsW0adOQlJSEQYMGAQAePHiAhIQExMfHCzG4uLhg8eLFUFBQwLZt2+Dm5oaMjAy0b99e6CsyMhIhISFYsGCBxD6WLl2K8PBwtG/fHh4eHvj8888hJ1f9P7mSkhKUlJQI7wsKCgAACjJiyMqKaz0W+p/S0lIAkLjSbmVlhe7du8Pc3Bzff/89vL294e3tLdR37NgRurq6cHJywpUrV2BmZlal38qTRqWlpcI+AKCiogIikUiirKlV7rs5Y6A3A8cKSYtjhaTFsULS4lh5OfX53JjgU6PJy8tDWVkZRo8eDWNjYwBA165dAQCOjo4SbTds2IDWrVvjyJEjcHV1rdLXjh07UFFRgW+//RaKioro3Lkzbt68iSlTpght1q5dCyMjI8TExEAkEqFjx464desWAgMDERISAhmZmieoaGpqYtiwYdixY4eQ4P/000/Q0dHBwIEDAQA2NjawsbERtgkPD8fevXuxf/9++Pv7C+WOjo744osvJPqfPn06unfvDi0tLRw/fhxBQUHIy8vDypUrq40nIiKiyqrvABBsWwFl5fIaj4MkVZ6cqU6bNm3w+++/V7kKD0BYKG/nzp2wtbWtUl95lX737t3o0KGDUH7lyhWYmprWut+mkpiY2Nwh0BuCY4WkxbFC0uJYIWlxrDRMbbeSvogJPjUaGxsbDBo0CF27doWTkxOGDh2KMWPGQFNTE//++y+Cg4ORnJyMO3fuoLy8HMXFxVXui650+fJlWFtbQ1FRUSjr169flTb9+vWDSCQSyuzt7VFYWIibN29KXGWvjqenJ3x9fbF27VooKCggLi4O48aNE04MFBYWIjQ0FAcOHBBOXjx+/LhKzD179qzSd0BAgPC3tbU1WrVqhU8//RQRERFQUFCo0j4oKEhim4KCAhgZGWHRWRmUycvWehz0PxdDnaotLywsxP3792Fvbw8XF5cq9cePHwcAuLm5wdraukq9WCxGaGgoSktLhe0LCgqQmZmJuXPnVttnUyktLUViYiKGDBkCeXn5ZouDXn8cKyQtjhWSFscKSYtj5eVUzu6VBhN8ajSysrJITEzE8ePH8fvvvyM6OhpffvklUlNTMWXKFNy/fx+rV6+GsbExFBQU0K9fP4lF6Zqam5sbxGIxDhw4gF69euHo0aNYtWqVUD9r1iwkJiYiMjIS5ubmUFJSwpgxY6rELM299X369EFZWRmys7NhaWlZpV5BQaHaxL+kQoSyclGVcqpe5Q/GrFmz4ObmBmNjY9y6dQsLFiyArKwsPvroI+Tk5GDHjh1wcXGBtrY2zp8/j88//xzvvfceevToIfTVsWNHREREYNSoUQCAmTNnIiIiAh07doSpqSnmz58PQ0NDjBkz5rX4oZKXl38t4qDXH8cKSYtjhaTFsULS4lhpmPp8ZkzwqVGJRCLY29vD3t4eISEhMDY2xt69e3Hs2DGsXbtWuNJ548YN3Lt3r8Z+rKyssH37djx58kS4in/ixIkqbXbv3g2xWCxcxT927BjU1NTQrl27OmNVVFTE6NGjERcXh8zMTFhaWqJ79+5C/bFjx+Dl5SUkeIWFhcjOzq7X51EpPT0dMjIyaNOmTYO2p/q5efMmxo8fj/v370NXVxfvvvsuTpw4AV1dXTx58gR//PEHoqKiUFRUBCMjI3zwwQcIDg6W6CMjIwMPHz4U3s+ZMwdFRUWYPHky8vPz8e677yIhIUFilgkRERERUXNigk+NJjU1FYcOHcLQoUPRpk0bpKam4u7du7CysoKFhQW2b9+Onj17oqCgALNnz4aSklKNfXl4eODLL7+Er68vgoKCkJ2djcjISIk2U6dORVRUFKZNmwZ/f39kZGRgwYIFCAgIqPX+++d5enrC1dUVly5dqrKKuoWFBfbs2QM3NzeIRCLMnz+/yqr71UlJSUFqaioGDhwINTU1pKSk4PPPP8dHH30ETU1NqeKil7Nz584a64yMjHDkyJE6+xCLJRc3FIlEWLhwIRYuXPjS8RERERERvQpM8KnRqKur488//0RUVBQKCgpgbGyMFStWYNiwYdDX18fkyZPRvXt3GBkZYcmSJZg1a1aNfamqquKXX36Bn58fbG1t0alTJyxbtgwffPCB0KZt27aIj4/H7NmzYWNjAy0tLfj4+FS5ElsbR0dHaGlpISMjAx4eHhJ1K1euxMcffww7Ozvo6OggMDBQqvtfFBQUsHPnToSGhqKkpASmpqb4/PPPJe6xJyIiIiIiamwi8YuXqYio2RUUFEBDQwP37t2DtrZ2c4dDr7HS0lLEx8fDxcWF97RRrThWSFocKyQtjhWSFsfKy6nMDR4+fAh1dfVa20o3j5mIiIiIiIiIXmtM8KlFysnJgaqqao2vmh7PR0RERERE9KbiPfjUIhkaGiI9Pb3WeiIiIiIiopaECT61SHJycjA3N2/uMIiIiIiIiJoMp+gTERERERERtQBM8ImIiIiIiIhaACb4RERERERERC0AE3wiIiIiIiKiFoAJPhEREREREVELwASfiIiIiIiIqAVggk9ERERERETUAjDBJyIiIiIiImoBmOATERERERERtQBM8ImIiIiIiIhaACb4RERERERERC0AE3wiIiIiIiKiFkCuuQMgopr1iTiEMjmV5g6j2WUvfb+5QyAiIiIieu299lfwHRwcMHPmzOYOgwjJyckQiUTIz89v7lDo/1u6dClEIpHE/xG3b9/GhAkToK+vDxUVFXTv3h27d++us6+vv/4aJiYmUFRURJ8+fZCWlvYKIyciIiIianyvfYK/Z88ehIeHN3cYb7xjx45BTk4O3bp1kyj/888/4ebmBkNDQ4hEIuzbt69Z4nsTbdmyBa1bt65SHhoaio4dO0JFRQWampoYPHgwUlNTmz7AFu7kyZP45ptvYG1tLVE+ceJEZGRkYP/+/bhw4QJGjx4Nd3d3nD17tsa+du3ahYCAACxYsABnzpyBjY0NnJyccOfOnVd9GEREREREjea1T/C1tLSgpqbW3GG8UcRiMcrKyoT3+fn5mDhxIgYNGlSlbVFREWxsbPD11183ZYhN7unTp022r3feeQcxMTG4cOEC/vrrL5iYmGDo0KG4e/duk8XQ0hUWFsLT0xOxsbHQ1NSUqDt+/DimTZuG3r17o0OHDggODkbr1q1x+vTpGvtbuXIlfH194e3tjU6dOmH9+vVQVlbGpk2bXvWhEBERERE1mtc+wX9+ir6JiQkWLVqEiRMnQlVVFcbGxti/fz/u3r2LESNGQFVVFdbW1jh16pSwfeVV1n379sHCwgKKiopwcnLCjRs3pI5h3bp1MDMzQ6tWrWBpaYnt27dL1ItEIqxbtw7Dhg2DkpISOnTogJ9++kmqvu3s7BAYGChRdvfuXcjLy+PPP/8EAGzfvh09e/aEmpoa9PX14eHhIXFlsXLq+MGDB9GjRw8oKCjgr7/+Eur9/Pzg4eGBfv36Vdn/sGHDsGjRIowaNUrqz+N5JSUlCAwMhJGRERQUFGBubo5vv/1WqD9y5Ah69+4NBQUFGBgYYO7cuRInHxwcHDBt2jTMnDkTmpqa0NPTQ2xsLIqKiuDt7Q01NTWYm5vj4MGDEvu9ePEihg0bBlVVVejp6WHChAm4d++eRL/+/v6YOXMmdHR04OTkVOtxZGdnQyQSIT09XSjLz8+HSCRCcnJylfbJycnw9vbGw4cPIRKJIBKJEBoaCgDw8PDA4MGD0aFDB3Tu3BkrV65EQUEBzp8/X49Plmrz2Wef4f3338fgwYOr1NnZ2WHXrl148OABKioqsHPnTjx58gQODg7V9vX06VOcPn1aoi8ZGRkMHjwYKSkpr+oQiIiIiIga3Ru3yN6qVauwZMkSzJ8/H6tWrcKECRNgZ2eHjz/+GF999RUCAwMxceJEXLp0CSKRCABQXFyMxYsXY9u2bWjVqhWmTp2KcePG4dixY3Xub+/evZgxYwaioqIwePBg/Prrr/D29ka7du0wcOBAod38+fOxdOlSrF69Gtu3b8e4ceNw4cIFWFlZ1dq/p6cnli9fLtxLDDybLmxoaIj+/fsDAEpLSxEeHg5LS0vcuXMHAQEB8PLyQnx8vERfc+fORWRkJDp06CBc1dy8eTOuXbuG7777DosWLZL+g5bSxIkTkZKSgjVr1sDGxgbXr18XEu3c3Fy4uLjAy8sL27Ztw5UrV+Dr6wtFRUUhGQaArVu3Ys6cOUhLS8OuXbswZcoU7N27F6NGjcK8efOE7zknJwfKysrIz8+Ho6MjPvnkE6xatQqPHz9GYGAg3N3dcfjwYYl+p0yZItX3XF92dnaIiopCSEgIMjIyAACqqqpV2j19+hQbNmyAhoYGbGxsauyvpKQEJSUlwvuCggIAgIKMGLKy4kaO/s1TWloq/L1r1y6cPn0aKSkpKC0thVgsRkVFhdAmLi4Onp6e0NbWhpycHJSVlfHjjz/C2NhYop9KeXl5KC8vh7a2tkS9jo4OLl++XO02r5PK+F73OKn5cayQtDhWSFocKyQtjpWXU5/P7Y1L8F1cXPDpp58CAEJCQrBu3Tr06tULY8eOBQAEBgaiX79++Pfff6Gvrw/g2QcSExODPn36AHiW+FlZWSEtLQ29e/eudX+RkZHw8vLC1KlTAQABAQE4ceIEIiMjJRL8sWPH4pNPPgEAhIeHIzExEdHR0Vi7dm2t/bu7u2PmzJn466+/hIR+x44dGD9+vJDwf/zxx0L7Dh06YM2aNejVqxcKCwslksqFCxdiyJAhwvurV69i7ty5OHr0KOTkGv+r/ueff/DDDz8gMTFRuPrZoUMHoX7t2rUwMjJCTEwMRCIROnbsiFu3biEwMBAhISGQkXk2gcTGxgbBwcEAgKCgICxduhQ6Ojrw9fUF8L/v+fz58+jbty9iYmJga2uLJUuWCPvatGkTjIyM8M8//+Cdd94BAFhYWGD58uWNftwA0KpVK2hoaEAkEgnj7Hm//vorxo0bh+LiYhgYGCAxMRE6Ojo19hcREYGwsLAq5cG2FVBWLm/U2N9ElSez7t69i1mzZiEsLEw4mXP//n1cv35daLNhwwZkZ2cjLCwM6urqSE1NxdixY7FkyRKYmJhU6fvBgwcAnk3tr/wbAK5du4b8/PwqJ9JeV4mJic0dAr0hOFZIWhwrJC2OFZIWx0rDFBcXS932jUvwn19QS09PDwDQtWvXKmV37twREi85OTn06tVLaNOxY0e0bt0aly9frjPBv3z5MiZPnixRZm9vj9WrV0uUvTj9vV+/fhLTvWuiq6uLoUOHIi4uDv3798f169eRkpKCb775Rmhz+vRphIaG4ty5c/jvv/9QUVEBAMjJyUGnTp2Edj179hT+Li8vh4eHB8LCwoSEt7Glp6dDVlYWAwYMqLb+8uXL6Nevn3CiAnj22RUWFuLmzZto3749AMnvVFZWFtra2jV+pwBw7tw5JCUlVXvFPCsrSzjeHj16vOQRNtzAgQORnp6Oe/fuITY2Fu7u7khNTUWbNm2qbR8UFISAgADhfUFBAYyMjLDorAzK5GWbKuzX1sXQZ7dY/Pzzz3j48CG++OILoa68vBx///03Dh48iIsXLyI+Ph5nz55F586dATybzu/s7IxLly4JJ+qe9/TpU/j6+sLMzAwuLi5C+U8//QRLS0uJstdRaWkpEhMTMWTIEMjLyzd3OPQa41ghaXGskLQ4VkhaHCsvp3J2rzTeuAT/+QFRmThWV1aZBL8JPD09MX36dERHR2PHjh3o2rWrkOAWFRXByckJTk5OiIuLg66uLnJycuDk5FRl4TgVlf89L/3Ro0c4deoUzp49C39/fwDPPhOxWAw5OTn8/vvvcHR0fKm4lZSUXmr7Si/+IxeJRLV+p4WFhXBzc8OyZcuq9GVgYCD8/fznUZfK2QRi8f+mw7/MFCIVFRWYm5vD3Nwcffv2hYWFBb799lsEBQVV215BQQEKCgpVyksqRCgrF1Wzxdulcjw4OTnhwoULEnXe3t7o2LEjAgMDhe9MQUFBYgxVzmCp7gdFXl4ePXr0wJEjRzBmzBgAz8ZaUlIS/P3935gfIXl5+TcmVmpeHCskLY4VkhbHCkmLY6Vh6vOZvfaL7DWGsrIyiYX3MjIykJ+fX+f98QBgZWVV5R7uY8eOSVw5B4ATJ05UeS9N/wAwYsQIPHnyBAkJCdixYwc8PT2FuitXruD+/ftYunQp+vfvj44dO0r16C51dXVcuHAB6enpwsvPzw+WlpZIT08Xbld4GV27dkVFRQWOHDlSbb2VlRVSUlIkkuZjx45BTU0N7dq1a/B+u3fvjkuXLsHExERIoitf9Unqn6erqwvg2f3YleqagdGqVSuUl0s3fb6iokLiHntqGDU1NXTp0kXipaKiAm1tbXTp0gUdO3aEubk5Pv30U6SlpSErKwsrVqxAYmIiRo4cKfQzaNAgxMTECO8DAgIQGxuLrVu34vLly5gyZYqw0CMRERER0ZvijbuC3xDy8vKYNm0a1qxZAzk5Ofj7+6Nv3751Ts8HgNmzZ8Pd3R22trYYPHgwfvnlF+zZswd//PGHRLsff/wRPXv2xLvvvou4uDikpaVJrCZfGxUVFYwcORLz58/H5cuXMX78eKGuffv2aNWqFaKjo+Hn54eLFy8iPDy8zj5lZGTQpUsXibI2bdpAUVFRorywsBCZmZnC++vXryM9PR1aWlrCFPqamJiYYNKkSfj444+FRfb+7//+D3fu3IG7uzumTp2KqKgoTJs2Df7+/sjIyMCCBQsQEBAgXDFviM8++wyxsbEYP3485syZAy0tLWRmZmLnzp3YuHEjZGXrP6VdSUkJffv2xdKlS2Fqaoo7d+4I6wLUxMTEBIWFhTh06BBsbGygrKwMsViMxYsXY/jw4TAwMMC9e/fw9ddfIzc3V1gngl4deXl5xMfHY+7cuXBzc0NhYSHMzc2xdetWian2WVlZEk9d+PDDD3H37l2EhITg9u3b6NatGxISEoTbQ4iIiIiI3gRvRYKvrKyMwMBAeHh4IDc3F/3795c6+R45ciRWr16NyMhIzJgxA6ampti8eXOVR26FhYVh586dmDp1KgwMDPD9999XucpfG09PT7i4uOC9996TSKx1dXWxZcsWzJs3D2vWrEH37t0RGRmJ4cOHS913bU6dOiWxWGDlfeCTJk3Cli1b6tx+3bp1mDdvHqZOnYr79++jffv2mDdvHgCgbdu2iI+Px+zZs2FjYwMtLS34+PjUmTjXxdDQEMeOHUNgYCCGDh2KkpISGBsbw9nZ+aVOHGzatAk+Pj7o0aMHLC0tsXz5cgwdOrTG9nZ2dvDz88OHH36I+/fvY8GCBZg7dy6uXLmCrVu34t69e9DW1kavXr1w9OhR4Z5walwvPsbQwsICu3fvrnWb7OzsKmX+/v7C7SxERERERG8ikfj5+dMt0JYtWzBz5kzk5+e/sn2IRCLs3btXYgow0csoKCiAhoaGcJKAqCalpaWIj4+Hi4sL72mjWnGskLQ4VkhaHCskLY6Vl1OZGzx8+BDq6uq1tn0r7sEnIiIiIiIiaune+gS/c+fOUFVVrfYVFxf30v0vWbKkxv6HDRvWCEfw6hw9erTG2Kt7RN3rLC4ursbj4NR5IiIiIiJqCVr8PfheXl7w8vKqsT4+Pr7Gx6FJu8BWbXc5+Pn5wd3dvdq6xnrM3KvSs2fPOleSf1MMHz68xicHcJoQERERERG1BC0+wa+LsbHxK+1fS0sLWlpar3Qfr4qSkhLMzc2bO4xGoaamBjU1teYOg4iIiIiI6JV566foExEREREREbUETPCJiIiIiIiIWgAm+EREREREREQtABN8IiIiIiIiohaACT4RERERERFRC8AEn4iIiIiIiKgFYIJPRERERERE1AIwwSciIiIiIiJqAZjgExEREREREbUATPCJiIiIiIiIWgAm+EREREREREQtABN8IiIiIiIiohaACT4RERERERFRCyDX3AEQUc36RBxCmZxKc4fRZLKXvl9t+dKlSxEUFIQZM2YgKipKok4sFsPFxQUJCQnYu3cvRo4cWWP/YrEYCxYsQGxsLPLz82Fvb49169bBwsKiEY+CiIiIiKh58Ao+tRheXl61Jnf0Zjp58iS++eYbWFtbV1sfFRUFkUgkVV/Lly/HmjVrsH79eqSmpkJFRQVOTk548uRJY4ZMRERERNQsmOBTk8jOzoaPjw9MTU2hpKQEMzMzLFiwAE+fPhXaJCcnY8SIETAwMICKigq6deuGuLi4Zoy6/qQ5TpJeYWEhPD09ERsbC01NzSr16enpWLFiBTZt2lRnX2KxGFFRUQgODsaIESNgbW2Nbdu24datW9i3b98riJ6IiIiIqGkxwadX7unTp7hy5QoqKirwzTff4NKlS1i1ahXWr1+PefPmCe2OHz8Oa2tr7N69G+fPn4e3tzcmTpyIX3/9tRmjrx9pjpOk99lnn+H999/H4MGDq9QVFxfDw8MDX3/9NfT19evs6/r167h9+7ZEXxoaGujTpw9SUlIaNW4iIiIioubAe/CbkYODA6ytraGoqIiNGzeiVatW8PPzQ2hoKLKzs2FqaoqzZ8+iW7duAID8/HxoamoiKSkJDg4OSE5OxsCBA5GQkIC5c+fiypUr6NevH3bu3InTp08jICAAubm5cHV1xcaNG6GsrFxrPBs2bEBoaChu3rwJGZn/nfsZMWIEtLW1sWnTJmRlZSEgIAAnTpxAUVERrKysEBERIZE0mZiYwMfHB1evXsW+ffswevRobNmyBc7OzkKbDh06ICMjA+vWrUNkZCQAVEmCZ8yYgd9//x179uyBq6ur1J9rZGQkVqxYgadPn2LcuHGIioqCvLw8AGD79u1YvXo1MjIyoKKiAkdHR0RFRaFNmzbC9pcuXUJgYCD+/PNPiMVidOvWDVu2bIGZmRkAYOPGjVixYgWuX78OExMTTJ8+HVOnTgUAODs713mc1SkpKUFJSYnwvqCgAACgICOGrKxY6mN/05WWlgp/79q1C6dPn0ZKSgpKS0shFotRUVEhtJkxYwb69u0LFxcXoaysrEyij+fdvHkTAKClpSXRRldXF7du3apxu9ddZdxvavzUdDhWSFocKyQtjhWSFsfKy6nP58YEv5lt3boVAQEBSE1NRUpKCry8vGBvb1+vRb9CQ0MRExMDZWVluLu7w93dHQoKCtixYwcKCwsxatQoREdHIzAwsNZ+xo4di2nTpiEpKQmDBg0CADx48AAJCQmIj48H8GzKtIuLCxYvXgwFBQVs27YNbm5uyMjIQPv27YW+IiMjERISggULFtS4v4cPH0JLS6vWmB4+fAgrKytpPwokJSXBwMAASUlJyMzMxIcffohu3brB19cXwLN/HOHh4bC0tMSdO3cQEBAALy8v4fhyc3Px3nvvwcHBAYcPH4a6ujqOHTuGsrIyAEBcXBxCQkIQExMDW1tbnD17Fr6+vlBRUcGkSZMafJwREREICwurUh5sWwFl5XKpj/9NV/k93L17F7NmzUJYWBgOHz4MALh//z6uX7+O+Ph4pKWl4cCBA1i5cqWwDQCcPn1aOJnzoitXrgAADh06JPF95OXlQSQSSfTzJkpMTGzuEOgNwbFC0uJYIWlxrJC0OFYapri4WOq2IrFY/PZcHnzNODg4oLy8HEePHhXKevfuDUdHR/j5+Ul9Bf+PP/4QEvLK1cazsrLQoUMHAICfnx+ys7ORkJBQZ0wjR46EtrY2vv32WwDPruqHhYXhxo0bElf1n9elSxf4+fnB398fwLMr+La2tti7d2+N+8nMzESPHj0QGRkpJN8v+uGHHzBhwgScOXMGnTt3rjN2Ly8vJCcnIysrC7KysgAAd3d3yMjIYOfOndVuc+rUKfTq1QuPHj2Cqqoq5s2bh507dyIjI6PaRNHc3Bzh4eEYP368ULZo0SLEx8fj+PHjDTpOoPor+EZGRug0eyfK5N+eVfQvhjoBAH7++WeMHTtW+B4BoLy8HCKRCDIyMvj000+xbt06iTFZXl4OGRkZvPvuu/jjjz+q9H3t2jV07NgRaWlpwr8pABg0aBBsbGywcuXKV3dgr1BpaSkSExMxZMiQGk9uEAEcKyQ9jhWSFscKSYtj5eUUFBRAR0cHDx8+hLq6eq1teQW/mb24MriBgQHu3LnT4D709PSgrKwsJPeVZWlpaVL15enpCV9fX6xduxYKCgqIi4vDuHHjhESqsLAQoaGhOHDgAPLy8lBWVobHjx8jJydHop+ePXvWuI/c3Fw4Oztj7NixNSa9SUlJ8Pb2RmxsrFTJfaXOnTtLJIUGBga4cOGC8P706dMIDQ3FuXPn8N9//6GiogIAkJOTg06dOiE9PR39+/ev9j+eoqIiZGVlwcfHRyLusrIyaGhoNOg4KykoKEBBQaFKeUmFCGXl0q0Q3xJUfu5OTk4S3xsAeHt7o2PHjggMDISOjg6mTJkiUd+1a1esWrUKbm5u1X5/77zzDvT19fHnn3+iV69eAJ79Z5mWloapU6e+8T828vLyb/wxUNPgWCFpcayQtDhWSFocKw1Tn8+MCX4ze/HLEolEqKioEBLq5ydY1HTvxfN9iESiGvuUhpubG8RiMQ4cOIBevXrh6NGjWLVqlVA/a9YsJCYmIjIyEubm5lBSUsKYMWOqrBKvolL9Vedbt25h4MCBsLOzw4YNG6ptc+TIEbi5uWHVqlWYOHGiVHFXqu3Yi4qK4OTkBCcnJ8TFxUFXVxc5OTlwcnIS4ldSUqqx78LCQgBAbGws+vTpI1H3/EkFaY+TaqampoYuXbpIlKmoqEBbW1sor25hvfbt28PU1FR437FjR0RERGDUqFEQiUSYOXMmFi1aBAsLC5iammL+/PkwNDTk4xWJiIiIqEVggv+a0tXVBfDs/mBbW1sAzx4J9qopKipi9OjRiIuLQ2ZmJiwtLdG9e3eh/tixY/Dy8sKoUaMAPEt6s7Ozpeo7NzcXAwcORI8ePbB58+Zqp/wnJyfD1dUVy5Ytw+TJkxvlmCpduXIF9+/fx9KlS2FkZATg2RT951lbW2Pr1q0oLS2tcrJAT08PhoaGuHbtGjw9PWvcjzTHSU0jIyMDDx8+FN7PmTMHRUVFmDx5MvLz8/Huu+8iISEBioqKzRglEREREVHjYIL/mlJSUkLfvn2xdOlSmJqa4s6dOwgODm6SfXt6esLV1RWXLl3CRx99JFFnYWGBPXv2wM3NDSKRCPPnz5dqdkBubi4cHBxgbGyMyMhI3L17V6irvBKblJQEV1dXzJgxAx988AFu374NAGjVqlWdi9RJo3379mjVqhWio6Ph5+eHixcvIjw8XKKNv78/oqOjMW7cOAQFBUFDQwMnTpxA7969YWlpibCwMEyfPh0aGhpwdnZGSUkJTp06hf/++094akFdx0kNk5ycXGt9dcuJvFgmEomwcOFCLFy4sDFDIyIiIiJ6LTDBf41t2rQJPj4+6NGjBywtLbF8+XIMHTr0le/X0dERWlpayMjIgIeHh0TdypUr8fHHH8POzg46OjoIDAwUHulWm8TERGRmZiIzMxPt2rWTqKtMwrZu3Yri4mJEREQgIiJCqB8wYECdyZ00dHV1sWXLFsybNw9r1qxB9+7dERkZieHDhwtttLW1cfjwYcyePRsDBgyArKwsunXrBnt7ewDAJ598AmVlZXz11VeYPXs2VFRU0LVrV8ycOVPq46yP1KBB0NbWbvhBExERERHRW4Or6BO9hgoKCqChoYF79+4xwadalZaWIj4+Hi4uLly0hmrFsULS4lghaXGskLQ4Vl5OZW4gzSr6vDmYiIiIiIiIqAVggv8WycnJgaqqao2vFx9197qpLfajR482d3hERERERETNivfgv0UMDQ1rXYnf0NCw6YJpgNpib9u2bdMFQkRERERE9Bpigv8WkZOTg7m5eXOH0WBvcuxERERERESvGqfoExEREREREbUATPCJiIiIiIiIWgAm+EREREREREQtABN8IiIiIiIiohaACT4RERERERFRC8AEn4iIiIiIiKgFYIJPRERERERE1AIwwSciIiIiIiJqAZjgExEREREREbUATPCJiIiIiIiIWgAm+EREREREREQtABN8IiIiIiIiohZArrkDIKKa9Yk4hDI5leYO45XLXvp+teVLly5FUFAQZsyYgaioKDx48AALFizA77//jpycHOjq6mLkyJEIDw+HhoZGjf2LxWIsWLAAsbGxyM/Ph729PdatWwcLC4tXdUhERERERE2OV/CpxfDy8sLIkSObOwxqJCdPnsQ333wDa2troezWrVu4desWIiMjcfHiRWzZsgUJCQnw8fGpta/ly5djzZo1WL9+PVJTU6GiogInJyc8efLkVR8GEREREVGTYYJPTa6kpATdunWDSCRCenq6UJ6dnQ2RSFTldeLEieYLtp6ys7Ph4+MDU1NTKCkpwczMDAsWLMDTp0+bO7Q3SmFhITw9PREbGwtNTU2hvEuXLti9ezfc3NxgZmYGR0dHLF68GL/88gvKysqq7UssFiMqKgrBwcEYMWIErK2tsW3bNty6dQv79u1roiMiIiIiInr1mODTK/dicjtnzhwYGhrW2P6PP/5AXl6e8OrRo8erDrHRXLlyBRUVFfjmm29w6dIlrFq1CuvXr8e8efOaO7Q3ymeffYb3338fgwcPrrPtw4cPoa6uDjm56u84un79Om7fvi3Rl4aGBvr06YOUlJRGi5mIiIiIqLkxwW9GDg4OmD59OubMmQMtLS3o6+sjNDQUwP+uZj9/hTs/Px8ikQjJyckAgOTkZIhEIvz222+wtbWFkpISHB0dcefOHRw8eBBWVlZQV1eHh4cHiouL64xnw4YNMDQ0REVFhUT5iBEj8PHHHwMAsrKyMGLECOjp6UFVVRW9evXCH3/8IdHexMQE4eHhmDhxItTV1TF58mSh7uDBg/j9998RGRlZYxza2trQ19cXXvLy8nXG/rzIyEgYGBhAW1sbn332GUpLS4W67du3o2fPnlBTU4O+vj48PDxw584die0vXboEV1dXqKurQ01NDf3790dWVpZQv3HjRlhZWUFRUREdO3bE2rVrhTpnZ2ds3rwZQ4cORYcOHTB8+HDMmjULe/bsqdcxvM127tyJM2fOICIios629+7dQ3h4uMQYe9Ht27cBAHp6ehLlenp6Qh0RERERUUvARfaa2datWxEQEIDU1FSkpKTAy8sL9vb29Vr8KzQ0FDExMVBWVoa7uzvc3d2hoKCAHTt2oLCwEKNGjUJ0dDQCAwNr7Wfs2LGYNm0akpKSMGjQIADAgwcPkJCQgPj4eADPpk67uLhg8eLFUFBQwLZt2+Dm5oaMjAy0b99e6CsyMhIhISFYsGCBUPbvv//C19cX+/btg7Kyco1xDB8+HE+ePME777yDOXPmYPjw4VJ/FklJSTAwMEBSUhIyMzPx4Ycfolu3bvD19QUAlJaWIjw8HJaWlrhz5w4CAgLg5eUlHF9ubi7ee+89ODg44PDhw1BXV8exY8eE6d9xcXEICQlBTEwMbG1tcfbsWfj6+kJFRQWTJk2qNqaHDx9CS0ur1rhLSkpQUlIivC8oKAAAKMiIISsrlvr431SVJ2Fu3LiBGTNmID4+HrKysigtLYVYLEZFRYXEiRrg2Wfk4uICKysrfPnll1XqK1V+d6WlpRJtKioqIBKJatzuTVEZ/5t+HPTqcayQtDhWSFocKyQtjpWXU5/PTSQWi1t+9vCacnBwQHl5OY4ePSqU9e7dG46OjvDz84OpqSnOnj2Lbt26AXh2BV9TUxNJSUlwcHBAcnIyBg4ciD/++ENIyCtXHc/KykKHDh0AAH5+fsjOzkZCQkKdMY0cORLa2tr49ttvATy7qh8WFoYbN25ARqb6CR9dunSBn58f/P39ATy7gm9ra4u9e/cKbcRiMVxcXGBvb4/g4GBkZ2dXOb579+5h27ZtsLe3h4yMDHbv3o3ly5dj3759UiX5Xl5eSE5ORlZWFmRlZQEA7u7ukJGRwc6dO6vd5tSpU+jVqxcePXoEVVVVzJs3Dzt37kRGRka1MwfMzc0RHh6O8ePHC2WLFi1CfHw8jh8/XqV9ZmYmevTogcjISOEkQ3VCQ0MRFhZWpXzHjh21ngxpaU6cOIGlS5dKjLXKRFwkEuHHH3+ErKwsHj9+jNDQUCgoKCA4OBitWrWqsc/bt2/Dz88PK1euFP5NAMCXX34JU1NTfPLJJ6/0mIiIiIiIXkZxcTE8PDyEW1Nrwyv4zez5FcIBwMDAoMqU8fr0oaenB2VlZYlERk9PD2lpaVL15enpCV9fX6xduxYKCgqIi4vDuHHjhISrsLAQoaGhOHDgAPLy8lBWVobHjx8jJydHop+ePXtKvI+OjsajR48QFBRU4751dHQQEBAgvO/Vqxdu3bqFr776Suqr+J07dxaSe+DZ53nhwgXh/enTpxEaGopz587hv//+E25HyMnJQadOnZCeno7+/ftXm9wXFRUhKysLPj4+Esl6WVlZtY9oy83NhbOzM8aOHVtrcg8AQUFBEsdeUFAAIyMjLDorgzJ52Vq2bBkuhjoBAPr37w93d3eJOl9fX1haWmLWrFno0qULCgoK8P7770NPTw/79++v8wSIWCxGaGgoSktL4eLiAuDZ55uZmYm5c+cKZW+q0tJSJCYmYsiQIfW+nYXeLhwrJC2OFZIWxwpJi2Pl5VTO7pUGE/xm9uIAF4lEqKioEBLq5ydY1DQ14/k+RCJRjX1Kw83NDWKxGAcOHECvXr1w9OhRrFq1SqifNWsWEhMTERkZCXNzcygpKWHMmDFVFtJTUZF8dvvhw4eRkpICBQUFifKePXvC09MTW7durTaePn36IDExUarYgZo/T+BZgu7k5AQnJyfExcVBV1cXOTk5cHJyEuJXUlKqse/CwkIAQGxsLPr06SNR9/xJBeDZ49wGDhwIOzs7bNiwoc64FRQUqnw2AFBSIUJZuajO7d90ld+blpZWldsZVFVVoaurC1tbWyG5Ly4uRlxcHB4/fozHjx8DAHR1dYXvoWPHjoiIiMCoUaMAADNnzkRERAQ6duwIU1NTzJ8/H4aGhhgzZkyL+ZGRl5dvMcdCrxbHCkmLY4WkxbFC0uJYaZj6fGZM8F9Turq6AIC8vDzY2toCgMSCe6+KoqIiRo8ejbi4OGRmZsLS0hLdu3cX6o8dOwYvLy8hcSosLER2dnad/a5ZswaLFi0S3t+6dQtOTk7YtWtXlWT5eenp6TAwMGj4AT3nypUruH//PpYuXQojIyMAz6boP8/a2hpbt25FaWlplX9Ienp6MDQ0xLVr1+Dp6VnjfnJzczFw4ED06NEDmzdvrvHWBqq/M2fOIDU1FcCz2yWed/36dZiYmAAAMjIy8PDhQ6Fuzpw5KCoqwuTJk5Gfn493330XCQkJUFRUbLLYiYiIiIheNSb4ryklJSX07dsXS5cuhampKe7cuYPg4OAm2benpydcXV1x6dIlfPTRRxJ1FhYW2LNnD9zc3CASiTB//nypZgc8vwAf8OyqLACYmZmhXbt2AJ4tONiqVSvhhMaePXuwadMmbNy4sTEOC+3bt0erVq0QHR0NPz8/XLx4EeHh4RJt/P39ER0djXHjxiEoKAgaGho4ceIEevfuDUtLS4SFhWH69OnQ0NCAs7MzSkpKcOrUKfz3338ICAhAbm4uHBwcYGxsjMjISNy9e1foW19fv1GO421T+dQI4Nm6FdIsG/JiG5FIhIULF2LhwoWNHR4RERER0WuDlxZfY5s2bUJZWRl69OiBmTNnSlwBf5UcHR2hpaWFjIwMeHh4SNStXLkSmpqasLOzg5ubG5ycnCSu8L+s8PBw9OjRA3369MHPP/+MXbt2wdvbu1H61tXVxZYtW/Djjz+iU6dOWLp0aZXH9Wlra+Pw4cMoLCzEgAED0KNHD8TGxgpX8z/55BNs3LgRmzdvRteuXTFgwABs2bIFpqamAIDExERkZmbi0KFDaNeuHQwMDIQXERERERHRq8RV9IleQwUFBdDQ0MC9e/egra3d3OHQa6y0tBTx8fFwcXHhPW1UK44VkhbHCkmLY4WkxbHycipzA2lW0ecVfCIiIiIiIqIWgAn+WyQnJweqqqo1vl581N3rprbYjx492tzhERERERERNSsusvcWMTQ0rHUlfkNDw6YLpgFqi71t27ZNFwgREREREdFriAn+W0ROTq7Ko8XeJG9y7ERERERERK8ap+gTERERERERtQBM8ImIiIiIiIhaACb4RERERERERC0AE3wiIiIiIiKiFoAJPhEREREREVELwASfiIiIiIiIqAVggk9ERERERETUAjDBJyIiIiIiImoBmOATERERERERtQBM8ImIiIiIiIhaACb4RERERERERC0AE3wiIiIiIiKiFkCuuQMgopr1iTiEMjmV5g6j0WQvfb+5QyAiIiIiarF4BZ/q5ODggJkzZzZ3GK8FkUiEffv2NXcYb7x169bB2toa6urqUFdXR79+/XDw4EGh/vbt25gwYQL09fWhoqKC7t27Y/fu3XX2+/XXX8PExASKioro06cP0tLSXuVhEBERERG9Vpjg0xvn/v37aNeuHUQiEfLz84Xy5ORkiESiKq/bt2+/kjiys7MhEomQnp4uUb5nzx707NkTrVu3hoqKCrp164bt27e/khjeVO3atcPSpUtx+vRpnDp1Co6OjhgxYgQuXboEAJg4cSIyMjKwf/9+XLhwAaNHj4a7uzvOnj1bY5+7du1CQEAAFixYgDNnzsDGxgZOTk64c+dOUx0WEREREVGzYoJPr73S0lKJ9z4+PrC2tq6xfUZGBvLy8oRXmzZtXnWIErS0tPDll18iJSUF58+fh7e3N7y9vfHbb781aRyvMzc3N7i4uMDCwgLvvPMOFi9eDFVVVZw4cQIAcPz4cUybNg29e/dGhw4dEBwcjNatW+P06dM19rly5Ur4+vrC29sbnTp1wvr166GsrIxNmzY11WERERERETUrJvhScHBwwPTp0zFnzhxoaWlBX18foaGhAA5w3h4AACWQSURBVKq/ipufnw+RSITk5GQA/7uy/Ntvv8HW1hZKSkpwdHTEnTt3cPDgQVhZWUFdXR0eHh4oLi6WOqZp06Zh5syZ0NTUhJ6eHmJjY1FUVARvb2+oqanB3NxcYtozAFy8eBHDhg2Dqqoq9PT0MGHCBNy7d0+oLyoqwsSJE6GqqgoDAwOsWLFC6s9p3rx56NOnT5VyGxsbLFy4EABw8uRJDBkyBDo6OtDQ0MCAAQNw5swZifYikQjr1q3D8OHDoaKigsWLFwt169atQ35+PmbNmlVjHG3atIG+vr7wkpGRbpibmJggKipKoqxbt27Cd/0iU1NTAICtrS1EIhEcHBwAPPtuRo0aBSsrK5iZmWHGjBmwtrbGX3/9JVUcb5vy8nLs3LkTRUVF/6+9e4+qKf3/AP4+XXVxSimVQki5JUQTv1xzqRmDL8PQ1/0yRg19sxoyRG415CvXZsYtQybDMBffxmhETJMQ0WAat4YhmmHShepUz+8Pqz2OLg7ROY73a62zVvvZz3nOZ2+fjvVpP8/e8PT0BAB069YNu3btwr1791BeXo64uDgUFRVJ5/hJJSUlSEtLg7e3t9Smo6MDb29vpKSk1MVhEBERERGpHW+yp6Jt27YhKCgIqampSElJwfjx49G9e3c4OTmpPMbChQuxbt06GBsbY8SIERgxYgQMDQ2xc+dOFBQUYOjQoVi7di1mz56tckwffvghTpw4gV27duH999/Hvn37MHToUMydOxerVq3CmDFjcP36dRgbGyM3Nxd9+vTB5MmTsWrVKjx8+BCzZ8/GiBEjkJiYCAAIDg5GUlISvvnmG1hbW2Pu3Lk4ffo03NzcnhqPn58fwsPDceXKFbRo0QIAcP78eZw7d05aP52fn49x48Zh7dq1EEJg5cqV8PX1xaVLl1C/fn2lcxUREYGoqCjo6T1K0wsXLmDRokVITU3F1atXq43Dzc0NxcXFaNeuHRYuXIju3burdD6f1YkTJ9C1a1f8+OOPaNu2LQwMDCr1EUIgMTERmZmZ+Pjjj6sdq7i4GMXFxdJ2Xl4eAMBQR0BXV7z44NXk8dkYGRkZ6NGjB4qKimBqaordu3fDyckJCoUCsbGx8PPzg6WlJfT09GBsbIzdu3ejadOmlWZ0AEB2djbKyspgaWmptL9hw4a4ePFile/RFhXHps3HSC8Gc4VUxVwhVTFXSFXMldp5lvPGAl9Frq6uWLBgAQDAyckJ69atw6FDh56pwF+yZIlUbE6aNAkhISG4cuUKmjdvDgAYPnw4Dh8+rHKB36FDB8ybNw8AEBISgoiICDRs2BBTpkwBAISGhiI6Ohrnzp3DG2+8gXXr1qFjx45YtmyZNMaWLVvg4OCA3377DXZ2dti8eTN27NiBvn37Anj0RwR7e3uV4mnbti06dOiAnTt3Yv78+QCA2NhYeHh4oGXLlgCAPn36KL3ns88+g7m5OZKSkvDWW29J7aNHj8aECROk7eLiYowaNQorVqxAkyZNqizwbW1t8cknn8Dd3R3FxcXYtGkTevXqhdTUVHTq1EmlY3gWVlZWAABLS0vY2Ngo7bt//z4aN26M4uJi6OrqYsOGDejXr1+1Y4WHhyMsLKxS+7yO5TA2LnuxgatRfHy89LNCoUBkZCQKCwuRkpKCMWPGYOnSpXBwcMBnn32GrKwshIWFQS6XIzU1Fe+88w6WLVuGZs2aVRr33r17AB5N7a/4GQCuXr2K3Nxcpc/VVgkJCeoOgV4RzBVSFXOFVMVcIVUxV56PqrO8ARb4Kntyzbetre0z37zr8TEaNWoEY2NjqbivaHuWu34/Pp6uri4sLS3Rvn17pfEASHGePXsWhw8fhqmpaaWxrly5gocPH6KkpERpmr2FhQWcnZ1VjsnPzw9btmzB/PnzIYTAF198gaCgIGn/nTt3MG/ePBw5cgQ5OTkoKyvDgwcPcP36daVx3N3dlbZDQkLQunVr/Pvf/672s52dnZVi7datG65cuYJVq1bV+U3u6tevj/T0dBQUFODQoUMICgpC8+bNq51iHhISonSe8vLy4ODggCVndFCqr1tHUb98vywcUGX7jBkzMHDgQJw9exbe3t6Ij4/HmTNn0LZtWwCAv78/Bg4ciPPnz2P69OmV3l9SUoIpU6agRYsW8PX1ldr37NkDZ2dnpTZto1AokJCQgH79+kFfX1/d4ZAGY66QqpgrpCrmCqmKuVI7FbN7VcECX0VPJqJMJkN5ebm0vluIf6ZRVzeF4vExZDJZtWPWJqYnPwOANGZBQQEGDRpU5VRxW1tbXL58WeXPrs6oUaMwe/ZsnD59Gg8fPsSNGzcwcuRIaf+4ceNw9+5drF69Gk2bNoWhoSE8PT1RUlKiNI6JifKz3xMTE5GRkYE9e/YA+Od8N2zYEB999FGVV78BoGvXriqvfdfR0VH6dwSefxqRjo6ONGvBzc0NFy9eRHh4eLUFvqGhIQwNDSu1F5fLUFome64YNFFNX+hCCCgUCumcGxoaKvWvWKpR1Rj6+vro3LkzkpKSMHz4cACP8v7w4cMICAh4Lf4j0dfXfy2Ok2qPuUKqYq6QqpgrpCrmyvN5lnPGAr+WKqZpZ2dno2PHjgBQ6bFpmqLiWeLNmjWTiqXHtWjRAvr6+khNTUWTJk0AAH///Td+++039OzZU6XPsLe3R8+ePREbG4uHDx+iX79+SnexT05OxoYNG6Qrqjdu3FC6yV91vvrqKzx8+FDaPnnyJCZOnIhjx45J6/2rkp6eDltbW5Vit7KyQnZ2trSdl5eHa9euVdu/Ys19WdnTp9CXl5crrbF/3YWEhMDHxwdNmjRBfn4+du7ciSNHjuCHH36Ai4sLWrZsiffeew+RkZGwtLTE119/jYSEBOzfv18ao2/fvhg6dCgCAgIAAEFBQRg3bhzc3d3RtWtXREVFSTedJCIiIiJ6HbDAryUjIyO88cYbiIiIgKOjI3JycqR18ZrG398fGzduxKhRo6QnAly+fBlxcXHYtGkTTE1NMWnSJAQHB8PS0hLW1tb46KOPVL4LfQU/Pz8sWLAAJSUlWLVqldI+JycnbN++He7u7sjLy0NwcDCMjIyeOuaTRXzFHwVat24Nc3NzAEBUVBQcHR3Rtm1bFBUVYdOmTUhMTMTBgwdVirtPnz6IiYnBoEGDYG5ujtDQUOjqVj893traGkZGRjhw4ADs7e1Rr149mJmZITw8HO7u7mjRogWKi4sRHx+P7du3Izo6WqU4Xgc5OTkYO3YssrOzYWZmBldXV/zwww/SfQri4+MxZ84cDBo0CAUFBWjZsiW2bdumNNX+ypUrSn8cGjlyJP7880+Ehobi9u3bcHNzw4EDB6SlKkRERERE2o4F/guwZcsWTJo0CZ07d4azszOWL1+O/v37qzusSuzs7JCcnIzZs2ejf//+KC4uRtOmTTFw4ECpiF+xYoU0lb9+/fqYNWsW7t+//0yfM3z4cAQEBEBXVxdDhgxR2rd582ZMnToVnTp1goODA5YtW1bjI++eRUlJCWbNmoWbN2/C2NgYrq6u+PHHH9G7d2+V3h8SEoJr167hrbfegpmZGRYvXlzjFXw9PT2sWbMGixYtQmhoKLy8vHDkyBEUFhZi+vTp+OOPP2BkZAQXFxfs2LFDaanC627z5s017ndycpKevFCdrKysSm0BAQHSFX0iIiIioteNTDy56JiI1C4vLw9mZmb466+/YGlpqe5wSIMpFArEx8fD19eXa9qoRswVUhVzhVTFXCFVMVdqp6I2uH//PuRyeY19n23uNRERERERERFpJBb4Guj69eswNTWt9vXkI+XqyrFjx2qMS5Np6jklIiIiIiJ6UbgGXwPZ2dnVeCd+Ozu7ugvmMe7u7hr7hICn0dRzSkRERERE9KKwwNdAenp60jPUNYmRkZFGxqUKTT2nRERERERELwqn6BMRERERERFpARb4RERERERERFqABT4RERERERGRFmCBT0RERERERKQFWOATERERERERaQEW+ERERERERERagAU+ERERERERkRZggU9ERERERESkBVjgExEREREREWkBFvhEREREREREWoAFPhEREREREZEWYIFPREREREREpAVY4BMRERERERFpAT11B0BE1fMIP4RSPRN1h/FCZEW8CQCIjo5GdHQ0srKyAABt27ZFaGgofHx8kJWVBUdHxyrf/+WXX+Kdd96pcp8QAgsWLMDGjRuRm5uL7t27Izo6Gk5OTi/lWIiIiIiINBGv4NehXr16ITAwUN1h0HPKysqCTCZDenq6ukN5pdnb2yMiIgJpaWk4deoU+vTpg8GDB+P8+fNwcHBAdna20issLAympqbw8fGpdszly5djzZo1+OSTT5CamgoTExMMGDAARUVFdXhkRERERETqxQK/Du3duxeLFy9WdxivvOTkZOjp6cHNzU2p/ejRoxg0aBDs7Owgk8nw9ddfv9Q4jhw5AplMhtzcXLXG8aoZNGgQfH194eTkhFatWmHp0qUwNTXF8ePHoaurCxsbG6XXvn37MGLECJiamlY5nhACUVFRmDdvHgYPHgxXV1d8/vnnuHXrFs89EREREb1WWODXIQsLC9SvX1/dYbxShBAoLS2VtnNzczF27Fj07du3Ut/CwkJ06NAB69evr8sQNTaOV0FZWRni4uJQWFgIT0/PSvvT0tKQnp6OSZMmVTvGtWvXcPv2bXh7e0ttZmZm8PDwQEpKykuJm4iIiIhIE3ENfh3q1asX3NzcEBUVhWbNmmHy5Mn47bffsHfvXlhaWmLt2rXw9PTE5MmTcejQITRv3hxbtmyBu7s7ACAmJgaBgYGIiYlBcHAwbty4gZ49e2LTpk1wcHBQKYbo6GhERkbixo0bcHR0xLx58zBmzBhpv0wmw4YNG/Dtt9/iyJEjsLW1xfLlyzF8+PCnjt2tWzd4eXnh448/ltr+/PNP2NnZ4dChQ+jRowe2b9+O1atXIzMzEyYmJujTpw+ioqJgbW0N4NFV8d69eyM+Ph7z5s1DRkYGDh48iF69egEApk2bhtGjR0NXV7fS1VkfH58ap3E/jUwmw759+zBkyBCpzdzcHFFRURg/frxS36ysLPTu3RsA0KBBAwDAuHHjEBMT81xxFBcXo7i4WNrOy8sDABjqCOjqiuc4Gs2jUCiknzMyMtCjRw8UFRXB1NQUu3fvhpOTk1IfANi4cSNcXFzQpUuXSvsq/PHHHwAe/QHt8T5WVla4detWte/TFhXHp+3HSbXHXCFVMVdIVcwVUhVzpXae5byxwFejVatWYdmyZZg/fz5WrVqFMWPGoFu3bpg4cSJWrFiB2bNnY+zYsTh//jxkMhkA4MGDB1i6dCk+//xzGBgYYPr06Xj33XeRnJz81M/bt28fZs6ciaioKHh7e2P//v2YMGEC7O3tpWIVAObPn4+IiAisXr0a27dvx7vvvouMjAy0bt26xvH9/PywfPlyRERESPHu2rULdnZ28PLyAvAoORcvXgxnZ2fk5OQgKCgI48ePR3x8vNJYc+bMQWRkJJo3by4V0Fu3bsXVq1exY8cOLFmyRPUT/RI4ODjgq6++wrBhw5CZmQm5XA4jI6PnHi88PBxhYWGV2ud1LIexcVltQtUYj/8bKxQKREZGorCwECkpKRgzZgyWLl2q9Ieq4uJibN++HSNGjKiUH4/79ddfAQCHDh2ChYWF1J6dnQ2ZTFbje7VJQkKCukOgVwRzhVTFXCFVMVdIVcyV5/PgwQOV+7LAVyNfX1+89957AIDQ0FBER0ejS5cu0p3CZ8+eDU9PT9y5cwc2NjYAHhVG69atg4eHBwBg27ZtaN26NU6cOIGuXbvW+HmRkZEYP348pk+fDgAICgrC8ePHERkZqVTgv/POO5g8eTIAYPHixUhISMDatWuxYcOGGscfMWIEAgMD8dNPP0kF/c6dOzFq1Cip4J84caLUv3nz5lizZg26dOmCgoICpTXWixYtQr9+/aTtS5cuYc6cOTh27Bj09NSftrq6ulIxaW1tDXNz81qNFxISgqCgIGk7Ly8PDg4OWHJGB6X6urUaW1P8snBAle0zZszAwIEDcfbsWen3AQB27NgBhUKBpUuXwsrKqtpxXVxcMGfOHLRr107pvgwrV65Ehw4d4Ovr+8KOQRMpFAokJCSgX79+0NfXV3c4pMGYK6Qq5gqpirlCqmKu1E7F7F5VqL9Seo25urpKPzdq1AgA0L59+0ptOTk5UoGvp6eHLl26SH1cXFxgbm6OixcvPrXAv3jxIqZOnarU1r17d6xevVqp7cm10J6enirdOd7Kygr9+/dHbGwsvLy8cO3aNaSkpODTTz+V+qSlpWHhwoU4e/Ys/v77b5SXlwMArl+/jjZt2kj9KpYlAI/WaY8ePRphYWFo1arVU+N4FRkaGsLQ0LBSe3G5DKVlMjVE9OLV9GUuhIBCoVDqs23bNrz99tuws7OrcdxWrVrBxsYGR48elX438vLycOLECUyfPv21+U9EX1//tTlWqh3mCqmKuUKqYq6Qqpgrz+dZzhlvsqdGj/9DVVzhrqqtogh+Ffj5+WHPnj1QKBTYuXMn2rdvL/3RorCwEAMGDIBcLkdsbCxOnjyJffv2AQBKSkqUxjEx+efZ7/n5+Th16hQCAgKgp6cHPT09LFq0CGfPnoWenh4SExNfSOwymQxCKK935zqhFy8kJARHjx5FVlYWMjIyEBISgiNHjsDPz0/qc/nyZRw9elSaSfIkFxcXKXdkMhkCAwOxZMkSfPvtt8jIyMDYsWNhZ2endD8FIiIiIiJtxwL/FVNaWopTp05J25mZmcjNzX3q+ngAaN26daW1+snJyUpXzgHg+PHjlbZVGR8ABg8ejKKiIhw4cAA7d+5UKtp+/fVX3L17FxEREfDy8oKLiwtycnKeOqZcLkdGRgbS09Ol17Rp0+Ds7Iz09HRpuUJtWVlZITs7W9q+dOlSjetdDAwMADyaYUCqy8nJwdixY+Hs7Iy+ffvi5MmT+OGHH5SWZGzZsgX29vbo379/lWNkZmbi/v370vaHH36IDz74AFOnTpWWfBw4cAD16tV76cdDRERERKQpOEX/FaOvr48PPvgAa9asgZ6eHgICAvDGG288dXo+AAQHB2PEiBHo2LEjvL298d1332Hv3r348ccflfrt3r0b7u7u+L//+z/ExsbixIkT2Lx5s0rxmZiYYMiQIZg/fz4uXryIUaNGSfuaNGkCAwMDrF27FtOmTcMvv/yCxYsXP3VMHR0dtGvXTqnN2toa9erVU2ovKCjA5cuXpe1r164hPT0dFhYWaNKkyVM/p0+fPli3bh08PT1RVlaG2bNn1zgdpmnTppDJZNi/fz98fX1hZGQEU1PTWseh7VTJpWXLlmHZsmXV7n9ypoVMJsOiRYuwaNGiWsdHRERERPSqYoH/ijE2Nsbs2bMxevRo3Lx5E15eXioX30OGDMHq1asRGRmJmTNnwtHREVu3bpUeQVchLCwMcXFxmD59OmxtbfHFF19UuspfEz8/P/j6+qJHjx5KBa2VlRViYmIwd+5crFmzBp06dUJkZCTefvttlceuyalTp5RuFlhx07qKx9c9zcqVKzFhwgR4eXnBzs4Oq1evRlpaWrX9GzdujLCwMMyZMwcTJkzA2LFjERMTU+s4Hpca0heWlpbP9B4iIiIiIno9ycSTl8JIY8XExCAwMBC5ubkv7TOqehY81b28vDyYmZnhr7/+YoFPNVIoFIiPj4evry9vWkM1Yq6QqpgrpCrmCqmKuVI7FbXB/fv3IZfLa+zLNfhEREREREREWoAFvhZp27YtTE1Nq3zFxsbWevxly5ZVO76Pj88LOIKX59ixY9XGbmpqqu7wiIiIiIiIao1r8F8h48ePx/jx46vdHx8fX+1j3Ro1aqTSZ9S0YmPatGkYMWJElfuMjIxUGl9d3N3dkZ6eru4wiIiIiIiIXhoW+FqkadOmL3V8CwsLWFhYvNTPeFmMjIzQsmVLdYdBRERERET00nCKPhEREREREZEWYIFPREREREREpAVY4BMRERERERFpARb4RERERERERFqABT4RERERERGRFmCBT0RERERERKQFWOATERERERERaQEW+ERERERERERagAU+ERERERERkRZggU9ERERERESkBVjgExEREREREWkBFvhEREREREREWoAFPhEREREREZEWYIFPREREREREpAVY4BMRERERERFpARb4RERERERERFqABT4RERERERGRFtBTdwBEVJkQAgCQn58PfX19NUdDmkyhUODBgwfIy8tjrlCNmCukKuYKqYq5QqpirtROXl4egH9qhJqwwCfSQHfv3gUAODo6qjkSIiIiIiLSBPn5+TAzM6uxDwt8Ig1kYWEBALh+/fpTf4np9ZaXlwcHBwfcuHEDcrlc3eGQBmOukKqYK6Qq5gqpirlSO0II5Ofnw87O7ql9WeATaSAdnUe3xzAzM+OXIKlELpczV0glzBVSFXOFVMVcIVUxV56fqhf9eJM9IiIiIiIiIi3AAp+IiIiIiIhIC7DAJ9JAhoaGWLBgAQwNDdUdCmk45gqpirlCqmKukKqYK6Qq5krdkQlV7rVPRERERERERBqNV/CJiIiIiIiItAALfCIiIiIiIiItwAKfiIiIiIiISAuwwCciIiIiIiLSAizwiTTQ+vXr0axZM9SrVw8eHh44ceKEukOiOnT06FEMGjQIdnZ2kMlk+Prrr5X2CyEQGhoKW1tbGBkZwdvbG5cuXVLqc+/ePfj5+UEul8Pc3ByTJk1CQUFBHR4F1YXw8HB06dIF9evXh7W1NYYMGYLMzEylPkVFRfD394elpSVMTU0xbNgw3LlzR6nP9evX8eabb8LY2BjW1tYIDg5GaWlpXR4KvWTR0dFwdXWFXC6HXC6Hp6cnvv/+e2k/84SqExERAZlMhsDAQKmN+UIAsHDhQshkMqWXi4uLtJ95oh4s8Ik0zK5duxAUFIQFCxbg9OnT6NChAwYMGICcnBx1h0Z1pLCwEB06dMD69eur3L98+XKsWbMGn3zyCVJTU2FiYoIBAwagqKhI6uPn54fz588jISEB+/fvx9GjRzF16tS6OgSqI0lJSfD398fx48eRkJAAhUKB/v37o7CwUOrzn//8B9999x12796NpKQk3Lp1C//617+k/WVlZXjzzTdRUlKCn3/+Gdu2bUNMTAxCQ0PVcUj0ktjb2yMiIgJpaWk4deoU+vTpg8GDB+P8+fMAmCdUtZMnT+LTTz+Fq6urUjvzhSq0bdsW2dnZ0uunn36S9jFP1EQQkUbp2rWr8Pf3l7bLysqEnZ2dCA8PV2NUpC4AxL59+6Tt8vJyYWNjI1asWCG15ebmCkNDQ/HFF18IIYS4cOGCACBOnjwp9fn++++FTCYTN2/erLPYqe7l5OQIACIpKUkI8Sg39PX1xe7du6U+Fy9eFABESkqKEEKI+Ph4oaOjI27fvi31iY6OFnK5XBQXF9ftAVCdatCggdi0aRPzhKqUn58vnJycREJCgujZs6eYOXOmEILfK/SPBQsWiA4dOlS5j3miPryCT6RBSkpKkJaWBm9vb6lNR0cH3t7eSElJUWNkpCmuXbuG27dvK+WImZkZPDw8pBxJSUmBubk53N3dpT7e3t7Q0dFBampqncdMdef+/fsAAAsLCwBAWloaFAqFUr64uLigSZMmSvnSvn17NGrUSOozYMAA5OXlSVd3SbuUlZUhLi4OhYWF8PT0ZJ5Qlfz9/fHmm28q5QXA7xVSdunSJdjZ2aF58+bw8/PD9evXATBP1ElP3QEQ0T/++usvlJWVKX3RAUCjRo3w66+/qikq0iS3b98GgCpzpGLf7du3YW1trbRfT08PFhYWUh/SPuXl5QgMDET37t3Rrl07AI9ywcDAAObm5kp9n8yXqvKpYh9pj4yMDHh6eqKoqAimpqbYt28f2rRpg/T0dOYJKYmLi8Pp06dx8uTJSvv4vUIVPDw8EBMTA2dnZ2RnZyMsLAxeXl745ZdfmCdqxAKfiIhIC/j7++OXX35RWv9I9DhnZ2ekp6fj/v372LNnD8aNG4ekpCR1h0Ua5saNG5g5cyYSEhJQr149dYdDGszHx0f62dXVFR4eHmjatCm+/PJLGBkZqTGy1xun6BNpkIYNG0JXV7fSHUbv3LkDGxsbNUVFmqQiD2rKERsbm0o3ZSwtLcW9e/eYR1oqICAA+/fvx+HDh2Fvby+129jYoKSkBLm5uUr9n8yXqvKpYh9pDwMDA7Rs2RKdO3dGeHg4OnTogNWrVzNPSElaWhpycnLQqVMn6OnpQU9PD0lJSVizZg309PTQqFEj5gtVydzcHK1atcLly5f5vaJGLPCJNIiBgQE6d+6MQ4cOSW3l5eU4dOgQPD091RgZaQpHR0fY2Ngo5UheXh5SU1OlHPH09ERubi7S0tKkPomJiSgvL4eHh0edx0wvjxACAQEB2LdvHxITE+Ho6Ki0v3PnztDX11fKl8zMTFy/fl0pXzIyMpT+KJSQkAC5XI42bdrUzYGQWpSXl6O4uJh5Qkr69u2LjIwMpKenSy93d3f4+flJPzNfqCoFBQW4cuUKbG1t+b2iTuq+yx8RKYuLixOGhoYiJiZGXLhwQUydOlWYm5sr3WGUtFt+fr44c+aMOHPmjAAg/vvf/4ozZ86I33//XQghREREhDA3NxfffPONOHfunBg8eLBwdHQUDx8+lMYYOHCg6Nixo0hNTRU//fSTcHJyEqNGjVLXIdFL8v777wszMzNx5MgRkZ2dLb0ePHgg9Zk2bZpo0qSJSExMFKdOnRKenp7C09NT2l9aWiratWsn+vfvL9LT08WBAweElZWVCAkJUcch0UsyZ84ckZSUJK5duybOnTsn5syZI2QymTh48KAQgnlCNXv8LvpCMF/okVmzZokjR46Ia9euieTkZOHt7S0aNmwocnJyhBDME3VhgU+kgdauXSuaNGkiDAwMRNeuXcXx48fVHRLVocOHDwsAlV7jxo0TQjx6VN78+fNFo0aNhKGhoejbt6/IzMxUGuPu3bti1KhRwtTUVMjlcjFhwgSRn5+vhqOhl6mqPAEgtm7dKvV5+PChmD59umjQoIEwNjYWQ4cOFdnZ2UrjZGVlCR8fH2FkZCQaNmwoZs2aJRQKRR0fDb1MEydOFE2bNhUGBgbCyspK9O3bVyruhWCeUM2eLPCZLySEECNHjhS2trbCwMBANG7cWIwcOVJcvnxZ2s88UQ+ZEEKoZ+4AEREREREREb0oXINPREREREREpAVY4BMRERERERFpARb4RERERERERFqABT4RERERERGRFmCBT0RERERERKQFWOATERERERERaQEW+ERERERERERagAU+ERERERERkRZggU9ERERERESkBVjgExEREdXC+PHjIZPJKr0uX76s7tCIiOg1o6fuAIiIiIhedQMHDsTWrVuV2qysrNQUjTKFQgF9fX11h0FERHWAV/CJiIiIasnQ0BA2NjZKL11d3Sr7/v777xg0aBAaNGgAExMTtG3bFvHx8dL+8+fP46233oJcLkf9+vXh5eWFK1euAADKy8uxaNEi2Nvbw9DQEG5ubjhw4ID03qysLMhkMuzatQs9e/ZEvXr1EBsbCwDYtGkTWrdujXr16sHFxQUbNmx4iWeEiIjUgVfwiYiIiOqQv78/SkpKcPToUZiYmODChQswNTUFANy8eRM9evRAr169kJiYCLlcjuTkZJSWlgIAVq9ejZUrV+LTTz9Fx44dsWXLFrz99ts4f/48nJycpM+YM2cOVq5ciY4dO0pFfmhoKNatW4eOHTvizJkzmDJlCkxMTDBu3Di1nAciInrxZEIIoe4giIiIiF5V48ePx44dO1CvXj2pzcfHB7t3766yv6urK4YNG4YFCxZU2jd37lzExcUhMzOzymn1jRs3hr+/P+bOnSu1de3aFV26dMH69euRlZUFR0dHREVFYebMmVKfli1bYvHixRg1apTUtmTJEsTHx+Pnn39+ruMmIiLNwyv4RERERLXUu3dvREdHS9smJibV9p0xYwbef/99HDx4EN7e3hg2bBhcXV0BAOnp6fDy8qqyuM/Ly8OtW7fQvXt3pfbu3bvj7NmzSm3u7u7Sz4WFhbhy5QomTZqEKVOmSO2lpaUwMzN7tgMlIiKNxgKfiIiIqJZMTEzQsmVLlfpOnjwZAwYMwP/+9z8cPHgQ4eHhWLlyJT744AMYGRm9sHgqFBQUAAA2btwIDw8PpX7V3SeAiIheTbzJHhEREVEdc3BwwLRp07B3717MmjULGzduBPBo+v6xY8egUCgqvUcul8POzg7JyclK7cnJyWjTpk21n9WoUSPY2dnh6tWraNmypdLL0dHxxR4YERGpFa/gExEREdWhwMBA+Pj4oFWrVvj7779x+PBhtG7dGgAQEBCAtWvX4t1330VISAjMzMxw/PhxdO3aFc7OzggODsaCBQvQokULuLm5YevWrUhPT5fulF+dsLAwzJgxA2ZmZhg4cCCKi4tx6tQp/P333wgKCqqLwyYiojrAAp+IiIioDpWVlcHf3x9//PEH5HI5Bg4ciFWrVgEALC0tkZiYiODgYPTs2RO6urpwc3OT1t3PmDED9+/fx6xZs5CTk4M2bdrg22+/VbqDflUmT54MY2NjrFixAsHBwTAxMUH79u0RGBj4sg+XiIjqEO+iT0RERERERKQFuAafiIiIiIiISAuwwCciIiIiIiLSAizwiYiIiIiIiLQAC3wiIiIiIiIiLcACn4iIiIiIiEgLsMAnIiIiIiIi0gIs8ImIiIiIiIi0AAt8IiIiIiIiIi3AAp+IiIiIiIhIC7DAJyIiIiIiItICLPCJiIiIiIiItMD/Ax8wwBA8MjmzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Light GBM Model - Evaluation with ROC&AUC]"
      ],
      "metadata": {
        "id": "PHDXGioT-m6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step4 Light GBM Model 정해서 학습하고 ROC AUC로 평가하기\n",
        "# n_estimators=500으로, early_stopping_rounds=100 으로 XGBoost와 동일하게 설정\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 모델 정의\n",
        "# verbose is moved to the LGBMClassifier constructor\n",
        "lgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_rounds=100, verbose=10,random_state=42)\n",
        "\n",
        "# 평가셋 정의\n",
        "eval_set = [(X_val, y_val)]\n",
        "\n",
        "# 모델 학습\n",
        "lgbm_clf.fit(\n",
        "    X_tr, y_tr,\n",
        "    eval_set=eval_set,\n",
        "    eval_metric='auc',\n",
        "  )\n",
        "\n",
        "# 테스트셋에 대한 ROC AUC 계산\n",
        "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
        "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxOXZZeJDcop",
        "outputId": "2c00cf41-624f-44f8-cb21-c12566e94125"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
            "[LightGBM] [Info] Number of positive: 1902, number of negative: 46750\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.953648\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.903329\n",
            "[LightGBM] [Debug] init for col-wise cost 0.093764 seconds, init for row-wise cost 0.121402 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100313 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 13745\n",
            "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 248\n",
            "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039094 -> initscore=-3.201908\n",
            "[LightGBM] [Info] Start training from score -3.201908\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
            "Early stopping, best iteration is:\n",
            "[26]\tvalid_0's auc: 0.839514\tvalid_0's binary_logloss: 0.133247\n",
            "ROC AUC: 0.8401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step5 XGBooster의  Hyperparameter Tuning을 위해 최적값 찾기\n",
        "\n",
        "!pip install hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n",
        "                     'max_depth': hp.quniform('max_depth', 100, 160, 1),\n",
        "                     'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n",
        "                     'subsample': hp.uniform('subsample', 0.7, 1),\n",
        "                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n",
        "                    }\n",
        "\n",
        "def objective_func(search_space):\n",
        "    # early_stopping_rounds is moved to the LGBMClassifier constructor\n",
        "    lgbm_clf =  LGBMClassifier(n_estimators=100, num_leaves=int(search_space['num_leaves']),\n",
        "                               max_depth=int(search_space['max_depth']),\n",
        "                               min_child_samples=int(search_space['min_child_samples']),\n",
        "                               subsample=search_space['subsample'],\n",
        "                               learning_rate=search_space['learning_rate'],\n",
        "                               early_stopping_rounds=30 # Specify early_stopping_rounds here\n",
        "                               )\n",
        "    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
        "    roc_auc_list = []\n",
        "\n",
        "    # 3개 k-fold방식 적용\n",
        "    kf = KFold(n_splits=3)\n",
        "    # X_train을 다시 학습과 검증용 데이터로 분리\n",
        "    for tr_index, val_index in kf.split(X_train):\n",
        "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리\n",
        "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
        "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
        "\n",
        "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.\n",
        "        # Removed early_stopping_rounds from fit()\n",
        "        lgbm_clf.fit(X_tr, y_tr, eval_metric=\"auc\",\n",
        "           eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
        "\n",
        "        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음.\n",
        "        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])\n",
        "        roc_auc_list.append(score)\n",
        "\n",
        "    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되,\n",
        "    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환.\n",
        "    return -1*np.mean(roc_auc_list)\n",
        "\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출.\n",
        "best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,\n",
        "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
        "            trials=trials, rstate=np.random.default_rng(seed=30))\n",
        "\n",
        "print('lgbmbest:', best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oLmeJ_4FrZ0",
        "outputId": "ca2820ea-62e6-4cb8-cd94-734f716dd7ca"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 20\n",
            "Early stopping, best iteration is:\n",
            "[31]\ttraining's auc: 0.895219\ttraining's binary_logloss: 0.118745\tvalid_1's auc: 0.835749\tvalid_1's binary_logloss: 0.136972\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.109634 seconds, init for row-wise cost 0.136776 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117366 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's auc: 0.89138\ttraining's binary_logloss: 0.120194\tvalid_1's auc: 0.830716\tvalid_1's binary_logloss: 0.135883\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.101974 seconds, init for row-wise cost 0.112643 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109861 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 21\n",
            "Early stopping, best iteration is:\n",
            "[30]\ttraining's auc: 0.890302\ttraining's binary_logloss: 0.121845\tvalid_1's auc: 0.835779\tvalid_1's binary_logloss: 0.13078\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.093743 seconds, init for row-wise cost 0.120395 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104363 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 36 and depth = 13\n",
            "Early stopping, best iteration is:\n",
            "[24]\ttraining's auc: 0.88255\ttraining's binary_logloss: 0.122328\tvalid_1's auc: 0.835161\tvalid_1's binary_logloss: 0.137151\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.103678 seconds, init for row-wise cost 0.114557 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125459 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "Early stopping, best iteration is:\n",
            "[21]\ttraining's auc: 0.893953\ttraining's binary_logloss: 0.11914\tvalid_1's auc: 0.829057\tvalid_1's binary_logloss: 0.13618\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.089712 seconds, init for row-wise cost 0.117476 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097571 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "Early stopping, best iteration is:\n",
            "[30]\ttraining's auc: 0.908126\ttraining's binary_logloss: 0.115502\tvalid_1's auc: 0.834479\tvalid_1's binary_logloss: 0.131194\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.138022 seconds, init for row-wise cost 0.129738 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 16\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's auc: 0.906639\ttraining's binary_logloss: 0.113813\tvalid_1's auc: 0.835706\tvalid_1's binary_logloss: 0.136692\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.090890 seconds, init for row-wise cost 0.111153 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100032 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 30\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 33\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "Early stopping, best iteration is:\n",
            "[34]\ttraining's auc: 0.889555\ttraining's binary_logloss: 0.123409\tvalid_1's auc: 0.831636\tvalid_1's binary_logloss: 0.136865\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.095054 seconds, init for row-wise cost 0.109978 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103128 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 26\n",
            "Early stopping, best iteration is:\n",
            "[54]\ttraining's auc: 0.901515\ttraining's binary_logloss: 0.118508\tvalid_1's auc: 0.835245\tvalid_1's binary_logloss: 0.131015\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.093802 seconds, init for row-wise cost 0.111241 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101468 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 20\n",
            "Early stopping, best iteration is:\n",
            "[35]\ttraining's auc: 0.888981\ttraining's binary_logloss: 0.122376\tvalid_1's auc: 0.835745\tvalid_1's binary_logloss: 0.13802\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.105150 seconds, init for row-wise cost 0.114021 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112618 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's auc: 0.865673\ttraining's binary_logloss: 0.132381\tvalid_1's auc: 0.827493\tvalid_1's binary_logloss: 0.140039\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.103975 seconds, init for row-wise cost 0.115844 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125813 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "Early stopping, best iteration is:\n",
            "[70]\ttraining's auc: 0.85939\ttraining's binary_logloss: 0.13914\tvalid_1's auc: 0.835253\tvalid_1's binary_logloss: 0.138196\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.124572 seconds, init for row-wise cost 0.119171 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133025 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 8\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's auc: 0.862398\ttraining's binary_logloss: 0.131836\tvalid_1's auc: 0.833291\tvalid_1's binary_logloss: 0.141133\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.090466 seconds, init for row-wise cost 0.125852 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104462 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[72]\ttraining's auc: 0.890116\ttraining's binary_logloss: 0.120786\tvalid_1's auc: 0.832287\tvalid_1's binary_logloss: 0.135738\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.092156 seconds, init for row-wise cost 0.116860 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099829 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[97]\ttraining's auc: 0.898387\ttraining's binary_logloss: 0.119163\tvalid_1's auc: 0.836743\tvalid_1's binary_logloss: 0.130496\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.113353 seconds, init for row-wise cost 0.130323 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140071 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 37 and depth = 18\n",
            "Early stopping, best iteration is:\n",
            "[45]\ttraining's auc: 0.876047\ttraining's binary_logloss: 0.126142\tvalid_1's auc: 0.836795\tvalid_1's binary_logloss: 0.138217\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.094466 seconds, init for row-wise cost 0.115100 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102250 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "Early stopping, best iteration is:\n",
            "[41]\ttraining's auc: 0.897675\ttraining's binary_logloss: 0.117975\tvalid_1's auc: 0.831779\tvalid_1's binary_logloss: 0.135624\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.097804 seconds, init for row-wise cost 0.130121 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 23\n",
            "Early stopping, best iteration is:\n",
            "[56]\ttraining's auc: 0.909107\ttraining's binary_logloss: 0.115603\tvalid_1's auc: 0.836025\tvalid_1's binary_logloss: 0.130585\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.104276 seconds, init for row-wise cost 0.117292 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113009 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "Early stopping, best iteration is:\n",
            "[36]\ttraining's auc: 0.89275\ttraining's binary_logloss: 0.119111\tvalid_1's auc: 0.835937\tvalid_1's binary_logloss: 0.136647\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.114862 seconds, init for row-wise cost 0.144610 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123647 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's auc: 0.885778\ttraining's binary_logloss: 0.122456\tvalid_1's auc: 0.83141\tvalid_1's binary_logloss: 0.135921\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.099468 seconds, init for row-wise cost 0.110299 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107957 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's auc: 0.857385\ttraining's binary_logloss: 0.139595\tvalid_1's auc: 0.835057\tvalid_1's binary_logloss: 0.138489\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.096453 seconds, init for row-wise cost 0.137400 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107401 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[74]\ttraining's auc: 0.875425\ttraining's binary_logloss: 0.125649\tvalid_1's auc: 0.837658\tvalid_1's binary_logloss: 0.13748\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.116957 seconds, init for row-wise cost 0.144101 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125042 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 22\n",
            "Early stopping, best iteration is:\n",
            "[26]\ttraining's auc: 0.902858\ttraining's binary_logloss: 0.116184\tvalid_1's auc: 0.830246\tvalid_1's binary_logloss: 0.136101\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.093714 seconds, init for row-wise cost 0.116808 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102422 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "Early stopping, best iteration is:\n",
            "[23]\ttraining's auc: 0.897194\ttraining's binary_logloss: 0.119629\tvalid_1's auc: 0.835902\tvalid_1's binary_logloss: 0.13119\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.104497 seconds, init for row-wise cost 0.139835 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112685 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 23\n",
            "Early stopping, best iteration is:\n",
            "[22]\ttraining's auc: 0.896262\ttraining's binary_logloss: 0.117787\tvalid_1's auc: 0.835465\tvalid_1's binary_logloss: 0.137079\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.098813 seconds, init for row-wise cost 0.118590 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128690 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "Early stopping, best iteration is:\n",
            "[63]\ttraining's auc: 0.899646\ttraining's binary_logloss: 0.117096\tvalid_1's auc: 0.831433\tvalid_1's binary_logloss: 0.135529\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.103269 seconds, init for row-wise cost 0.131152 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.141798 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "Early stopping, best iteration is:\n",
            "[48]\ttraining's auc: 0.888797\ttraining's binary_logloss: 0.122445\tvalid_1's auc: 0.837543\tvalid_1's binary_logloss: 0.130775\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.109359 seconds, init for row-wise cost 0.112248 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117305 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 35 and depth = 16\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[72]\ttraining's auc: 0.90459\ttraining's binary_logloss: 0.114652\tvalid_1's auc: 0.837471\tvalid_1's binary_logloss: 0.136067\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.090669 seconds, init for row-wise cost 0.109030 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098371 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "Early stopping, best iteration is:\n",
            "[25]\ttraining's auc: 0.899438\ttraining's binary_logloss: 0.11808\tvalid_1's auc: 0.831287\tvalid_1's binary_logloss: 0.13608\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.092781 seconds, init for row-wise cost 0.113725 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101327 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 16\n",
            "Early stopping, best iteration is:\n",
            "[7]\ttraining's auc: 0.867526\ttraining's binary_logloss: 0.137319\tvalid_1's auc: 0.833761\tvalid_1's binary_logloss: 0.138222\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.096058 seconds, init for row-wise cost 0.118989 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129265 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 31\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 20\n",
            "Early stopping, best iteration is:\n",
            "[12]\ttraining's auc: 0.875878\ttraining's binary_logloss: 0.127684\tvalid_1's auc: 0.83395\tvalid_1's binary_logloss: 0.140162\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.092267 seconds, init for row-wise cost 0.112835 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099955 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 23\n",
            "Early stopping, best iteration is:\n",
            "[23]\ttraining's auc: 0.897375\ttraining's binary_logloss: 0.117442\tvalid_1's auc: 0.831159\tvalid_1's binary_logloss: 0.136121\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.940312\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.877981\n",
            "[LightGBM] [Debug] init for col-wise cost 0.099186 seconds, init for row-wise cost 0.116172 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125378 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 13008\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "Early stopping, best iteration is:\n",
            "[24]\ttraining's auc: 0.897862\ttraining's binary_logloss: 0.118964\tvalid_1's auc: 0.83583\tvalid_1's binary_logloss: 0.130982\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.106936 seconds, init for row-wise cost 0.110236 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114752 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 13\n",
            "Early stopping, best iteration is:\n",
            "[16]\ttraining's auc: 0.887085\ttraining's binary_logloss: 0.121176\tvalid_1's auc: 0.837306\tvalid_1's binary_logloss: 0.136826\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.092199 seconds, init for row-wise cost 0.130105 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139976 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "Early stopping, best iteration is:\n",
            "[46]\ttraining's auc: 0.906111\ttraining's binary_logloss: 0.115038\tvalid_1's auc: 0.829996\tvalid_1's binary_logloss: 0.135994\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.097902 seconds, init for row-wise cost 0.114491 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106350 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's auc: 0.914141\ttraining's binary_logloss: 0.113585\tvalid_1's auc: 0.836951\tvalid_1's binary_logloss: 0.130625\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.089629 seconds, init for row-wise cost 0.109099 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097373 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 25\n",
            "Early stopping, best iteration is:\n",
            "[33]\ttraining's auc: 0.894453\ttraining's binary_logloss: 0.119326\tvalid_1's auc: 0.835931\tvalid_1's binary_logloss: 0.137057\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.091923 seconds, init for row-wise cost 0.117157 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099825 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "Early stopping, best iteration is:\n",
            "[8]\ttraining's auc: 0.873006\ttraining's binary_logloss: 0.127874\tvalid_1's auc: 0.827915\tvalid_1's binary_logloss: 0.138361\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.097893 seconds, init for row-wise cost 0.116920 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105800 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "Early stopping, best iteration is:\n",
            "[17]\ttraining's auc: 0.891045\ttraining's binary_logloss: 0.120879\tvalid_1's auc: 0.833737\tvalid_1's binary_logloss: 0.131842\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.106017 seconds, init for row-wise cost 0.136246 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113224 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 39 and depth = 19\n",
            "Early stopping, best iteration is:\n",
            "[15]\ttraining's auc: 0.889988\ttraining's binary_logloss: 0.119523\tvalid_1's auc: 0.833085\tvalid_1's binary_logloss: 0.13735\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938662\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.875068\n",
            "[LightGBM] [Debug] init for col-wise cost 0.104569 seconds, init for row-wise cost 0.135695 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115504 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12827\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "Early stopping, best iteration is:\n",
            "[64]\ttraining's auc: 0.890585\ttraining's binary_logloss: 0.124906\tvalid_1's auc: 0.831592\tvalid_1's binary_logloss: 0.137863\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938643\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874837\n",
            "[LightGBM] [Debug] init for col-wise cost 0.094808 seconds, init for row-wise cost 0.114163 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12946\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[98]\ttraining's auc: 0.900064\ttraining's binary_logloss: 0.120225\tvalid_1's auc: 0.834152\tvalid_1's binary_logloss: 0.131623\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.938735\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.874581\n",
            "[LightGBM] [Debug] init for col-wise cost 0.092372 seconds, init for row-wise cost 0.126630 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104700 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12855\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 32\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 13\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[79]\ttraining's auc: 0.8945\ttraining's binary_logloss: 0.121017\tvalid_1's auc: 0.835051\tvalid_1's binary_logloss: 0.138241\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.940978\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.879422\n",
            "[LightGBM] [Debug] init for col-wise cost 0.097815 seconds, init for row-wise cost 0.115363 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106592 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12895\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[85]\ttraining's auc: 0.904325\ttraining's binary_logloss: 0.115466\tvalid_1's auc: 0.832696\tvalid_1's binary_logloss: 0.135594\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.941896\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.880973\n",
            "[LightGBM] [Debug] init for col-wise cost 0.114609 seconds, init for row-wise cost 0.147897 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159595 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 13046\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[71]\ttraining's auc: 0.895229\ttraining's binary_logloss: 0.119958\tvalid_1's auc: 0.83829\tvalid_1's binary_logloss: 0.13037\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.940714\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.878375\n",
            "[LightGBM] [Debug] init for col-wise cost 0.097441 seconds, init for row-wise cost 0.115413 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105692 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12915\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "Early stopping, best iteration is:\n",
            "[42]\ttraining's auc: 0.880406\ttraining's binary_logloss: 0.123703\tvalid_1's auc: 0.83768\tvalid_1's binary_logloss: 0.136956\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.940978\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.879422\n",
            "[LightGBM] [Debug] init for col-wise cost 0.099848 seconds, init for row-wise cost 0.117386 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109277 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12895\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "Early stopping, best iteration is:\n",
            "[22]\ttraining's auc: 0.903536\ttraining's binary_logloss: 0.116334\tvalid_1's auc: 0.829045\tvalid_1's binary_logloss: 0.13634\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.941896\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.880973\n",
            "[LightGBM] [Debug] init for col-wise cost 0.095554 seconds, init for row-wise cost 0.127518 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106031 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 13046\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 30\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 30\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 19\n",
            "Early stopping, best iteration is:\n",
            "[26]\ttraining's auc: 0.907771\ttraining's binary_logloss: 0.115433\tvalid_1's auc: 0.835926\tvalid_1's binary_logloss: 0.131222\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.940714\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.878375\n",
            "[LightGBM] [Debug] init for col-wise cost 0.102224 seconds, init for row-wise cost 0.117856 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127553 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12915\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 21\n",
            "Early stopping, best iteration is:\n",
            "[18]\ttraining's auc: 0.897709\ttraining's binary_logloss: 0.11834\tvalid_1's auc: 0.834657\tvalid_1's binary_logloss: 0.137588\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.940334\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.878209\n",
            "[LightGBM] [Debug] init for col-wise cost 0.096942 seconds, init for row-wise cost 0.125699 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105996 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12885\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "Early stopping, best iteration is:\n",
            "[25]\ttraining's auc: 0.895377\ttraining's binary_logloss: 0.118275\tvalid_1's auc: 0.830974\tvalid_1's binary_logloss: 0.135881\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.941273\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.879794\n",
            "[LightGBM] [Debug] init for col-wise cost 0.096795 seconds, init for row-wise cost 0.119186 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104512 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 13037\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "Early stopping, best iteration is:\n",
            "[30]\ttraining's auc: 0.899723\ttraining's binary_logloss: 0.11817\tvalid_1's auc: 0.837348\tvalid_1's binary_logloss: 0.130793\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.940714\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.878375\n",
            "[LightGBM] [Debug] init for col-wise cost 0.095877 seconds, init for row-wise cost 0.111261 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103543 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12915\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's auc: 0.900515\ttraining's binary_logloss: 0.115523\tvalid_1's auc: 0.835878\tvalid_1's binary_logloss: 0.136581\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.942226\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.881778\n",
            "[LightGBM] [Debug] init for col-wise cost 0.107668 seconds, init for row-wise cost 0.118909 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116216 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12926\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 30\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 30\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 32\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "Early stopping, best iteration is:\n",
            "[40]\ttraining's auc: 0.918157\ttraining's binary_logloss: 0.110446\tvalid_1's auc: 0.830875\tvalid_1's binary_logloss: 0.136074\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.942808\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.882700\n",
            "[LightGBM] [Debug] init for col-wise cost 0.105549 seconds, init for row-wise cost 0.130120 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113243 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 13094\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 32\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 31\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 29\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "Early stopping, best iteration is:\n",
            "[17]\ttraining's auc: 0.886925\ttraining's binary_logloss: 0.126151\tvalid_1's auc: 0.835208\tvalid_1's binary_logloss: 0.133511\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.942289\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.881360\n",
            "[LightGBM] [Debug] init for col-wise cost 0.098384 seconds, init for row-wise cost 0.121119 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106203 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12950\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 28\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 26\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 18\n",
            "Early stopping, best iteration is:\n",
            "[43]\ttraining's auc: 0.920927\ttraining's binary_logloss: 0.108508\tvalid_1's auc: 0.835286\tvalid_1's binary_logloss: 0.136897\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.941919\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.881197\n",
            "[LightGBM] [Debug] init for col-wise cost 0.117910 seconds, init for row-wise cost 0.157919 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126639 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12922\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
            "[LightGBM] [Info] Start training from score -3.205872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "Early stopping, best iteration is:\n",
            "[43]\ttraining's auc: 0.897475\ttraining's binary_logloss: 0.118376\tvalid_1's auc: 0.831328\tvalid_1's binary_logloss: 0.135789\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.942808\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.882700\n",
            "[LightGBM] [Debug] init for col-wise cost 0.099913 seconds, init for row-wise cost 0.123603 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109630 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 13094\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
            "[LightGBM] [Info] Start training from score -3.186281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "Early stopping, best iteration is:\n",
            "[55]\ttraining's auc: 0.903379\ttraining's binary_logloss: 0.117121\tvalid_1's auc: 0.838443\tvalid_1's binary_logloss: 0.130262\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.942289\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.881360\n",
            "[LightGBM] [Debug] init for col-wise cost 0.096487 seconds, init for row-wise cost 0.118806 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104434 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 12950\n",
            "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
            "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
            "[LightGBM] [Info] Start training from score -3.218465\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 24\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 41 and depth = 14\n",
            "Early stopping, best iteration is:\n",
            "[59]\ttraining's auc: 0.90819\ttraining's binary_logloss: 0.113368\tvalid_1's auc: 0.837301\tvalid_1's binary_logloss: 0.136206\n",
            "100%|██████████| 50/50 [11:43<00:00, 14.07s/trial, best loss: -0.8362219933743916]\n",
            "lgbmbest: {'learning_rate': np.float64(0.04589753644367517), 'max_depth': np.float64(119.0), 'min_child_samples': np.float64(69.0), 'num_leaves': np.float64(33.0), 'subsample': np.float64(0.9332360463629378)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6 최적값으로 Tuning 실시후 재평가\n",
        "# n_estimators=500으로, early_stopping_rounds=100 으로 앞에서 한 설정값과 동일하게 설정\n",
        "\n",
        "lgbm_clf =  LGBMClassifier(n_estimators=500, num_leaves=33,\n",
        "                           max_depth=119,\n",
        "                           min_child_samples=69,\n",
        "                           subsample=round(0.9332360463629378, 5),\n",
        "                           learning_rate=round(0.04589753644367517, 5),\n",
        "                           early_stopping_rounds=100,\n",
        "                           eval_metric=\"auc\"\n",
        "                          )\n",
        "\n",
        "# evaluation metric을 auc로, early stopping은 100 으로 설정하고 학습 수행.\n",
        "# Added X_tr and y_tr as the first two arguments to fit()\n",
        "lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
        "\n",
        "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])\n",
        "print('ROC AUC - LightGBM: {0:.4f}'.format(lgbm_roc_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4iWK5jdqsdS",
        "outputId": "ce595539-1ebb-4b89-a25a-816fd825db39"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Info] Number of positive: 1902, number of negative: 46750\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.942524\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.881986\n",
            "[LightGBM] [Debug] init for col-wise cost 0.085698 seconds, init for row-wise cost 0.173144 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105597 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 13377\n",
            "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 203\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039094 -> initscore=-3.201908\n",
            "[LightGBM] [Info] Start training from score -3.201908\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 25\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 22\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 27\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 23\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 21\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 16\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 15\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 19\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 20\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 12\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 11\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 17\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 13\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 14\n",
            "Early stopping, best iteration is:\n",
            "[116]\ttraining's binary_logloss: 0.113968\tvalid_1's binary_logloss: 0.13285\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "ROC AUC - LightGBM: 0.8430\n"
          ]
        }
      ]
    }
  ]
}